{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Anime GAN TEST 20210126.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jinkim3371/ImagePreprocessingTools/blob/main/Anime_GAN_TEST_20210126.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JF31jMiynq_6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22d119bc-908f-4970-cdfc-b644c60dbd67"
      },
      "source": [
        "!git clone https://github.com/TachibanaYoshino/AnimeGAN"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'AnimeGAN'...\n",
            "remote: Enumerating objects: 1199, done.\u001b[K\n",
            "^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "54aaj28gnvfL",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "69fd6a75-f075-41a4-c04d-192e3f6e758c"
      },
      "source": [
        "import os\n",
        "os.chdir('AnimeGAN')\n",
        "print(os.getcwd())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-9f21d294b7dd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'AnimeGAN'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetcwd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'AnimeGAN'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ss4cpevFl9M"
      },
      "source": [
        "%cd /content/AnimeGAN\r\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "54RvEXDlNzf1",
        "outputId": "d0316fbd-bb40-41f5-985f-39e22f7a2f9b"
      },
      "source": [
        "!wget --no-check-certificate 'https://docs.google.com/uc?export=download&id=1PCKe0KHruxSTMsNmFVo6zSRYfQO0jCF4' -O animeGAN_download_staffs.sh"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-11 13:22:43--  https://docs.google.com/uc?export=download&id=1PCKe0KHruxSTMsNmFVo6zSRYfQO0jCF4\n",
            "Resolving docs.google.com (docs.google.com)... 172.217.15.78, 2607:f8b0:4004:810::200e\n",
            "Connecting to docs.google.com (docs.google.com)|172.217.15.78|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Moved Temporarily\n",
            "Location: https://doc-0o-38-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/9052qd4ut7v2uqcfa62mgf28dsqe99q1/1613049750000/14487424781251610458/*/1PCKe0KHruxSTMsNmFVo6zSRYfQO0jCF4?e=download [following]\n",
            "Warning: wildcards not supported in HTTP.\n",
            "--2021-02-11 13:22:43--  https://doc-0o-38-docs.googleusercontent.com/docs/securesc/ha0ro937gcuc7l7deffksulhg5h7mbp1/9052qd4ut7v2uqcfa62mgf28dsqe99q1/1613049750000/14487424781251610458/*/1PCKe0KHruxSTMsNmFVo6zSRYfQO0jCF4?e=download\n",
            "Resolving doc-0o-38-docs.googleusercontent.com (doc-0o-38-docs.googleusercontent.com)... 172.217.2.97, 2607:f8b0:4004:80a::2001\n",
            "Connecting to doc-0o-38-docs.googleusercontent.com (doc-0o-38-docs.googleusercontent.com)|172.217.2.97|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 979 [text/x-sh]\n",
            "Saving to: ‘animeGAN_download_staffs.sh’\n",
            "\n",
            "animeGAN_download_s 100%[===================>]     979  --.-KB/s    in 0s      \n",
            "\n",
            "2021-02-11 13:22:43 (53.8 MB/s) - ‘animeGAN_download_staffs.sh’ saved [979/979]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsrRG-v7N3yi",
        "outputId": "3ccb204a-f0a2-4e26-a671-508142deda70"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " animeGAN_download_staffs.sh    __pycache__\n",
            " animeGAN_download_sttaffs.sh   README.md\n",
            " AnimeGAN.py\t\t       'Requirements installation tutorial.md'\n",
            " checkpoint\t\t        result\n",
            "'checkpoint'$'\\r'\t        samples\n",
            " dataset\t\t        test.py\n",
            " dataset.zip\t\t        tmp\n",
            " doc\t\t\t        tools\n",
            " logs\t\t\t        vgg19_weight\n",
            " main.py\t\t        video\n",
            " net\t\t\t       'view?usp=sharing'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xVCHvFk6nxaZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ab59591e-8ec0-4e3f-ba7a-fa37f0b59dba"
      },
      "source": [
        "!wget https://github.com/TachibanaYoshino/AnimeGAN/releases/download/Haoyao-style_v1.0/Haoyao-style.zip\r\n",
        "!unzip Haoyao-style.zip -d checkpoint/saved_model"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-11 13:27:49--  https://github.com/TachibanaYoshino/AnimeGAN/releases/download/Haoyao-style_v1.0/Haoyao-style.zip\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-releases.githubusercontent.com/196959890/76720f00-b39b-11e9-8c45-f9eaf126fbe1?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210211%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210211T132749Z&X-Amz-Expires=300&X-Amz-Signature=6c58095e4a900b03716d0e62eb5ea3e3caababd73eb19a00bbd26908a0e10672&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=196959890&response-content-disposition=attachment%3B%20filename%3DHaoyao-style.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-02-11 13:27:49--  https://github-releases.githubusercontent.com/196959890/76720f00-b39b-11e9-8c45-f9eaf126fbe1?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210211%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210211T132749Z&X-Amz-Expires=300&X-Amz-Signature=6c58095e4a900b03716d0e62eb5ea3e3caababd73eb19a00bbd26908a0e10672&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=196959890&response-content-disposition=attachment%3B%20filename%3DHaoyao-style.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.109.154, 185.199.111.154, 185.199.110.154, ...\n",
            "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.109.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 501858599 (479M) [application/octet-stream]\n",
            "Saving to: ‘Haoyao-style.zip’\n",
            "\n",
            "Haoyao-style.zip    100%[===================>] 478.61M  89.8MB/s    in 5.4s    \n",
            "\n",
            "2021-02-11 13:27:54 (88.5 MB/s) - ‘Haoyao-style.zip’ saved [501858599/501858599]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xc1-VwnhR_sL"
      },
      "source": [
        "!wget https://github.com/TachibanaYoshino/AnimeGAN/releases/download/dataset-1/dataset.zip\r\n",
        "!unzip dataset.zip -d ./dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpQDRaJHSSIC",
        "outputId": "f21053e5-74bf-4ebf-fcf9-4440263e204a"
      },
      "source": [
        "%cd /content/AnimeGAN/vgg19_weight/\r\n",
        "!wget https://github.com/TachibanaYoshino/AnimeGAN/releases/download/vgg16%2F19.npy/vgg19.npy"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/AnimeGAN/vgg19_weight\n",
            "--2021-02-11 13:35:55--  https://github.com/TachibanaYoshino/AnimeGAN/releases/download/vgg16%2F19.npy/vgg19.npy\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-releases.githubusercontent.com/196959890/32e69980-6f58-11ea-8561-f3de8bea8505?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210211%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210211T133555Z&X-Amz-Expires=300&X-Amz-Signature=81a4d36de9b6b7115e6551be52feb4ccda87af7df7ac21cc69eda8f28d0abe75&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=196959890&response-content-disposition=attachment%3B%20filename%3Dvgg19.npy&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-02-11 13:35:55--  https://github-releases.githubusercontent.com/196959890/32e69980-6f58-11ea-8561-f3de8bea8505?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210211%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210211T133555Z&X-Amz-Expires=300&X-Amz-Signature=81a4d36de9b6b7115e6551be52feb4ccda87af7df7ac21cc69eda8f28d0abe75&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=196959890&response-content-disposition=attachment%3B%20filename%3Dvgg19.npy&response-content-type=application%2Foctet-stream\n",
            "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.109.154, 185.199.108.154, 185.199.111.154, ...\n",
            "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.109.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 574670860 (548M) [application/octet-stream]\n",
            "Saving to: ‘vgg19.npy.1’\n",
            "\n",
            "vgg19.npy.1         100%[===================>] 548.05M  79.3MB/s    in 8.8s    \n",
            "\n",
            "2021-02-11 13:36:04 (62.6 MB/s) - ‘vgg19.npy.1’ saved [574670860/574670860]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OS6PPhWRT6xY",
        "outputId": "0090d0b3-d663-48c8-d34e-035a9c70dc9d"
      },
      "source": [
        "%cd /content/AnimeGAN/\r\n",
        "%ls\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/AnimeGAN\n",
            " animeGAN_download_staffs.sh    \u001b[0m\u001b[01;34mnet\u001b[0m/\n",
            " animeGAN_download_sttaffs.sh   \u001b[01;34m__pycache__\u001b[0m/\n",
            " AnimeGAN.py                    README.md\n",
            " \u001b[01;34mcheckpoint\u001b[0m/                   'Requirements installation tutorial.md'\n",
            "\u001b[01;34m'checkpoint'$'\\r'\u001b[0m/              \u001b[01;34mresult\u001b[0m/\n",
            " \u001b[01;34mdataset\u001b[0m/                       \u001b[01;34msamples\u001b[0m/\n",
            " dataset.zip                    test.py\n",
            " dataset.zip.1                  \u001b[01;34mtmp\u001b[0m/\n",
            " \u001b[01;34mdoc\u001b[0m/                           \u001b[01;34mtools\u001b[0m/\n",
            " Haoyao-style.zip               \u001b[01;34mvgg19_weight\u001b[0m/\n",
            " \u001b[01;34mlogs\u001b[0m/                          \u001b[01;34mvideo\u001b[0m/\n",
            " main.py                       'view?usp=sharing'\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6CESkBuMoA_k",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e3c29dfe-e19c-4bc1-835f-ef04c112e704"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Thu Feb 11 12:34:29 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   54C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cAbm9tLvIJQX"
      },
      "source": [
        "# ****Download dataset****"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AmJbH1p7Hpzc",
        "outputId": "a45bfa15-bfdd-4a48-99cb-8d18fd2d9bb4"
      },
      "source": [
        "!wget https://github.com/TachibanaYoshino/AnimeGAN/releases/download/dataset-1/dataset.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-02-13 01:52:17--  https://github.com/TachibanaYoshino/AnimeGAN/releases/download/dataset-1/dataset.zip\n",
            "Resolving github.com (github.com)... 192.30.255.112\n",
            "Connecting to github.com (github.com)|192.30.255.112|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://github-releases.githubusercontent.com/196959890/41e63100-6ef1-11ea-915e-040466ad8024?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210213%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210213T015217Z&X-Amz-Expires=300&X-Amz-Signature=a496ff4c2980eb66d6d1363d7fc8d615bc6e7d192f51e5ab62966756dfa3daae&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=196959890&response-content-disposition=attachment%3B%20filename%3Ddataset.zip&response-content-type=application%2Foctet-stream [following]\n",
            "--2021-02-13 01:52:17--  https://github-releases.githubusercontent.com/196959890/41e63100-6ef1-11ea-915e-040466ad8024?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAIWNJYAX4CSVEH53A%2F20210213%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20210213T015217Z&X-Amz-Expires=300&X-Amz-Signature=a496ff4c2980eb66d6d1363d7fc8d615bc6e7d192f51e5ab62966756dfa3daae&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=196959890&response-content-disposition=attachment%3B%20filename%3Ddataset.zip&response-content-type=application%2Foctet-stream\n",
            "Resolving github-releases.githubusercontent.com (github-releases.githubusercontent.com)... 185.199.111.154, 185.199.109.154, 185.199.108.154, ...\n",
            "Connecting to github-releases.githubusercontent.com (github-releases.githubusercontent.com)|185.199.111.154|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 793065091 (756M) [application/octet-stream]\n",
            "Saving to: ‘dataset.zip’\n",
            "\n",
            "dataset.zip          33%[=====>              ] 254.67M  77.8MB/s    eta 7s     ^C\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NuHotnVwIe_X",
        "outputId": "2ae53682-bc72-490d-c8cc-8133de788907"
      },
      "source": [
        "!unzip dataset.zip -d /dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  dataset.zip\n",
            "  End-of-central-directory signature not found.  Either this file is not\n",
            "  a zipfile, or it constitutes one disk of a multi-part archive.  In the\n",
            "  latter case the central directory and zipfile comment will be found on\n",
            "  the last disk(s) of this archive.\n",
            "unzip:  cannot find zipfile directory in one of dataset.zip or\n",
            "        dataset.zip.zip, and cannot find dataset.zip.ZIP, period.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "owjArj3LoPcM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "96eacb16-6922-4675-9dae-da70b6e6db74"
      },
      "source": [
        "!pip install tensorflow==1.15"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 38kB/s \n",
            "\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.3.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.32.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 47.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.19.5)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.10.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.12.4)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 48.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.36.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.12.1)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.15) (53.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.3)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.7.4.3)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=f8b4224f672ae95aac741e88e329bd06e6c26b730d51a7bc8714e1fd247dfbb0\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast, tensorflow-estimator, tensorboard, keras-applications, tensorflow\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3_gqPWj2oSlg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "788483cd-bc99-4e5d-ded0-3483f4b58cc8"
      },
      "source": [
        "!python main.py --phase train --dataset Hayao --epoch 1 --init_epoch 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-02-13 01:52:25.768884: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "Traceback (most recent call last):\n",
            "  File \"main.py\", line 1, in <module>\n",
            "    from AnimeGAN import AnimeGAN\n",
            "  File \"/content/AnimeGAN/AnimeGAN.py\", line 1, in <module>\n",
            "    from tools.ops import *\n",
            "  File \"/content/AnimeGAN/tools/ops.py\", line 1, in <module>\n",
            "    import tensorflow as tf\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py\", line 41, in <module>\n",
            "    from tensorflow.python.tools import module_util as _module_util\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/__init__.py\", line 48, in <module>\n",
            "    from tensorflow.python import keras\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/__init__.py\", line 27, in <module>\n",
            "    from tensorflow.python.keras import models\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/models.py\", line 27, in <module>\n",
            "    from tensorflow.python.keras.engine import sequential\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/sequential.py\", line 28, in <module>\n",
            "    from tensorflow.python.keras import layers as layer_module\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/__init__.py\", line 154, in <module>\n",
            "    from tensorflow.python.keras.layers.merge import Add\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/layers/merge.py\", line 26, in <module>\n",
            "    from tensorflow.python.keras.utils import tf_utils\n",
            "  File \"<frozen importlib._bootstrap>\", line 1008, in _handle_fromlist\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhjxMp3v3FJc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb81b535-7d51-4d5e-d4c5-29af4c386884"
      },
      "source": [
        "!python test.py --checkpoint_dir checkpoint/saved_model --test_dir dataset/test/real2 --style_name B"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-02-13 01:52:27.581858: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
            "Traceback (most recent call last):\n",
            "  File \"test.py\", line 2, in <module>\n",
            "    from tools.utils import *\n",
            "  File \"/content/AnimeGAN/tools/utils.py\", line 1, in <module>\n",
            "    import tensorflow as tf\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/__init__.py\", line 55, in <module>\n",
            "    from ._api.v2 import compat\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/_api/v2/compat/__init__.py\", line 39, in <module>\n",
            "    from . import v1\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/_api/v2/compat/v1/__init__.py\", line 34, in <module>\n",
            "    from . import compat\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/_api/v2/compat/v1/compat/__init__.py\", line 40, in <module>\n",
            "    from . import v2\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/_api/v2/compat/v1/compat/v2/__init__.py\", line 32, in <module>\n",
            "    from tensorflow._api.v2.compat.v2 import __internal__\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/_api/v2/compat/v2/__init__.py\", line 37, in <module>\n",
            "    from . import compat\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/_api/v2/compat/v2/compat/__init__.py\", line 40, in <module>\n",
            "    from . import v2\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/_api/v2/compat/v2/compat/v2/__init__.py\", line 62, in <module>\n",
            "    from tensorflow._api.v2.compat.v2 import raw_ops\n",
            "  File \"/usr/local/lib/python3.6/dist-packages/tensorflow/_api/v2/compat/v2/raw_ops/__init__.py\", line 978, in <module>\n",
            "    from tensorflow.python.ops.gen_ragged_conversion_ops import RaggedTensorFromVariant\n",
            "  File \"<frozen importlib._bootstrap>\", line 997, in _handle_fromlist\n",
            "KeyboardInterrupt\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xvqKBTdevf7f",
        "outputId": "829b1f3c-20b3-428d-c2c6-335dd3ccc881"
      },
      "source": [
        "!cd content\r\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/bin/bash: line 0: cd: content: No such file or directory\n",
            " AnimeGAN.py   main.py\t\t\t\t        result\n",
            " checkpoint    net\t\t\t\t        test.py\n",
            " dataset       __pycache__\t\t\t        tools\n",
            " dataset.zip   README.md\t\t\t        vgg19_weight\n",
            " doc\t      'Requirements installation tutorial.md'   video\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pu_R9kqG4Ml8"
      },
      "source": [
        "# **Mounting Google Drive (0000@gmail)**\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9golmXYRxt9V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "988e6a12-dc3b-4380-e5c7-6e84506bb47c"
      },
      "source": [
        "from google.colab import drive\r\n",
        "drive.mount('/content/gdrive/')\r\n",
        "\r\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DD_vNkR14hWM",
        "outputId": "baada61c-315b-454a-b336-9b774fe138ee"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "gdrive\tsample_data\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9D18WFi4hhc",
        "outputId": "a6d33509-1c75-4229-8e83-adab3978e8fb"
      },
      "source": [
        "%cd /content/gdrive/My\\ Drive/AnimeGAN  \r\n",
        "\r\n",
        "%ls"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/gdrive/My Drive/AnimeGAN\n",
            "'AnimeGAN (1).py'\n",
            "'AnimeGAN AI & Google Colab - Installation Tutorial.mp4'\n",
            " AnimeGAN.py\n",
            " \u001b[0m\u001b[01;34mBrightness_tool\u001b[0m/\n",
            " \u001b[01;34mcheckpoint\u001b[0m/\n",
            " data_loader.py\n",
            " \u001b[01;34mdataset\u001b[0m/\n",
            " \u001b[01;34mdoc\u001b[0m/\n",
            " download_staffs.sh\n",
            " edge_smooth.py\n",
            " \u001b[01;34mlogs\u001b[0m/\n",
            " main.py\n",
            " \u001b[01;34mnet\u001b[0m/\n",
            " ops.py\n",
            " \u001b[01;34m__pycache__\u001b[0m/\n",
            " README.md\n",
            "'Requirements installation tutorial.md'\n",
            " \u001b[01;34mresult\u001b[0m/\n",
            " \u001b[01;34mresults\u001b[0m/\n",
            " \u001b[01;34msamples\u001b[0m/\n",
            " test.py\n",
            " utils.py\n",
            "'vgg19 (1).py'\n",
            " vgg19.py\n",
            " \u001b[01;34mvgg19_weight\u001b[0m/\n",
            " video2anime.py\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bIyVRTQqUHcp",
        "outputId": "b2b1a6ff-440d-457e-f284-4ee5fb06cd3c"
      },
      "source": [
        "!pip install tensorflow==1.15"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow==1.15\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3f/98/5a99af92fb911d7a88a0005ad55005f35b4c1ba8d75fba02df726cd936e6/tensorflow-1.15.0-cp36-cp36m-manylinux2010_x86_64.whl (412.3MB)\n",
            "\u001b[K     |████████████████████████████████| 412.3MB 38kB/s \n",
            "\u001b[?25hRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.3.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.10.0)\n",
            "Collecting gast==0.2.2\n",
            "  Downloading https://files.pythonhosted.org/packages/4e/35/11749bf99b2d4e3cceb4d55ca22590b0d7c2c62b9de38ac4a4a7f4687421/gast-0.2.2.tar.gz\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Collecting tensorflow-estimator==1.15.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/62/2ee9cd74c9fa2fa450877847ba560b260f5d0fb70ee0595203082dafcc9d/tensorflow_estimator-1.15.1-py2.py3-none-any.whl (503kB)\n",
            "\u001b[K     |████████████████████████████████| 512kB 34.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.12.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.32.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (3.12.4)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.19.5)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Collecting keras-applications>=1.0.8\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 6.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow==1.15) (0.36.2)\n",
            "Collecting tensorboard<1.16.0,>=1.15.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1e/e9/d3d747a97f7188f48aa5eda486907f3b345cd409f0a0850468ba867db246/tensorboard-1.15.0-py3-none-any.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 35.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow==1.15) (53.0.0)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (2.10.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.3)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.7.4.3)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.4.0)\n",
            "Building wheels for collected packages: gast\n",
            "  Building wheel for gast (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gast: filename=gast-0.2.2-cp36-none-any.whl size=7540 sha256=d536610fa20f41c2b2b09650fd47ccc06ab179313dccb2d23db6b860f134f92c\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/2e/7e/a1d4d4fcebe6c381f378ce7743a3ced3699feb89bcfbdadadd\n",
            "Successfully built gast\n",
            "\u001b[31mERROR: tensorflow-probability 0.12.1 has requirement gast>=0.3.2, but you'll have gast 0.2.2 which is incompatible.\u001b[0m\n",
            "Installing collected packages: gast, tensorflow-estimator, keras-applications, tensorboard, tensorflow\n",
            "  Found existing installation: gast 0.3.3\n",
            "    Uninstalling gast-0.3.3:\n",
            "      Successfully uninstalled gast-0.3.3\n",
            "  Found existing installation: tensorflow-estimator 2.4.0\n",
            "    Uninstalling tensorflow-estimator-2.4.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.4.0\n",
            "  Found existing installation: tensorboard 2.4.1\n",
            "    Uninstalling tensorboard-2.4.1:\n",
            "      Successfully uninstalled tensorboard-2.4.1\n",
            "  Found existing installation: tensorflow 2.4.1\n",
            "    Uninstalling tensorflow-2.4.1:\n",
            "      Successfully uninstalled tensorflow-2.4.1\n",
            "Successfully installed gast-0.2.2 keras-applications-1.0.8 tensorboard-1.15.0 tensorflow-1.15.0 tensorflow-estimator-1.15.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nPNihK6dlkSW",
        "outputId": "394599bb-7abb-4f8a-d663-e163656914cf"
      },
      "source": [
        "!python main.py --phase train --dataset SummerWar --epoch 100 --init_epoch 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n",
            "Epoch:  96 Step:  1487  time: 1.339258 s d_loss: 1.04307342, g_loss: 1000.64556885 -- mean_d_loss: 3.77444673, mean_g_loss: 1012.68731689\n",
            "Epoch:  96 Step:  1488  time: 1.310277 s d_loss: 0.78303641, g_loss: 977.46899414 -- mean_d_loss: 3.74083543, mean_g_loss: 1012.29162598\n",
            "Epoch:  96 Step:  1489  time: 1.326565 s d_loss: 0.77902687, g_loss: 834.40057373 -- mean_d_loss: 3.70792651, mean_g_loss: 1010.31500244\n",
            "Epoch:  96 Step:  1490  time: 1.326771 s d_loss: 1.39056909, g_loss: 991.79846191 -- mean_d_loss: 3.68246102, mean_g_loss: 1010.11151123\n",
            "Epoch:  96 Step:  1491  time: 1.310062 s d_loss: 0.83998579, g_loss: 1206.61669922 -- mean_d_loss: 3.65156460, mean_g_loss: 1012.24743652\n",
            "Epoch:  96 Step:  1492  time: 1.329763 s d_loss: 0.81241608, g_loss: 939.41882324 -- mean_d_loss: 3.62103605, mean_g_loss: 1011.46435547\n",
            "Epoch:  96 Step:  1493  time: 1.320435 s d_loss: 1.00866878, g_loss: 996.03466797 -- mean_d_loss: 3.59324479, mean_g_loss: 1011.30017090\n",
            "Epoch:  96 Step:  1494  time: 1.327456 s d_loss: 0.64909822, g_loss: 981.45715332 -- mean_d_loss: 3.56225395, mean_g_loss: 1010.98608398\n",
            "Epoch:  96 Step:  1495  time: 1.321628 s d_loss: 1.00371361, g_loss: 998.72424316 -- mean_d_loss: 3.53560257, mean_g_loss: 1010.85839844\n",
            "Epoch:  96 Step:  1496  time: 1.314001 s d_loss: 0.83774322, g_loss: 893.80700684 -- mean_d_loss: 3.50778961, mean_g_loss: 1009.65167236\n",
            "Epoch:  96 Step:  1497  time: 1.296108 s d_loss: 0.75618100, g_loss: 1172.95898438 -- mean_d_loss: 3.47971201, mean_g_loss: 1011.31805420\n",
            "Epoch:  96 Step:  1498  time: 1.296878 s d_loss: 0.96273905, g_loss: 1015.49090576 -- mean_d_loss: 3.45428801, mean_g_loss: 1011.36022949\n",
            "Epoch:  96 Step:  1499  time: 1.302987 s d_loss: 1.05475366, g_loss: 1005.70159912 -- mean_d_loss: 3.43029261, mean_g_loss: 1011.30364990\n",
            "Epoch:  96 Step:  1500  time: 1.291579 s d_loss: 0.85767245, g_loss: 1049.30273438 -- mean_d_loss: 3.40482116, mean_g_loss: 1011.67993164\n",
            "Epoch:  96 Step:  1501  time: 1.319481 s d_loss: 0.81133407, g_loss: 900.98620605 -- mean_d_loss: 3.37939477, mean_g_loss: 1010.59466553\n",
            "Epoch:  96 Step:  1502  time: 1.315128 s d_loss: 0.59939796, g_loss: 997.67425537 -- mean_d_loss: 3.35240459, mean_g_loss: 1010.46917725\n",
            "Epoch:  96 Step:  1503  time: 1.327220 s d_loss: 0.72659940, g_loss: 1046.39086914 -- mean_d_loss: 3.32715631, mean_g_loss: 1010.81457520\n",
            "Epoch:  96 Step:  1504  time: 1.284029 s d_loss: 0.87539941, g_loss: 869.04443359 -- mean_d_loss: 3.30380630, mean_g_loss: 1009.46441650\n",
            "Epoch:  96 Step:  1505  time: 1.298568 s d_loss: 0.84298223, g_loss: 1023.35156250 -- mean_d_loss: 3.28059101, mean_g_loss: 1009.59545898\n",
            "Epoch:  96 Step:  1506  time: 1.317391 s d_loss: 10.35202599, g_loss: 1140.37475586 -- mean_d_loss: 3.34667921, mean_g_loss: 1010.81768799\n",
            "Epoch:  96 Step:  1507  time: 1.322189 s d_loss: 1.55676234, g_loss: 1066.29528809 -- mean_d_loss: 3.33010578, mean_g_loss: 1011.33135986\n",
            "Epoch:  96 Step:  1508  time: 1.321614 s d_loss: 5.17611980, g_loss: 1106.82714844 -- mean_d_loss: 3.34704161, mean_g_loss: 1012.20751953\n",
            "Epoch:  96 Step:  1509  time: 1.322829 s d_loss: 6.35502529, g_loss: 1154.28698730 -- mean_d_loss: 3.37438679, mean_g_loss: 1013.49914551\n",
            "Epoch:  96 Step:  1510  time: 1.287003 s d_loss: 1.72046316, g_loss: 901.15338135 -- mean_d_loss: 3.35948658, mean_g_loss: 1012.48706055\n",
            "Epoch:  96 Step:  1511  time: 1.314038 s d_loss: 0.93034220, g_loss: 853.01147461 -- mean_d_loss: 3.33779764, mean_g_loss: 1011.06311035\n",
            "Epoch:  96 Step:  1512  time: 1.296352 s d_loss: 0.77987367, g_loss: 1025.62963867 -- mean_d_loss: 3.31516123, mean_g_loss: 1011.19207764\n",
            "Epoch:  96 Step:  1513  time: 1.292261 s d_loss: 1.02320659, g_loss: 1139.92468262 -- mean_d_loss: 3.29505634, mean_g_loss: 1012.32128906\n",
            "Epoch:  96 Step:  1514  time: 1.315138 s d_loss: 0.81461322, g_loss: 904.33483887 -- mean_d_loss: 3.27348709, mean_g_loss: 1011.38226318\n",
            "Epoch:  96 Step:  1515  time: 1.288370 s d_loss: 0.72205669, g_loss: 972.45300293 -- mean_d_loss: 3.25149202, mean_g_loss: 1011.04669189\n",
            "Epoch:  96 Step:  1516  time: 1.293440 s d_loss: 0.86661905, g_loss: 1098.74133301 -- mean_d_loss: 3.23110843, mean_g_loss: 1011.79620361\n",
            "Epoch:  96 Step:  1517  time: 1.340729 s d_loss: 2.38709474, g_loss: 1086.73303223 -- mean_d_loss: 3.22395563, mean_g_loss: 1012.43127441\n",
            "Epoch:  96 Step:  1518  time: 1.295089 s d_loss: 0.70938915, g_loss: 934.95953369 -- mean_d_loss: 3.20282459, mean_g_loss: 1011.78027344\n",
            "Epoch:  96 Step:  1519  time: 1.313049 s d_loss: 42.53254700, g_loss: 1082.67187500 -- mean_d_loss: 3.53057241, mean_g_loss: 1012.37103271\n",
            "Epoch:  96 Step:  1520  time: 1.282513 s d_loss: 3.40064931, g_loss: 957.20806885 -- mean_d_loss: 3.52949858, mean_g_loss: 1011.91516113\n",
            "Epoch:  96 Step:  1521  time: 1.297650 s d_loss: 1.45395851, g_loss: 960.97912598 -- mean_d_loss: 3.51248598, mean_g_loss: 1011.49761963\n",
            "Epoch:  96 Step:  1522  time: 1.305023 s d_loss: 0.89949995, g_loss: 1019.22924805 -- mean_d_loss: 3.49124217, mean_g_loss: 1011.56048584\n",
            "Epoch:  96 Step:  1523  time: 1.307027 s d_loss: 3.69791722, g_loss: 1052.66259766 -- mean_d_loss: 3.49290895, mean_g_loss: 1011.89196777\n",
            "Epoch:  96 Step:  1524  time: 1.281260 s d_loss: 0.85643417, g_loss: 873.93426514 -- mean_d_loss: 3.47181726, mean_g_loss: 1010.78833008\n",
            "Epoch:  96 Step:  1525  time: 1.294833 s d_loss: 1.13815427, g_loss: 1058.84216309 -- mean_d_loss: 3.45329595, mean_g_loss: 1011.16967773\n",
            "Epoch:  96 Step:  1526  time: 1.317032 s d_loss: 0.79473513, g_loss: 1004.40466309 -- mean_d_loss: 3.43236256, mean_g_loss: 1011.11645508\n",
            "Epoch:  96 Step:  1527  time: 1.320203 s d_loss: 7.03556299, g_loss: 902.70843506 -- mean_d_loss: 3.46051240, mean_g_loss: 1010.26953125\n",
            "Epoch:  96 Step:  1528  time: 1.321593 s d_loss: 0.95279717, g_loss: 894.31298828 -- mean_d_loss: 3.44107270, mean_g_loss: 1009.37066650\n",
            "Epoch:  96 Step:  1529  time: 1.312113 s d_loss: 1.02957344, g_loss: 1022.89172363 -- mean_d_loss: 3.42252278, mean_g_loss: 1009.47460938\n",
            "Epoch:  96 Step:  1530  time: 1.311974 s d_loss: 1.07715988, g_loss: 1129.20019531 -- mean_d_loss: 3.40461898, mean_g_loss: 1010.38861084\n",
            "Epoch:  96 Step:  1531  time: 1.324108 s d_loss: 0.70251328, g_loss: 941.74401855 -- mean_d_loss: 3.38414860, mean_g_loss: 1009.86859131\n",
            "Epoch:  96 Step:  1532  time: 1.317590 s d_loss: 0.96672165, g_loss: 1098.82250977 -- mean_d_loss: 3.36597252, mean_g_loss: 1010.53747559\n",
            "Epoch:  96 Step:  1533  time: 1.312112 s d_loss: 1.78958201, g_loss: 1056.40295410 -- mean_d_loss: 3.35420847, mean_g_loss: 1010.87976074\n",
            "Epoch:  96 Step:  1534  time: 1.289075 s d_loss: 1.03637826, g_loss: 1036.51794434 -- mean_d_loss: 3.33703923, mean_g_loss: 1011.06970215\n",
            "Epoch:  96 Step:  1535  time: 1.317965 s d_loss: 0.96273744, g_loss: 1127.93322754 -- mean_d_loss: 3.31958127, mean_g_loss: 1011.92901611\n",
            "Epoch:  96 Step:  1536  time: 1.332992 s d_loss: 0.73748910, g_loss: 952.85681152 -- mean_d_loss: 3.30073380, mean_g_loss: 1011.49780273\n",
            "Epoch:  96 Step:  1537  time: 1.314335 s d_loss: 0.95057237, g_loss: 1062.15405273 -- mean_d_loss: 3.28370357, mean_g_loss: 1011.86492920\n",
            "Epoch:  96 Step:  1538  time: 1.291167 s d_loss: 0.91439855, g_loss: 1005.28332520 -- mean_d_loss: 3.26665831, mean_g_loss: 1011.81756592\n",
            "Epoch:  96 Step:  1539  time: 1.311516 s d_loss: 9.00613022, g_loss: 1238.05749512 -- mean_d_loss: 3.30765438, mean_g_loss: 1013.43359375\n",
            "Epoch:  96 Step:  1540  time: 1.312604 s d_loss: 1.10234213, g_loss: 1042.31396484 -- mean_d_loss: 3.29201412, mean_g_loss: 1013.63842773\n",
            "Epoch:  96 Step:  1541  time: 1.306602 s d_loss: 2.83613992, g_loss: 985.66308594 -- mean_d_loss: 3.28880382, mean_g_loss: 1013.44134521\n",
            "Epoch:  96 Step:  1542  time: 1.319382 s d_loss: 3.91686916, g_loss: 959.00024414 -- mean_d_loss: 3.29319572, mean_g_loss: 1013.06066895\n",
            "Epoch:  96 Step:  1543  time: 1.281560 s d_loss: 2.56225514, g_loss: 1040.84265137 -- mean_d_loss: 3.28811979, mean_g_loss: 1013.25360107\n",
            "Epoch:  96 Step:  1544  time: 1.290987 s d_loss: 1.51259255, g_loss: 1082.52355957 -- mean_d_loss: 3.27587485, mean_g_loss: 1013.73138428\n",
            "Epoch:  96 Step:  1545  time: 1.319730 s d_loss: 2.99232936, g_loss: 877.60394287 -- mean_d_loss: 3.27393293, mean_g_loss: 1012.79901123\n",
            "Epoch:  96 Step:  1546  time: 1.290830 s d_loss: 1.01132369, g_loss: 884.23999023 -- mean_d_loss: 3.25854087, mean_g_loss: 1011.92443848\n",
            "Epoch:  96 Step:  1547  time: 1.319257 s d_loss: 1.04899371, g_loss: 1093.68298340 -- mean_d_loss: 3.24361157, mean_g_loss: 1012.47686768\n",
            "Epoch:  96 Step:  1548  time: 1.311429 s d_loss: 1.08983254, g_loss: 1088.11669922 -- mean_d_loss: 3.22915673, mean_g_loss: 1012.98449707\n",
            "Epoch:  96 Step:  1549  time: 1.297452 s d_loss: 0.79541266, g_loss: 867.22668457 -- mean_d_loss: 3.21293163, mean_g_loss: 1012.01281738\n",
            "Epoch:  96 Step:  1550  time: 1.299023 s d_loss: 1.10391116, g_loss: 1128.05187988 -- mean_d_loss: 3.19896460, mean_g_loss: 1012.78125000\n",
            "Epoch:  96 Step:  1551  time: 1.313467 s d_loss: 0.74688548, g_loss: 1115.56640625 -- mean_d_loss: 3.18283272, mean_g_loss: 1013.45745850\n",
            "Epoch:  96 Step:  1552  time: 1.302010 s d_loss: 1.19249046, g_loss: 1065.48559570 -- mean_d_loss: 3.16982388, mean_g_loss: 1013.79748535\n",
            "Epoch:  96 Step:  1553  time: 1.298862 s d_loss: 1.33756125, g_loss: 1180.32861328 -- mean_d_loss: 3.15792608, mean_g_loss: 1014.87884521\n",
            "Epoch:  96 Step:  1554  time: 1.315807 s d_loss: 1.16351843, g_loss: 1093.03149414 -- mean_d_loss: 3.14505887, mean_g_loss: 1015.38305664\n",
            "Epoch:  96 Step:  1555  time: 1.322205 s d_loss: 0.61754739, g_loss: 1099.29663086 -- mean_d_loss: 3.12885690, mean_g_loss: 1015.92095947\n",
            "Epoch:  96 Step:  1556  time: 1.321744 s d_loss: 0.79639941, g_loss: 1092.14916992 -- mean_d_loss: 3.11400056, mean_g_loss: 1016.40655518\n",
            "Epoch:  96 Step:  1557  time: 1.314094 s d_loss: 0.75498813, g_loss: 1057.06677246 -- mean_d_loss: 3.09906983, mean_g_loss: 1016.66387939\n",
            "Epoch:  96 Step:  1558  time: 1.301724 s d_loss: 0.73878324, g_loss: 859.26794434 -- mean_d_loss: 3.08422518, mean_g_loss: 1015.67395020\n",
            "Epoch:  96 Step:  1559  time: 1.342338 s d_loss: 0.80605537, g_loss: 1189.49072266 -- mean_d_loss: 3.06998682, mean_g_loss: 1016.76025391\n",
            "Epoch:  96 Step:  1560  time: 1.322403 s d_loss: 0.94374955, g_loss: 897.82452393 -- mean_d_loss: 3.05678034, mean_g_loss: 1016.02154541\n",
            "Epoch:  96 Step:  1561  time: 1.323528 s d_loss: 0.85542953, g_loss: 1128.66870117 -- mean_d_loss: 3.04319191, mean_g_loss: 1016.71691895\n",
            "Epoch:  96 Step:  1562  time: 1.321798 s d_loss: 0.89001030, g_loss: 900.84887695 -- mean_d_loss: 3.02998209, mean_g_loss: 1016.00604248\n",
            "Epoch:  96 Step:  1563  time: 1.315389 s d_loss: 0.84131843, g_loss: 1021.13275146 -- mean_d_loss: 3.01663661, mean_g_loss: 1016.03723145\n",
            "Epoch:  96 Step:  1564  time: 1.286808 s d_loss: 1.11902320, g_loss: 970.94744873 -- mean_d_loss: 3.00513577, mean_g_loss: 1015.76403809\n",
            "Epoch:  96 Step:  1565  time: 1.291924 s d_loss: 1.07614815, g_loss: 997.39770508 -- mean_d_loss: 2.99351549, mean_g_loss: 1015.65332031\n",
            "Epoch:  96 Step:  1566  time: 1.323543 s d_loss: 1.06187260, g_loss: 1020.96459961 -- mean_d_loss: 2.98194861, mean_g_loss: 1015.68518066\n",
            "Epoch:  96 Step:  1567  time: 1.320725 s d_loss: 0.80840820, g_loss: 898.38909912 -- mean_d_loss: 2.96901083, mean_g_loss: 1014.98699951\n",
            "Epoch:  96 Step:  1568  time: 1.301251 s d_loss: 1.41903317, g_loss: 920.27148438 -- mean_d_loss: 2.95983934, mean_g_loss: 1014.42651367\n",
            "Epoch:  96 Step:  1569  time: 1.306529 s d_loss: 1.14710855, g_loss: 980.30560303 -- mean_d_loss: 2.94917631, mean_g_loss: 1014.22583008\n",
            "Epoch:  96 Step:  1570  time: 1.330944 s d_loss: 1.61194766, g_loss: 880.80432129 -- mean_d_loss: 2.94135618, mean_g_loss: 1013.44555664\n",
            "Epoch:  96 Step:  1571  time: 1.291913 s d_loss: 1.69982243, g_loss: 908.98645020 -- mean_d_loss: 2.93413782, mean_g_loss: 1012.83819580\n",
            "Epoch:  96 Step:  1572  time: 1.308417 s d_loss: 2.16533089, g_loss: 1064.78564453 -- mean_d_loss: 2.92969394, mean_g_loss: 1013.13842773\n",
            "Epoch:  96 Step:  1573  time: 1.315378 s d_loss: 1.13015509, g_loss: 1039.80773926 -- mean_d_loss: 2.91935182, mean_g_loss: 1013.29174805\n",
            "Epoch:  96 Step:  1574  time: 1.319294 s d_loss: 1.70871687, g_loss: 1229.75012207 -- mean_d_loss: 2.91243386, mean_g_loss: 1014.52868652\n",
            "Epoch:  96 Step:  1575  time: 1.324634 s d_loss: 0.90800226, g_loss: 867.98565674 -- mean_d_loss: 2.90104508, mean_g_loss: 1013.69604492\n",
            "Epoch:  96 Step:  1576  time: 1.287481 s d_loss: 0.88835478, g_loss: 960.23669434 -- mean_d_loss: 2.88967395, mean_g_loss: 1013.39398193\n",
            "Epoch:  96 Step:  1577  time: 1.311502 s d_loss: 1.57115567, g_loss: 1163.13500977 -- mean_d_loss: 2.88226652, mean_g_loss: 1014.23522949\n",
            "Epoch:  96 Step:  1578  time: 1.352969 s d_loss: 1.13098466, g_loss: 1056.89233398 -- mean_d_loss: 2.87248302, mean_g_loss: 1014.47357178\n",
            "Epoch:  96 Step:  1579  time: 1.313098 s d_loss: 0.79838508, g_loss: 846.60168457 -- mean_d_loss: 2.86096025, mean_g_loss: 1013.54095459\n",
            "Epoch:  96 Step:  1580  time: 1.296904 s d_loss: 3.27147722, g_loss: 1069.27966309 -- mean_d_loss: 2.86322832, mean_g_loss: 1013.84893799\n",
            "Epoch:  96 Step:  1581  time: 1.333701 s d_loss: 0.57933807, g_loss: 922.01483154 -- mean_d_loss: 2.85067940, mean_g_loss: 1013.34436035\n",
            "Epoch:  96 Step:  1582  time: 1.318643 s d_loss: 3.02502680, g_loss: 1163.93334961 -- mean_d_loss: 2.85163212, mean_g_loss: 1014.16723633\n",
            "Epoch:  96 Step:  1583  time: 1.299520 s d_loss: 3.09980249, g_loss: 971.11779785 -- mean_d_loss: 2.85298085, mean_g_loss: 1013.93334961\n",
            "Epoch:  96 Step:  1584  time: 1.335468 s d_loss: 1.02870369, g_loss: 900.37609863 -- mean_d_loss: 2.84311986, mean_g_loss: 1013.31951904\n",
            "Epoch:  96 Step:  1585  time: 1.320174 s d_loss: 2.40101886, g_loss: 1072.07006836 -- mean_d_loss: 2.84074283, mean_g_loss: 1013.63531494\n",
            "Epoch:  96 Step:  1586  time: 1.293506 s d_loss: 1.08388388, g_loss: 893.68835449 -- mean_d_loss: 2.83134770, mean_g_loss: 1012.99389648\n",
            "Epoch:  96 Step:  1587  time: 1.284918 s d_loss: 4.20930243, g_loss: 894.49444580 -- mean_d_loss: 2.83867717, mean_g_loss: 1012.36358643\n",
            "Epoch:  96 Step:  1588  time: 1.316035 s d_loss: 0.84525627, g_loss: 888.47088623 -- mean_d_loss: 2.82813025, mean_g_loss: 1011.70806885\n",
            "Epoch:  96 Step:  1589  time: 1.318082 s d_loss: 1.17835569, g_loss: 962.99914551 -- mean_d_loss: 2.81944704, mean_g_loss: 1011.45172119\n",
            "Epoch:  96 Step:  1590  time: 1.331353 s d_loss: 0.77361870, g_loss: 906.08245850 -- mean_d_loss: 2.80873585, mean_g_loss: 1010.90002441\n",
            "Epoch:  96 Step:  1591  time: 1.292457 s d_loss: 0.77158934, g_loss: 917.43188477 -- mean_d_loss: 2.79812598, mean_g_loss: 1010.41326904\n",
            "Epoch:  96 Step:  1592  time: 1.322187 s d_loss: 0.73276299, g_loss: 1044.28662109 -- mean_d_loss: 2.78742456, mean_g_loss: 1010.58874512\n",
            "Epoch:  96 Step:  1593  time: 1.314019 s d_loss: 2.16449857, g_loss: 1163.49755859 -- mean_d_loss: 2.78421378, mean_g_loss: 1011.37695312\n",
            "Epoch:  96 Step:  1594  time: 1.294507 s d_loss: 4.23254824, g_loss: 1052.28295898 -- mean_d_loss: 2.79164100, mean_g_loss: 1011.58666992\n",
            "Epoch:  96 Step:  1595  time: 1.350009 s d_loss: 0.80214280, g_loss: 960.86865234 -- mean_d_loss: 2.78149033, mean_g_loss: 1011.32794189\n",
            "Epoch:  96 Step:  1596  time: 1.340847 s d_loss: 0.89379871, g_loss: 991.85388184 -- mean_d_loss: 2.77190828, mean_g_loss: 1011.22912598\n",
            "Epoch:  96 Step:  1597  time: 1.323155 s d_loss: 0.67042267, g_loss: 1156.71691895 -- mean_d_loss: 2.76129460, mean_g_loss: 1011.96392822\n",
            "Epoch:  96 Step:  1598  time: 1.302969 s d_loss: 0.78636760, g_loss: 1119.56848145 -- mean_d_loss: 2.75137043, mean_g_loss: 1012.50463867\n",
            "Epoch:  96 Step:  1599  time: 1.315012 s d_loss: 0.80091053, g_loss: 1050.32983398 -- mean_d_loss: 2.74161816, mean_g_loss: 1012.69372559\n",
            "Epoch:  96 Step:  1600  time: 1.323240 s d_loss: 5.30902910, g_loss: 1127.01586914 -- mean_d_loss: 5.30902910, mean_g_loss: 1127.01586914\n",
            "Epoch:  96 Step:  1601  time: 1.311117 s d_loss: 0.96530986, g_loss: 1252.02539062 -- mean_d_loss: 3.13716936, mean_g_loss: 1189.52062988\n",
            "Epoch:  96 Step:  1602  time: 1.323554 s d_loss: 3.54652572, g_loss: 935.05395508 -- mean_d_loss: 3.27362156, mean_g_loss: 1104.69836426\n",
            "Epoch:  96 Step:  1603  time: 1.317442 s d_loss: 1.34273255, g_loss: 956.42956543 -- mean_d_loss: 2.79089928, mean_g_loss: 1067.63122559\n",
            "Epoch:  96 Step:  1604  time: 1.329330 s d_loss: 0.83952022, g_loss: 902.67053223 -- mean_d_loss: 2.40062356, mean_g_loss: 1034.63903809\n",
            "Epoch:  96 Step:  1605  time: 1.323596 s d_loss: 2.77183104, g_loss: 893.21362305 -- mean_d_loss: 2.46249127, mean_g_loss: 1011.06817627\n",
            "Epoch:  96 Step:  1606  time: 1.334049 s d_loss: 1.00320053, g_loss: 982.86511230 -- mean_d_loss: 2.25402117, mean_g_loss: 1007.03918457\n",
            "Epoch:  96 Step:  1607  time: 1.316003 s d_loss: 1.28815305, g_loss: 815.67590332 -- mean_d_loss: 2.13328767, mean_g_loss: 983.11877441\n",
            "Epoch:  96 Step:  1608  time: 1.288502 s d_loss: 1.03849149, g_loss: 1092.42187500 -- mean_d_loss: 2.01164365, mean_g_loss: 995.26354980\n",
            "Epoch:  96 Step:  1609  time: 1.320766 s d_loss: 1.22373593, g_loss: 949.59020996 -- mean_d_loss: 1.93285298, mean_g_loss: 990.69616699\n",
            "Epoch:  96 Step:  1610  time: 1.311974 s d_loss: 0.83824939, g_loss: 853.03320312 -- mean_d_loss: 1.83334351, mean_g_loss: 978.18139648\n",
            "Epoch:  96 Step:  1611  time: 1.311182 s d_loss: 0.82093471, g_loss: 971.93627930 -- mean_d_loss: 1.74897611, mean_g_loss: 977.66094971\n",
            "Epoch:  96 Step:  1612  time: 1.322158 s d_loss: 0.69569522, g_loss: 1224.46765137 -- mean_d_loss: 1.66795456, mean_g_loss: 996.64611816\n",
            "Epoch:  96 Step:  1613  time: 1.322227 s d_loss: 0.92306828, g_loss: 1019.56176758 -- mean_d_loss: 1.61474836, mean_g_loss: 998.28289795\n",
            "Epoch:  96 Step:  1614  time: 1.348207 s d_loss: 2.27896929, g_loss: 1018.34259033 -- mean_d_loss: 1.65902972, mean_g_loss: 999.62023926\n",
            "Epoch:  96 Step:  1615  time: 1.295598 s d_loss: 1.39577985, g_loss: 1092.18298340 -- mean_d_loss: 1.64257669, mean_g_loss: 1005.40539551\n",
            "Epoch:  96 Step:  1616  time: 1.313644 s d_loss: 2.54349971, g_loss: 1049.73071289 -- mean_d_loss: 1.69557214, mean_g_loss: 1008.01275635\n",
            "Epoch:  96 Step:  1617  time: 1.344517 s d_loss: 1.33030200, g_loss: 986.24365234 -- mean_d_loss: 1.67527926, mean_g_loss: 1006.80340576\n",
            "Epoch:  96 Step:  1618  time: 1.315568 s d_loss: 0.87959111, g_loss: 889.10266113 -- mean_d_loss: 1.63340092, mean_g_loss: 1000.60864258\n",
            "Epoch:  96 Step:  1619  time: 1.317403 s d_loss: 1.49377275, g_loss: 1133.14794922 -- mean_d_loss: 1.62641966, mean_g_loss: 1007.23565674\n",
            "Epoch:  96 Step:  1620  time: 1.324352 s d_loss: 0.94260180, g_loss: 940.91430664 -- mean_d_loss: 1.59385681, mean_g_loss: 1004.07745361\n",
            "Epoch:  96 Step:  1621  time: 1.317926 s d_loss: 2.96892571, g_loss: 1078.53808594 -- mean_d_loss: 1.65635991, mean_g_loss: 1007.46197510\n",
            "Epoch:  96 Step:  1622  time: 1.322689 s d_loss: 2.01541114, g_loss: 963.26904297 -- mean_d_loss: 1.67197084, mean_g_loss: 1005.54058838\n",
            "Epoch:  96 Step:  1623  time: 1.336777 s d_loss: 1.52259195, g_loss: 1197.17053223 -- mean_d_loss: 1.66574669, mean_g_loss: 1013.52514648\n",
            "Epoch:  96 Step:  1624  time: 1.320642 s d_loss: 0.58283931, g_loss: 904.02465820 -- mean_d_loss: 1.62243044, mean_g_loss: 1009.14514160\n",
            "Epoch:  96 Step:  1625  time: 1.328412 s d_loss: 0.59298861, g_loss: 858.28381348 -- mean_d_loss: 1.58283639, mean_g_loss: 1003.34277344\n",
            "Epoch:  96 Step:  1626  time: 1.288570 s d_loss: 38.27320862, g_loss: 1115.89184570 -- mean_d_loss: 2.94173908, mean_g_loss: 1007.51129150\n",
            "Epoch:  96 Step:  1627  time: 1.331017 s d_loss: 1.41752887, g_loss: 1136.34643555 -- mean_d_loss: 2.88730288, mean_g_loss: 1012.11248779\n",
            "Epoch:  96 Step:  1628  time: 1.335072 s d_loss: 1.60504985, g_loss: 1141.48400879 -- mean_d_loss: 2.84308720, mean_g_loss: 1016.57360840\n",
            "Epoch:  96 Step:  1629  time: 1.330609 s d_loss: 1.39564955, g_loss: 1076.98388672 -- mean_d_loss: 2.79483938, mean_g_loss: 1018.58728027\n",
            "Epoch:  96 Step:  1630  time: 1.321004 s d_loss: 1.92263067, g_loss: 1155.69714355 -- mean_d_loss: 2.76670361, mean_g_loss: 1023.01019287\n",
            "Epoch:  96 Step:  1631  time: 1.322510 s d_loss: 1.80642939, g_loss: 1023.24993896 -- mean_d_loss: 2.73669505, mean_g_loss: 1023.01770020\n",
            "Epoch:  96 Step:  1632  time: 1.294491 s d_loss: 0.89173222, g_loss: 1037.03613281 -- mean_d_loss: 2.68078709, mean_g_loss: 1023.44244385\n",
            "Epoch:  96 Step:  1633  time: 1.307081 s d_loss: 1.06122708, g_loss: 1074.95495605 -- mean_d_loss: 2.63315296, mean_g_loss: 1024.95751953\n",
            "Epoch:  96 Step:  1634  time: 1.333102 s d_loss: 0.80768102, g_loss: 1076.57446289 -- mean_d_loss: 2.58099651, mean_g_loss: 1026.43225098\n",
            "Epoch:  96 Step:  1635  time: 1.283981 s d_loss: 0.77473855, g_loss: 1164.54150391 -- mean_d_loss: 2.53082275, mean_g_loss: 1030.26867676\n",
            "Epoch:  96 Step:  1636  time: 1.317187 s d_loss: 0.97324246, g_loss: 986.81237793 -- mean_d_loss: 2.48872614, mean_g_loss: 1029.09411621\n",
            "Epoch:  96 Step:  1637  time: 1.333979 s d_loss: 1.88980091, g_loss: 1080.71203613 -- mean_d_loss: 2.47296476, mean_g_loss: 1030.45251465\n",
            "Epoch:  96 Step:  1638  time: 1.304570 s d_loss: 2.56719327, g_loss: 1141.97277832 -- mean_d_loss: 2.47538090, mean_g_loss: 1033.31201172\n",
            "Epoch:  96 Step:  1639  time: 1.315690 s d_loss: 0.97724074, g_loss: 1112.33642578 -- mean_d_loss: 2.43792748, mean_g_loss: 1035.28759766\n",
            "Epoch:  96 Step:  1640  time: 1.334783 s d_loss: 1.11039114, g_loss: 996.80090332 -- mean_d_loss: 2.40554857, mean_g_loss: 1034.34887695\n",
            "Epoch:  96 Step:  1641  time: 1.284743 s d_loss: 1.17988181, g_loss: 994.75610352 -- mean_d_loss: 2.37636590, mean_g_loss: 1033.40625000\n",
            "Epoch:  96 Step:  1642  time: 1.306228 s d_loss: 0.92609155, g_loss: 874.57629395 -- mean_d_loss: 2.34263849, mean_g_loss: 1029.71252441\n",
            "Epoch:  96 Step:  1643  time: 1.296826 s d_loss: 0.70558882, g_loss: 913.40466309 -- mean_d_loss: 2.30543303, mean_g_loss: 1027.06921387\n",
            "Epoch:  96 Step:  1644  time: 1.326865 s d_loss: 0.72814107, g_loss: 1128.32519531 -- mean_d_loss: 2.27038193, mean_g_loss: 1029.31933594\n",
            "Epoch:  96 Step:  1645  time: 1.335580 s d_loss: 1.49424136, g_loss: 1117.99401855 -- mean_d_loss: 2.25350928, mean_g_loss: 1031.24707031\n",
            "Epoch:  96 Step:  1646  time: 1.317838 s d_loss: 0.72109443, g_loss: 1133.35644531 -- mean_d_loss: 2.22090483, mean_g_loss: 1033.41955566\n",
            "Epoch:  96 Step:  1647  time: 1.340924 s d_loss: 0.80364525, g_loss: 965.36938477 -- mean_d_loss: 2.19137836, mean_g_loss: 1032.00183105\n",
            "Epoch:  96 Step:  1648  time: 1.304750 s d_loss: 0.58882523, g_loss: 1083.89990234 -- mean_d_loss: 2.15867329, mean_g_loss: 1033.06103516\n",
            "Epoch:  96 Step:  1649  time: 1.318897 s d_loss: 0.68738866, g_loss: 989.07592773 -- mean_d_loss: 2.12924767, mean_g_loss: 1032.18127441\n",
            "Epoch:  96 Step:  1650  time: 1.320899 s d_loss: 0.83007568, g_loss: 1152.79370117 -- mean_d_loss: 2.10377359, mean_g_loss: 1034.54614258\n",
            "Epoch:  96 Step:  1651  time: 1.327224 s d_loss: 0.76941311, g_loss: 1130.04736328 -- mean_d_loss: 2.07811308, mean_g_loss: 1036.38269043\n",
            "Epoch:  96 Step:  1652  time: 1.313373 s d_loss: 2.23232532, g_loss: 1127.85961914 -- mean_d_loss: 2.08102250, mean_g_loss: 1038.10876465\n",
            "Epoch:  96 Step:  1653  time: 1.343811 s d_loss: 0.77114570, g_loss: 1112.20275879 -- mean_d_loss: 2.05676556, mean_g_loss: 1039.48083496\n",
            "Epoch:  96 Step:  1654  time: 1.357526 s d_loss: 0.65614277, g_loss: 1085.30444336 -- mean_d_loss: 2.03129983, mean_g_loss: 1040.31396484\n",
            "Epoch:  96 Step:  1655  time: 1.328207 s d_loss: 0.63880759, g_loss: 1123.81567383 -- mean_d_loss: 2.00643396, mean_g_loss: 1041.80505371\n",
            "Epoch:  96 Step:  1656  time: 1.292510 s d_loss: 19.93356705, g_loss: 1054.14331055 -- mean_d_loss: 2.32094502, mean_g_loss: 1042.02160645\n",
            "Epoch:  96 Step:  1657  time: 1.328919 s d_loss: 1.00722790, g_loss: 1115.94262695 -- mean_d_loss: 2.29829478, mean_g_loss: 1043.29602051\n",
            "Epoch:  96 Step:  1658  time: 1.320877 s d_loss: 0.97249132, g_loss: 989.67138672 -- mean_d_loss: 2.27582359, mean_g_loss: 1042.38720703\n",
            "Epoch:  96 Step:  1659  time: 1.330949 s d_loss: 1.49661183, g_loss: 1043.64379883 -- mean_d_loss: 2.26283669, mean_g_loss: 1042.40808105\n",
            "Epoch:  96 Step:  1660  time: 1.313358 s d_loss: 41.32176971, g_loss: 1015.19604492 -- mean_d_loss: 2.90314722, mean_g_loss: 1041.96203613\n",
            "Epoch:  96 Step:  1661  time: 1.328008 s d_loss: 1.97747982, g_loss: 907.66845703 -- mean_d_loss: 2.88821697, mean_g_loss: 1039.79602051\n",
            "Epoch:  96 Step:  1662  time: 1.288268 s d_loss: 1.37980521, g_loss: 1019.22094727 -- mean_d_loss: 2.86427402, mean_g_loss: 1039.46948242\n",
            "Epoch:  96 Step:  1663  time: 1.325421 s d_loss: 1.04715872, g_loss: 1080.64025879 -- mean_d_loss: 2.83588171, mean_g_loss: 1040.11267090\n",
            "val: 0./dataset/val/2014-09-08 05_31_48.jpg\n",
            "val: 1./dataset/val/2014-12-07 05_00_46.jpg\n",
            "val: 2./dataset/val/2015-04-23 10_12_24.jpg\n",
            "val: 3./dataset/val/1.jpg\n",
            "val: 4./dataset/val/3.jpg\n",
            "val: 5./dataset/val/4.jpg\n",
            "val: 6./dataset/val/6.jpg\n",
            "val: 7./dataset/val/5.jpg\n",
            "val: 8./dataset/val/7.jpg\n",
            "val: 9./dataset/val/8.jpg\n",
            "val: 10./dataset/val/9.jpg\n",
            "val: 11./dataset/val/10.jpg\n",
            "val: 12./dataset/val/2.jpg\n",
            "val: 13./dataset/val/12.jpg\n",
            "val: 14./dataset/val/13.jpg\n",
            "val: 15./dataset/val/14.jpg\n",
            "val: 16./dataset/val/15.jpg\n",
            "val: 17./dataset/val/16.jpg\n",
            "val: 18./dataset/val/17.jpg\n",
            "val: 19./dataset/val/18.jpg\n",
            "val: 20./dataset/val/19.jpg\n",
            "val: 21./dataset/val/20.jpg\n",
            "val: 22./dataset/val/21.jpg\n",
            "val: 23./dataset/val/22.jpg\n",
            "val: 24./dataset/val/23.jpg\n",
            "val: 25./dataset/val/24.jpg\n",
            "val: 26./dataset/val/25.jpg\n",
            "val: 27./dataset/val/26.jpg\n",
            "val: 28./dataset/val/27.jpg\n",
            "val: 29./dataset/val/28.jpg\n",
            "val: 30./dataset/val/29.jpg\n",
            "val: 31./dataset/val/30.jpg\n",
            "val: 32./dataset/val/31.jpg\n",
            "val: 33./dataset/val/32.jpg\n",
            "val: 34./dataset/val/33.jpg\n",
            "val: 35./dataset/val/34.jpg\n",
            "val: 36./dataset/val/35.jpg\n",
            "val: 37./dataset/val/36.jpg\n",
            "val: 38./dataset/val/37.jpg\n",
            "val: 39./dataset/val/38.jpg\n",
            "val: 40./dataset/val/39.jpg\n",
            "val: 41./dataset/val/40.jpg\n",
            "val: 42./dataset/val/41.jpg\n",
            "val: 43./dataset/val/42.jpg\n",
            "val: 44./dataset/val/43.jpg\n",
            "val: 45./dataset/val/44.jpg\n",
            "val: 46./dataset/val/45.jpg\n",
            "val: 47./dataset/val/46.jpg\n",
            "val: 48./dataset/val/49.jpg\n",
            "val: 49./dataset/val/48.jpg\n",
            "val: 50./dataset/val/47.jpg\n",
            "val: 51./dataset/val/50.jpg\n",
            "val: 52./dataset/val/51.jpg\n",
            "val: 53./dataset/val/52.jpg\n",
            "val: 54./dataset/val/53.jpg\n",
            "val: 55./dataset/val/55.jpg\n",
            "val: 56./dataset/val/57.jpg\n",
            "val: 57./dataset/val/56.jpg\n",
            "val: 58./dataset/val/54.jpg\n",
            "val: 59./dataset/val/58.jpg\n",
            "val: 60./dataset/val/59.jpg\n",
            "val: 61./dataset/val/60.jpg\n",
            "val: 62./dataset/val/11.jpg\n",
            "val: 63./dataset/val/61.jpg\n",
            "val: 64./dataset/val/hww.jpg\n",
            "val: 65./dataset/val/lzl.jpg\n",
            "val: 66./dataset/val/wzy.jpg\n",
            "Epoch:  97 Step:     0  time: 1.295727 s d_loss: 0.71052724, g_loss: 950.97314453 -- mean_d_loss: 2.80318403, mean_g_loss: 1038.74133301\n",
            "Epoch:  97 Step:     1  time: 1.330360 s d_loss: 0.77669644, g_loss: 1194.71423340 -- mean_d_loss: 2.77247977, mean_g_loss: 1041.10449219\n",
            "Epoch:  97 Step:     2  time: 1.325193 s d_loss: 0.98099899, g_loss: 1153.53833008 -- mean_d_loss: 2.74574113, mean_g_loss: 1042.78259277\n",
            "Epoch:  97 Step:     3  time: 1.312380 s d_loss: 0.83230984, g_loss: 956.23669434 -- mean_d_loss: 2.71760249, mean_g_loss: 1041.50988770\n",
            "Epoch:  97 Step:     4  time: 1.335478 s d_loss: 0.70814061, g_loss: 856.39831543 -- mean_d_loss: 2.68847990, mean_g_loss: 1038.82714844\n",
            "Epoch:  97 Step:     5  time: 1.313109 s d_loss: 0.60520035, g_loss: 979.11871338 -- mean_d_loss: 2.65871859, mean_g_loss: 1037.97412109\n",
            "Epoch:  97 Step:     6  time: 1.298585 s d_loss: 0.61034274, g_loss: 1011.15368652 -- mean_d_loss: 2.62986827, mean_g_loss: 1037.59643555\n",
            "Epoch:  97 Step:     7  time: 1.344485 s d_loss: 0.59318340, g_loss: 945.60729980 -- mean_d_loss: 2.60158086, mean_g_loss: 1036.31884766\n",
            "Epoch:  97 Step:     8  time: 1.351257 s d_loss: 0.95304805, g_loss: 954.96435547 -- mean_d_loss: 2.57899833, mean_g_loss: 1035.20434570\n",
            "Epoch:  97 Step:     9  time: 1.335042 s d_loss: 2.31313491, g_loss: 1143.84887695 -- mean_d_loss: 2.57540560, mean_g_loss: 1036.67248535\n",
            "Epoch:  97 Step:    10  time: 1.354442 s d_loss: 1.56213856, g_loss: 1112.66235352 -- mean_d_loss: 2.56189537, mean_g_loss: 1037.68566895\n",
            "Epoch:  97 Step:    11  time: 1.296983 s d_loss: 0.98340738, g_loss: 1065.12646484 -- mean_d_loss: 2.54112577, mean_g_loss: 1038.04675293\n",
            "Epoch:  97 Step:    12  time: 1.324681 s d_loss: 0.71881288, g_loss: 1103.62890625 -- mean_d_loss: 2.51745939, mean_g_loss: 1038.89855957\n",
            "Epoch:  97 Step:    13  time: 1.354124 s d_loss: 0.70650226, g_loss: 1085.75341797 -- mean_d_loss: 2.49424195, mean_g_loss: 1039.49914551\n",
            "Epoch:  97 Step:    14  time: 1.305012 s d_loss: 0.64956790, g_loss: 1123.68017578 -- mean_d_loss: 2.47089171, mean_g_loss: 1040.56481934\n",
            "Epoch:  97 Step:    15  time: 1.337286 s d_loss: 0.89718688, g_loss: 1038.08471680 -- mean_d_loss: 2.45122027, mean_g_loss: 1040.53381348\n",
            "Epoch:  97 Step:    16  time: 1.326712 s d_loss: 0.66248333, g_loss: 1027.78173828 -- mean_d_loss: 2.42913723, mean_g_loss: 1040.37634277\n",
            "Epoch:  97 Step:    17  time: 1.314527 s d_loss: 0.76512843, g_loss: 964.13085938 -- mean_d_loss: 2.40884447, mean_g_loss: 1039.44653320\n",
            "Epoch:  97 Step:    18  time: 1.324371 s d_loss: 0.86168122, g_loss: 1043.76293945 -- mean_d_loss: 2.39020371, mean_g_loss: 1039.49853516\n",
            "Epoch:  97 Step:    19  time: 1.340168 s d_loss: 0.59580636, g_loss: 1088.76928711 -- mean_d_loss: 2.36884189, mean_g_loss: 1040.08508301\n",
            "Epoch:  97 Step:    20  time: 1.334276 s d_loss: 1.27009022, g_loss: 934.26171875 -- mean_d_loss: 2.35591555, mean_g_loss: 1038.84008789\n",
            "Epoch:  97 Step:    21  time: 1.311700 s d_loss: 1.22159910, g_loss: 1240.13330078 -- mean_d_loss: 2.34272599, mean_g_loss: 1041.18066406\n",
            "Epoch:  97 Step:    22  time: 1.325486 s d_loss: 0.76917756, g_loss: 904.66613770 -- mean_d_loss: 2.32463908, mean_g_loss: 1039.61157227\n",
            "Epoch:  97 Step:    23  time: 1.295455 s d_loss: 4.28285503, g_loss: 969.58190918 -- mean_d_loss: 2.34689164, mean_g_loss: 1038.81567383\n",
            "Epoch:  97 Step:    24  time: 1.321725 s d_loss: 0.71801013, g_loss: 945.65545654 -- mean_d_loss: 2.32858968, mean_g_loss: 1037.76892090\n",
            "Epoch:  97 Step:    25  time: 1.320137 s d_loss: 1.18663037, g_loss: 1073.79748535 -- mean_d_loss: 2.31590128, mean_g_loss: 1038.16931152\n",
            "Epoch:  97 Step:    26  time: 1.318027 s d_loss: 0.72267687, g_loss: 868.60626221 -- mean_d_loss: 2.29839325, mean_g_loss: 1036.30603027\n",
            "Epoch:  97 Step:    27  time: 1.311074 s d_loss: 0.65192991, g_loss: 921.46838379 -- mean_d_loss: 2.28049684, mean_g_loss: 1035.05773926\n",
            "Epoch:  97 Step:    28  time: 1.331785 s d_loss: 0.55100197, g_loss: 971.12487793 -- mean_d_loss: 2.26189995, mean_g_loss: 1034.37023926\n",
            "Epoch:  97 Step:    29  time: 1.313192 s d_loss: 0.58953977, g_loss: 972.75366211 -- mean_d_loss: 2.24410892, mean_g_loss: 1033.71472168\n",
            "Epoch:  97 Step:    30  time: 1.334795 s d_loss: 0.69151372, g_loss: 1016.68920898 -- mean_d_loss: 2.22776580, mean_g_loss: 1033.53552246\n",
            "Epoch:  97 Step:    31  time: 1.308844 s d_loss: 2.82108259, g_loss: 1081.31311035 -- mean_d_loss: 2.23394608, mean_g_loss: 1034.03320312\n",
            "Epoch:  97 Step:    32  time: 1.338949 s d_loss: 0.61680883, g_loss: 1027.11743164 -- mean_d_loss: 2.21727467, mean_g_loss: 1033.96191406\n",
            "Epoch:  97 Step:    33  time: 1.316021 s d_loss: 0.56978995, g_loss: 1130.02209473 -- mean_d_loss: 2.20046353, mean_g_loss: 1034.94213867\n",
            "Epoch:  97 Step:    34  time: 1.309295 s d_loss: 0.88552320, g_loss: 978.92572021 -- mean_d_loss: 2.18718147, mean_g_loss: 1034.37622070\n",
            "Epoch:  97 Step:    35  time: 1.301162 s d_loss: 0.80973166, g_loss: 1035.59277344 -- mean_d_loss: 2.17340708, mean_g_loss: 1034.38842773\n",
            "Epoch:  97 Step:    36  time: 1.279466 s d_loss: 24.11878586, g_loss: 1048.99108887 -- mean_d_loss: 2.39068794, mean_g_loss: 1034.53308105\n",
            "Epoch:  97 Step:    37  time: 1.307748 s d_loss: 1.22670472, g_loss: 1048.62011719 -- mean_d_loss: 2.37927628, mean_g_loss: 1034.67114258\n",
            "Epoch:  97 Step:    38  time: 1.293171 s d_loss: 1.13201070, g_loss: 1153.21557617 -- mean_d_loss: 2.36716700, mean_g_loss: 1035.82202148\n",
            "Epoch:  97 Step:    39  time: 1.298555 s d_loss: 0.73462576, g_loss: 895.05871582 -- mean_d_loss: 2.35146928, mean_g_loss: 1034.46862793\n",
            "Epoch:  97 Step:    40  time: 1.288885 s d_loss: 0.88576812, g_loss: 1092.51599121 -- mean_d_loss: 2.33751035, mean_g_loss: 1035.02148438\n",
            "Epoch:  97 Step:    41  time: 1.281157 s d_loss: 4.14955091, g_loss: 941.11071777 -- mean_d_loss: 2.35460496, mean_g_loss: 1034.13549805\n",
            "Epoch:  97 Step:    42  time: 1.282558 s d_loss: 1.38022077, g_loss: 1035.75854492 -- mean_d_loss: 2.34549856, mean_g_loss: 1034.15063477\n",
            "Epoch:  97 Step:    43  time: 1.318521 s d_loss: 1.12598705, g_loss: 1049.06091309 -- mean_d_loss: 2.33420682, mean_g_loss: 1034.28869629\n",
            "Epoch:  97 Step:    44  time: 1.328454 s d_loss: 0.86417961, g_loss: 889.58288574 -- mean_d_loss: 2.32072043, mean_g_loss: 1032.96118164\n",
            "Epoch:  97 Step:    45  time: 1.333836 s d_loss: 0.97173816, g_loss: 999.05572510 -- mean_d_loss: 2.30845690, mean_g_loss: 1032.65295410\n",
            "Epoch:  97 Step:    46  time: 1.278255 s d_loss: 0.57107556, g_loss: 1029.58447266 -- mean_d_loss: 2.29280496, mean_g_loss: 1032.62524414\n",
            "Epoch:  97 Step:    47  time: 1.315997 s d_loss: 0.70439488, g_loss: 1058.19531250 -- mean_d_loss: 2.27862263, mean_g_loss: 1032.85363770\n",
            "Epoch:  97 Step:    48  time: 1.284861 s d_loss: 0.66157049, g_loss: 956.30950928 -- mean_d_loss: 2.26431251, mean_g_loss: 1032.17626953\n",
            "Epoch:  97 Step:    49  time: 1.309518 s d_loss: 0.85014278, g_loss: 945.64501953 -- mean_d_loss: 2.25190735, mean_g_loss: 1031.41723633\n",
            "Epoch:  97 Step:    50  time: 1.300945 s d_loss: 2.97665715, g_loss: 1084.37573242 -- mean_d_loss: 2.25820947, mean_g_loss: 1031.87768555\n",
            "Epoch:  97 Step:    51  time: 1.272032 s d_loss: 0.95164281, g_loss: 1204.67724609 -- mean_d_loss: 2.24694586, mean_g_loss: 1033.36743164\n",
            "Epoch:  97 Step:    52  time: 1.317823 s d_loss: 0.78844333, g_loss: 1134.56799316 -- mean_d_loss: 2.23448014, mean_g_loss: 1034.23242188\n",
            "Epoch:  97 Step:    53  time: 1.326174 s d_loss: 0.75520277, g_loss: 1323.15649414 -- mean_d_loss: 2.22194386, mean_g_loss: 1036.68090820\n",
            "Epoch:  97 Step:    54  time: 1.287325 s d_loss: 0.65746725, g_loss: 976.03833008 -- mean_d_loss: 2.20879698, mean_g_loss: 1036.17126465\n",
            "Epoch:  97 Step:    55  time: 1.291147 s d_loss: 0.69471639, g_loss: 1019.67089844 -- mean_d_loss: 2.19617939, mean_g_loss: 1036.03381348\n",
            "Epoch:  97 Step:    56  time: 1.335776 s d_loss: 0.93071121, g_loss: 989.90747070 -- mean_d_loss: 2.18572116, mean_g_loss: 1035.65258789\n",
            "Epoch:  97 Step:    57  time: 1.331862 s d_loss: 0.73742545, g_loss: 1014.67413330 -- mean_d_loss: 2.17384982, mean_g_loss: 1035.48059082\n",
            "Epoch:  97 Step:    58  time: 1.284515 s d_loss: 0.88459456, g_loss: 999.74462891 -- mean_d_loss: 2.16336799, mean_g_loss: 1035.19006348\n",
            "Epoch:  97 Step:    59  time: 1.344419 s d_loss: 0.61278373, g_loss: 957.36291504 -- mean_d_loss: 2.15086341, mean_g_loss: 1034.56237793\n",
            "Epoch:  97 Step:    60  time: 1.314410 s d_loss: 0.85589385, g_loss: 1065.20373535 -- mean_d_loss: 2.14050364, mean_g_loss: 1034.80749512\n",
            "Epoch:  97 Step:    61  time: 1.289828 s d_loss: 0.77275360, g_loss: 1169.15173340 -- mean_d_loss: 2.12964869, mean_g_loss: 1035.87365723\n",
            "Epoch:  97 Step:    62  time: 1.317065 s d_loss: 1.25571895, g_loss: 1005.33801270 -- mean_d_loss: 2.12276721, mean_g_loss: 1035.63330078\n",
            "Epoch:  97 Step:    63  time: 1.307674 s d_loss: 2.68704820, g_loss: 1076.45996094 -- mean_d_loss: 2.12717557, mean_g_loss: 1035.95214844\n",
            "Epoch:  97 Step:    64  time: 1.327733 s d_loss: 0.83547121, g_loss: 1031.50439453 -- mean_d_loss: 2.11716247, mean_g_loss: 1035.91760254\n",
            "Epoch:  97 Step:    65  time: 1.302239 s d_loss: 0.56342989, g_loss: 880.08398438 -- mean_d_loss: 2.10521054, mean_g_loss: 1034.71887207\n",
            "Epoch:  97 Step:    66  time: 1.323309 s d_loss: 0.56745267, g_loss: 916.55993652 -- mean_d_loss: 2.09347177, mean_g_loss: 1033.81689453\n",
            "Epoch:  97 Step:    67  time: 1.357288 s d_loss: 0.69937450, g_loss: 1126.25903320 -- mean_d_loss: 2.08291054, mean_g_loss: 1034.51733398\n",
            "Epoch:  97 Step:    68  time: 1.321522 s d_loss: 0.64573038, g_loss: 993.24658203 -- mean_d_loss: 2.07210445, mean_g_loss: 1034.20703125\n",
            "Epoch:  97 Step:    69  time: 1.294587 s d_loss: 0.91664195, g_loss: 920.75836182 -- mean_d_loss: 2.06348181, mean_g_loss: 1033.36047363\n",
            "Epoch:  97 Step:    70  time: 1.318900 s d_loss: 0.63306987, g_loss: 1051.36511230 -- mean_d_loss: 2.05288601, mean_g_loss: 1033.49377441\n",
            "Epoch:  97 Step:    71  time: 1.321654 s d_loss: 0.77897310, g_loss: 1121.49597168 -- mean_d_loss: 2.04351902, mean_g_loss: 1034.14086914\n",
            "Epoch:  97 Step:    72  time: 1.339089 s d_loss: 1.38962018, g_loss: 997.53967285 -- mean_d_loss: 2.03874588, mean_g_loss: 1033.87377930\n",
            "Epoch:  97 Step:    73  time: 1.308424 s d_loss: 1.02304280, g_loss: 1185.69396973 -- mean_d_loss: 2.03138590, mean_g_loss: 1034.97387695\n",
            "Epoch:  97 Step:    74  time: 1.301273 s d_loss: 0.90585953, g_loss: 1070.16870117 -- mean_d_loss: 2.02328849, mean_g_loss: 1035.22705078\n",
            "Epoch:  97 Step:    75  time: 1.318867 s d_loss: 0.89080179, g_loss: 1046.86596680 -- mean_d_loss: 2.01519918, mean_g_loss: 1035.31018066\n",
            "Epoch:  97 Step:    76  time: 1.318224 s d_loss: 0.96578097, g_loss: 1005.44207764 -- mean_d_loss: 2.00775671, mean_g_loss: 1035.09826660\n",
            "Epoch:  97 Step:    77  time: 1.310613 s d_loss: 0.65198159, g_loss: 982.03631592 -- mean_d_loss: 1.99820888, mean_g_loss: 1034.72460938\n",
            "Epoch:  97 Step:    78  time: 1.329830 s d_loss: 0.59108907, g_loss: 952.87286377 -- mean_d_loss: 1.98836899, mean_g_loss: 1034.15222168\n",
            "Epoch:  97 Step:    79  time: 1.300449 s d_loss: 1.29941487, g_loss: 973.90576172 -- mean_d_loss: 1.98358452, mean_g_loss: 1033.73388672\n",
            "Epoch:  97 Step:    80  time: 1.338039 s d_loss: 0.57253706, g_loss: 1003.86877441 -- mean_d_loss: 1.97385311, mean_g_loss: 1033.52795410\n",
            "Epoch:  97 Step:    81  time: 1.329333 s d_loss: 0.63584149, g_loss: 906.58813477 -- mean_d_loss: 1.96468866, mean_g_loss: 1032.65844727\n",
            "Epoch:  97 Step:    82  time: 1.341691 s d_loss: 0.81837207, g_loss: 857.72021484 -- mean_d_loss: 1.95689046, mean_g_loss: 1031.46838379\n",
            "Epoch:  97 Step:    83  time: 1.328607 s d_loss: 0.71132141, g_loss: 916.31616211 -- mean_d_loss: 1.94847453, mean_g_loss: 1030.69030762\n",
            "Epoch:  97 Step:    84  time: 1.329519 s d_loss: 0.65600282, g_loss: 964.70880127 -- mean_d_loss: 1.93980026, mean_g_loss: 1030.24743652\n",
            "Epoch:  97 Step:    85  time: 1.307026 s d_loss: 0.49917963, g_loss: 1062.17199707 -- mean_d_loss: 1.93019617, mean_g_loss: 1030.46032715\n",
            "Epoch:  97 Step:    86  time: 1.315890 s d_loss: 0.63320279, g_loss: 844.60375977 -- mean_d_loss: 1.92160678, mean_g_loss: 1029.22949219\n",
            "Epoch:  97 Step:    87  time: 1.301291 s d_loss: 0.70155722, g_loss: 960.98840332 -- mean_d_loss: 1.91358030, mean_g_loss: 1028.78051758\n",
            "Epoch:  97 Step:    88  time: 1.293437 s d_loss: 0.68047690, g_loss: 1099.69409180 -- mean_d_loss: 1.90552080, mean_g_loss: 1029.24401855\n",
            "Epoch:  97 Step:    89  time: 1.295728 s d_loss: 0.66397673, g_loss: 979.15142822 -- mean_d_loss: 1.89745879, mean_g_loss: 1028.91870117\n",
            "Epoch:  97 Step:    90  time: 1.316929 s d_loss: 0.68085480, g_loss: 1104.36499023 -- mean_d_loss: 1.88960969, mean_g_loss: 1029.40539551\n",
            "Epoch:  97 Step:    91  time: 1.326163 s d_loss: 0.70951647, g_loss: 893.93304443 -- mean_d_loss: 1.88204491, mean_g_loss: 1028.53710938\n",
            "Epoch:  97 Step:    92  time: 1.325750 s d_loss: 1.19188535, g_loss: 1078.58862305 -- mean_d_loss: 1.87764895, mean_g_loss: 1028.85583496\n",
            "Epoch:  97 Step:    93  time: 1.323558 s d_loss: 0.67419028, g_loss: 1035.35168457 -- mean_d_loss: 1.87003219, mean_g_loss: 1028.89709473\n",
            "Epoch:  97 Step:    94  time: 1.326722 s d_loss: 0.70451105, g_loss: 1077.61254883 -- mean_d_loss: 1.86270177, mean_g_loss: 1029.20336914\n",
            "Epoch:  97 Step:    95  time: 1.318774 s d_loss: 0.64489007, g_loss: 969.15417480 -- mean_d_loss: 1.85509050, mean_g_loss: 1028.82812500\n",
            "Epoch:  97 Step:    96  time: 1.286832 s d_loss: 0.54868156, g_loss: 891.06335449 -- mean_d_loss: 1.84697616, mean_g_loss: 1027.97241211\n",
            "Epoch:  97 Step:    97  time: 1.296307 s d_loss: 1.61837101, g_loss: 1031.81445312 -- mean_d_loss: 1.84556508, mean_g_loss: 1027.99609375\n",
            "Epoch:  97 Step:    98  time: 1.336705 s d_loss: 0.70593661, g_loss: 998.20910645 -- mean_d_loss: 1.83857346, mean_g_loss: 1027.81335449\n",
            "Epoch:  97 Step:    99  time: 1.325270 s d_loss: 1.18377531, g_loss: 945.48339844 -- mean_d_loss: 1.83458078, mean_g_loss: 1027.31140137\n",
            "Epoch:  97 Step:   100  time: 1.322519 s d_loss: 0.43076649, g_loss: 1001.75622559 -- mean_d_loss: 1.82607269, mean_g_loss: 1027.15649414\n",
            "Epoch:  97 Step:   101  time: 1.295310 s d_loss: 0.54832357, g_loss: 996.55273438 -- mean_d_loss: 1.81837535, mean_g_loss: 1026.97204590\n",
            "Epoch:  97 Step:   102  time: 1.307829 s d_loss: 0.71111888, g_loss: 1170.81018066 -- mean_d_loss: 1.81174505, mean_g_loss: 1027.83337402\n",
            "Epoch:  97 Step:   103  time: 1.296041 s d_loss: 0.52725548, g_loss: 979.59179688 -- mean_d_loss: 1.80409932, mean_g_loss: 1027.54626465\n",
            "Epoch:  97 Step:   104  time: 1.294740 s d_loss: 0.58828175, g_loss: 907.01074219 -- mean_d_loss: 1.79690516, mean_g_loss: 1026.83300781\n",
            "Epoch:  97 Step:   105  time: 1.316662 s d_loss: 0.52085501, g_loss: 1086.70922852 -- mean_d_loss: 1.78939891, mean_g_loss: 1027.18518066\n",
            "Epoch:  97 Step:   106  time: 1.316933 s d_loss: 0.67533255, g_loss: 985.61108398 -- mean_d_loss: 1.78288388, mean_g_loss: 1026.94201660\n",
            "Epoch:  97 Step:   107  time: 1.302673 s d_loss: 0.48312014, g_loss: 907.60504150 -- mean_d_loss: 1.77532709, mean_g_loss: 1026.24829102\n",
            "Epoch:  97 Step:   108  time: 1.317102 s d_loss: 0.62211102, g_loss: 844.20098877 -- mean_d_loss: 1.76866102, mean_g_loss: 1025.19604492\n",
            "Epoch:  97 Step:   109  time: 1.316844 s d_loss: 0.67356825, g_loss: 925.28582764 -- mean_d_loss: 1.76236737, mean_g_loss: 1024.62182617\n",
            "Epoch:  97 Step:   110  time: 1.319761 s d_loss: 0.47308227, g_loss: 985.59051514 -- mean_d_loss: 1.75500000, mean_g_loss: 1024.39880371\n",
            "Epoch:  97 Step:   111  time: 1.318073 s d_loss: 1.35557616, g_loss: 921.74340820 -- mean_d_loss: 1.75273061, mean_g_loss: 1023.81549072\n",
            "Epoch:  97 Step:   112  time: 1.315014 s d_loss: 0.58431232, g_loss: 1115.72497559 -- mean_d_loss: 1.74612939, mean_g_loss: 1024.33471680\n",
            "Epoch:  97 Step:   113  time: 1.317349 s d_loss: 0.83784080, g_loss: 1018.70605469 -- mean_d_loss: 1.74102664, mean_g_loss: 1024.30310059\n",
            "Epoch:  97 Step:   114  time: 1.311464 s d_loss: 0.51506066, g_loss: 952.06860352 -- mean_d_loss: 1.73417771, mean_g_loss: 1023.89953613\n",
            "Epoch:  97 Step:   115  time: 1.281187 s d_loss: 0.77163255, g_loss: 970.00445557 -- mean_d_loss: 1.72883034, mean_g_loss: 1023.60009766\n",
            "Epoch:  97 Step:   116  time: 1.301931 s d_loss: 19.99364662, g_loss: 972.48803711 -- mean_d_loss: 1.82974088, mean_g_loss: 1023.31768799\n",
            "Epoch:  97 Step:   117  time: 1.290679 s d_loss: 1.09964812, g_loss: 846.69342041 -- mean_d_loss: 1.82572937, mean_g_loss: 1022.34716797\n",
            "Epoch:  97 Step:   118  time: 1.316951 s d_loss: 1.06563592, g_loss: 981.86804199 -- mean_d_loss: 1.82157588, mean_g_loss: 1022.12603760\n",
            "Epoch:  97 Step:   119  time: 1.305056 s d_loss: 0.69208199, g_loss: 928.47827148 -- mean_d_loss: 1.81543732, mean_g_loss: 1021.61712646\n",
            "Epoch:  97 Step:   120  time: 1.306762 s d_loss: 0.66960722, g_loss: 1032.99560547 -- mean_d_loss: 1.80924368, mean_g_loss: 1021.67864990\n",
            "Epoch:  97 Step:   121  time: 1.338519 s d_loss: 0.52991271, g_loss: 931.04040527 -- mean_d_loss: 1.80236554, mean_g_loss: 1021.19134521\n",
            "Epoch:  97 Step:   122  time: 1.325496 s d_loss: 0.59988618, g_loss: 965.92077637 -- mean_d_loss: 1.79593515, mean_g_loss: 1020.89581299\n",
            "Epoch:  97 Step:   123  time: 1.315551 s d_loss: 0.56420869, g_loss: 1053.74658203 -- mean_d_loss: 1.78938341, mean_g_loss: 1021.07055664\n",
            "Epoch:  97 Step:   124  time: 1.320276 s d_loss: 0.80302835, g_loss: 968.82263184 -- mean_d_loss: 1.78416467, mean_g_loss: 1020.79412842\n",
            "Epoch:  97 Step:   125  time: 1.325382 s d_loss: 0.48783362, g_loss: 1040.11938477 -- mean_d_loss: 1.77734184, mean_g_loss: 1020.89587402\n",
            "Epoch:  97 Step:   126  time: 1.321028 s d_loss: 0.80554390, g_loss: 931.80053711 -- mean_d_loss: 1.77225387, mean_g_loss: 1020.42938232\n",
            "Epoch:  97 Step:   127  time: 1.324145 s d_loss: 0.70583057, g_loss: 1141.13488770 -- mean_d_loss: 1.76669967, mean_g_loss: 1021.05810547\n",
            "Epoch:  97 Step:   128  time: 1.287402 s d_loss: 0.71758139, g_loss: 950.11456299 -- mean_d_loss: 1.76126385, mean_g_loss: 1020.69049072\n",
            "Epoch:  97 Step:   129  time: 1.289109 s d_loss: 0.96576983, g_loss: 1008.04772949 -- mean_d_loss: 1.75716329, mean_g_loss: 1020.62530518\n",
            "Epoch:  97 Step:   130  time: 1.326009 s d_loss: 0.65327185, g_loss: 1046.53112793 -- mean_d_loss: 1.75150228, mean_g_loss: 1020.75817871\n",
            "Epoch:  97 Step:   131  time: 1.297421 s d_loss: 0.60659432, g_loss: 840.51330566 -- mean_d_loss: 1.74566090, mean_g_loss: 1019.83856201\n",
            "Epoch:  97 Step:   132  time: 1.291934 s d_loss: 11.19232082, g_loss: 959.23150635 -- mean_d_loss: 1.79361343, mean_g_loss: 1019.53094482\n",
            "Epoch:  97 Step:   133  time: 1.310841 s d_loss: 1.16970825, g_loss: 836.76196289 -- mean_d_loss: 1.79046249, mean_g_loss: 1018.60784912\n",
            "Epoch:  97 Step:   134  time: 1.299886 s d_loss: 1.35623598, g_loss: 1176.05493164 -- mean_d_loss: 1.78828037, mean_g_loss: 1019.39910889\n",
            "Epoch:  97 Step:   135  time: 1.300369 s d_loss: 0.80858034, g_loss: 959.53784180 -- mean_d_loss: 1.78338194, mean_g_loss: 1019.09979248\n",
            "Epoch:  97 Step:   136  time: 1.318208 s d_loss: 0.47625485, g_loss: 1072.58666992 -- mean_d_loss: 1.77687883, mean_g_loss: 1019.36590576\n",
            "Epoch:  97 Step:   137  time: 1.337442 s d_loss: 0.59729528, g_loss: 1134.78576660 -- mean_d_loss: 1.77103925, mean_g_loss: 1019.93725586\n",
            "Epoch:  97 Step:   138  time: 1.320133 s d_loss: 0.66834676, g_loss: 861.82800293 -- mean_d_loss: 1.76560724, mean_g_loss: 1019.15838623\n",
            "Epoch:  97 Step:   139  time: 1.302603 s d_loss: 0.98009068, g_loss: 999.95983887 -- mean_d_loss: 1.76175678, mean_g_loss: 1019.06427002\n",
            "Epoch:  97 Step:   140  time: 1.321919 s d_loss: 0.82124144, g_loss: 877.63073730 -- mean_d_loss: 1.75716877, mean_g_loss: 1018.37432861\n",
            "Epoch:  97 Step:   141  time: 1.317152 s d_loss: 0.59580237, g_loss: 1192.71520996 -- mean_d_loss: 1.75153100, mean_g_loss: 1019.22064209\n",
            "Epoch:  97 Step:   142  time: 1.328061 s d_loss: 0.57792366, g_loss: 987.63439941 -- mean_d_loss: 1.74586141, mean_g_loss: 1019.06811523\n",
            "Epoch:  97 Step:   143  time: 1.312685 s d_loss: 4.08479309, g_loss: 1017.92004395 -- mean_d_loss: 1.75710618, mean_g_loss: 1019.06256104\n",
            "Epoch:  97 Step:   144  time: 1.294540 s d_loss: 0.60669166, g_loss: 885.18981934 -- mean_d_loss: 1.75160182, mean_g_loss: 1018.42199707\n",
            "Epoch:  97 Step:   145  time: 1.323879 s d_loss: 0.66412228, g_loss: 967.52905273 -- mean_d_loss: 1.74642336, mean_g_loss: 1018.17968750\n",
            "Epoch:  97 Step:   146  time: 1.320458 s d_loss: 0.79450136, g_loss: 1057.70434570 -- mean_d_loss: 1.74191189, mean_g_loss: 1018.36700439\n",
            "Epoch:  97 Step:   147  time: 1.283576 s d_loss: 0.81263095, g_loss: 1122.78161621 -- mean_d_loss: 1.73752844, mean_g_loss: 1018.85949707\n",
            "Epoch:  97 Step:   148  time: 1.333172 s d_loss: 1.21723270, g_loss: 900.00665283 -- mean_d_loss: 1.73508561, mean_g_loss: 1018.30151367\n",
            "Epoch:  97 Step:   149  time: 1.314945 s d_loss: 0.61322170, g_loss: 1074.08007812 -- mean_d_loss: 1.72984326, mean_g_loss: 1018.56213379\n",
            "Epoch:  97 Step:   150  time: 1.311092 s d_loss: 0.75363320, g_loss: 993.71270752 -- mean_d_loss: 1.72530282, mean_g_loss: 1018.44659424\n",
            "Epoch:  97 Step:   151  time: 1.289852 s d_loss: 0.91747522, g_loss: 1026.16833496 -- mean_d_loss: 1.72156286, mean_g_loss: 1018.48236084\n",
            "Epoch:  97 Step:   152  time: 1.341705 s d_loss: 0.89732516, g_loss: 1044.19824219 -- mean_d_loss: 1.71776462, mean_g_loss: 1018.60089111\n",
            "Epoch:  97 Step:   153  time: 1.341162 s d_loss: 2.06866765, g_loss: 1104.45068359 -- mean_d_loss: 1.71937418, mean_g_loss: 1018.99468994\n",
            "Epoch:  97 Step:   154  time: 1.313031 s d_loss: 0.56422555, g_loss: 1138.13464355 -- mean_d_loss: 1.71409965, mean_g_loss: 1019.53875732\n",
            "Epoch:  97 Step:   155  time: 1.300445 s d_loss: 0.63565290, g_loss: 922.50708008 -- mean_d_loss: 1.70919764, mean_g_loss: 1019.09765625\n",
            "Epoch:  97 Step:   156  time: 1.317009 s d_loss: 0.80621052, g_loss: 970.09582520 -- mean_d_loss: 1.70511162, mean_g_loss: 1018.87591553\n",
            "Epoch:  97 Step:   157  time: 1.322916 s d_loss: 0.66481900, g_loss: 1110.43750000 -- mean_d_loss: 1.70042574, mean_g_loss: 1019.28833008\n",
            "Epoch:  97 Step:   158  time: 1.318174 s d_loss: 2.56894302, g_loss: 1042.50207520 -- mean_d_loss: 1.70432043, mean_g_loss: 1019.39245605\n",
            "Epoch:  97 Step:   159  time: 1.306322 s d_loss: 0.82445502, g_loss: 1067.12719727 -- mean_d_loss: 1.70039248, mean_g_loss: 1019.60552979\n",
            "Epoch:  97 Step:   160  time: 1.325297 s d_loss: 0.49698943, g_loss: 982.88616943 -- mean_d_loss: 1.69504392, mean_g_loss: 1019.44238281\n",
            "Epoch:  97 Step:   161  time: 1.287889 s d_loss: 0.59228796, g_loss: 1009.17285156 -- mean_d_loss: 1.69016445, mean_g_loss: 1019.39691162\n",
            "Epoch:  97 Step:   162  time: 1.318322 s d_loss: 0.67193937, g_loss: 1020.27832031 -- mean_d_loss: 1.68567884, mean_g_loss: 1019.40081787\n",
            "Epoch:  97 Step:   163  time: 1.343709 s d_loss: 0.75266892, g_loss: 1048.11328125 -- mean_d_loss: 1.68158674, mean_g_loss: 1019.52673340\n",
            "Epoch:  97 Step:   164  time: 1.328398 s d_loss: 0.47203574, g_loss: 1018.27990723 -- mean_d_loss: 1.67630482, mean_g_loss: 1019.52130127\n",
            "Epoch:  97 Step:   165  time: 1.307307 s d_loss: 0.50953281, g_loss: 1067.58068848 -- mean_d_loss: 1.67123187, mean_g_loss: 1019.73022461\n",
            "Epoch:  97 Step:   166  time: 1.297830 s d_loss: 0.49564222, g_loss: 1018.08093262 -- mean_d_loss: 1.66614270, mean_g_loss: 1019.72308350\n",
            "Epoch:  97 Step:   167  time: 1.327651 s d_loss: 0.72438979, g_loss: 1036.75732422 -- mean_d_loss: 1.66208351, mean_g_loss: 1019.79644775\n",
            "Epoch:  97 Step:   168  time: 1.315723 s d_loss: 0.55174798, g_loss: 927.08825684 -- mean_d_loss: 1.65731812, mean_g_loss: 1019.39862061\n",
            "Epoch:  97 Step:   169  time: 1.314425 s d_loss: 0.91313684, g_loss: 1176.30932617 -- mean_d_loss: 1.65413785, mean_g_loss: 1020.06915283\n",
            "Epoch:  97 Step:   170  time: 1.315689 s d_loss: 0.92369318, g_loss: 1014.22760010 -- mean_d_loss: 1.65102971, mean_g_loss: 1020.04437256\n",
            "Epoch:  97 Step:   171  time: 1.295749 s d_loss: 14.79938984, g_loss: 948.34381104 -- mean_d_loss: 1.70674300, mean_g_loss: 1019.74053955\n",
            "Epoch:  97 Step:   172  time: 1.332500 s d_loss: 0.74638391, g_loss: 1026.14941406 -- mean_d_loss: 1.70269096, mean_g_loss: 1019.76757812\n",
            "Epoch:  97 Step:   173  time: 1.323750 s d_loss: 5.21742439, g_loss: 1118.12780762 -- mean_d_loss: 1.71745872, mean_g_loss: 1020.18084717\n",
            "Epoch:  97 Step:   174  time: 1.316880 s d_loss: 11.86732960, g_loss: 1103.64306641 -- mean_d_loss: 1.75992692, mean_g_loss: 1020.53009033\n",
            "Epoch:  97 Step:   175  time: 1.298605 s d_loss: 1.54027152, g_loss: 1094.89428711 -- mean_d_loss: 1.75901175, mean_g_loss: 1020.83990479\n",
            "Epoch:  97 Step:   176  time: 1.294858 s d_loss: 1.93390667, g_loss: 1045.42822266 -- mean_d_loss: 1.75973737, mean_g_loss: 1020.94189453\n",
            "Epoch:  97 Step:   177  time: 1.325775 s d_loss: 3.66563511, g_loss: 1028.60107422 -- mean_d_loss: 1.76761305, mean_g_loss: 1020.97351074\n",
            "Epoch:  97 Step:   178  time: 1.310963 s d_loss: 6.60916519, g_loss: 940.75921631 -- mean_d_loss: 1.78753710, mean_g_loss: 1020.64343262\n",
            "Epoch:  97 Step:   179  time: 1.331777 s d_loss: 1.60199320, g_loss: 990.46850586 -- mean_d_loss: 1.78677666, mean_g_loss: 1020.51977539\n",
            "Epoch:  97 Step:   180  time: 1.318445 s d_loss: 2.21480680, g_loss: 968.96771240 -- mean_d_loss: 1.78852379, mean_g_loss: 1020.30938721\n",
            "Epoch:  97 Step:   181  time: 1.321911 s d_loss: 0.85935253, g_loss: 1040.00415039 -- mean_d_loss: 1.78474665, mean_g_loss: 1020.38940430\n",
            "Epoch:  97 Step:   182  time: 1.333908 s d_loss: 2.43356323, g_loss: 1161.61389160 -- mean_d_loss: 1.78737342, mean_g_loss: 1020.96118164\n",
            "Epoch:  97 Step:   183  time: 1.316532 s d_loss: 1.27555203, g_loss: 989.03540039 -- mean_d_loss: 1.78530955, mean_g_loss: 1020.83239746\n",
            "Epoch:  97 Step:   184  time: 1.303984 s d_loss: 47.48380280, g_loss: 1099.13183594 -- mean_d_loss: 1.96883762, mean_g_loss: 1021.14685059\n",
            "Epoch:  97 Step:   185  time: 1.314473 s d_loss: 1.98504674, g_loss: 1134.96655273 -- mean_d_loss: 1.96890247, mean_g_loss: 1021.60211182\n",
            "Epoch:  97 Step:   186  time: 1.321365 s d_loss: 1.36422420, g_loss: 1031.44995117 -- mean_d_loss: 1.96649337, mean_g_loss: 1021.64135742\n",
            "Epoch:  97 Step:   187  time: 1.327272 s d_loss: 2.77341580, g_loss: 1159.19555664 -- mean_d_loss: 1.96969545, mean_g_loss: 1022.18725586\n",
            "Epoch:  97 Step:   188  time: 1.336604 s d_loss: 12.71434689, g_loss: 1001.30639648 -- mean_d_loss: 2.01216435, mean_g_loss: 1022.10473633\n",
            "Epoch:  97 Step:   189  time: 1.321465 s d_loss: 3.44267154, g_loss: 961.72863770 -- mean_d_loss: 2.01779628, mean_g_loss: 1021.86706543\n",
            "Epoch:  97 Step:   190  time: 1.317208 s d_loss: 2.06733894, g_loss: 1104.95800781 -- mean_d_loss: 2.01799059, mean_g_loss: 1022.19287109\n",
            "Epoch:  97 Step:   191  time: 1.324946 s d_loss: 1.11558533, g_loss: 1050.20336914 -- mean_d_loss: 2.01446557, mean_g_loss: 1022.30230713\n",
            "Epoch:  97 Step:   192  time: 1.317197 s d_loss: 0.96473777, g_loss: 1155.41223145 -- mean_d_loss: 2.01038098, mean_g_loss: 1022.82031250\n",
            "Epoch:  97 Step:   193  time: 1.317223 s d_loss: 0.90431190, g_loss: 1093.49230957 -- mean_d_loss: 2.00609374, mean_g_loss: 1023.09423828\n",
            "Epoch:  97 Step:   194  time: 1.312601 s d_loss: 2.55261397, g_loss: 936.96948242 -- mean_d_loss: 2.00820398, mean_g_loss: 1022.76171875\n",
            "Epoch:  97 Step:   195  time: 1.327402 s d_loss: 1.53922653, g_loss: 1057.80151367 -- mean_d_loss: 2.00640035, mean_g_loss: 1022.89648438\n",
            "Epoch:  97 Step:   196  time: 1.327976 s d_loss: 2.30093598, g_loss: 1031.67041016 -- mean_d_loss: 2.00752878, mean_g_loss: 1022.93005371\n",
            "Epoch:  97 Step:   197  time: 1.321661 s d_loss: 2.16751862, g_loss: 1168.67565918 -- mean_d_loss: 2.00813961, mean_g_loss: 1023.48638916\n",
            "Epoch:  97 Step:   198  time: 1.298670 s d_loss: 1.67575979, g_loss: 944.98345947 -- mean_d_loss: 2.00687575, mean_g_loss: 1023.18786621\n",
            "Epoch:  97 Step:   199  time: 1.313518 s d_loss: 1.76772535, g_loss: 1119.25842285 -- mean_d_loss: 2.00597000, mean_g_loss: 1023.55175781\n",
            "Epoch:  97 Step:   200  time: 1.301563 s d_loss: 0.80932319, g_loss: 1037.52856445 -- mean_d_loss: 0.80932319, mean_g_loss: 1037.52856445\n",
            "Epoch:  97 Step:   201  time: 1.329139 s d_loss: 54.81853485, g_loss: 1107.68945312 -- mean_d_loss: 27.81392860, mean_g_loss: 1072.60900879\n",
            "Epoch:  97 Step:   202  time: 1.305271 s d_loss: 2.39948845, g_loss: 860.94409180 -- mean_d_loss: 19.34244728, mean_g_loss: 1002.05401611\n",
            "Epoch:  97 Step:   203  time: 1.281165 s d_loss: 1.89188612, g_loss: 1114.12426758 -- mean_d_loss: 14.97980785, mean_g_loss: 1030.07153320\n",
            "Epoch:  97 Step:   204  time: 1.336806 s d_loss: 33.99559021, g_loss: 1009.23266602 -- mean_d_loss: 18.78296471, mean_g_loss: 1025.90368652\n",
            "Epoch:  97 Step:   205  time: 1.318563 s d_loss: 2.23416352, g_loss: 940.02832031 -- mean_d_loss: 16.02483177, mean_g_loss: 1011.59112549\n",
            "Epoch:  97 Step:   206  time: 1.316197 s d_loss: 5.97199965, g_loss: 1049.54785156 -- mean_d_loss: 14.58871269, mean_g_loss: 1017.01354980\n",
            "Epoch:  97 Step:   207  time: 1.329942 s d_loss: 7.26890945, g_loss: 964.10131836 -- mean_d_loss: 13.67373657, mean_g_loss: 1010.39953613\n",
            "Epoch:  97 Step:   208  time: 1.334237 s d_loss: 5.04443455, g_loss: 1124.28344727 -- mean_d_loss: 12.71492481, mean_g_loss: 1023.05328369\n",
            "Epoch:  97 Step:   209  time: 1.311785 s d_loss: 3.60570335, g_loss: 1053.00048828 -- mean_d_loss: 11.80400276, mean_g_loss: 1026.04809570\n",
            "Epoch:  97 Step:   210  time: 1.333078 s d_loss: 2.04505014, g_loss: 855.74475098 -- mean_d_loss: 10.91682529, mean_g_loss: 1010.56597900\n",
            "Epoch:  97 Step:   211  time: 1.330000 s d_loss: 3.12693977, g_loss: 1001.92456055 -- mean_d_loss: 10.26766872, mean_g_loss: 1009.84588623\n",
            "Epoch:  97 Step:   212  time: 1.327057 s d_loss: 1.46386373, g_loss: 836.10522461 -- mean_d_loss: 9.59045315, mean_g_loss: 996.48120117\n",
            "Epoch:  97 Step:   213  time: 1.326793 s d_loss: 1.59066510, g_loss: 1078.96875000 -- mean_d_loss: 9.01904011, mean_g_loss: 1002.37316895\n",
            "Epoch:  97 Step:   214  time: 1.314481 s d_loss: 1.62075424, g_loss: 964.61254883 -- mean_d_loss: 8.52582073, mean_g_loss: 999.85577393\n",
            "Epoch:  97 Step:   215  time: 1.325471 s d_loss: 1.06416392, g_loss: 886.92126465 -- mean_d_loss: 8.05946732, mean_g_loss: 992.79736328\n",
            "Epoch:  97 Step:   216  time: 1.340276 s d_loss: 1.49218059, g_loss: 1009.72985840 -- mean_d_loss: 7.67315674, mean_g_loss: 993.79345703\n",
            "Epoch:  97 Step:   217  time: 1.302533 s d_loss: 0.83474094, g_loss: 1026.56542969 -- mean_d_loss: 7.29324532, mean_g_loss: 995.61413574\n",
            "Epoch:  97 Step:   218  time: 1.302523 s d_loss: 0.84408331, g_loss: 926.07946777 -- mean_d_loss: 6.95381546, mean_g_loss: 991.95446777\n",
            "Epoch:  97 Step:   219  time: 1.300748 s d_loss: 0.96110368, g_loss: 1141.92968750 -- mean_d_loss: 6.65418005, mean_g_loss: 999.45324707\n",
            "Epoch:  97 Step:   220  time: 1.314345 s d_loss: 1.85165226, g_loss: 1039.04541016 -- mean_d_loss: 6.42548847, mean_g_loss: 1001.33856201\n",
            "Epoch:  97 Step:   221  time: 1.335582 s d_loss: 1.71298063, g_loss: 1109.09851074 -- mean_d_loss: 6.21128368, mean_g_loss: 1006.23669434\n",
            "Epoch:  97 Step:   222  time: 1.323518 s d_loss: 38.85745239, g_loss: 918.99450684 -- mean_d_loss: 7.63068247, mean_g_loss: 1002.44354248\n",
            "Epoch:  97 Step:   223  time: 1.320731 s d_loss: 15.06314945, g_loss: 1074.73706055 -- mean_d_loss: 7.94036865, mean_g_loss: 1005.45574951\n",
            "Epoch:  97 Step:   224  time: 1.282619 s d_loss: 4.94045544, g_loss: 1083.86254883 -- mean_d_loss: 7.82037210, mean_g_loss: 1008.59204102\n",
            "Epoch:  97 Step:   225  time: 1.321357 s d_loss: 1.33601391, g_loss: 1024.76745605 -- mean_d_loss: 7.57097387, mean_g_loss: 1009.21417236\n",
            "Epoch:  97 Step:   226  time: 1.320662 s d_loss: 4.88849068, g_loss: 1003.88305664 -- mean_d_loss: 7.47162247, mean_g_loss: 1009.01672363\n",
            "Epoch:  97 Step:   227  time: 1.318696 s d_loss: 3.28695226, g_loss: 933.81079102 -- mean_d_loss: 7.32217026, mean_g_loss: 1006.33074951\n",
            "Epoch:  97 Step:   228  time: 1.310830 s d_loss: 18.47975922, g_loss: 1112.90612793 -- mean_d_loss: 7.70691442, mean_g_loss: 1010.00579834\n",
            "Epoch:  97 Step:   229  time: 1.312779 s d_loss: 0.94118184, g_loss: 950.20184326 -- mean_d_loss: 7.48139000, mean_g_loss: 1008.01232910\n",
            "Epoch:  97 Step:   230  time: 1.324239 s d_loss: 2.09254313, g_loss: 1118.10925293 -- mean_d_loss: 7.30755615, mean_g_loss: 1011.56384277\n",
            "Epoch:  97 Step:   231  time: 1.313777 s d_loss: 0.89522088, g_loss: 1157.43566895 -- mean_d_loss: 7.10717058, mean_g_loss: 1016.12231445\n",
            "Epoch:  97 Step:   232  time: 1.300615 s d_loss: 3.23286867, g_loss: 1214.53112793 -- mean_d_loss: 6.98976755, mean_g_loss: 1022.13470459\n",
            "Epoch:  97 Step:   233  time: 1.317494 s d_loss: 3.98902726, g_loss: 937.43774414 -- mean_d_loss: 6.90151024, mean_g_loss: 1019.64361572\n",
            "Epoch:  97 Step:   234  time: 1.310567 s d_loss: 1.32319534, g_loss: 1019.06408691 -- mean_d_loss: 6.74212980, mean_g_loss: 1019.62701416\n",
            "Epoch:  97 Step:   235  time: 1.312797 s d_loss: 1.50486660, g_loss: 1062.75964355 -- mean_d_loss: 6.59665060, mean_g_loss: 1020.82507324\n",
            "Epoch:  97 Step:   236  time: 1.326025 s d_loss: 1.28571796, g_loss: 914.70605469 -- mean_d_loss: 6.45311165, mean_g_loss: 1017.95703125\n",
            "Epoch:  97 Step:   237  time: 1.325272 s d_loss: 0.60774904, g_loss: 821.23229980 -- mean_d_loss: 6.29928637, mean_g_loss: 1012.78002930\n",
            "Epoch:  97 Step:   238  time: 1.334251 s d_loss: 0.86240953, g_loss: 973.87322998 -- mean_d_loss: 6.15987921, mean_g_loss: 1011.78247070\n",
            "Epoch:  97 Step:   239  time: 1.327919 s d_loss: 0.76258665, g_loss: 953.69409180 -- mean_d_loss: 6.02494717, mean_g_loss: 1010.33026123\n",
            "Epoch:  97 Step:   240  time: 1.309076 s d_loss: 0.52953964, g_loss: 1009.05291748 -- mean_d_loss: 5.89091253, mean_g_loss: 1010.29913330\n",
            "Epoch:  97 Step:   241  time: 1.292523 s d_loss: 27.16142082, g_loss: 1034.22778320 -- mean_d_loss: 6.39735317, mean_g_loss: 1010.86883545\n",
            "Epoch:  97 Step:   242  time: 1.307854 s d_loss: 2.18050575, g_loss: 946.30218506 -- mean_d_loss: 6.29928732, mean_g_loss: 1009.36724854\n",
            "Epoch:  97 Step:   243  time: 1.284127 s d_loss: 2.99132156, g_loss: 1044.89721680 -- mean_d_loss: 6.22410631, mean_g_loss: 1010.17480469\n",
            "Epoch:  97 Step:   244  time: 1.296245 s d_loss: 4.63605213, g_loss: 950.85461426 -- mean_d_loss: 6.18881655, mean_g_loss: 1008.85656738\n",
            "Epoch:  97 Step:   245  time: 1.316630 s d_loss: 5.02298641, g_loss: 890.89550781 -- mean_d_loss: 6.16347218, mean_g_loss: 1006.29217529\n",
            "Epoch:  97 Step:   246  time: 1.319520 s d_loss: 6.34010124, g_loss: 1018.74554443 -- mean_d_loss: 6.16722965, mean_g_loss: 1006.55718994\n",
            "Epoch:  97 Step:   247  time: 1.327605 s d_loss: 1.28553152, g_loss: 855.14721680 -- mean_d_loss: 6.06552744, mean_g_loss: 1003.40283203\n",
            "Epoch:  97 Step:   248  time: 1.334769 s d_loss: 1.07153082, g_loss: 1016.39465332 -- mean_d_loss: 5.96360922, mean_g_loss: 1003.66796875\n",
            "Epoch:  97 Step:   249  time: 1.303332 s d_loss: 11.90535450, g_loss: 1132.14819336 -- mean_d_loss: 6.08244467, mean_g_loss: 1006.23754883\n",
            "Epoch:  97 Step:   250  time: 1.288250 s d_loss: 1.53964746, g_loss: 1147.14025879 -- mean_d_loss: 5.99337006, mean_g_loss: 1009.00036621\n",
            "Epoch:  97 Step:   251  time: 1.304134 s d_loss: 1.28271949, g_loss: 1066.66406250 -- mean_d_loss: 5.90278053, mean_g_loss: 1010.10931396\n",
            "Epoch:  97 Step:   252  time: 1.293743 s d_loss: 1.14151883, g_loss: 872.09155273 -- mean_d_loss: 5.81294489, mean_g_loss: 1007.50518799\n",
            "Epoch:  97 Step:   253  time: 1.308072 s d_loss: 1.55995917, g_loss: 1056.58081055 -- mean_d_loss: 5.73418617, mean_g_loss: 1008.41400146\n",
            "Epoch:  97 Step:   254  time: 1.348716 s d_loss: 43.06689072, g_loss: 1038.71191406 -- mean_d_loss: 6.41296291, mean_g_loss: 1008.96484375\n",
            "Epoch:  97 Step:   255  time: 1.332024 s d_loss: 28.98665237, g_loss: 830.20874023 -- mean_d_loss: 6.81606436, mean_g_loss: 1005.77276611\n",
            "Epoch:  97 Step:   256  time: 1.302451 s d_loss: 4.47729826, g_loss: 945.97045898 -- mean_d_loss: 6.77503347, mean_g_loss: 1004.72357178\n",
            "Epoch:  97 Step:   257  time: 1.304655 s d_loss: 3.12485099, g_loss: 1012.74389648 -- mean_d_loss: 6.71209908, mean_g_loss: 1004.86181641\n",
            "Epoch:  97 Step:   258  time: 1.323223 s d_loss: 4.50854111, g_loss: 1031.05651855 -- mean_d_loss: 6.67475080, mean_g_loss: 1005.30572510\n",
            "Epoch:  97 Step:   259  time: 1.291357 s d_loss: 13.55942726, g_loss: 1013.04022217 -- mean_d_loss: 6.78949547, mean_g_loss: 1005.43463135\n",
            "Epoch:  97 Step:   260  time: 1.316576 s d_loss: 3.27078128, g_loss: 865.18652344 -- mean_d_loss: 6.73181152, mean_g_loss: 1003.13549805\n",
            "Epoch:  97 Step:   261  time: 1.329382 s d_loss: 4.59843540, g_loss: 1143.26770020 -- mean_d_loss: 6.69740248, mean_g_loss: 1005.39575195\n",
            "Epoch:  97 Step:   262  time: 1.277066 s d_loss: 3.65790272, g_loss: 1145.27416992 -- mean_d_loss: 6.64915657, mean_g_loss: 1007.61602783\n",
            "Epoch:  97 Step:   263  time: 1.300092 s d_loss: 2.73787737, g_loss: 991.70922852 -- mean_d_loss: 6.58804274, mean_g_loss: 1007.36749268\n",
            "Epoch:  97 Step:   264  time: 1.324657 s d_loss: 3.71965051, g_loss: 1077.48535156 -- mean_d_loss: 6.54391384, mean_g_loss: 1008.44628906\n",
            "Epoch:  97 Step:   265  time: 1.285129 s d_loss: 1.34534693, g_loss: 959.50964355 -- mean_d_loss: 6.46514750, mean_g_loss: 1007.70477295\n",
            "Epoch:  97 Step:   266  time: 1.285662 s d_loss: 1.75356209, g_loss: 1068.97705078 -- mean_d_loss: 6.39482546, mean_g_loss: 1008.61926270\n",
            "Epoch:  97 Step:   267  time: 1.285853 s d_loss: 4.82438707, g_loss: 1008.65625000 -- mean_d_loss: 6.37173080, mean_g_loss: 1008.61981201\n",
            "Epoch:  97 Step:   268  time: 1.317142 s d_loss: 61.72826004, g_loss: 1061.48205566 -- mean_d_loss: 7.17399979, mean_g_loss: 1009.38598633\n",
            "Epoch:  97 Step:   269  time: 1.334193 s d_loss: 2.24136257, g_loss: 1140.49121094 -- mean_d_loss: 7.10353327, mean_g_loss: 1011.25891113\n",
            "Epoch:  97 Step:   270  time: 1.320223 s d_loss: 3.54014659, g_loss: 1002.62207031 -- mean_d_loss: 7.05334520, mean_g_loss: 1011.13732910\n",
            "Epoch:  97 Step:   271  time: 1.360371 s d_loss: 2.59972024, g_loss: 1042.03759766 -- mean_d_loss: 6.99148941, mean_g_loss: 1011.56652832\n",
            "Epoch:  97 Step:   272  time: 1.281880 s d_loss: 1.92781734, g_loss: 959.50921631 -- mean_d_loss: 6.92212439, mean_g_loss: 1010.85339355\n",
            "Epoch:  97 Step:   273  time: 1.332834 s d_loss: 1.80441058, g_loss: 1002.56274414 -- mean_d_loss: 6.85296583, mean_g_loss: 1010.74133301\n",
            "Epoch:  97 Step:   274  time: 1.330013 s d_loss: 1.12775207, g_loss: 845.67059326 -- mean_d_loss: 6.77662945, mean_g_loss: 1008.54040527\n",
            "Epoch:  97 Step:   275  time: 1.294250 s d_loss: 0.79538542, g_loss: 919.52893066 -- mean_d_loss: 6.69792891, mean_g_loss: 1007.36926270\n",
            "Epoch:  97 Step:   276  time: 1.323005 s d_loss: 0.84692115, g_loss: 1165.35192871 -- mean_d_loss: 6.62194204, mean_g_loss: 1009.42095947\n",
            "Epoch:  97 Step:   277  time: 1.318362 s d_loss: 1.36184645, g_loss: 1012.87756348 -- mean_d_loss: 6.55450487, mean_g_loss: 1009.46527100\n",
            "Epoch:  97 Step:   278  time: 1.312740 s d_loss: 2.46368527, g_loss: 1043.18664551 -- mean_d_loss: 6.50272274, mean_g_loss: 1009.89208984\n",
            "Epoch:  97 Step:   279  time: 1.303718 s d_loss: 0.78152192, g_loss: 940.34643555 -- mean_d_loss: 6.43120718, mean_g_loss: 1009.02276611\n",
            "Epoch:  97 Step:   280  time: 1.330487 s d_loss: 2.03602958, g_loss: 1166.34790039 -- mean_d_loss: 6.37694550, mean_g_loss: 1010.96508789\n",
            "Epoch:  97 Step:   281  time: 1.335332 s d_loss: 1.90561557, g_loss: 1076.57128906 -- mean_d_loss: 6.32241726, mean_g_loss: 1011.76513672\n",
            "Epoch:  97 Step:   282  time: 1.326457 s d_loss: 1.02614152, g_loss: 907.83886719 -- mean_d_loss: 6.25860691, mean_g_loss: 1010.51300049\n",
            "Epoch:  97 Step:   283  time: 1.287248 s d_loss: 0.70587242, g_loss: 1004.73382568 -- mean_d_loss: 6.19250250, mean_g_loss: 1010.44421387\n",
            "Epoch:  97 Step:   284  time: 1.296271 s d_loss: 0.79693311, g_loss: 931.26745605 -- mean_d_loss: 6.12902546, mean_g_loss: 1009.51269531\n",
            "Epoch:  97 Step:   285  time: 1.311695 s d_loss: 0.62366366, g_loss: 980.79541016 -- mean_d_loss: 6.06500959, mean_g_loss: 1009.17877197\n",
            "Epoch:  97 Step:   286  time: 1.324995 s d_loss: 47.41232300, g_loss: 929.13983154 -- mean_d_loss: 6.54026651, mean_g_loss: 1008.25878906\n",
            "Epoch:  97 Step:   287  time: 1.293118 s d_loss: 2.42724085, g_loss: 998.15606689 -- mean_d_loss: 6.49352741, mean_g_loss: 1008.14398193\n",
            "Epoch:  97 Step:   288  time: 1.314055 s d_loss: 1.28202569, g_loss: 861.09448242 -- mean_d_loss: 6.43497133, mean_g_loss: 1006.49176025\n",
            "Epoch:  97 Step:   289  time: 1.325322 s d_loss: 3.11977339, g_loss: 891.59313965 -- mean_d_loss: 6.39813566, mean_g_loss: 1005.21508789\n",
            "Epoch:  97 Step:   290  time: 1.299326 s d_loss: 0.98706716, g_loss: 1092.03833008 -- mean_d_loss: 6.33867311, mean_g_loss: 1006.16918945\n",
            "Epoch:  97 Step:   291  time: 1.315805 s d_loss: 0.86473477, g_loss: 935.78967285 -- mean_d_loss: 6.27917433, mean_g_loss: 1005.40423584\n",
            "Epoch:  97 Step:   292  time: 1.343025 s d_loss: 0.60952109, g_loss: 982.54846191 -- mean_d_loss: 6.21820974, mean_g_loss: 1005.15844727\n",
            "Epoch:  97 Step:   293  time: 1.292396 s d_loss: 0.89640903, g_loss: 966.16870117 -- mean_d_loss: 6.16159534, mean_g_loss: 1004.74371338\n",
            "Epoch:  97 Step:   294  time: 1.318263 s d_loss: 1.19374001, g_loss: 1092.04919434 -- mean_d_loss: 6.10930157, mean_g_loss: 1005.66265869\n",
            "Epoch:  97 Step:   295  time: 1.320132 s d_loss: 0.71823055, g_loss: 1034.01904297 -- mean_d_loss: 6.05314445, mean_g_loss: 1005.95800781\n",
            "Epoch:  97 Step:   296  time: 1.306936 s d_loss: 0.96729636, g_loss: 1018.74243164 -- mean_d_loss: 6.00071287, mean_g_loss: 1006.08978271\n",
            "Epoch:  97 Step:   297  time: 1.336260 s d_loss: 1.81910729, g_loss: 1089.65356445 -- mean_d_loss: 5.95804310, mean_g_loss: 1006.94250488\n",
            "Epoch:  97 Step:   298  time: 1.328945 s d_loss: 1.22441995, g_loss: 985.45379639 -- mean_d_loss: 5.91022921, mean_g_loss: 1006.72546387\n",
            "Epoch:  97 Step:   299  time: 1.303136 s d_loss: 0.65540898, g_loss: 1068.79101562 -- mean_d_loss: 5.85768080, mean_g_loss: 1007.34606934\n",
            "Epoch:  97 Step:   300  time: 1.301148 s d_loss: 1.05339646, g_loss: 1165.40283203 -- mean_d_loss: 5.81011343, mean_g_loss: 1008.91107178\n",
            "Epoch:  97 Step:   301  time: 1.326545 s d_loss: 2.03026247, g_loss: 994.34985352 -- mean_d_loss: 5.77305651, mean_g_loss: 1008.76831055\n",
            "Epoch:  97 Step:   302  time: 1.322705 s d_loss: 0.70185161, g_loss: 1185.12158203 -- mean_d_loss: 5.72382116, mean_g_loss: 1010.48052979\n",
            "Epoch:  97 Step:   303  time: 1.316925 s d_loss: 0.77730024, g_loss: 1047.89099121 -- mean_d_loss: 5.67625856, mean_g_loss: 1010.84020996\n",
            "Epoch:  97 Step:   304  time: 1.319990 s d_loss: 0.80981988, g_loss: 1247.24340820 -- mean_d_loss: 5.62991142, mean_g_loss: 1013.09167480\n",
            "Epoch:  97 Step:   305  time: 1.286291 s d_loss: 0.68843734, g_loss: 1071.41442871 -- mean_d_loss: 5.58329344, mean_g_loss: 1013.64190674\n",
            "Epoch:  97 Step:   306  time: 1.315152 s d_loss: 36.01101685, g_loss: 924.99676514 -- mean_d_loss: 5.86766434, mean_g_loss: 1012.81347656\n",
            "Epoch:  97 Step:   307  time: 1.315574 s d_loss: 4.49193525, g_loss: 1003.76574707 -- mean_d_loss: 5.85492611, mean_g_loss: 1012.72967529\n",
            "Epoch:  97 Step:   308  time: 1.320515 s d_loss: 1.68378079, g_loss: 1080.95092773 -- mean_d_loss: 5.81665897, mean_g_loss: 1013.35559082\n",
            "Epoch:  97 Step:   309  time: 1.314209 s d_loss: 2.70918274, g_loss: 1059.13171387 -- mean_d_loss: 5.78840876, mean_g_loss: 1013.77172852\n",
            "Epoch:  97 Step:   310  time: 1.336795 s d_loss: 0.94772023, g_loss: 999.20336914 -- mean_d_loss: 5.74479866, mean_g_loss: 1013.64050293\n",
            "Epoch:  97 Step:   311  time: 1.321599 s d_loss: 1.55302477, g_loss: 997.88464355 -- mean_d_loss: 5.70737219, mean_g_loss: 1013.49981689\n",
            "Epoch:  97 Step:   312  time: 1.323815 s d_loss: 2.19230151, g_loss: 1140.68334961 -- mean_d_loss: 5.67626572, mean_g_loss: 1014.62530518\n",
            "Epoch:  97 Step:   313  time: 1.320636 s d_loss: 1.10763180, g_loss: 1087.09472656 -- mean_d_loss: 5.63618994, mean_g_loss: 1015.26098633\n",
            "Epoch:  97 Step:   314  time: 1.312447 s d_loss: 0.79556119, g_loss: 930.97479248 -- mean_d_loss: 5.59409714, mean_g_loss: 1014.52807617\n",
            "Epoch:  97 Step:   315  time: 1.337839 s d_loss: 2.09635162, g_loss: 998.87255859 -- mean_d_loss: 5.56394434, mean_g_loss: 1014.39312744\n",
            "Epoch:  97 Step:   316  time: 1.338084 s d_loss: 0.64472049, g_loss: 1144.66479492 -- mean_d_loss: 5.52189970, mean_g_loss: 1015.50653076\n",
            "Epoch:  97 Step:   317  time: 1.316217 s d_loss: 0.99633974, g_loss: 1013.47412109 -- mean_d_loss: 5.48354721, mean_g_loss: 1015.48931885\n",
            "Epoch:  97 Step:   318  time: 1.295449 s d_loss: 1.43325031, g_loss: 969.26739502 -- mean_d_loss: 5.44951105, mean_g_loss: 1015.10089111\n",
            "Epoch:  97 Step:   319  time: 1.318964 s d_loss: 0.71975935, g_loss: 888.18341064 -- mean_d_loss: 5.41009665, mean_g_loss: 1014.04321289\n",
            "Epoch:  97 Step:   320  time: 1.316632 s d_loss: 0.58628470, g_loss: 929.63195801 -- mean_d_loss: 5.37023067, mean_g_loss: 1013.34564209\n",
            "Epoch:  97 Step:   321  time: 1.307644 s d_loss: 0.62412357, g_loss: 1073.82214355 -- mean_d_loss: 5.33132839, mean_g_loss: 1013.84130859\n",
            "Epoch:  97 Step:   322  time: 1.328900 s d_loss: 0.80056798, g_loss: 1184.00695801 -- mean_d_loss: 5.29449320, mean_g_loss: 1015.22479248\n",
            "Epoch:  97 Step:   323  time: 1.326590 s d_loss: 0.71922624, g_loss: 1069.01623535 -- mean_d_loss: 5.25759602, mean_g_loss: 1015.65856934\n",
            "Epoch:  97 Step:   324  time: 1.319191 s d_loss: 0.77135128, g_loss: 926.17211914 -- mean_d_loss: 5.22170591, mean_g_loss: 1014.94268799\n",
            "Epoch:  97 Step:   325  time: 1.313876 s d_loss: 0.65321022, g_loss: 859.87194824 -- mean_d_loss: 5.18544817, mean_g_loss: 1013.71197510\n",
            "Epoch:  97 Step:   326  time: 1.298471 s d_loss: 0.51630288, g_loss: 950.17163086 -- mean_d_loss: 5.14868307, mean_g_loss: 1013.21166992\n",
            "Epoch:  97 Step:   327  time: 1.322622 s d_loss: 0.47543007, g_loss: 1004.75366211 -- mean_d_loss: 5.11217308, mean_g_loss: 1013.14556885\n",
            "Epoch:  97 Step:   328  time: 1.317145 s d_loss: 0.75511390, g_loss: 963.24841309 -- mean_d_loss: 5.07839775, mean_g_loss: 1012.75878906\n",
            "Epoch:  97 Step:   329  time: 1.325778 s d_loss: 0.59499019, g_loss: 926.03851318 -- mean_d_loss: 5.04390955, mean_g_loss: 1012.09173584\n",
            "Epoch:  97 Step:   330  time: 1.322183 s d_loss: 1.26224375, g_loss: 1185.75659180 -- mean_d_loss: 5.01504230, mean_g_loss: 1013.41735840\n",
            "Epoch:  97 Step:   331  time: 1.350466 s d_loss: 0.52508092, g_loss: 924.56695557 -- mean_d_loss: 4.98102713, mean_g_loss: 1012.74420166\n",
            "Epoch:  97 Step:   332  time: 1.326005 s d_loss: 0.68266529, g_loss: 1187.14575195 -- mean_d_loss: 4.94870901, mean_g_loss: 1014.05548096\n",
            "Epoch:  97 Step:   333  time: 1.329699 s d_loss: 0.91753775, g_loss: 1046.01611328 -- mean_d_loss: 4.91862535, mean_g_loss: 1014.29394531\n",
            "Epoch:  97 Step:   334  time: 1.321219 s d_loss: 0.65165609, g_loss: 955.49926758 -- mean_d_loss: 4.88701868, mean_g_loss: 1013.85845947\n",
            "Epoch:  97 Step:   335  time: 1.314476 s d_loss: 0.55202812, g_loss: 946.66082764 -- mean_d_loss: 4.85514355, mean_g_loss: 1013.36431885\n",
            "Epoch:  97 Step:   336  time: 1.315354 s d_loss: 0.80918503, g_loss: 990.31152344 -- mean_d_loss: 4.82561111, mean_g_loss: 1013.19604492\n",
            "Epoch:  97 Step:   337  time: 1.323901 s d_loss: 1.09462929, g_loss: 885.93432617 -- mean_d_loss: 4.79857492, mean_g_loss: 1012.27386475\n",
            "Epoch:  97 Step:   338  time: 1.322466 s d_loss: 0.76753110, g_loss: 1095.03320312 -- mean_d_loss: 4.76957417, mean_g_loss: 1012.86926270\n",
            "Epoch:  97 Step:   339  time: 1.314261 s d_loss: 1.64798760, g_loss: 1166.09570312 -- mean_d_loss: 4.74727726, mean_g_loss: 1013.96374512\n",
            "Epoch:  97 Step:   340  time: 1.321848 s d_loss: 0.63282979, g_loss: 837.12329102 -- mean_d_loss: 4.71809673, mean_g_loss: 1012.70953369\n",
            "Epoch:  97 Step:   341  time: 1.341740 s d_loss: 1.00946772, g_loss: 892.64453125 -- mean_d_loss: 4.69197941, mean_g_loss: 1011.86401367\n",
            "Epoch:  97 Step:   342  time: 1.341038 s d_loss: 1.24892449, g_loss: 1072.98767090 -- mean_d_loss: 4.66790199, mean_g_loss: 1012.29138184\n",
            "Epoch:  97 Step:   343  time: 1.331760 s d_loss: 0.82037973, g_loss: 1023.12756348 -- mean_d_loss: 4.64118338, mean_g_loss: 1012.36663818\n",
            "Epoch:  97 Step:   344  time: 1.336266 s d_loss: 0.65003771, g_loss: 964.34143066 -- mean_d_loss: 4.61365795, mean_g_loss: 1012.03546143\n",
            "Epoch:  97 Step:   345  time: 1.307044 s d_loss: 0.66730767, g_loss: 957.33203125 -- mean_d_loss: 4.58662796, mean_g_loss: 1011.66076660\n",
            "Epoch:  97 Step:   346  time: 1.294876 s d_loss: 0.56812555, g_loss: 930.92132568 -- mean_d_loss: 4.55929136, mean_g_loss: 1011.11151123\n",
            "Epoch:  97 Step:   347  time: 1.314556 s d_loss: 0.62354773, g_loss: 1003.42053223 -- mean_d_loss: 4.53269815, mean_g_loss: 1011.05957031\n",
            "Epoch:  97 Step:   348  time: 1.320967 s d_loss: 0.68039382, g_loss: 852.08276367 -- mean_d_loss: 4.50684404, mean_g_loss: 1009.99255371\n",
            "Epoch:  97 Step:   349  time: 1.308105 s d_loss: 0.78500170, g_loss: 1195.07971191 -- mean_d_loss: 4.48203182, mean_g_loss: 1011.22644043\n",
            "Epoch:  97 Step:   350  time: 1.301859 s d_loss: 0.55520535, g_loss: 941.18640137 -- mean_d_loss: 4.45602608, mean_g_loss: 1010.76263428\n",
            "Epoch:  97 Step:   351  time: 1.296488 s d_loss: 0.77760965, g_loss: 1028.83972168 -- mean_d_loss: 4.43182564, mean_g_loss: 1010.88159180\n",
            "Epoch:  97 Step:   352  time: 1.311863 s d_loss: 0.57137144, g_loss: 924.44622803 -- mean_d_loss: 4.40659380, mean_g_loss: 1010.31671143\n",
            "Epoch:  97 Step:   353  time: 1.288939 s d_loss: 0.85898876, g_loss: 1110.22570801 -- mean_d_loss: 4.38355780, mean_g_loss: 1010.96539307\n",
            "Epoch:  97 Step:   354  time: 1.290316 s d_loss: 1.25596273, g_loss: 1095.67016602 -- mean_d_loss: 4.36337948, mean_g_loss: 1011.51190186\n",
            "Epoch:  97 Step:   355  time: 1.321126 s d_loss: 0.60930860, g_loss: 913.77758789 -- mean_d_loss: 4.33931494, mean_g_loss: 1010.88543701\n",
            "Epoch:  97 Step:   356  time: 1.315479 s d_loss: 0.50395209, g_loss: 1063.04064941 -- mean_d_loss: 4.31488609, mean_g_loss: 1011.21765137\n",
            "Epoch:  97 Step:   357  time: 1.337982 s d_loss: 0.63154387, g_loss: 970.41979980 -- mean_d_loss: 4.29157400, mean_g_loss: 1010.95947266\n",
            "Epoch:  97 Step:   358  time: 1.328843 s d_loss: 0.61241835, g_loss: 998.15173340 -- mean_d_loss: 4.26843452, mean_g_loss: 1010.87890625\n",
            "Epoch:  97 Step:   359  time: 1.293819 s d_loss: 0.71715307, g_loss: 1083.13000488 -- mean_d_loss: 4.24623919, mean_g_loss: 1011.33044434\n",
            "Epoch:  97 Step:   360  time: 1.301863 s d_loss: 0.60450369, g_loss: 930.14123535 -- mean_d_loss: 4.22361946, mean_g_loss: 1010.82617188\n",
            "Epoch:  97 Step:   361  time: 1.315216 s d_loss: 0.58591527, g_loss: 928.30310059 -- mean_d_loss: 4.20116472, mean_g_loss: 1010.31677246\n",
            "Epoch:  97 Step:   362  time: 1.298739 s d_loss: 0.77997583, g_loss: 1021.44390869 -- mean_d_loss: 4.18017578, mean_g_loss: 1010.38494873\n",
            "Epoch:  97 Step:   363  time: 1.328703 s d_loss: 0.96225113, g_loss: 1106.86376953 -- mean_d_loss: 4.16055441, mean_g_loss: 1010.97320557\n",
            "Epoch:  97 Step:   364  time: 1.319049 s d_loss: 0.66111827, g_loss: 1058.38232422 -- mean_d_loss: 4.13934565, mean_g_loss: 1011.26049805\n",
            "Epoch:  97 Step:   365  time: 1.312499 s d_loss: 0.70985895, g_loss: 934.35693359 -- mean_d_loss: 4.11868620, mean_g_loss: 1010.79724121\n",
            "Epoch:  97 Step:   366  time: 1.318720 s d_loss: 0.71775293, g_loss: 977.37145996 -- mean_d_loss: 4.09832144, mean_g_loss: 1010.59710693\n",
            "Epoch:  97 Step:   367  time: 1.288486 s d_loss: 0.60961866, g_loss: 898.58752441 -- mean_d_loss: 4.07755518, mean_g_loss: 1009.93041992\n",
            "Epoch:  97 Step:   368  time: 1.332532 s d_loss: 0.89467436, g_loss: 967.75878906 -- mean_d_loss: 4.05872154, mean_g_loss: 1009.68090820\n",
            "Epoch:  97 Step:   369  time: 1.299927 s d_loss: 1.23807871, g_loss: 1001.16137695 -- mean_d_loss: 4.04212952, mean_g_loss: 1009.63079834\n",
            "Epoch:  97 Step:   370  time: 1.327350 s d_loss: 0.70951337, g_loss: 882.15161133 -- mean_d_loss: 4.02264071, mean_g_loss: 1008.88531494\n",
            "Epoch:  97 Step:   371  time: 1.313445 s d_loss: 0.67805159, g_loss: 1132.64904785 -- mean_d_loss: 4.00319529, mean_g_loss: 1009.60491943\n",
            "Epoch:  97 Step:   372  time: 1.323582 s d_loss: 0.58879244, g_loss: 988.57183838 -- mean_d_loss: 3.98345923, mean_g_loss: 1009.48339844\n",
            "Epoch:  97 Step:   373  time: 1.332608 s d_loss: 0.75410259, g_loss: 1319.90661621 -- mean_d_loss: 3.96489954, mean_g_loss: 1011.26739502\n",
            "Epoch:  97 Step:   374  time: 1.325745 s d_loss: 0.75486571, g_loss: 986.16430664 -- mean_d_loss: 3.94655657, mean_g_loss: 1011.12402344\n",
            "Epoch:  97 Step:   375  time: 1.294260 s d_loss: 10.72773170, g_loss: 1103.53588867 -- mean_d_loss: 3.98508596, mean_g_loss: 1011.64904785\n",
            "Epoch:  97 Step:   376  time: 1.313500 s d_loss: 1.00536990, g_loss: 1058.96997070 -- mean_d_loss: 3.96825147, mean_g_loss: 1011.91638184\n",
            "Epoch:  97 Step:   377  time: 1.315465 s d_loss: 0.74233943, g_loss: 906.92138672 -- mean_d_loss: 3.95012808, mean_g_loss: 1011.32653809\n",
            "Epoch:  97 Step:   378  time: 1.289005 s d_loss: 0.75431693, g_loss: 996.88366699 -- mean_d_loss: 3.93227458, mean_g_loss: 1011.24591064\n",
            "Epoch:  97 Step:   379  time: 1.323400 s d_loss: 0.59434754, g_loss: 941.03186035 -- mean_d_loss: 3.91373062, mean_g_loss: 1010.85583496\n",
            "Epoch:  97 Step:   380  time: 1.328638 s d_loss: 1.26211357, g_loss: 1114.09704590 -- mean_d_loss: 3.89908051, mean_g_loss: 1011.42620850\n",
            "Epoch:  97 Step:   381  time: 1.319854 s d_loss: 1.15899026, g_loss: 942.10986328 -- mean_d_loss: 3.88402510, mean_g_loss: 1011.04534912\n",
            "Epoch:  97 Step:   382  time: 1.332214 s d_loss: 0.59242672, g_loss: 1017.30859375 -- mean_d_loss: 3.86603808, mean_g_loss: 1011.07958984\n",
            "Epoch:  97 Step:   383  time: 1.332416 s d_loss: 1.02779508, g_loss: 786.42401123 -- mean_d_loss: 3.85061288, mean_g_loss: 1009.85858154\n",
            "Epoch:  97 Step:   384  time: 1.334146 s d_loss: 55.14054871, g_loss: 1025.67480469 -- mean_d_loss: 4.12785578, mean_g_loss: 1009.94409180\n",
            "Epoch:  97 Step:   385  time: 1.295060 s d_loss: 2.12096000, g_loss: 1011.80761719 -- mean_d_loss: 4.11706591, mean_g_loss: 1009.95416260\n",
            "Epoch:  97 Step:   386  time: 1.319280 s d_loss: 1.81121230, g_loss: 983.15393066 -- mean_d_loss: 4.10473537, mean_g_loss: 1009.81085205\n",
            "Epoch:  97 Step:   387  time: 1.318291 s d_loss: 2.27281618, g_loss: 1045.88818359 -- mean_d_loss: 4.09499121, mean_g_loss: 1010.00274658\n",
            "Epoch:  97 Step:   388  time: 1.323162 s d_loss: 1.30807209, g_loss: 896.03027344 -- mean_d_loss: 4.08024549, mean_g_loss: 1009.39971924\n",
            "Epoch:  97 Step:   389  time: 1.289181 s d_loss: 0.77388161, g_loss: 885.93811035 -- mean_d_loss: 4.06284332, mean_g_loss: 1008.74993896\n",
            "Epoch:  97 Step:   390  time: 1.323360 s d_loss: 0.88794690, g_loss: 858.94970703 -- mean_d_loss: 4.04622078, mean_g_loss: 1007.96563721\n",
            "Epoch:  97 Step:   391  time: 1.326392 s d_loss: 29.40311050, g_loss: 1042.04907227 -- mean_d_loss: 4.17828798, mean_g_loss: 1008.14312744\n",
            "Epoch:  97 Step:   392  time: 1.315598 s d_loss: 1.12039042, g_loss: 1025.15173340 -- mean_d_loss: 4.16244411, mean_g_loss: 1008.23132324\n",
            "Epoch:  97 Step:   393  time: 1.338196 s d_loss: 2.60597420, g_loss: 931.16577148 -- mean_d_loss: 4.15442085, mean_g_loss: 1007.83410645\n",
            "Epoch:  97 Step:   394  time: 1.321815 s d_loss: 1.22189772, g_loss: 1147.67919922 -- mean_d_loss: 4.13938236, mean_g_loss: 1008.55120850\n",
            "Epoch:  97 Step:   395  time: 1.316013 s d_loss: 1.49203587, g_loss: 1030.53662109 -- mean_d_loss: 4.12587547, mean_g_loss: 1008.66333008\n",
            "Epoch:  97 Step:   396  time: 1.296880 s d_loss: 4.21378851, g_loss: 1049.74853516 -- mean_d_loss: 4.12632179, mean_g_loss: 1008.87188721\n",
            "Epoch:  97 Step:   397  time: 1.307364 s d_loss: 4.10383463, g_loss: 1077.61059570 -- mean_d_loss: 4.12620831, mean_g_loss: 1009.21905518\n",
            "Epoch:  97 Step:   398  time: 1.319843 s d_loss: 4.51251316, g_loss: 1232.15673828 -- mean_d_loss: 4.12814951, mean_g_loss: 1010.33935547\n",
            "Epoch:  97 Step:   399  time: 1.320662 s d_loss: 3.57442403, g_loss: 972.84118652 -- mean_d_loss: 4.12538099, mean_g_loss: 1010.15185547\n",
            "Epoch:  97 Step:   400  time: 1.313447 s d_loss: 4.07845783, g_loss: 1030.30432129 -- mean_d_loss: 4.07845783, mean_g_loss: 1030.30432129\n",
            "Epoch:  97 Step:   401  time: 1.289471 s d_loss: 1.54341114, g_loss: 1045.70043945 -- mean_d_loss: 2.81093454, mean_g_loss: 1038.00244141\n",
            "Epoch:  97 Step:   402  time: 1.305898 s d_loss: 0.84212840, g_loss: 1030.42077637 -- mean_d_loss: 2.15466571, mean_g_loss: 1035.47521973\n",
            "Epoch:  97 Step:   403  time: 1.349023 s d_loss: 1.30301929, g_loss: 994.75714111 -- mean_d_loss: 1.94175410, mean_g_loss: 1025.29577637\n",
            "Epoch:  97 Step:   404  time: 1.327348 s d_loss: 7.91511059, g_loss: 1167.77966309 -- mean_d_loss: 3.13642550, mean_g_loss: 1053.79260254\n",
            "Epoch:  97 Step:   405  time: 1.307295 s d_loss: 2.90073705, g_loss: 1003.00927734 -- mean_d_loss: 3.09714413, mean_g_loss: 1045.32873535\n",
            "Epoch:  97 Step:   406  time: 1.326836 s d_loss: 3.41091776, g_loss: 1003.35900879 -- mean_d_loss: 3.14196897, mean_g_loss: 1039.33300781\n",
            "Epoch:  97 Step:   407  time: 1.307688 s d_loss: 1.63904524, g_loss: 960.55108643 -- mean_d_loss: 2.95410347, mean_g_loss: 1029.48522949\n",
            "Epoch:  97 Step:   408  time: 1.322224 s d_loss: 0.98776364, g_loss: 1078.13085938 -- mean_d_loss: 2.73562145, mean_g_loss: 1034.89025879\n",
            "Epoch:  97 Step:   409  time: 1.325994 s d_loss: 0.81101584, g_loss: 921.86328125 -- mean_d_loss: 2.54316092, mean_g_loss: 1023.58758545\n",
            "Epoch:  97 Step:   410  time: 1.319919 s d_loss: 1.06906199, g_loss: 943.59631348 -- mean_d_loss: 2.40915179, mean_g_loss: 1016.31567383\n",
            "Epoch:  97 Step:   411  time: 1.303828 s d_loss: 1.82748401, g_loss: 946.55615234 -- mean_d_loss: 2.36067939, mean_g_loss: 1010.50244141\n",
            "Epoch:  97 Step:   412  time: 1.331495 s d_loss: 0.61169690, g_loss: 975.72753906 -- mean_d_loss: 2.22614241, mean_g_loss: 1007.82745361\n",
            "Epoch:  97 Step:   413  time: 1.324960 s d_loss: 1.30288398, g_loss: 982.80438232 -- mean_d_loss: 2.16019511, mean_g_loss: 1006.04010010\n",
            "Epoch:  97 Step:   414  time: 1.334176 s d_loss: 0.56670409, g_loss: 970.58843994 -- mean_d_loss: 2.05396247, mean_g_loss: 1003.67669678\n",
            "Epoch:  97 Step:   415  time: 1.314420 s d_loss: 0.56649089, g_loss: 971.02575684 -- mean_d_loss: 1.96099544, mean_g_loss: 1001.63598633\n",
            "Epoch:  97 Step:   416  time: 1.325561 s d_loss: 0.62822264, g_loss: 1089.55053711 -- mean_d_loss: 1.88259709, mean_g_loss: 1006.80743408\n",
            "Epoch:  97 Step:   417  time: 1.290872 s d_loss: 0.73710275, g_loss: 952.80615234 -- mean_d_loss: 1.81895852, mean_g_loss: 1003.80737305\n",
            "Epoch:  97 Step:   418  time: 1.316995 s d_loss: 0.84525883, g_loss: 1116.38122559 -- mean_d_loss: 1.76771128, mean_g_loss: 1009.73229980\n",
            "Epoch:  97 Step:   419  time: 1.329959 s d_loss: 0.66514224, g_loss: 1046.19580078 -- mean_d_loss: 1.71258283, mean_g_loss: 1011.55548096\n",
            "Epoch:  97 Step:   420  time: 1.333946 s d_loss: 0.85382003, g_loss: 912.95544434 -- mean_d_loss: 1.67168939, mean_g_loss: 1006.86022949\n",
            "Epoch:  97 Step:   421  time: 1.292186 s d_loss: 0.78130323, g_loss: 1031.98876953 -- mean_d_loss: 1.63121724, mean_g_loss: 1008.00238037\n",
            "Epoch:  97 Step:   422  time: 1.314148 s d_loss: 0.97509480, g_loss: 988.22332764 -- mean_d_loss: 1.60269010, mean_g_loss: 1007.14239502\n",
            "Epoch:  97 Step:   423  time: 1.319976 s d_loss: 0.96665305, g_loss: 957.42846680 -- mean_d_loss: 1.57618856, mean_g_loss: 1005.07098389\n",
            "Epoch:  97 Step:   424  time: 1.325942 s d_loss: 0.61080807, g_loss: 980.46923828 -- mean_d_loss: 1.53757334, mean_g_loss: 1004.08685303\n",
            "Epoch:  97 Step:   425  time: 1.326205 s d_loss: 0.61943275, g_loss: 1027.65478516 -- mean_d_loss: 1.50226033, mean_g_loss: 1004.99328613\n",
            "Epoch:  97 Step:   426  time: 1.290085 s d_loss: 0.67241430, g_loss: 1122.48986816 -- mean_d_loss: 1.47152531, mean_g_loss: 1009.34503174\n",
            "Epoch:  97 Step:   427  time: 1.320057 s d_loss: 0.80119210, g_loss: 1092.01171875 -- mean_d_loss: 1.44758487, mean_g_loss: 1012.29742432\n",
            "Epoch:  97 Step:   428  time: 1.318112 s d_loss: 0.63881010, g_loss: 992.09545898 -- mean_d_loss: 1.41969597, mean_g_loss: 1011.60083008\n",
            "Epoch:  97 Step:   429  time: 1.329932 s d_loss: 0.71219176, g_loss: 958.66760254 -- mean_d_loss: 1.39611256, mean_g_loss: 1009.83636475\n",
            "Epoch:  97 Step:   430  time: 1.294290 s d_loss: 0.64949322, g_loss: 1065.02832031 -- mean_d_loss: 1.37202811, mean_g_loss: 1011.61682129\n",
            "Epoch:  97 Step:   431  time: 1.314101 s d_loss: 0.82060474, g_loss: 1053.59936523 -- mean_d_loss: 1.35479617, mean_g_loss: 1012.92877197\n",
            "Epoch:  97 Step:   432  time: 1.313936 s d_loss: 0.92066574, g_loss: 1049.97497559 -- mean_d_loss: 1.34164071, mean_g_loss: 1014.05139160\n",
            "Epoch:  97 Step:   433  time: 1.320805 s d_loss: 1.00356984, g_loss: 1016.35290527 -- mean_d_loss: 1.33169746, mean_g_loss: 1014.11901855\n",
            "Epoch:  97 Step:   434  time: 1.339842 s d_loss: 10.25979710, g_loss: 1041.89868164 -- mean_d_loss: 1.58678603, mean_g_loss: 1014.91271973\n",
            "Epoch:  97 Step:   435  time: 1.293590 s d_loss: 1.27539062, g_loss: 1193.48388672 -- mean_d_loss: 1.57813609, mean_g_loss: 1019.87304688\n",
            "Epoch:  97 Step:   436  time: 1.280125 s d_loss: 4.22332811, g_loss: 1132.32568359 -- mean_d_loss: 1.64962780, mean_g_loss: 1022.91229248\n",
            "Epoch:  97 Step:   437  time: 1.332437 s d_loss: 1.27961719, g_loss: 825.66845703 -- mean_d_loss: 1.63989067, mean_g_loss: 1017.72161865\n",
            "Epoch:  97 Step:   438  time: 1.287034 s d_loss: 9.97913837, g_loss: 891.18078613 -- mean_d_loss: 1.85371757, mean_g_loss: 1014.47698975\n",
            "Epoch:  97 Step:   439  time: 1.299079 s d_loss: 1.54019523, g_loss: 1189.40917969 -- mean_d_loss: 1.84587932, mean_g_loss: 1018.85028076\n",
            "Epoch:  97 Step:   440  time: 1.340916 s d_loss: 1.37041569, g_loss: 980.49108887 -- mean_d_loss: 1.83428264, mean_g_loss: 1017.91473389\n",
            "Epoch:  97 Step:   441  time: 1.326960 s d_loss: 1.41253197, g_loss: 1122.29443359 -- mean_d_loss: 1.82424092, mean_g_loss: 1020.39990234\n",
            "Epoch:  97 Step:   442  time: 1.334732 s d_loss: 0.76181757, g_loss: 1122.05346680 -- mean_d_loss: 1.79953337, mean_g_loss: 1022.76397705\n",
            "Epoch:  97 Step:   443  time: 1.288357 s d_loss: 0.99574339, g_loss: 965.05572510 -- mean_d_loss: 1.78126538, mean_g_loss: 1021.45239258\n",
            "Epoch:  97 Step:   444  time: 1.287501 s d_loss: 1.17480505, g_loss: 980.00122070 -- mean_d_loss: 1.76778853, mean_g_loss: 1020.53125000\n",
            "Epoch:  97 Step:   445  time: 1.309215 s d_loss: 0.92475867, g_loss: 1008.82299805 -- mean_d_loss: 1.74946177, mean_g_loss: 1020.27673340\n",
            "Epoch:  97 Step:   446  time: 1.284806 s d_loss: 1.23141241, g_loss: 1222.89855957 -- mean_d_loss: 1.73843956, mean_g_loss: 1024.58789062\n",
            "Epoch:  97 Step:   447  time: 1.315188 s d_loss: 2.16851735, g_loss: 1198.32983398 -- mean_d_loss: 1.74739945, mean_g_loss: 1028.20739746\n",
            "Epoch:  97 Step:   448  time: 1.328257 s d_loss: 1.13008511, g_loss: 939.04370117 -- mean_d_loss: 1.73480129, mean_g_loss: 1026.38769531\n",
            "Epoch:  97 Step:   449  time: 1.293061 s d_loss: 1.84654808, g_loss: 1088.88659668 -- mean_d_loss: 1.73703623, mean_g_loss: 1027.63769531\n",
            "Epoch:  97 Step:   450  time: 1.320842 s d_loss: 0.88388228, g_loss: 959.72644043 -- mean_d_loss: 1.72030771, mean_g_loss: 1026.30615234\n",
            "Epoch:  97 Step:   451  time: 1.282181 s d_loss: 0.63224286, g_loss: 867.30688477 -- mean_d_loss: 1.69938338, mean_g_loss: 1023.24847412\n",
            "Epoch:  97 Step:   452  time: 1.352339 s d_loss: 1.04749942, g_loss: 993.46398926 -- mean_d_loss: 1.68708372, mean_g_loss: 1022.68652344\n",
            "Epoch:  97 Step:   453  time: 1.334467 s d_loss: 0.77373952, g_loss: 1076.65612793 -- mean_d_loss: 1.67016995, mean_g_loss: 1023.68597412\n",
            "Epoch:  97 Step:   454  time: 1.331373 s d_loss: 0.61672044, g_loss: 943.77136230 -- mean_d_loss: 1.65101635, mean_g_loss: 1022.23297119\n",
            "Epoch:  97 Step:   455  time: 1.309795 s d_loss: 0.63742578, g_loss: 1007.75964355 -- mean_d_loss: 1.63291657, mean_g_loss: 1021.97448730\n",
            "Epoch:  97 Step:   456  time: 1.317399 s d_loss: 0.78245670, g_loss: 1069.08288574 -- mean_d_loss: 1.61799622, mean_g_loss: 1022.80090332\n",
            "Epoch:  97 Step:   457  time: 1.305904 s d_loss: 0.57898283, g_loss: 1127.04016113 -- mean_d_loss: 1.60008216, mean_g_loss: 1024.59814453\n",
            "Epoch:  97 Step:   458  time: 1.316456 s d_loss: 0.69192284, g_loss: 1046.35424805 -- mean_d_loss: 1.58468962, mean_g_loss: 1024.96691895\n",
            "Epoch:  97 Step:   459  time: 1.315919 s d_loss: 0.88446438, g_loss: 1111.18115234 -- mean_d_loss: 1.57301927, mean_g_loss: 1026.40380859\n",
            "Epoch:  97 Step:   460  time: 1.316310 s d_loss: 0.96606356, g_loss: 923.28778076 -- mean_d_loss: 1.56306922, mean_g_loss: 1024.71337891\n",
            "Epoch:  97 Step:   461  time: 1.318638 s d_loss: 0.75527233, g_loss: 1188.30541992 -- mean_d_loss: 1.55004025, mean_g_loss: 1027.35192871\n",
            "Epoch:  97 Step:   462  time: 1.287958 s d_loss: 1.14774156, g_loss: 1038.41894531 -- mean_d_loss: 1.54365456, mean_g_loss: 1027.52758789\n",
            "Epoch:  97 Step:   463  time: 1.317902 s d_loss: 0.62089616, g_loss: 911.82116699 -- mean_d_loss: 1.52923644, mean_g_loss: 1025.71972656\n",
            "Epoch:  97 Step:   464  time: 1.313952 s d_loss: 1.11463487, g_loss: 1002.75659180 -- mean_d_loss: 1.52285790, mean_g_loss: 1025.36645508\n",
            "Epoch:  97 Step:   465  time: 1.308070 s d_loss: 0.82306504, g_loss: 1024.16699219 -- mean_d_loss: 1.51225495, mean_g_loss: 1025.34826660\n",
            "Epoch:  97 Step:   466  time: 1.311409 s d_loss: 0.93964845, g_loss: 1026.07336426 -- mean_d_loss: 1.50370872, mean_g_loss: 1025.35900879\n",
            "Epoch:  97 Step:   467  time: 1.339810 s d_loss: 0.72253793, g_loss: 977.24877930 -- mean_d_loss: 1.49222088, mean_g_loss: 1024.65148926\n",
            "Epoch:  97 Step:   468  time: 1.301038 s d_loss: 0.96797556, g_loss: 1121.93994141 -- mean_d_loss: 1.48462296, mean_g_loss: 1026.06152344\n",
            "Epoch:  97 Step:   469  time: 1.315322 s d_loss: 0.56709087, g_loss: 1108.34216309 -- mean_d_loss: 1.47151542, mean_g_loss: 1027.23693848\n",
            "Epoch:  97 Step:   470  time: 1.290191 s d_loss: 0.75346273, g_loss: 892.32324219 -- mean_d_loss: 1.46140206, mean_g_loss: 1025.33666992\n",
            "Epoch:  97 Step:   471  time: 1.325019 s d_loss: 0.74190801, g_loss: 1101.20129395 -- mean_d_loss: 1.45140898, mean_g_loss: 1026.39038086\n",
            "Epoch:  97 Step:   472  time: 1.357313 s d_loss: 0.83005786, g_loss: 1079.75683594 -- mean_d_loss: 1.44289732, mean_g_loss: 1027.12145996\n",
            "Epoch:  97 Step:   473  time: 1.302476 s d_loss: 1.30484509, g_loss: 1164.23461914 -- mean_d_loss: 1.44103181, mean_g_loss: 1028.97436523\n",
            "Epoch:  97 Step:   474  time: 1.311273 s d_loss: 0.79628247, g_loss: 940.71020508 -- mean_d_loss: 1.43243515, mean_g_loss: 1027.79748535\n",
            "Epoch:  97 Step:   475  time: 1.290314 s d_loss: 0.67705268, g_loss: 1069.56494141 -- mean_d_loss: 1.42249584, mean_g_loss: 1028.34704590\n",
            "Epoch:  97 Step:   476  time: 1.306668 s d_loss: 1.19403362, g_loss: 1025.57067871 -- mean_d_loss: 1.41952884, mean_g_loss: 1028.31103516\n",
            "Epoch:  97 Step:   477  time: 1.325098 s d_loss: 0.78373343, g_loss: 888.78363037 -- mean_d_loss: 1.41137767, mean_g_loss: 1026.52209473\n",
            "Epoch:  97 Step:   478  time: 1.291359 s d_loss: 0.77140582, g_loss: 1115.26586914 -- mean_d_loss: 1.40327680, mean_g_loss: 1027.64550781\n",
            "Epoch:  97 Step:   479  time: 1.330712 s d_loss: 0.61523199, g_loss: 928.82507324 -- mean_d_loss: 1.39342618, mean_g_loss: 1026.41027832\n",
            "Epoch:  97 Step:   480  time: 1.329473 s d_loss: 0.63118029, g_loss: 1011.55505371 -- mean_d_loss: 1.38401580, mean_g_loss: 1026.22680664\n",
            "Epoch:  97 Step:   481  time: 1.313915 s d_loss: 0.54214162, g_loss: 1057.46276855 -- mean_d_loss: 1.37374902, mean_g_loss: 1026.60778809\n",
            "Epoch:  97 Step:   482  time: 1.318220 s d_loss: 0.57971567, g_loss: 1020.45526123 -- mean_d_loss: 1.36418235, mean_g_loss: 1026.53356934\n",
            "Epoch:  97 Step:   483  time: 1.293792 s d_loss: 0.53588617, g_loss: 980.14862061 -- mean_d_loss: 1.35432172, mean_g_loss: 1025.98144531\n",
            "Epoch:  97 Step:   484  time: 1.297526 s d_loss: 0.61804730, g_loss: 1037.47631836 -- mean_d_loss: 1.34565973, mean_g_loss: 1026.11657715\n",
            "Epoch:  97 Step:   485  time: 1.337487 s d_loss: 0.62214077, g_loss: 893.35919189 -- mean_d_loss: 1.33724666, mean_g_loss: 1024.57299805\n",
            "Epoch:  97 Step:   486  time: 1.317114 s d_loss: 0.68243086, g_loss: 1025.43420410 -- mean_d_loss: 1.32972002, mean_g_loss: 1024.58288574\n",
            "Epoch:  97 Step:   487  time: 1.306129 s d_loss: 0.67904687, g_loss: 925.87841797 -- mean_d_loss: 1.32232606, mean_g_loss: 1023.46118164\n",
            "Epoch:  97 Step:   488  time: 1.303226 s d_loss: 0.65930152, g_loss: 950.22192383 -- mean_d_loss: 1.31487632, mean_g_loss: 1022.63824463\n",
            "Epoch:  97 Step:   489  time: 1.290270 s d_loss: 0.76621705, g_loss: 1047.57556152 -- mean_d_loss: 1.30878019, mean_g_loss: 1022.91534424\n",
            "Epoch:  97 Step:   490  time: 1.303159 s d_loss: 0.84588158, g_loss: 1255.67236328 -- mean_d_loss: 1.30369329, mean_g_loss: 1025.47314453\n",
            "Epoch:  97 Step:   491  time: 1.302393 s d_loss: 0.60004699, g_loss: 1111.66308594 -- mean_d_loss: 1.29604495, mean_g_loss: 1026.41003418\n",
            "Epoch:  97 Step:   492  time: 1.307903 s d_loss: 0.55871785, g_loss: 979.15502930 -- mean_d_loss: 1.28811669, mean_g_loss: 1025.90185547\n",
            "Epoch:  97 Step:   493  time: 1.309894 s d_loss: 0.65304691, g_loss: 893.22448730 -- mean_d_loss: 1.28136063, mean_g_loss: 1024.49047852\n",
            "Epoch:  97 Step:   494  time: 1.310529 s d_loss: 1.01056015, g_loss: 1077.15502930 -- mean_d_loss: 1.27851009, mean_g_loss: 1025.04479980\n",
            "Epoch:  97 Step:   495  time: 1.304942 s d_loss: 0.65630370, g_loss: 1050.61047363 -- mean_d_loss: 1.27202880, mean_g_loss: 1025.31115723\n",
            "Epoch:  97 Step:   496  time: 1.319679 s d_loss: 0.70834088, g_loss: 1075.39819336 -- mean_d_loss: 1.26621759, mean_g_loss: 1025.82751465\n",
            "Epoch:  97 Step:   497  time: 1.324039 s d_loss: 0.75394046, g_loss: 1095.20385742 -- mean_d_loss: 1.26099026, mean_g_loss: 1026.53540039\n",
            "Epoch:  97 Step:   498  time: 1.295628 s d_loss: 0.60693866, g_loss: 1098.84765625 -- mean_d_loss: 1.25438368, mean_g_loss: 1027.26574707\n",
            "Epoch:  97 Step:   499  time: 1.321715 s d_loss: 1.48612332, g_loss: 922.10900879 -- mean_d_loss: 1.25670099, mean_g_loss: 1026.21423340\n",
            "Epoch:  97 Step:   500  time: 1.280786 s d_loss: 0.45473483, g_loss: 1020.82812500 -- mean_d_loss: 1.24876082, mean_g_loss: 1026.16088867\n",
            "Epoch:  97 Step:   501  time: 1.322652 s d_loss: 1.04130399, g_loss: 1185.76953125 -- mean_d_loss: 1.24672687, mean_g_loss: 1027.72558594\n",
            "Epoch:  97 Step:   502  time: 1.327479 s d_loss: 0.67527300, g_loss: 1080.17126465 -- mean_d_loss: 1.24117875, mean_g_loss: 1028.23486328\n",
            "Epoch:  97 Step:   503  time: 1.324775 s d_loss: 0.57700682, g_loss: 951.42028809 -- mean_d_loss: 1.23479259, mean_g_loss: 1027.49621582\n",
            "Epoch:  97 Step:   504  time: 1.325130 s d_loss: 0.67480242, g_loss: 1071.68347168 -- mean_d_loss: 1.22945929, mean_g_loss: 1027.91699219\n",
            "Epoch:  97 Step:   505  time: 1.309956 s d_loss: 47.42624283, g_loss: 812.91101074 -- mean_d_loss: 1.66527808, mean_g_loss: 1025.88867188\n",
            "Epoch:  97 Step:   506  time: 1.319022 s d_loss: 3.23494387, g_loss: 903.77667236 -- mean_d_loss: 1.67994773, mean_g_loss: 1024.74743652\n",
            "Epoch:  97 Step:   507  time: 1.341402 s d_loss: 1.91395593, g_loss: 927.22106934 -- mean_d_loss: 1.68211448, mean_g_loss: 1023.84442139\n",
            "Epoch:  97 Step:   508  time: 1.309103 s d_loss: 1.94752789, g_loss: 918.87969971 -- mean_d_loss: 1.68454945, mean_g_loss: 1022.88146973\n",
            "Epoch:  97 Step:   509  time: 1.317622 s d_loss: 1.67677748, g_loss: 1093.47326660 -- mean_d_loss: 1.68447876, mean_g_loss: 1023.52325439\n",
            "Epoch:  97 Step:   510  time: 1.308959 s d_loss: 1.02379358, g_loss: 923.20397949 -- mean_d_loss: 1.67852664, mean_g_loss: 1022.61944580\n",
            "Epoch:  97 Step:   511  time: 1.298195 s d_loss: 1.49406421, g_loss: 872.42749023 -- mean_d_loss: 1.67687964, mean_g_loss: 1021.27844238\n",
            "Epoch:  97 Step:   512  time: 1.332448 s d_loss: 0.89951837, g_loss: 1045.17346191 -- mean_d_loss: 1.67000031, mean_g_loss: 1021.48992920\n",
            "Epoch:  97 Step:   513  time: 1.330107 s d_loss: 0.63049144, g_loss: 993.73059082 -- mean_d_loss: 1.66088188, mean_g_loss: 1021.24645996\n",
            "Epoch:  97 Step:   514  time: 1.335586 s d_loss: 0.83064735, g_loss: 916.88610840 -- mean_d_loss: 1.65366232, mean_g_loss: 1020.33892822\n",
            "Epoch:  97 Step:   515  time: 1.297114 s d_loss: 0.72771466, g_loss: 1106.66137695 -- mean_d_loss: 1.64568019, mean_g_loss: 1021.08312988\n",
            "Epoch:  97 Step:   516  time: 1.308327 s d_loss: 0.71693414, g_loss: 1078.57727051 -- mean_d_loss: 1.63774216, mean_g_loss: 1021.57452393\n",
            "Epoch:  97 Step:   517  time: 1.309084 s d_loss: 1.09204531, g_loss: 1005.55786133 -- mean_d_loss: 1.63311756, mean_g_loss: 1021.43878174\n",
            "Epoch:  97 Step:   518  time: 1.312651 s d_loss: 0.76421678, g_loss: 984.00604248 -- mean_d_loss: 1.62581587, mean_g_loss: 1021.12420654\n",
            "Epoch:  97 Step:   519  time: 1.316108 s d_loss: 0.70163929, g_loss: 1109.45263672 -- mean_d_loss: 1.61811447, mean_g_loss: 1021.86029053\n",
            "Epoch:  97 Step:   520  time: 1.325672 s d_loss: 0.55776638, g_loss: 1144.04724121 -- mean_d_loss: 1.60935128, mean_g_loss: 1022.87011719\n",
            "Epoch:  97 Step:   521  time: 1.322505 s d_loss: 21.33689308, g_loss: 1029.40368652 -- mean_d_loss: 1.77105248, mean_g_loss: 1022.92364502\n",
            "Epoch:  97 Step:   522  time: 1.320134 s d_loss: 1.94861293, g_loss: 984.39245605 -- mean_d_loss: 1.77249610, mean_g_loss: 1022.61041260\n",
            "Epoch:  97 Step:   523  time: 1.319453 s d_loss: 1.65199387, g_loss: 986.52770996 -- mean_d_loss: 1.77152419, mean_g_loss: 1022.31945801\n",
            "Epoch:  97 Step:   524  time: 1.319396 s d_loss: 1.77229548, g_loss: 1059.88134766 -- mean_d_loss: 1.77153039, mean_g_loss: 1022.61993408\n",
            "Epoch:  97 Step:   525  time: 1.315103 s d_loss: 0.92532021, g_loss: 808.02471924 -- mean_d_loss: 1.76481450, mean_g_loss: 1020.91680908\n",
            "Epoch:  97 Step:   526  time: 1.320733 s d_loss: 0.81330144, g_loss: 1030.44250488 -- mean_d_loss: 1.75732231, mean_g_loss: 1020.99182129\n",
            "Epoch:  97 Step:   527  time: 1.324513 s d_loss: 1.06902182, g_loss: 979.84838867 -- mean_d_loss: 1.75194490, mean_g_loss: 1020.67041016\n",
            "Epoch:  97 Step:   528  time: 1.316445 s d_loss: 1.74194336, g_loss: 1108.58325195 -- mean_d_loss: 1.75186741, mean_g_loss: 1021.35186768\n",
            "Epoch:  97 Step:   529  time: 1.290269 s d_loss: 0.84287608, g_loss: 970.56414795 -- mean_d_loss: 1.74487519, mean_g_loss: 1020.96118164\n",
            "Epoch:  97 Step:   530  time: 1.322771 s d_loss: 0.80768239, g_loss: 1000.24395752 -- mean_d_loss: 1.73772097, mean_g_loss: 1020.80310059\n",
            "Epoch:  97 Step:   531  time: 1.325246 s d_loss: 1.37034786, g_loss: 1087.80200195 -- mean_d_loss: 1.73493779, mean_g_loss: 1021.31060791\n",
            "Epoch:  97 Step:   532  time: 1.292209 s d_loss: 0.84751672, g_loss: 1010.91851807 -- mean_d_loss: 1.72826552, mean_g_loss: 1021.23248291\n",
            "Epoch:  97 Step:   533  time: 1.318960 s d_loss: 13.86125946, g_loss: 1023.16546631 -- mean_d_loss: 1.81881034, mean_g_loss: 1021.24694824\n",
            "Epoch:  97 Step:   534  time: 1.290600 s d_loss: 1.35778880, g_loss: 964.09680176 -- mean_d_loss: 1.81539536, mean_g_loss: 1020.82360840\n",
            "Epoch:  97 Step:   535  time: 1.305694 s d_loss: 1.85638309, g_loss: 914.14733887 -- mean_d_loss: 1.81569672, mean_g_loss: 1020.03918457\n",
            "Epoch:  97 Step:   536  time: 1.334607 s d_loss: 1.59395289, g_loss: 1121.17895508 -- mean_d_loss: 1.81407809, mean_g_loss: 1020.77734375\n",
            "Epoch:  97 Step:   537  time: 1.314809 s d_loss: 1.02761781, g_loss: 1088.58935547 -- mean_d_loss: 1.80837917, mean_g_loss: 1021.26879883\n",
            "Epoch:  97 Step:   538  time: 1.313668 s d_loss: 0.97919482, g_loss: 992.50366211 -- mean_d_loss: 1.80241382, mean_g_loss: 1021.06182861\n",
            "Epoch:  97 Step:   539  time: 1.302356 s d_loss: 44.82524872, g_loss: 1116.40490723 -- mean_d_loss: 2.10971975, mean_g_loss: 1021.74285889\n",
            "Epoch:  97 Step:   540  time: 1.299397 s d_loss: 2.61532974, g_loss: 1009.19592285 -- mean_d_loss: 2.11330581, mean_g_loss: 1021.65393066\n",
            "Epoch:  97 Step:   541  time: 1.296691 s d_loss: 4.37479687, g_loss: 1006.24694824 -- mean_d_loss: 2.12923169, mean_g_loss: 1021.54547119\n",
            "Epoch:  97 Step:   542  time: 1.288500 s d_loss: 1.00529218, g_loss: 1190.84765625 -- mean_d_loss: 2.12137175, mean_g_loss: 1022.72937012\n",
            "Epoch:  97 Step:   543  time: 1.318513 s d_loss: 1.12172568, g_loss: 971.79437256 -- mean_d_loss: 2.11442995, mean_g_loss: 1022.37567139\n",
            "Epoch:  97 Step:   544  time: 1.318423 s d_loss: 3.19805813, g_loss: 1043.98608398 -- mean_d_loss: 2.12190318, mean_g_loss: 1022.52465820\n",
            "Epoch:  97 Step:   545  time: 1.317703 s d_loss: 1.20383632, g_loss: 876.57202148 -- mean_d_loss: 2.11561489, mean_g_loss: 1021.52502441\n",
            "Epoch:  97 Step:   546  time: 1.322832 s d_loss: 1.15516627, g_loss: 868.37670898 -- mean_d_loss: 2.10908127, mean_g_loss: 1020.48321533\n",
            "Epoch:  97 Step:   547  time: 1.317309 s d_loss: 0.90901381, g_loss: 1054.06445312 -- mean_d_loss: 2.10097265, mean_g_loss: 1020.71008301\n",
            "Epoch:  97 Step:   548  time: 1.320996 s d_loss: 1.00542593, g_loss: 924.97216797 -- mean_d_loss: 2.09362006, mean_g_loss: 1020.06750488\n",
            "Epoch:  97 Step:   549  time: 1.311647 s d_loss: 1.36862969, g_loss: 945.67559814 -- mean_d_loss: 2.08878684, mean_g_loss: 1019.57153320\n",
            "Epoch:  97 Step:   550  time: 1.307186 s d_loss: 1.17625320, g_loss: 1216.16857910 -- mean_d_loss: 2.08274341, mean_g_loss: 1020.87353516\n",
            "Epoch:  97 Step:   551  time: 1.309519 s d_loss: 1.65741503, g_loss: 1147.32128906 -- mean_d_loss: 2.07994533, mean_g_loss: 1021.70550537\n",
            "Epoch:  97 Step:   552  time: 1.348010 s d_loss: 0.91874599, g_loss: 1003.82971191 -- mean_d_loss: 2.07235551, mean_g_loss: 1021.58862305\n",
            "Epoch:  97 Step:   553  time: 1.327215 s d_loss: 3.54198122, g_loss: 942.04626465 -- mean_d_loss: 2.08189869, mean_g_loss: 1021.07214355\n",
            "Epoch:  97 Step:   554  time: 1.310632 s d_loss: 1.30936909, g_loss: 980.15795898 -- mean_d_loss: 2.07691455, mean_g_loss: 1020.80816650\n",
            "Epoch:  97 Step:   555  time: 1.310779 s d_loss: 0.92923939, g_loss: 916.15966797 -- mean_d_loss: 2.06955767, mean_g_loss: 1020.13732910\n",
            "Epoch:  97 Step:   556  time: 1.300254 s d_loss: 1.31052172, g_loss: 903.98864746 -- mean_d_loss: 2.06472301, mean_g_loss: 1019.39752197\n",
            "Epoch:  97 Step:   557  time: 1.319691 s d_loss: 0.59869903, g_loss: 980.93579102 -- mean_d_loss: 2.05544424, mean_g_loss: 1019.15405273\n",
            "Epoch:  97 Step:   558  time: 1.330640 s d_loss: 0.60717297, g_loss: 1218.00891113 -- mean_d_loss: 2.04633570, mean_g_loss: 1020.40478516\n",
            "Epoch:  97 Step:   559  time: 1.324211 s d_loss: 0.96489662, g_loss: 1024.14660645 -- mean_d_loss: 2.03957677, mean_g_loss: 1020.42810059\n",
            "Epoch:  97 Step:   560  time: 1.311888 s d_loss: 0.86276042, g_loss: 984.73632812 -- mean_d_loss: 2.03226733, mean_g_loss: 1020.20642090\n",
            "Epoch:  97 Step:   561  time: 1.298630 s d_loss: 1.06203294, g_loss: 1147.04858398 -- mean_d_loss: 2.02627826, mean_g_loss: 1020.98937988\n",
            "Epoch:  97 Step:   562  time: 1.335892 s d_loss: 0.82547992, g_loss: 930.89916992 -- mean_d_loss: 2.01891136, mean_g_loss: 1020.43670654\n",
            "Epoch:  97 Step:   563  time: 1.346896 s d_loss: 0.70368636, g_loss: 1196.18408203 -- mean_d_loss: 2.01089168, mean_g_loss: 1021.50836182\n",
            "Epoch:  97 Step:   564  time: 1.328245 s d_loss: 0.88363737, g_loss: 1088.50598145 -- mean_d_loss: 2.00405979, mean_g_loss: 1021.91436768\n",
            "Epoch:  97 Step:   565  time: 1.351368 s d_loss: 0.72772521, g_loss: 920.73577881 -- mean_d_loss: 1.99637103, mean_g_loss: 1021.30487061\n",
            "Epoch:  97 Step:   566  time: 1.314254 s d_loss: 0.72865629, g_loss: 991.78283691 -- mean_d_loss: 1.98877990, mean_g_loss: 1021.12811279\n",
            "Epoch:  97 Step:   567  time: 1.286250 s d_loss: 0.75674188, g_loss: 1022.77239990 -- mean_d_loss: 1.98144639, mean_g_loss: 1021.13781738\n",
            "Epoch:  97 Step:   568  time: 1.331768 s d_loss: 0.70206660, g_loss: 920.42041016 -- mean_d_loss: 1.97387600, mean_g_loss: 1020.54187012\n",
            "Epoch:  97 Step:   569  time: 1.324312 s d_loss: 0.81408101, g_loss: 1123.46850586 -- mean_d_loss: 1.96705377, mean_g_loss: 1021.14733887\n",
            "Epoch:  97 Step:   570  time: 1.343500 s d_loss: 0.50433064, g_loss: 978.43640137 -- mean_d_loss: 1.95849979, mean_g_loss: 1020.89758301\n",
            "Epoch:  97 Step:   571  time: 1.328018 s d_loss: 1.15788531, g_loss: 1035.41088867 -- mean_d_loss: 1.95384514, mean_g_loss: 1020.98193359\n",
            "Epoch:  97 Step:   572  time: 1.322603 s d_loss: 0.90668106, g_loss: 1219.28295898 -- mean_d_loss: 1.94779217, mean_g_loss: 1022.12817383\n",
            "Epoch:  97 Step:   573  time: 1.303904 s d_loss: 0.57915908, g_loss: 900.81579590 -- mean_d_loss: 1.93992651, mean_g_loss: 1021.43096924\n",
            "Epoch:  97 Step:   574  time: 1.336876 s d_loss: 0.55476552, g_loss: 937.78723145 -- mean_d_loss: 1.93201137, mean_g_loss: 1020.95294189\n",
            "Epoch:  97 Step:   575  time: 1.328095 s d_loss: 0.56071103, g_loss: 1013.42480469 -- mean_d_loss: 1.92421985, mean_g_loss: 1020.91015625\n",
            "Epoch:  97 Step:   576  time: 1.319639 s d_loss: 0.76190472, g_loss: 953.67913818 -- mean_d_loss: 1.91765308, mean_g_loss: 1020.53027344\n",
            "Epoch:  97 Step:   577  time: 1.328895 s d_loss: 0.93014568, g_loss: 905.38476562 -- mean_d_loss: 1.91210520, mean_g_loss: 1019.88342285\n",
            "Epoch:  97 Step:   578  time: 1.292563 s d_loss: 0.50224906, g_loss: 1115.01220703 -- mean_d_loss: 1.90422904, mean_g_loss: 1020.41491699\n",
            "Epoch:  97 Step:   579  time: 1.323568 s d_loss: 1.08006370, g_loss: 938.41870117 -- mean_d_loss: 1.89965045, mean_g_loss: 1019.95935059\n",
            "Epoch:  97 Step:   580  time: 1.321417 s d_loss: 0.82387286, g_loss: 996.06616211 -- mean_d_loss: 1.89370692, mean_g_loss: 1019.82733154\n",
            "Epoch:  97 Step:   581  time: 1.322474 s d_loss: 0.82390785, g_loss: 997.25915527 -- mean_d_loss: 1.88782895, mean_g_loss: 1019.70336914\n",
            "Epoch:  97 Step:   582  time: 1.329018 s d_loss: 0.69701952, g_loss: 1138.69311523 -- mean_d_loss: 1.88132179, mean_g_loss: 1020.35357666\n",
            "Epoch:  97 Step:   583  time: 1.318373 s d_loss: 14.15616703, g_loss: 906.51599121 -- mean_d_loss: 1.94803286, mean_g_loss: 1019.73486328\n",
            "Epoch:  97 Step:   584  time: 1.285537 s d_loss: 1.05137217, g_loss: 915.71105957 -- mean_d_loss: 1.94318604, mean_g_loss: 1019.17260742\n",
            "Epoch:  97 Step:   585  time: 1.337013 s d_loss: 0.77007204, g_loss: 1203.35266113 -- mean_d_loss: 1.93687904, mean_g_loss: 1020.16290283\n",
            "Epoch:  97 Step:   586  time: 1.302296 s d_loss: 0.98534328, g_loss: 1006.10925293 -- mean_d_loss: 1.93179059, mean_g_loss: 1020.08770752\n",
            "Epoch:  97 Step:   587  time: 1.299533 s d_loss: 0.63013577, g_loss: 939.09344482 -- mean_d_loss: 1.92486691, mean_g_loss: 1019.65692139\n",
            "Epoch:  97 Step:   588  time: 1.304273 s d_loss: 0.61591959, g_loss: 954.02056885 -- mean_d_loss: 1.91794109, mean_g_loss: 1019.30963135\n",
            "Epoch:  97 Step:   589  time: 1.331630 s d_loss: 0.77111977, g_loss: 905.07623291 -- mean_d_loss: 1.91190517, mean_g_loss: 1018.70837402\n",
            "Epoch:  97 Step:   590  time: 1.321096 s d_loss: 0.58358318, g_loss: 1026.87182617 -- mean_d_loss: 1.90495074, mean_g_loss: 1018.75115967\n",
            "Epoch:  97 Step:   591  time: 1.320383 s d_loss: 2.44264412, g_loss: 1092.40014648 -- mean_d_loss: 1.90775120, mean_g_loss: 1019.13476562\n",
            "Epoch:  97 Step:   592  time: 1.321135 s d_loss: 0.75202394, g_loss: 983.36993408 -- mean_d_loss: 1.90176296, mean_g_loss: 1018.94946289\n",
            "Epoch:  97 Step:   593  time: 1.319837 s d_loss: 0.92305815, g_loss: 1022.43481445 -- mean_d_loss: 1.89671814, mean_g_loss: 1018.96746826\n",
            "Epoch:  97 Step:   594  time: 1.312831 s d_loss: 1.17143941, g_loss: 990.17687988 -- mean_d_loss: 1.89299881, mean_g_loss: 1018.81976318\n",
            "Epoch:  97 Step:   595  time: 1.314956 s d_loss: 0.88939846, g_loss: 856.40881348 -- mean_d_loss: 1.88787842, mean_g_loss: 1017.99114990\n",
            "Epoch:  97 Step:   596  time: 1.321481 s d_loss: 0.78637040, g_loss: 1162.49926758 -- mean_d_loss: 1.88228703, mean_g_loss: 1018.72467041\n",
            "Epoch:  97 Step:   597  time: 1.318825 s d_loss: 1.15901113, g_loss: 1023.88128662 -- mean_d_loss: 1.87863410, mean_g_loss: 1018.75073242\n",
            "Epoch:  97 Step:   598  time: 1.301164 s d_loss: 1.09578860, g_loss: 1005.72113037 -- mean_d_loss: 1.87470019, mean_g_loss: 1018.68524170\n",
            "Epoch:  97 Step:   599  time: 1.319278 s d_loss: 0.94840115, g_loss: 1110.06298828 -- mean_d_loss: 1.87006867, mean_g_loss: 1019.14208984\n",
            "Epoch:  97 Step:   600  time: 1.317712 s d_loss: 2.34226704, g_loss: 1027.09692383 -- mean_d_loss: 2.34226704, mean_g_loss: 1027.09692383\n",
            "Epoch:  97 Step:   601  time: 1.326304 s d_loss: 1.28215468, g_loss: 989.68157959 -- mean_d_loss: 1.81221080, mean_g_loss: 1008.38928223\n",
            "Epoch:  97 Step:   602  time: 1.326030 s d_loss: 0.84730494, g_loss: 1064.23388672 -- mean_d_loss: 1.49057543, mean_g_loss: 1027.00415039\n",
            "Epoch:  97 Step:   603  time: 1.325517 s d_loss: 1.20394599, g_loss: 1072.02514648 -- mean_d_loss: 1.41891813, mean_g_loss: 1038.25939941\n",
            "Epoch:  97 Step:   604  time: 1.327757 s d_loss: 0.64780128, g_loss: 1018.66186523 -- mean_d_loss: 1.26469481, mean_g_loss: 1034.33984375\n",
            "Epoch:  97 Step:   605  time: 1.299355 s d_loss: 0.45964491, g_loss: 923.41821289 -- mean_d_loss: 1.13051975, mean_g_loss: 1015.85284424\n",
            "Epoch:  97 Step:   606  time: 1.327699 s d_loss: 2.09637523, g_loss: 1034.54394531 -- mean_d_loss: 1.26849914, mean_g_loss: 1018.52301025\n",
            "Epoch:  97 Step:   607  time: 1.310992 s d_loss: 1.17704105, g_loss: 1159.27368164 -- mean_d_loss: 1.25706685, mean_g_loss: 1036.11682129\n",
            "Epoch:  97 Step:   608  time: 1.302460 s d_loss: 34.98084641, g_loss: 1097.00341797 -- mean_d_loss: 5.00415325, mean_g_loss: 1042.88195801\n",
            "Epoch:  97 Step:   609  time: 1.318599 s d_loss: 1.20887411, g_loss: 993.98596191 -- mean_d_loss: 4.62462521, mean_g_loss: 1037.99243164\n",
            "Epoch:  97 Step:   610  time: 1.315964 s d_loss: 3.65636611, g_loss: 997.74597168 -- mean_d_loss: 4.53660154, mean_g_loss: 1034.33361816\n",
            "Epoch:  97 Step:   611  time: 1.342294 s d_loss: 1.04049468, g_loss: 1183.97497559 -- mean_d_loss: 4.24525928, mean_g_loss: 1046.80371094\n",
            "Epoch:  97 Step:   612  time: 1.321842 s d_loss: 4.37334347, g_loss: 1147.01635742 -- mean_d_loss: 4.25511217, mean_g_loss: 1054.51245117\n",
            "Epoch:  97 Step:   613  time: 1.347013 s d_loss: 0.90030873, g_loss: 891.08789062 -- mean_d_loss: 4.01548338, mean_g_loss: 1042.83923340\n",
            "Epoch:  97 Step:   614  time: 1.313966 s d_loss: 0.94629949, g_loss: 1116.32934570 -- mean_d_loss: 3.81087112, mean_g_loss: 1047.73852539\n",
            "Epoch:  97 Step:   615  time: 1.320109 s d_loss: 0.78055698, g_loss: 1037.47705078 -- mean_d_loss: 3.62147641, mean_g_loss: 1047.09716797\n",
            "Epoch:  97 Step:   616  time: 1.284334 s d_loss: 1.83830953, g_loss: 1015.40655518 -- mean_d_loss: 3.51658440, mean_g_loss: 1045.23303223\n",
            "Epoch:  97 Step:   617  time: 1.284300 s d_loss: 1.45386064, g_loss: 1114.22583008 -- mean_d_loss: 3.40198851, mean_g_loss: 1049.06591797\n",
            "Epoch:  97 Step:   618  time: 1.316768 s d_loss: 4.05042601, g_loss: 919.90911865 -- mean_d_loss: 3.43611670, mean_g_loss: 1042.26818848\n",
            "Epoch:  97 Step:   619  time: 1.316526 s d_loss: 0.53051895, g_loss: 962.86138916 -- mean_d_loss: 3.29083681, mean_g_loss: 1038.29785156\n",
            "Epoch:  97 Step:   620  time: 1.310114 s d_loss: 0.51355129, g_loss: 993.05059814 -- mean_d_loss: 3.15858507, mean_g_loss: 1036.14318848\n",
            "Epoch:  97 Step:   621  time: 1.319769 s d_loss: 0.59108567, g_loss: 1214.09521484 -- mean_d_loss: 3.04188061, mean_g_loss: 1044.23193359\n",
            "Epoch:  97 Step:   622  time: 1.301685 s d_loss: 0.63816595, g_loss: 1130.04870605 -- mean_d_loss: 2.93737125, mean_g_loss: 1047.96313477\n",
            "Epoch:  97 Step:   623  time: 1.323630 s d_loss: 3.60940647, g_loss: 1102.39624023 -- mean_d_loss: 2.96537280, mean_g_loss: 1050.23120117\n",
            "Epoch:  97 Step:   624  time: 1.326306 s d_loss: 0.98752409, g_loss: 956.60455322 -- mean_d_loss: 2.88625884, mean_g_loss: 1046.48620605\n",
            "Epoch:  97 Step:   625  time: 1.323798 s d_loss: 1.06195891, g_loss: 1116.85656738 -- mean_d_loss: 2.81609344, mean_g_loss: 1049.19274902\n",
            "Epoch:  97 Step:   626  time: 1.308788 s d_loss: 0.66865849, g_loss: 955.23181152 -- mean_d_loss: 2.73655868, mean_g_loss: 1045.71276855\n",
            "Epoch:  97 Step:   627  time: 1.292238 s d_loss: 44.94905853, g_loss: 1039.03137207 -- mean_d_loss: 4.24414778, mean_g_loss: 1045.47412109\n",
            "Epoch:  97 Step:   628  time: 1.310088 s d_loss: 1.93386650, g_loss: 921.67535400 -- mean_d_loss: 4.16448307, mean_g_loss: 1041.20520020\n",
            "Epoch:  97 Step:   629  time: 1.316484 s d_loss: 1.81602693, g_loss: 1012.44970703 -- mean_d_loss: 4.08620119, mean_g_loss: 1040.24670410\n",
            "Epoch:  97 Step:   630  time: 1.318333 s d_loss: 21.94308662, g_loss: 916.46569824 -- mean_d_loss: 4.66223001, mean_g_loss: 1036.25366211\n",
            "Epoch:  97 Step:   631  time: 1.319299 s d_loss: 1.54369855, g_loss: 1068.66821289 -- mean_d_loss: 4.56477594, mean_g_loss: 1037.26672363\n",
            "Epoch:  97 Step:   632  time: 1.289883 s d_loss: 2.03922701, g_loss: 942.52514648 -- mean_d_loss: 4.48824406, mean_g_loss: 1034.39575195\n",
            "Epoch:  97 Step:   633  time: 1.316414 s d_loss: 1.97125757, g_loss: 1044.47973633 -- mean_d_loss: 4.41421509, mean_g_loss: 1034.69238281\n",
            "Epoch:  97 Step:   634  time: 1.332334 s d_loss: 1.60883141, g_loss: 1092.52111816 -- mean_d_loss: 4.33406115, mean_g_loss: 1036.34448242\n",
            "Epoch:  97 Step:   635  time: 1.309653 s d_loss: 1.11659110, g_loss: 958.53112793 -- mean_d_loss: 4.24468708, mean_g_loss: 1034.18310547\n",
            "Epoch:  97 Step:   636  time: 1.323116 s d_loss: 1.30380857, g_loss: 986.03741455 -- mean_d_loss: 4.16520357, mean_g_loss: 1032.88183594\n",
            "Epoch:  97 Step:   637  time: 1.316682 s d_loss: 1.01161420, g_loss: 1219.48095703 -- mean_d_loss: 4.08221436, mean_g_loss: 1037.79235840\n",
            "Epoch:  97 Step:   638  time: 1.318693 s d_loss: 0.96656901, g_loss: 1136.87597656 -- mean_d_loss: 4.00232601, mean_g_loss: 1040.33288574\n",
            "Epoch:  97 Step:   639  time: 1.336882 s d_loss: 1.15761709, g_loss: 1032.80200195 -- mean_d_loss: 3.93120837, mean_g_loss: 1040.14465332\n",
            "Epoch:  97 Step:   640  time: 1.316831 s d_loss: 0.85154778, g_loss: 937.70733643 -- mean_d_loss: 3.85609484, mean_g_loss: 1037.64611816\n",
            "Epoch:  97 Step:   641  time: 1.321409 s d_loss: 13.40814686, g_loss: 977.11840820 -- mean_d_loss: 4.08352423, mean_g_loss: 1036.20495605\n",
            "Epoch:  97 Step:   642  time: 1.292598 s d_loss: 1.13768446, g_loss: 966.40625000 -- mean_d_loss: 4.01501656, mean_g_loss: 1034.58178711\n",
            "Epoch:  97 Step:   643  time: 1.328301 s d_loss: 54.43397903, g_loss: 1070.94555664 -- mean_d_loss: 5.16090202, mean_g_loss: 1035.40820312\n",
            "Epoch:  97 Step:   644  time: 1.321785 s d_loss: 26.61578560, g_loss: 907.69409180 -- mean_d_loss: 5.63767719, mean_g_loss: 1032.57019043\n",
            "Epoch:  97 Step:   645  time: 1.323514 s d_loss: 1.77884948, g_loss: 926.03234863 -- mean_d_loss: 5.55378962, mean_g_loss: 1030.25402832\n",
            "Epoch:  97 Step:   646  time: 1.320661 s d_loss: 1.54860616, g_loss: 994.76739502 -- mean_d_loss: 5.46857262, mean_g_loss: 1029.49902344\n",
            "Epoch:  97 Step:   647  time: 1.330756 s d_loss: 2.13912058, g_loss: 923.15734863 -- mean_d_loss: 5.39920950, mean_g_loss: 1027.28356934\n",
            "Epoch:  97 Step:   648  time: 1.324189 s d_loss: 1.87183797, g_loss: 1087.33618164 -- mean_d_loss: 5.32722187, mean_g_loss: 1028.50903320\n",
            "Epoch:  97 Step:   649  time: 1.335285 s d_loss: 1.98608828, g_loss: 1034.70483398 -- mean_d_loss: 5.26039934, mean_g_loss: 1028.63293457\n",
            "Epoch:  97 Step:   650  time: 1.289885 s d_loss: 1.85619199, g_loss: 969.08386230 -- mean_d_loss: 5.19365025, mean_g_loss: 1027.46533203\n",
            "Epoch:  97 Step:   651  time: 1.330825 s d_loss: 76.98151398, g_loss: 942.33355713 -- mean_d_loss: 6.57418585, mean_g_loss: 1025.82812500\n",
            "Epoch:  97 Step:   652  time: 1.348935 s d_loss: 7.30733299, g_loss: 1038.41333008 -- mean_d_loss: 6.58801889, mean_g_loss: 1026.06555176\n",
            "Epoch:  97 Step:   653  time: 1.312737 s d_loss: 6.17771721, g_loss: 1418.17431641 -- mean_d_loss: 6.58042049, mean_g_loss: 1033.32690430\n",
            "Epoch:  97 Step:   654  time: 1.320149 s d_loss: 6.37580681, g_loss: 951.22631836 -- mean_d_loss: 6.57670021, mean_g_loss: 1031.83410645\n",
            "Epoch:  97 Step:   655  time: 1.296522 s d_loss: 3.50749230, g_loss: 937.90209961 -- mean_d_loss: 6.52189302, mean_g_loss: 1030.15686035\n",
            "Epoch:  97 Step:   656  time: 1.325297 s d_loss: 3.38365698, g_loss: 1046.07275391 -- mean_d_loss: 6.46683645, mean_g_loss: 1030.43603516\n",
            "Epoch:  97 Step:   657  time: 1.319206 s d_loss: 2.64843488, g_loss: 985.38293457 -- mean_d_loss: 6.40100193, mean_g_loss: 1029.65930176\n",
            "Epoch:  97 Step:   658  time: 1.308069 s d_loss: 1.53312218, g_loss: 865.49755859 -- mean_d_loss: 6.31849527, mean_g_loss: 1026.87683105\n",
            "Epoch:  97 Step:   659  time: 1.310246 s d_loss: 1.21970415, g_loss: 1093.36108398 -- mean_d_loss: 6.23351526, mean_g_loss: 1027.98486328\n",
            "Epoch:  97 Step:   660  time: 1.311918 s d_loss: 1.25345457, g_loss: 1048.82922363 -- mean_d_loss: 6.15187502, mean_g_loss: 1028.32653809\n",
            "Epoch:  97 Step:   661  time: 1.303347 s d_loss: 1.39409709, g_loss: 957.72613525 -- mean_d_loss: 6.07513666, mean_g_loss: 1027.18786621\n",
            "Epoch:  97 Step:   662  time: 1.312114 s d_loss: 4.12975693, g_loss: 1136.16723633 -- mean_d_loss: 6.04425764, mean_g_loss: 1028.91772461\n",
            "Epoch:  97 Step:   663  time: 1.294544 s d_loss: 55.91730499, g_loss: 1063.54638672 -- mean_d_loss: 6.82352400, mean_g_loss: 1029.45874023\n",
            "Epoch:  97 Step:   664  time: 1.334854 s d_loss: 143.47978210, g_loss: 942.89294434 -- mean_d_loss: 8.92592812, mean_g_loss: 1028.12695312\n",
            "Epoch:  97 Step:   665  time: 1.319302 s d_loss: 8.59240723, g_loss: 971.77618408 -- mean_d_loss: 8.92087460, mean_g_loss: 1027.27307129\n",
            "Epoch:  97 Step:   666  time: 1.283282 s d_loss: 11.55784512, g_loss: 935.71069336 -- mean_d_loss: 8.96023273, mean_g_loss: 1025.90649414\n",
            "Epoch:  97 Step:   667  time: 1.305828 s d_loss: 6.28879786, g_loss: 1135.31738281 -- mean_d_loss: 8.92094707, mean_g_loss: 1027.51550293\n",
            "Epoch:  97 Step:   668  time: 1.293003 s d_loss: 5.18888378, g_loss: 945.24987793 -- mean_d_loss: 8.86685944, mean_g_loss: 1026.32324219\n",
            "Epoch:  97 Step:   669  time: 1.314779 s d_loss: 2.17785740, g_loss: 981.30871582 -- mean_d_loss: 8.77130222, mean_g_loss: 1025.68029785\n",
            "Epoch:  97 Step:   670  time: 1.314541 s d_loss: 1.85393536, g_loss: 1018.14965820 -- mean_d_loss: 8.67387486, mean_g_loss: 1025.57421875\n",
            "Epoch:  97 Step:   671  time: 1.321149 s d_loss: 8.62863636, g_loss: 1057.26074219 -- mean_d_loss: 8.67324638, mean_g_loss: 1026.01416016\n",
            "Epoch:  97 Step:   672  time: 1.331051 s d_loss: 1.94326997, g_loss: 1048.75817871 -- mean_d_loss: 8.58105564, mean_g_loss: 1026.32580566\n",
            "Epoch:  97 Step:   673  time: 1.297691 s d_loss: 4.48229694, g_loss: 1054.53845215 -- mean_d_loss: 8.52566719, mean_g_loss: 1026.70703125\n",
            "Epoch:  97 Step:   674  time: 1.317699 s d_loss: 1.31225562, g_loss: 1057.37194824 -- mean_d_loss: 8.42948818, mean_g_loss: 1027.11596680\n",
            "Epoch:  97 Step:   675  time: 1.320966 s d_loss: 1.06344640, g_loss: 972.33850098 -- mean_d_loss: 8.33256721, mean_g_loss: 1026.39514160\n",
            "Epoch:  97 Step:   676  time: 1.336962 s d_loss: 1.52548623, g_loss: 951.21679688 -- mean_d_loss: 8.24416351, mean_g_loss: 1025.41882324\n",
            "Epoch:  97 Step:   677  time: 1.330515 s d_loss: 0.94897640, g_loss: 1033.72729492 -- mean_d_loss: 8.15063572, mean_g_loss: 1025.52539062\n",
            "Epoch:  97 Step:   678  time: 1.295755 s d_loss: 1.64536023, g_loss: 1105.40612793 -- mean_d_loss: 8.06829071, mean_g_loss: 1026.53649902\n",
            "Epoch:  97 Step:   679  time: 1.320071 s d_loss: 1.33750856, g_loss: 1139.11120605 -- mean_d_loss: 7.98415613, mean_g_loss: 1027.94360352\n",
            "Epoch:  97 Step:   680  time: 1.295666 s d_loss: 17.87408638, g_loss: 1001.45184326 -- mean_d_loss: 8.10625362, mean_g_loss: 1027.61657715\n",
            "Epoch:  97 Step:   681  time: 1.280813 s d_loss: 3.73247051, g_loss: 995.20849609 -- mean_d_loss: 8.05291557, mean_g_loss: 1027.22143555\n",
            "Epoch:  97 Step:   682  time: 1.305281 s d_loss: 11.34223938, g_loss: 1132.67065430 -- mean_d_loss: 8.09254551, mean_g_loss: 1028.49194336\n",
            "Epoch:  97 Step:   683  time: 1.318529 s d_loss: 1.48137844, g_loss: 987.94793701 -- mean_d_loss: 8.01384163, mean_g_loss: 1028.00915527\n",
            "Epoch:  97 Step:   684  time: 1.328614 s d_loss: 3.75353885, g_loss: 1027.32971191 -- mean_d_loss: 7.96371984, mean_g_loss: 1028.00122070\n",
            "Epoch:  97 Step:   685  time: 1.315918 s d_loss: 0.92380029, g_loss: 909.68933105 -- mean_d_loss: 7.88186073, mean_g_loss: 1026.62548828\n",
            "Epoch:  97 Step:   686  time: 1.329799 s d_loss: 1.01195610, g_loss: 1155.83654785 -- mean_d_loss: 7.80289650, mean_g_loss: 1028.11059570\n",
            "Epoch:  97 Step:   687  time: 1.311960 s d_loss: 0.93942583, g_loss: 857.76959229 -- mean_d_loss: 7.72490263, mean_g_loss: 1026.17492676\n",
            "Epoch:  97 Step:   688  time: 1.316347 s d_loss: 1.00027633, g_loss: 970.54364014 -- mean_d_loss: 7.64934540, mean_g_loss: 1025.54992676\n",
            "Epoch:  97 Step:   689  time: 1.328791 s d_loss: 1.27852762, g_loss: 1081.69641113 -- mean_d_loss: 7.57855844, mean_g_loss: 1026.17382812\n",
            "Epoch:  97 Step:   690  time: 1.286189 s d_loss: 1.39980507, g_loss: 1063.53149414 -- mean_d_loss: 7.51065969, mean_g_loss: 1026.58435059\n",
            "Epoch:  97 Step:   691  time: 1.299280 s d_loss: 6.26636553, g_loss: 853.80407715 -- mean_d_loss: 7.49713469, mean_g_loss: 1024.70629883\n",
            "Epoch:  97 Step:   692  time: 1.299808 s d_loss: 2.22250295, g_loss: 957.99481201 -- mean_d_loss: 7.44041777, mean_g_loss: 1023.98889160\n",
            "Epoch:  97 Step:   693  time: 1.322352 s d_loss: 1.37231004, g_loss: 1015.90808105 -- mean_d_loss: 7.37586355, mean_g_loss: 1023.90295410\n",
            "Epoch:  97 Step:   694  time: 1.291872 s d_loss: 1.31930888, g_loss: 882.47009277 -- mean_d_loss: 7.31211042, mean_g_loss: 1022.41412354\n",
            "Epoch:  97 Step:   695  time: 1.319437 s d_loss: 1.60739410, g_loss: 1007.85192871 -- mean_d_loss: 7.25268698, mean_g_loss: 1022.26245117\n",
            "Epoch:  97 Step:   696  time: 1.330333 s d_loss: 1.23949742, g_loss: 1008.55841064 -- mean_d_loss: 7.19069529, mean_g_loss: 1022.12115479\n",
            "Epoch:  97 Step:   697  time: 1.323379 s d_loss: 0.93246466, g_loss: 1067.74780273 -- mean_d_loss: 7.12683582, mean_g_loss: 1022.58673096\n",
            "Epoch:  97 Step:   698  time: 1.321585 s d_loss: 42.90832901, g_loss: 943.90814209 -- mean_d_loss: 7.48826504, mean_g_loss: 1021.79199219\n",
            "Epoch:  97 Step:   699  time: 1.312514 s d_loss: 1.74624276, g_loss: 893.03625488 -- mean_d_loss: 7.43084478, mean_g_loss: 1020.50445557\n",
            "Epoch:  97 Step:   700  time: 1.321682 s d_loss: 5.92307043, g_loss: 976.84179688 -- mean_d_loss: 7.41591644, mean_g_loss: 1020.07214355\n",
            "Epoch:  97 Step:   701  time: 1.331777 s d_loss: 1.12148798, g_loss: 983.76647949 -- mean_d_loss: 7.35420609, mean_g_loss: 1019.71624756\n",
            "Epoch:  97 Step:   702  time: 1.303779 s d_loss: 38.81393814, g_loss: 1001.30456543 -- mean_d_loss: 7.65964079, mean_g_loss: 1019.53747559\n",
            "Epoch:  97 Step:   703  time: 1.313878 s d_loss: 3.06486750, g_loss: 1095.18750000 -- mean_d_loss: 7.61546040, mean_g_loss: 1020.26489258\n",
            "Epoch:  97 Step:   704  time: 1.330418 s d_loss: 6.06700706, g_loss: 1013.28570557 -- mean_d_loss: 7.60071325, mean_g_loss: 1020.19842529\n",
            "Epoch:  97 Step:   705  time: 1.305934 s d_loss: 42.21881104, g_loss: 958.64746094 -- mean_d_loss: 7.92729902, mean_g_loss: 1019.61779785\n",
            "Epoch:  97 Step:   706  time: 1.321270 s d_loss: 18.52182770, g_loss: 1107.56933594 -- mean_d_loss: 8.02631378, mean_g_loss: 1020.43975830\n",
            "Epoch:  97 Step:   707  time: 1.325870 s d_loss: 7.38309336, g_loss: 1157.36987305 -- mean_d_loss: 8.02035809, mean_g_loss: 1021.70758057\n",
            "Epoch:  97 Step:   708  time: 1.332404 s d_loss: 1.78343904, g_loss: 1174.11816406 -- mean_d_loss: 7.96313858, mean_g_loss: 1023.10583496\n",
            "Epoch:  97 Step:   709  time: 1.311775 s d_loss: 2.89547205, g_loss: 1040.11145020 -- mean_d_loss: 7.91706896, mean_g_loss: 1023.26043701\n",
            "Epoch:  97 Step:   710  time: 1.327837 s d_loss: 6.68221712, g_loss: 1021.25177002 -- mean_d_loss: 7.90594387, mean_g_loss: 1023.24230957\n",
            "Epoch:  97 Step:   711  time: 1.321322 s d_loss: 2.61443853, g_loss: 958.75207520 -- mean_d_loss: 7.85869837, mean_g_loss: 1022.66650391\n",
            "Epoch:  97 Step:   712  time: 1.297747 s d_loss: 0.91197455, g_loss: 953.03857422 -- mean_d_loss: 7.79722261, mean_g_loss: 1022.05035400\n",
            "Epoch:  97 Step:   713  time: 1.330275 s d_loss: 53.43151855, g_loss: 1106.10925293 -- mean_d_loss: 8.19752407, mean_g_loss: 1022.78771973\n",
            "Epoch:  97 Step:   714  time: 1.344862 s d_loss: 4.03729820, g_loss: 990.56140137 -- mean_d_loss: 8.16134739, mean_g_loss: 1022.50744629\n",
            "Epoch:  97 Step:   715  time: 1.290505 s d_loss: 1.94156647, g_loss: 1095.32275391 -- mean_d_loss: 8.10772896, mean_g_loss: 1023.13519287\n",
            "Epoch:  97 Step:   716  time: 1.313489 s d_loss: 26.66864777, g_loss: 1155.93066406 -- mean_d_loss: 8.26636982, mean_g_loss: 1024.27014160\n",
            "Epoch:  97 Step:   717  time: 1.325808 s d_loss: 8.07785416, g_loss: 1092.60180664 -- mean_d_loss: 8.26477242, mean_g_loss: 1024.84924316\n",
            "Epoch:  97 Step:   718  time: 1.318146 s d_loss: 1.45882094, g_loss: 1024.85839844 -- mean_d_loss: 8.20757866, mean_g_loss: 1024.84936523\n",
            "Epoch:  97 Step:   719  time: 1.313840 s d_loss: 1.10852587, g_loss: 933.06030273 -- mean_d_loss: 8.14842033, mean_g_loss: 1024.08447266\n",
            "Epoch:  97 Step:   720  time: 1.291479 s d_loss: 0.96712375, g_loss: 971.89715576 -- mean_d_loss: 8.08907032, mean_g_loss: 1023.65313721\n",
            "Epoch:  97 Step:   721  time: 1.329487 s d_loss: 1.68701792, g_loss: 960.13189697 -- mean_d_loss: 8.03659439, mean_g_loss: 1023.13250732\n",
            "Epoch:  97 Step:   722  time: 1.306112 s d_loss: 0.97201532, g_loss: 1115.34545898 -- mean_d_loss: 7.97915888, mean_g_loss: 1023.88220215\n",
            "Epoch:  97 Step:   723  time: 1.314852 s d_loss: 0.80735534, g_loss: 1037.66809082 -- mean_d_loss: 7.92132187, mean_g_loss: 1023.99340820\n",
            "Epoch:  97 Step:   724  time: 1.309941 s d_loss: 0.90523821, g_loss: 1016.48339844 -- mean_d_loss: 7.86519289, mean_g_loss: 1023.93328857\n",
            "Epoch:  97 Step:   725  time: 1.319244 s d_loss: 16.33550644, g_loss: 970.35009766 -- mean_d_loss: 7.93241739, mean_g_loss: 1023.50805664\n",
            "Epoch:  97 Step:   726  time: 1.284172 s d_loss: 9.52833271, g_loss: 1027.20654297 -- mean_d_loss: 7.94498396, mean_g_loss: 1023.53717041\n",
            "Epoch:  97 Step:   727  time: 1.319732 s d_loss: 52.82507324, g_loss: 859.37512207 -- mean_d_loss: 8.29560947, mean_g_loss: 1022.25463867\n",
            "Epoch:  97 Step:   728  time: 1.310375 s d_loss: 1.63946152, g_loss: 1096.11791992 -- mean_d_loss: 8.24401093, mean_g_loss: 1022.82727051\n",
            "Epoch:  97 Step:   729  time: 1.297341 s d_loss: 1.13579118, g_loss: 1121.60375977 -- mean_d_loss: 8.18933201, mean_g_loss: 1023.58715820\n",
            "Epoch:  97 Step:   730  time: 1.324821 s d_loss: 2.18840170, g_loss: 1202.06005859 -- mean_d_loss: 8.14352322, mean_g_loss: 1024.94958496\n",
            "Epoch:  97 Step:   731  time: 1.325475 s d_loss: 0.96315563, g_loss: 945.99719238 -- mean_d_loss: 8.08912659, mean_g_loss: 1024.35144043\n",
            "Epoch:  97 Step:   732  time: 1.322105 s d_loss: 1.96071804, g_loss: 934.03063965 -- mean_d_loss: 8.04304790, mean_g_loss: 1023.67236328\n",
            "Epoch:  97 Step:   733  time: 1.328150 s d_loss: 1.32454944, g_loss: 1061.57373047 -- mean_d_loss: 7.99290991, mean_g_loss: 1023.95520020\n",
            "Epoch:  97 Step:   734  time: 1.332000 s d_loss: 2.49940538, g_loss: 974.54339600 -- mean_d_loss: 7.95221710, mean_g_loss: 1023.58923340\n",
            "Epoch:  97 Step:   735  time: 1.300567 s d_loss: 1.00652838, g_loss: 880.16320801 -- mean_d_loss: 7.90114546, mean_g_loss: 1022.53460693\n",
            "Epoch:  97 Step:   736  time: 1.316948 s d_loss: 2.47755051, g_loss: 807.14916992 -- mean_d_loss: 7.86155701, mean_g_loss: 1020.96246338\n",
            "Epoch:  97 Step:   737  time: 1.329931 s d_loss: 1.61753309, g_loss: 1113.24768066 -- mean_d_loss: 7.81631088, mean_g_loss: 1021.63122559\n",
            "Epoch:  97 Step:   738  time: 1.294724 s d_loss: 1.00969005, g_loss: 1151.37573242 -- mean_d_loss: 7.76734209, mean_g_loss: 1022.56463623\n",
            "Epoch:  97 Step:   739  time: 1.297843 s d_loss: 0.89492315, g_loss: 1004.06689453 -- mean_d_loss: 7.71825314, mean_g_loss: 1022.43249512\n",
            "Epoch:  97 Step:   740  time: 1.318349 s d_loss: 0.85719675, g_loss: 867.74169922 -- mean_d_loss: 7.66959286, mean_g_loss: 1021.33532715\n",
            "Epoch:  97 Step:   741  time: 1.316039 s d_loss: 0.86254656, g_loss: 1018.54479980 -- mean_d_loss: 7.62165594, mean_g_loss: 1021.31567383\n",
            "Epoch:  97 Step:   742  time: 1.320210 s d_loss: 0.65464950, g_loss: 904.81689453 -- mean_d_loss: 7.57293558, mean_g_loss: 1020.50097656\n",
            "Epoch:  97 Step:   743  time: 1.297167 s d_loss: 1.03528929, g_loss: 1102.78881836 -- mean_d_loss: 7.52753544, mean_g_loss: 1021.07238770\n",
            "Epoch:  97 Step:   744  time: 1.299516 s d_loss: 18.59049416, g_loss: 1203.69580078 -- mean_d_loss: 7.60383129, mean_g_loss: 1022.33190918\n",
            "Epoch:  97 Step:   745  time: 1.293995 s d_loss: 41.80756378, g_loss: 967.57751465 -- mean_d_loss: 7.83810377, mean_g_loss: 1021.95684814\n",
            "Epoch:  97 Step:   746  time: 1.315861 s d_loss: 1.59938264, g_loss: 947.88977051 -- mean_d_loss: 7.79566336, mean_g_loss: 1021.45300293\n",
            "Epoch:  97 Step:   747  time: 1.314815 s d_loss: 10.87851715, g_loss: 857.42236328 -- mean_d_loss: 7.81649351, mean_g_loss: 1020.34472656\n",
            "Epoch:  97 Step:   748  time: 1.309081 s d_loss: 11.78899384, g_loss: 1015.17541504 -- mean_d_loss: 7.84315443, mean_g_loss: 1020.30999756\n",
            "Epoch:  97 Step:   749  time: 1.297199 s d_loss: 52.32830048, g_loss: 1164.93676758 -- mean_d_loss: 8.13972187, mean_g_loss: 1021.27416992\n",
            "Epoch:  97 Step:   750  time: 1.286031 s d_loss: 9.87633514, g_loss: 1086.42114258 -- mean_d_loss: 8.15122223, mean_g_loss: 1021.70562744\n",
            "Epoch:  97 Step:   751  time: 1.282107 s d_loss: 1.72455907, g_loss: 971.87713623 -- mean_d_loss: 8.10894203, mean_g_loss: 1021.37774658\n",
            "Epoch:  97 Step:   752  time: 1.284625 s d_loss: 1.88024628, g_loss: 1111.38256836 -- mean_d_loss: 8.06823158, mean_g_loss: 1021.96600342\n",
            "Epoch:  97 Step:   753  time: 1.308378 s d_loss: 7.43365335, g_loss: 957.25805664 -- mean_d_loss: 8.06411076, mean_g_loss: 1021.54583740\n",
            "Epoch:  97 Step:   754  time: 1.328243 s d_loss: 1.29427207, g_loss: 1073.65014648 -- mean_d_loss: 8.02043438, mean_g_loss: 1021.88208008\n",
            "Epoch:  97 Step:   755  time: 1.329279 s d_loss: 21.97389984, g_loss: 1198.83276367 -- mean_d_loss: 8.10987949, mean_g_loss: 1023.01629639\n",
            "Epoch:  97 Step:   756  time: 1.341347 s d_loss: 51.63991165, g_loss: 1104.25061035 -- mean_d_loss: 8.38714123, mean_g_loss: 1023.53375244\n",
            "Epoch:  97 Step:   757  time: 1.354031 s d_loss: 6.79079008, g_loss: 1039.44763184 -- mean_d_loss: 8.37703705, mean_g_loss: 1023.63452148\n",
            "Epoch:  97 Step:   758  time: 1.285053 s d_loss: 78.98747253, g_loss: 1018.62097168 -- mean_d_loss: 8.82112789, mean_g_loss: 1023.60296631\n",
            "Epoch:  97 Step:   759  time: 1.323027 s d_loss: 3.30824423, g_loss: 972.10803223 -- mean_d_loss: 8.78667259, mean_g_loss: 1023.28112793\n",
            "Epoch:  97 Step:   760  time: 1.322830 s d_loss: 11.17211342, g_loss: 1096.10400391 -- mean_d_loss: 8.80148888, mean_g_loss: 1023.73352051\n",
            "Epoch:  97 Step:   761  time: 1.288992 s d_loss: 3.95283914, g_loss: 1006.91973877 -- mean_d_loss: 8.77155876, mean_g_loss: 1023.62969971\n",
            "Epoch:  97 Step:   762  time: 1.317637 s d_loss: 64.61392975, g_loss: 968.88269043 -- mean_d_loss: 9.11415005, mean_g_loss: 1023.29382324\n",
            "Epoch:  97 Step:   763  time: 1.323892 s d_loss: 3.95578480, g_loss: 1103.59521484 -- mean_d_loss: 9.08269691, mean_g_loss: 1023.78344727\n",
            "Epoch:  97 Step:   764  time: 1.323785 s d_loss: 3.34918308, g_loss: 1166.15356445 -- mean_d_loss: 9.04794884, mean_g_loss: 1024.64636230\n",
            "Epoch:  97 Step:   765  time: 1.303732 s d_loss: 1.65504134, g_loss: 905.49798584 -- mean_d_loss: 9.00341320, mean_g_loss: 1023.92852783\n",
            "Epoch:  97 Step:   766  time: 1.314568 s d_loss: 1.40706956, g_loss: 819.84289551 -- mean_d_loss: 8.95792580, mean_g_loss: 1022.70648193\n",
            "Epoch:  97 Step:   767  time: 1.341402 s d_loss: 1.70683730, g_loss: 1111.02832031 -- mean_d_loss: 8.91476440, mean_g_loss: 1023.23223877\n",
            "Epoch:  97 Step:   768  time: 1.296611 s d_loss: 3.11022115, g_loss: 917.32580566 -- mean_d_loss: 8.88041782, mean_g_loss: 1022.60559082\n",
            "Epoch:  97 Step:   769  time: 1.320596 s d_loss: 3.24480987, g_loss: 1062.06420898 -- mean_d_loss: 8.84726715, mean_g_loss: 1022.83770752\n",
            "Epoch:  97 Step:   770  time: 1.291547 s d_loss: 1.19716835, g_loss: 832.07031250 -- mean_d_loss: 8.80252934, mean_g_loss: 1021.72204590\n",
            "Epoch:  97 Step:   771  time: 1.312377 s d_loss: 1.21551180, g_loss: 1059.25170898 -- mean_d_loss: 8.75841904, mean_g_loss: 1021.94024658\n",
            "Epoch:  97 Step:   772  time: 1.324083 s d_loss: 30.83521652, g_loss: 1148.23510742 -- mean_d_loss: 8.88603020, mean_g_loss: 1022.67022705\n",
            "Epoch:  97 Step:   773  time: 1.302454 s d_loss: 14.65524006, g_loss: 971.03710938 -- mean_d_loss: 8.91918659, mean_g_loss: 1022.37347412\n",
            "Epoch:  97 Step:   774  time: 1.325761 s d_loss: 2.24112177, g_loss: 927.46142578 -- mean_d_loss: 8.88102627, mean_g_loss: 1021.83117676\n",
            "Epoch:  97 Step:   775  time: 1.312129 s d_loss: 3.47535300, g_loss: 990.69311523 -- mean_d_loss: 8.85031223, mean_g_loss: 1021.65423584\n",
            "Epoch:  97 Step:   776  time: 1.317589 s d_loss: 1.27072012, g_loss: 1077.69970703 -- mean_d_loss: 8.80748940, mean_g_loss: 1021.97088623\n",
            "Epoch:  97 Step:   777  time: 1.296983 s d_loss: 5.10203028, g_loss: 1098.95556641 -- mean_d_loss: 8.78667259, mean_g_loss: 1022.40338135\n",
            "Epoch:  97 Step:   778  time: 1.308236 s d_loss: 1.32934844, g_loss: 903.64550781 -- mean_d_loss: 8.74501133, mean_g_loss: 1021.73986816\n",
            "Epoch:  97 Step:   779  time: 1.300360 s d_loss: 1.79078674, g_loss: 940.58380127 -- mean_d_loss: 8.70637703, mean_g_loss: 1021.28900146\n",
            "Epoch:  97 Step:   780  time: 1.311299 s d_loss: 6.91758013, g_loss: 955.87280273 -- mean_d_loss: 8.69649410, mean_g_loss: 1020.92755127\n",
            "Epoch:  97 Step:   781  time: 1.279370 s d_loss: 2.19137311, g_loss: 994.53503418 -- mean_d_loss: 8.66075230, mean_g_loss: 1020.78253174\n",
            "Epoch:  97 Step:   782  time: 1.303043 s d_loss: 1.58978927, g_loss: 970.15905762 -- mean_d_loss: 8.62211323, mean_g_loss: 1020.50592041\n",
            "Epoch:  97 Step:   783  time: 1.302793 s d_loss: 1.40199947, g_loss: 1177.26867676 -- mean_d_loss: 8.58287334, mean_g_loss: 1021.35784912\n",
            "Epoch:  97 Step:   784  time: 1.314745 s d_loss: 1.19138503, g_loss: 982.02752686 -- mean_d_loss: 8.54291916, mean_g_loss: 1021.14526367\n",
            "Epoch:  97 Step:   785  time: 1.287810 s d_loss: 1.14586318, g_loss: 1055.78137207 -- mean_d_loss: 8.50314999, mean_g_loss: 1021.33148193\n",
            "Epoch:  97 Step:   786  time: 1.339647 s d_loss: 0.90560639, g_loss: 1177.20483398 -- mean_d_loss: 8.46252155, mean_g_loss: 1022.16503906\n",
            "Epoch:  97 Step:   787  time: 1.344215 s d_loss: 6.72261429, g_loss: 1014.18157959 -- mean_d_loss: 8.45326710, mean_g_loss: 1022.12261963\n",
            "Epoch:  97 Step:   788  time: 1.342714 s d_loss: 1.90084326, g_loss: 956.45874023 -- mean_d_loss: 8.41859818, mean_g_loss: 1021.77514648\n",
            "Epoch:  97 Step:   789  time: 1.290963 s d_loss: 2.91588736, g_loss: 993.48028564 -- mean_d_loss: 8.38963699, mean_g_loss: 1021.62622070\n",
            "Epoch:  97 Step:   790  time: 1.318229 s d_loss: 1.16827428, g_loss: 872.31945801 -- mean_d_loss: 8.35182858, mean_g_loss: 1020.84448242\n",
            "Epoch:  97 Step:   791  time: 1.337228 s d_loss: 1.25577807, g_loss: 1174.33483887 -- mean_d_loss: 8.31486988, mean_g_loss: 1021.64385986\n",
            "Epoch:  97 Step:   792  time: 1.325682 s d_loss: 3.71540236, g_loss: 1150.84375000 -- mean_d_loss: 8.29103947, mean_g_loss: 1022.31329346\n",
            "Epoch:  97 Step:   793  time: 1.292205 s d_loss: 1.16559958, g_loss: 890.96289062 -- mean_d_loss: 8.25431061, mean_g_loss: 1021.63629150\n",
            "Epoch:  97 Step:   794  time: 1.332129 s d_loss: 1.14724815, g_loss: 921.15039062 -- mean_d_loss: 8.21786404, mean_g_loss: 1021.12097168\n",
            "Epoch:  97 Step:   795  time: 1.323084 s d_loss: 10.07738972, g_loss: 845.42712402 -- mean_d_loss: 8.22735119, mean_g_loss: 1020.22454834\n",
            "Epoch:  97 Step:   796  time: 1.312282 s d_loss: 51.86516190, g_loss: 944.36193848 -- mean_d_loss: 8.44886208, mean_g_loss: 1019.83947754\n",
            "Epoch:  97 Step:   797  time: 1.345592 s d_loss: 2.49031925, g_loss: 883.80078125 -- mean_d_loss: 8.41876888, mean_g_loss: 1019.15240479\n",
            "Epoch:  97 Step:   798  time: 1.313278 s d_loss: 1.75982058, g_loss: 968.73022461 -- mean_d_loss: 8.38530636, mean_g_loss: 1018.89904785\n",
            "Epoch:  97 Step:   799  time: 1.315045 s d_loss: 1.87188697, g_loss: 948.68725586 -- mean_d_loss: 8.35273933, mean_g_loss: 1018.54797363\n",
            "Epoch:  97 Step:   800  time: 1.319226 s d_loss: 1.13753557, g_loss: 911.86706543 -- mean_d_loss: 1.13753557, mean_g_loss: 911.86706543\n",
            "Epoch:  97 Step:   801  time: 1.325365 s d_loss: 1.06944823, g_loss: 901.69030762 -- mean_d_loss: 1.10349190, mean_g_loss: 906.77868652\n",
            "Epoch:  97 Step:   802  time: 1.313759 s d_loss: 6.88248920, g_loss: 1089.27661133 -- mean_d_loss: 3.02982426, mean_g_loss: 967.61132812\n",
            "Epoch:  97 Step:   803  time: 1.324080 s d_loss: 41.10838318, g_loss: 901.80389404 -- mean_d_loss: 12.54946423, mean_g_loss: 951.15948486\n",
            "Epoch:  97 Step:   804  time: 1.316083 s d_loss: 1.81819630, g_loss: 1021.15539551 -- mean_d_loss: 10.40321064, mean_g_loss: 965.15869141\n",
            "Epoch:  97 Step:   805  time: 1.324683 s d_loss: 1.38898122, g_loss: 828.75140381 -- mean_d_loss: 8.90083885, mean_g_loss: 942.42413330\n",
            "Epoch:  97 Step:   806  time: 1.323023 s d_loss: 1.37439835, g_loss: 1041.34240723 -- mean_d_loss: 7.82563305, mean_g_loss: 956.55529785\n",
            "Epoch:  97 Step:   807  time: 1.328638 s d_loss: 0.87211901, g_loss: 888.37249756 -- mean_d_loss: 6.95644379, mean_g_loss: 948.03247070\n",
            "Epoch:  97 Step:   808  time: 1.283760 s d_loss: 1.15804660, g_loss: 1029.61267090 -- mean_d_loss: 6.31217766, mean_g_loss: 957.09692383\n",
            "Epoch:  97 Step:   809  time: 1.344888 s d_loss: 1.24335897, g_loss: 1152.55371094 -- mean_d_loss: 5.80529547, mean_g_loss: 976.64257812\n",
            "Epoch:  97 Step:   810  time: 1.314249 s d_loss: 0.85005790, g_loss: 1022.74859619 -- mean_d_loss: 5.35481977, mean_g_loss: 980.83404541\n",
            "Epoch:  97 Step:   811  time: 1.314387 s d_loss: 0.76765764, g_loss: 945.11761475 -- mean_d_loss: 4.97255611, mean_g_loss: 977.85766602\n",
            "Epoch:  97 Step:   812  time: 1.322970 s d_loss: 1.59146678, g_loss: 1113.21789551 -- mean_d_loss: 4.71247196, mean_g_loss: 988.26995850\n",
            "Epoch:  97 Step:   813  time: 1.331472 s d_loss: 1.37813842, g_loss: 1214.58020020 -- mean_d_loss: 4.47430563, mean_g_loss: 1004.43499756\n",
            "Epoch:  97 Step:   814  time: 1.324358 s d_loss: 3.05152512, g_loss: 1112.17272949 -- mean_d_loss: 4.37945366, mean_g_loss: 1011.61749268\n",
            "Epoch:  97 Step:   815  time: 1.311412 s d_loss: 3.16466141, g_loss: 1033.27783203 -- mean_d_loss: 4.30352879, mean_g_loss: 1012.97131348\n",
            "Epoch:  97 Step:   816  time: 1.316369 s d_loss: 0.96024501, g_loss: 897.55175781 -- mean_d_loss: 4.10686493, mean_g_loss: 1006.18200684\n",
            "Epoch:  97 Step:   817  time: 1.319873 s d_loss: 1.04125440, g_loss: 961.65893555 -- mean_d_loss: 3.93655300, mean_g_loss: 1003.70843506\n",
            "Epoch:  97 Step:   818  time: 1.303335 s d_loss: 1.86522007, g_loss: 1006.38629150 -- mean_d_loss: 3.82753563, mean_g_loss: 1003.84942627\n",
            "Epoch:  97 Step:   819  time: 1.305232 s d_loss: 1.25589883, g_loss: 1019.88287354 -- mean_d_loss: 3.69895363, mean_g_loss: 1004.65106201\n",
            "Epoch:  97 Step:   820  time: 1.312149 s d_loss: 0.89357930, g_loss: 903.58300781 -- mean_d_loss: 3.56536436, mean_g_loss: 999.83837891\n",
            "Epoch:  97 Step:   821  time: 1.321694 s d_loss: 1.87333357, g_loss: 955.70373535 -- mean_d_loss: 3.48845387, mean_g_loss: 997.83221436\n",
            "Epoch:  97 Step:   822  time: 1.340451 s d_loss: 2.11145568, g_loss: 958.71710205 -- mean_d_loss: 3.42858458, mean_g_loss: 996.13153076\n",
            "Epoch:  97 Step:   823  time: 1.321602 s d_loss: 1.10966122, g_loss: 1001.88562012 -- mean_d_loss: 3.33196282, mean_g_loss: 996.37127686\n",
            "Epoch:  97 Step:   824  time: 1.323420 s d_loss: 4.04509068, g_loss: 984.55450439 -- mean_d_loss: 3.36048794, mean_g_loss: 995.89862061\n",
            "Epoch:  97 Step:   825  time: 1.288366 s d_loss: 1.18795288, g_loss: 985.33496094 -- mean_d_loss: 3.27692890, mean_g_loss: 995.49230957\n",
            "Epoch:  97 Step:   826  time: 1.286495 s d_loss: 44.76697159, g_loss: 958.65466309 -- mean_d_loss: 4.81359673, mean_g_loss: 994.12799072\n",
            "Epoch:  97 Step:   827  time: 1.319073 s d_loss: 1.31038642, g_loss: 939.97863770 -- mean_d_loss: 4.68848181, mean_g_loss: 992.19403076\n",
            "Epoch:  97 Step:   828  time: 1.316930 s d_loss: 4.84719086, g_loss: 1045.63769531 -- mean_d_loss: 4.69395494, mean_g_loss: 994.03692627\n",
            "Epoch:  97 Step:   829  time: 1.290587 s d_loss: 1.74837589, g_loss: 921.53308105 -- mean_d_loss: 4.59576941, mean_g_loss: 991.62011719\n",
            "Epoch:  97 Step:   830  time: 1.301935 s d_loss: 1.12224984, g_loss: 868.15270996 -- mean_d_loss: 4.48372030, mean_g_loss: 987.63726807\n",
            "Epoch:  97 Step:   831  time: 1.319865 s d_loss: 1.50201356, g_loss: 919.15100098 -- mean_d_loss: 4.39054203, mean_g_loss: 985.49707031\n",
            "Epoch:  97 Step:   832  time: 1.315428 s d_loss: 3.00684738, g_loss: 1018.38555908 -- mean_d_loss: 4.34861183, mean_g_loss: 986.49365234\n",
            "Epoch:  97 Step:   833  time: 1.338470 s d_loss: 1.43613613, g_loss: 1005.16741943 -- mean_d_loss: 4.26295090, mean_g_loss: 987.04284668\n",
            "Epoch:  97 Step:   834  time: 1.321572 s d_loss: 1.51643586, g_loss: 1048.86743164 -- mean_d_loss: 4.18447924, mean_g_loss: 988.80926514\n",
            "Epoch:  97 Step:   835  time: 1.330702 s d_loss: 0.90390694, g_loss: 871.56665039 -- mean_d_loss: 4.09335184, mean_g_loss: 985.55249023\n",
            "Epoch:  97 Step:   836  time: 1.290051 s d_loss: 2.62623501, g_loss: 960.29223633 -- mean_d_loss: 4.05370045, mean_g_loss: 984.86981201\n",
            "Epoch:  97 Step:   837  time: 1.291205 s d_loss: 0.87715793, g_loss: 952.60351562 -- mean_d_loss: 3.97010684, mean_g_loss: 984.02075195\n",
            "Epoch:  97 Step:   838  time: 1.339922 s d_loss: 13.87142277, g_loss: 1039.13049316 -- mean_d_loss: 4.22398710, mean_g_loss: 985.43377686\n",
            "Epoch:  97 Step:   839  time: 1.314110 s d_loss: 18.34633827, g_loss: 1014.33392334 -- mean_d_loss: 4.57704592, mean_g_loss: 986.15625000\n",
            "Epoch:  97 Step:   840  time: 1.308179 s d_loss: 9.83429432, g_loss: 1055.33264160 -- mean_d_loss: 4.70527124, mean_g_loss: 987.84344482\n",
            "Epoch:  97 Step:   841  time: 1.318233 s d_loss: 3.81540537, g_loss: 905.85504150 -- mean_d_loss: 4.68408394, mean_g_loss: 985.89135742\n",
            "Epoch:  97 Step:   842  time: 1.327604 s d_loss: 1.18452847, g_loss: 1019.65167236 -- mean_d_loss: 4.60269880, mean_g_loss: 986.67651367\n",
            "Epoch:  97 Step:   843  time: 1.325402 s d_loss: 44.45724487, g_loss: 1107.65112305 -- mean_d_loss: 5.50848389, mean_g_loss: 989.42596436\n",
            "Epoch:  97 Step:   844  time: 1.317026 s d_loss: 32.49449539, g_loss: 1204.83325195 -- mean_d_loss: 6.10817337, mean_g_loss: 994.21276855\n",
            "Epoch:  97 Step:   845  time: 1.323126 s d_loss: 16.11999321, g_loss: 1390.73193359 -- mean_d_loss: 6.32582140, mean_g_loss: 1002.83270264\n",
            "Epoch:  97 Step:   846  time: 1.311816 s d_loss: 1.59274781, g_loss: 920.20788574 -- mean_d_loss: 6.22511768, mean_g_loss: 1001.07470703\n",
            "Epoch:  97 Step:   847  time: 1.319985 s d_loss: 7.49386883, g_loss: 957.22204590 -- mean_d_loss: 6.25155020, mean_g_loss: 1000.16113281\n",
            "Epoch:  97 Step:   848  time: 1.317911 s d_loss: 1.00623453, g_loss: 1046.02636719 -- mean_d_loss: 6.14450264, mean_g_loss: 1001.09716797\n",
            "Epoch:  97 Step:   849  time: 1.291249 s d_loss: 1.87942958, g_loss: 949.88928223 -- mean_d_loss: 6.05920124, mean_g_loss: 1000.07305908\n",
            "Epoch:  97 Step:   850  time: 1.319481 s d_loss: 1.08845448, g_loss: 1056.78393555 -- mean_d_loss: 5.96173525, mean_g_loss: 1001.18505859\n",
            "Epoch:  97 Step:   851  time: 1.327450 s d_loss: 1.34349275, g_loss: 1010.07446289 -- mean_d_loss: 5.87292290, mean_g_loss: 1001.35601807\n",
            "Epoch:  97 Step:   852  time: 1.316114 s d_loss: 1.74132764, g_loss: 1031.71496582 -- mean_d_loss: 5.79496861, mean_g_loss: 1001.92883301\n",
            "Epoch:  97 Step:   853  time: 1.315137 s d_loss: 1.62840378, g_loss: 1002.91723633 -- mean_d_loss: 5.71781015, mean_g_loss: 1001.94714355\n",
            "Epoch:  97 Step:   854  time: 1.331910 s d_loss: 1.19773364, g_loss: 979.15527344 -- mean_d_loss: 5.63562679, mean_g_loss: 1001.53271484\n",
            "Epoch:  97 Step:   855  time: 1.327372 s d_loss: 1.59969890, g_loss: 1045.12658691 -- mean_d_loss: 5.56355667, mean_g_loss: 1002.31115723\n",
            "Epoch:  97 Step:   856  time: 1.331053 s d_loss: 1.88451457, g_loss: 1030.45935059 -- mean_d_loss: 5.49901199, mean_g_loss: 1002.80505371\n",
            "Epoch:  97 Step:   857  time: 1.287708 s d_loss: 1.20554399, g_loss: 942.98291016 -- mean_d_loss: 5.42498684, mean_g_loss: 1001.77362061\n",
            "Epoch:  97 Step:   858  time: 1.296720 s d_loss: 1.70531249, g_loss: 956.97955322 -- mean_d_loss: 5.36194181, mean_g_loss: 1001.01440430\n",
            "Epoch:  97 Step:   859  time: 1.334798 s d_loss: 1.12834060, g_loss: 1007.81945801 -- mean_d_loss: 5.29138136, mean_g_loss: 1001.12786865\n",
            "Epoch:  97 Step:   860  time: 1.326808 s d_loss: 0.87391961, g_loss: 1077.99121094 -- mean_d_loss: 5.21896410, mean_g_loss: 1002.38793945\n",
            "Epoch:  97 Step:   861  time: 1.317840 s d_loss: 0.82582450, g_loss: 917.70520020 -- mean_d_loss: 5.14810705, mean_g_loss: 1001.02209473\n",
            "Epoch:  97 Step:   862  time: 1.304149 s d_loss: 34.78958130, g_loss: 869.50292969 -- mean_d_loss: 5.61860704, mean_g_loss: 998.93450928\n",
            "Epoch:  97 Step:   863  time: 1.336524 s d_loss: 12.23667526, g_loss: 1040.36987305 -- mean_d_loss: 5.72201395, mean_g_loss: 999.58197021\n",
            "Epoch:  97 Step:   864  time: 1.298390 s d_loss: 1.04473937, g_loss: 1110.93347168 -- mean_d_loss: 5.65005589, mean_g_loss: 1001.29504395\n",
            "Epoch:  97 Step:   865  time: 1.318397 s d_loss: 0.99359173, g_loss: 1033.42004395 -- mean_d_loss: 5.57950354, mean_g_loss: 1001.78186035\n",
            "Epoch:  97 Step:   866  time: 1.312521 s d_loss: 2.25833321, g_loss: 963.27563477 -- mean_d_loss: 5.52993345, mean_g_loss: 1001.20709229\n",
            "Epoch:  97 Step:   867  time: 1.320616 s d_loss: 1.10489774, g_loss: 913.75341797 -- mean_d_loss: 5.46485949, mean_g_loss: 999.92095947\n",
            "Epoch:  97 Step:   868  time: 1.354151 s d_loss: 1.83650959, g_loss: 930.63415527 -- mean_d_loss: 5.41227484, mean_g_loss: 998.91680908\n",
            "Epoch:  97 Step:   869  time: 1.321018 s d_loss: 2.35112166, g_loss: 1067.85095215 -- mean_d_loss: 5.36854410, mean_g_loss: 999.90155029\n",
            "Epoch:  97 Step:   870  time: 1.337462 s d_loss: 0.98414826, g_loss: 1010.52514648 -- mean_d_loss: 5.30679226, mean_g_loss: 1000.05114746\n",
            "Epoch:  97 Step:   871  time: 1.321806 s d_loss: 10.97844887, g_loss: 909.91876221 -- mean_d_loss: 5.38556528, mean_g_loss: 998.79937744\n",
            "Epoch:  97 Step:   872  time: 1.318582 s d_loss: 2.03442359, g_loss: 1000.86218262 -- mean_d_loss: 5.33965921, mean_g_loss: 998.82757568\n",
            "Epoch:  97 Step:   873  time: 1.282544 s d_loss: 3.26202822, g_loss: 1023.76013184 -- mean_d_loss: 5.31158304, mean_g_loss: 999.16448975\n",
            "Epoch:  97 Step:   874  time: 1.321845 s d_loss: 1.13878357, g_loss: 915.53735352 -- mean_d_loss: 5.25594616, mean_g_loss: 998.04949951\n",
            "Epoch:  97 Step:   875  time: 1.346897 s d_loss: 1.60224938, g_loss: 1064.13830566 -- mean_d_loss: 5.20787144, mean_g_loss: 998.91912842\n",
            "Epoch:  97 Step:   876  time: 1.299146 s d_loss: 30.44890404, g_loss: 963.75720215 -- mean_d_loss: 5.53567696, mean_g_loss: 998.46246338\n",
            "Epoch:  97 Step:   877  time: 1.322082 s d_loss: 3.23789334, g_loss: 1043.48510742 -- mean_d_loss: 5.50621796, mean_g_loss: 999.03967285\n",
            "Epoch:  97 Step:   878  time: 1.325152 s d_loss: 40.79293823, g_loss: 1096.22814941 -- mean_d_loss: 5.95288563, mean_g_loss: 1000.26989746\n",
            "Epoch:  97 Step:   879  time: 1.320194 s d_loss: 2.43878150, g_loss: 1157.50866699 -- mean_d_loss: 5.90895939, mean_g_loss: 1002.23535156\n",
            "Epoch:  97 Step:   880  time: 1.296184 s d_loss: 6.40120029, g_loss: 855.32427979 -- mean_d_loss: 5.91503620, mean_g_loss: 1000.42169189\n",
            "Epoch:  97 Step:   881  time: 1.349778 s d_loss: 7.80787230, g_loss: 1160.77355957 -- mean_d_loss: 5.93811989, mean_g_loss: 1002.37719727\n",
            "Epoch:  97 Step:   882  time: 1.304692 s d_loss: 3.34146404, g_loss: 929.09252930 -- mean_d_loss: 5.90683460, mean_g_loss: 1001.49426270\n",
            "Epoch:  97 Step:   883  time: 1.316037 s d_loss: 2.04930758, g_loss: 985.40124512 -- mean_d_loss: 5.86091185, mean_g_loss: 1001.30261230\n",
            "Epoch:  97 Step:   884  time: 1.284321 s d_loss: 7.55326939, g_loss: 1128.59313965 -- mean_d_loss: 5.88082218, mean_g_loss: 1002.80017090\n",
            "Epoch:  97 Step:   885  time: 1.293854 s d_loss: 6.37133789, g_loss: 912.57788086 -- mean_d_loss: 5.88652563, mean_g_loss: 1001.75109863\n",
            "Epoch:  97 Step:   886  time: 1.293972 s d_loss: 5.33468819, g_loss: 983.82238770 -- mean_d_loss: 5.88018274, mean_g_loss: 1001.54498291\n",
            "Epoch:  97 Step:   887  time: 1.320423 s d_loss: 6.65466452, g_loss: 1054.59851074 -- mean_d_loss: 5.88898420, mean_g_loss: 1002.14788818\n",
            "Epoch:  97 Step:   888  time: 1.295402 s d_loss: 4.90187502, g_loss: 1001.92163086 -- mean_d_loss: 5.87789249, mean_g_loss: 1002.14538574\n",
            "Epoch:  97 Step:   889  time: 1.322146 s d_loss: 58.02804565, g_loss: 1151.53076172 -- mean_d_loss: 6.45733929, mean_g_loss: 1003.80523682\n",
            "Epoch:  97 Step:   890  time: 1.317451 s d_loss: 8.86743355, g_loss: 975.32006836 -- mean_d_loss: 6.48382378, mean_g_loss: 1003.49218750\n",
            "Epoch:  97 Step:   891  time: 1.317306 s d_loss: 8.12448883, g_loss: 950.37609863 -- mean_d_loss: 6.50165701, mean_g_loss: 1002.91485596\n",
            "Epoch:  97 Step:   892  time: 1.338122 s d_loss: 20.22657204, g_loss: 1103.70397949 -- mean_d_loss: 6.64923668, mean_g_loss: 1003.99859619\n",
            "Epoch:  97 Step:   893  time: 1.303751 s d_loss: 4.33599043, g_loss: 965.22363281 -- mean_d_loss: 6.62462807, mean_g_loss: 1003.58612061\n",
            "Epoch:  97 Step:   894  time: 1.299105 s d_loss: 2.43110085, g_loss: 1085.70349121 -- mean_d_loss: 6.58048534, mean_g_loss: 1004.45050049\n",
            "Epoch:  97 Step:   895  time: 1.322035 s d_loss: 55.53690720, g_loss: 808.54266357 -- mean_d_loss: 7.09044838, mean_g_loss: 1002.40972900\n",
            "Epoch:  97 Step:   896  time: 1.329539 s d_loss: 27.79248619, g_loss: 1080.30786133 -- mean_d_loss: 7.30387115, mean_g_loss: 1003.21276855\n",
            "Epoch:  97 Step:   897  time: 1.298817 s d_loss: 1.89036071, g_loss: 1009.46643066 -- mean_d_loss: 7.24863148, mean_g_loss: 1003.27661133\n",
            "Epoch:  97 Step:   898  time: 1.307853 s d_loss: 1.03270686, g_loss: 1015.37493896 -- mean_d_loss: 7.18584442, mean_g_loss: 1003.39880371\n",
            "Epoch:  97 Step:   899  time: 1.320969 s d_loss: 1.07278562, g_loss: 1062.99768066 -- mean_d_loss: 7.12471437, mean_g_loss: 1003.99487305\n",
            "Epoch:  97 Step:   900  time: 1.344297 s d_loss: 2.53095627, g_loss: 1146.56970215 -- mean_d_loss: 7.07923126, mean_g_loss: 1005.40649414\n",
            "Epoch:  97 Step:   901  time: 1.323502 s d_loss: 1.01902711, g_loss: 945.81079102 -- mean_d_loss: 7.01981783, mean_g_loss: 1004.82220459\n",
            "Epoch:  97 Step:   902  time: 1.337878 s d_loss: 35.49559784, g_loss: 970.26672363 -- mean_d_loss: 7.29628181, mean_g_loss: 1004.48675537\n",
            "Epoch:  97 Step:   903  time: 1.308197 s d_loss: 1.33751369, g_loss: 878.25109863 -- mean_d_loss: 7.23898602, mean_g_loss: 1003.27288818\n",
            "Epoch:  97 Step:   904  time: 1.317306 s d_loss: 18.84686279, g_loss: 1002.26794434 -- mean_d_loss: 7.34953737, mean_g_loss: 1003.26330566\n",
            "Epoch:  97 Step:   905  time: 1.307400 s d_loss: 1.83845329, g_loss: 922.25671387 -- mean_d_loss: 7.29754591, mean_g_loss: 1002.49914551\n",
            "Epoch:  97 Step:   906  time: 1.320880 s d_loss: 2.16873288, g_loss: 925.93896484 -- mean_d_loss: 7.24961329, mean_g_loss: 1001.78356934\n",
            "Epoch:  97 Step:   907  time: 1.317315 s d_loss: 24.91934204, g_loss: 923.55267334 -- mean_d_loss: 7.41322136, mean_g_loss: 1001.05926514\n",
            "Epoch:  97 Step:   908  time: 1.316638 s d_loss: 7.90897655, g_loss: 911.09606934 -- mean_d_loss: 7.41776991, mean_g_loss: 1000.23388672\n",
            "Epoch:  97 Step:   909  time: 1.314857 s d_loss: 1.65951633, g_loss: 1034.79223633 -- mean_d_loss: 7.36542225, mean_g_loss: 1000.54803467\n",
            "Epoch:  97 Step:   910  time: 1.302488 s d_loss: 2.45291400, g_loss: 956.65588379 -- mean_d_loss: 7.32116604, mean_g_loss: 1000.15258789\n",
            "Epoch:  97 Step:   911  time: 1.299313 s d_loss: 2.58190036, g_loss: 903.88659668 -- mean_d_loss: 7.27885103, mean_g_loss: 999.29302979\n",
            "Epoch:  97 Step:   912  time: 1.321783 s d_loss: 18.75575256, g_loss: 1070.95654297 -- mean_d_loss: 7.38041639, mean_g_loss: 999.92718506\n",
            "Epoch:  97 Step:   913  time: 1.293553 s d_loss: 8.04635048, g_loss: 922.66027832 -- mean_d_loss: 7.38625765, mean_g_loss: 999.24945068\n",
            "Epoch:  97 Step:   914  time: 1.302767 s d_loss: 2.15089083, g_loss: 1047.52221680 -- mean_d_loss: 7.34073257, mean_g_loss: 999.66925049\n",
            "Epoch:  97 Step:   915  time: 1.313716 s d_loss: 1.63149858, g_loss: 1019.51910400 -- mean_d_loss: 7.29151487, mean_g_loss: 999.84033203\n",
            "Epoch:  97 Step:   916  time: 1.304027 s d_loss: 2.02209496, g_loss: 1002.60668945 -- mean_d_loss: 7.24647713, mean_g_loss: 999.86395264\n",
            "Epoch:  97 Step:   917  time: 1.328138 s d_loss: 6.58462048, g_loss: 1016.80627441 -- mean_d_loss: 7.24086809, mean_g_loss: 1000.00756836\n",
            "Epoch:  97 Step:   918  time: 1.318442 s d_loss: 1.83051753, g_loss: 870.65887451 -- mean_d_loss: 7.19540262, mean_g_loss: 998.92053223\n",
            "Epoch:  97 Step:   919  time: 1.346059 s d_loss: 41.47169113, g_loss: 1157.47290039 -- mean_d_loss: 7.48103857, mean_g_loss: 1000.24188232\n",
            "Epoch:  97 Step:   920  time: 1.313346 s d_loss: 3.00608039, g_loss: 921.04541016 -- mean_d_loss: 7.44405556, mean_g_loss: 999.58734131\n",
            "Epoch:  97 Step:   921  time: 1.323372 s d_loss: 8.16084671, g_loss: 852.83935547 -- mean_d_loss: 7.44993067, mean_g_loss: 998.38446045\n",
            "Epoch:  97 Step:   922  time: 1.324921 s d_loss: 1.36806309, g_loss: 988.69189453 -- mean_d_loss: 7.40048456, mean_g_loss: 998.30572510\n",
            "Epoch:  97 Step:   923  time: 1.315162 s d_loss: 1.42779946, g_loss: 1000.44628906 -- mean_d_loss: 7.35231733, mean_g_loss: 998.32293701\n",
            "Epoch:  97 Step:   924  time: 1.288116 s d_loss: 9.14009285, g_loss: 1068.20300293 -- mean_d_loss: 7.36661959, mean_g_loss: 998.88201904\n",
            "Epoch:  97 Step:   925  time: 1.302743 s d_loss: 3.33522081, g_loss: 954.45141602 -- mean_d_loss: 7.33462429, mean_g_loss: 998.52941895\n",
            "Epoch:  97 Step:   926  time: 1.333633 s d_loss: 1.47020233, g_loss: 904.98034668 -- mean_d_loss: 7.28844786, mean_g_loss: 997.79272461\n",
            "Epoch:  97 Step:   927  time: 1.319447 s d_loss: 1.36789095, g_loss: 1095.31909180 -- mean_d_loss: 7.24219370, mean_g_loss: 998.55468750\n",
            "Epoch:  97 Step:   928  time: 1.313461 s d_loss: 1.41367114, g_loss: 1071.02258301 -- mean_d_loss: 7.19701147, mean_g_loss: 999.11645508\n",
            "Epoch:  97 Step:   929  time: 1.319959 s d_loss: 1.70784688, g_loss: 1003.91223145 -- mean_d_loss: 7.15478706, mean_g_loss: 999.15338135\n",
            "Epoch:  97 Step:   930  time: 1.297280 s d_loss: 4.54610634, g_loss: 967.58422852 -- mean_d_loss: 7.13487339, mean_g_loss: 998.91241455\n",
            "Epoch:  97 Step:   931  time: 1.318718 s d_loss: 1.70460260, g_loss: 1021.06494141 -- mean_d_loss: 7.09373474, mean_g_loss: 999.08026123\n",
            "Epoch:  97 Step:   932  time: 1.341820 s d_loss: 0.90837204, g_loss: 1043.01989746 -- mean_d_loss: 7.04722834, mean_g_loss: 999.41058350\n",
            "Epoch:  97 Step:   933  time: 1.327293 s d_loss: 1.24905038, g_loss: 874.31201172 -- mean_d_loss: 7.00395823, mean_g_loss: 998.47705078\n",
            "Epoch:  97 Step:   934  time: 1.325801 s d_loss: 20.97023582, g_loss: 834.03027344 -- mean_d_loss: 7.10741186, mean_g_loss: 997.25891113\n",
            "Epoch:  97 Step:   935  time: 1.332550 s d_loss: 1.20244014, g_loss: 1037.21337891 -- mean_d_loss: 7.06399298, mean_g_loss: 997.55273438\n",
            "Epoch:  97 Step:   936  time: 1.291978 s d_loss: 0.74698246, g_loss: 987.94647217 -- mean_d_loss: 7.01788378, mean_g_loss: 997.48266602\n",
            "Epoch:  97 Step:   937  time: 1.285008 s d_loss: 16.05846786, g_loss: 939.07409668 -- mean_d_loss: 7.08339548, mean_g_loss: 997.05944824\n",
            "Epoch:  97 Step:   938  time: 1.331263 s d_loss: 2.76982093, g_loss: 963.37841797 -- mean_d_loss: 7.05236244, mean_g_loss: 996.81713867\n",
            "Epoch:  97 Step:   939  time: 1.313594 s d_loss: 4.92074585, g_loss: 1189.99023438 -- mean_d_loss: 7.03713655, mean_g_loss: 998.19689941\n",
            "Epoch:  97 Step:   940  time: 1.312606 s d_loss: 3.36332202, g_loss: 1176.02124023 -- mean_d_loss: 7.01108122, mean_g_loss: 999.45800781\n",
            "Epoch:  97 Step:   941  time: 1.326725 s d_loss: 1.07589757, g_loss: 1035.26000977 -- mean_d_loss: 6.96928406, mean_g_loss: 999.71014404\n",
            "Epoch:  97 Step:   942  time: 1.290788 s d_loss: 0.83474237, g_loss: 1073.48937988 -- mean_d_loss: 6.92638540, mean_g_loss: 1000.22607422\n",
            "Epoch:  97 Step:   943  time: 1.307490 s d_loss: 1.24101603, g_loss: 1071.09057617 -- mean_d_loss: 6.88690376, mean_g_loss: 1000.71820068\n",
            "Epoch:  97 Step:   944  time: 1.315945 s d_loss: 55.73552704, g_loss: 961.75756836 -- mean_d_loss: 7.22379017, mean_g_loss: 1000.44946289\n",
            "Epoch:  97 Step:   945  time: 1.322342 s d_loss: 1.27628636, g_loss: 1033.19067383 -- mean_d_loss: 7.18305349, mean_g_loss: 1000.67370605\n",
            "Epoch:  97 Step:   946  time: 1.332194 s d_loss: 2.14174080, g_loss: 1117.59204102 -- mean_d_loss: 7.14875889, mean_g_loss: 1001.46905518\n",
            "Epoch:  97 Step:   947  time: 1.319515 s d_loss: 1.66004860, g_loss: 1096.53833008 -- mean_d_loss: 7.11167288, mean_g_loss: 1002.11138916\n",
            "Epoch:  97 Step:   948  time: 1.315500 s d_loss: 1.89642739, g_loss: 1000.63342285 -- mean_d_loss: 7.07667160, mean_g_loss: 1002.10150146\n",
            "Epoch:  97 Step:   949  time: 1.298343 s d_loss: 1.05165482, g_loss: 948.96081543 -- mean_d_loss: 7.03650475, mean_g_loss: 1001.74719238\n",
            "Epoch:  97 Step:   950  time: 1.338200 s d_loss: 3.68298888, g_loss: 986.83801270 -- mean_d_loss: 7.01429605, mean_g_loss: 1001.64849854\n",
            "Epoch:  97 Step:   951  time: 1.312876 s d_loss: 1.01872182, g_loss: 918.65063477 -- mean_d_loss: 6.97485113, mean_g_loss: 1001.10247803\n",
            "Epoch:  97 Step:   952  time: 1.313259 s d_loss: 1.62006938, g_loss: 997.07830811 -- mean_d_loss: 6.93985271, mean_g_loss: 1001.07617188\n",
            "Epoch:  97 Step:   953  time: 1.314339 s d_loss: 3.14196229, g_loss: 896.21728516 -- mean_d_loss: 6.91519117, mean_g_loss: 1000.39526367\n",
            "Epoch:  97 Step:   954  time: 1.299488 s d_loss: 1.85124230, g_loss: 996.73828125 -- mean_d_loss: 6.88252020, mean_g_loss: 1000.37164307\n",
            "Epoch:  97 Step:   955  time: 1.324397 s d_loss: 1.29490352, g_loss: 1126.34753418 -- mean_d_loss: 6.84670258, mean_g_loss: 1001.17919922\n",
            "Epoch:  97 Step:   956  time: 1.291312 s d_loss: 1.37093163, g_loss: 932.19189453 -- mean_d_loss: 6.81182528, mean_g_loss: 1000.73974609\n",
            "Epoch:  97 Step:   957  time: 1.305787 s d_loss: 5.32467556, g_loss: 889.76562500 -- mean_d_loss: 6.80241299, mean_g_loss: 1000.03735352\n",
            "Epoch:  97 Step:   958  time: 1.285584 s d_loss: 0.94006068, g_loss: 1186.94775391 -- mean_d_loss: 6.76554298, mean_g_loss: 1001.21295166\n",
            "Epoch:  97 Step:   959  time: 1.298760 s d_loss: 1.07490730, g_loss: 920.42138672 -- mean_d_loss: 6.72997665, mean_g_loss: 1000.70800781\n",
            "Epoch:  97 Step:   960  time: 1.321664 s d_loss: 0.79491168, g_loss: 926.21057129 -- mean_d_loss: 6.69311285, mean_g_loss: 1000.24523926\n",
            "Epoch:  97 Step:   961  time: 1.311727 s d_loss: 0.86518848, g_loss: 886.54809570 -- mean_d_loss: 6.65713835, mean_g_loss: 999.54339600\n",
            "Epoch:  97 Step:   962  time: 1.316679 s d_loss: 3.85371327, g_loss: 878.13793945 -- mean_d_loss: 6.63993979, mean_g_loss: 998.79858398\n",
            "Epoch:  97 Step:   963  time: 1.310633 s d_loss: 8.62007904, g_loss: 1187.51171875 -- mean_d_loss: 6.65201378, mean_g_loss: 999.94934082\n",
            "Epoch:  97 Step:   964  time: 1.273873 s d_loss: 3.71646333, g_loss: 1180.80810547 -- mean_d_loss: 6.63422251, mean_g_loss: 1001.04547119\n",
            "Epoch:  97 Step:   965  time: 1.285092 s d_loss: 1.36553109, g_loss: 1151.88134766 -- mean_d_loss: 6.60248327, mean_g_loss: 1001.95404053\n",
            "Epoch:  97 Step:   966  time: 1.325398 s d_loss: 1.58353198, g_loss: 931.18017578 -- mean_d_loss: 6.57242918, mean_g_loss: 1001.53033447\n",
            "Epoch:  97 Step:   967  time: 1.300665 s d_loss: 23.21964836, g_loss: 964.08093262 -- mean_d_loss: 6.67151976, mean_g_loss: 1001.30737305\n",
            "Epoch:  97 Step:   968  time: 1.318218 s d_loss: 1.59586334, g_loss: 942.38452148 -- mean_d_loss: 6.64148617, mean_g_loss: 1000.95874023\n",
            "Epoch:  97 Step:   969  time: 1.303377 s d_loss: 7.25725985, g_loss: 1041.04101562 -- mean_d_loss: 6.64510775, mean_g_loss: 1001.19458008\n",
            "Epoch:  97 Step:   970  time: 1.290550 s d_loss: 1.18983209, g_loss: 1147.31103516 -- mean_d_loss: 6.61320543, mean_g_loss: 1002.04907227\n",
            "Epoch:  97 Step:   971  time: 1.292617 s d_loss: 10.82589436, g_loss: 950.64007568 -- mean_d_loss: 6.63769817, mean_g_loss: 1001.75018311\n",
            "Epoch:  97 Step:   972  time: 1.319714 s d_loss: 26.54729271, g_loss: 1057.26416016 -- mean_d_loss: 6.75278234, mean_g_loss: 1002.07110596\n",
            "Epoch:  97 Step:   973  time: 1.297447 s d_loss: 1.02800798, g_loss: 967.95916748 -- mean_d_loss: 6.71988106, mean_g_loss: 1001.87500000\n",
            "Epoch:  97 Step:   974  time: 1.317064 s d_loss: 15.68486500, g_loss: 979.23809814 -- mean_d_loss: 6.77110910, mean_g_loss: 1001.74560547\n",
            "Epoch:  97 Step:   975  time: 1.328950 s d_loss: 3.18942499, g_loss: 1036.48999023 -- mean_d_loss: 6.75075865, mean_g_loss: 1001.94299316\n",
            "Epoch:  97 Step:   976  time: 1.319192 s d_loss: 1.36599791, g_loss: 1032.35009766 -- mean_d_loss: 6.72033644, mean_g_loss: 1002.11474609\n",
            "Epoch:  97 Step:   977  time: 1.326953 s d_loss: 2.64837527, g_loss: 1020.77252197 -- mean_d_loss: 6.69745970, mean_g_loss: 1002.21954346\n",
            "Epoch:  97 Step:   978  time: 1.320186 s d_loss: 70.84594727, g_loss: 1151.97131348 -- mean_d_loss: 7.05583096, mean_g_loss: 1003.05615234\n",
            "Epoch:  97 Step:   979  time: 1.316959 s d_loss: 3.20628500, g_loss: 1184.52783203 -- mean_d_loss: 7.03444481, mean_g_loss: 1004.06433105\n",
            "Epoch:  97 Step:   980  time: 1.321780 s d_loss: 15.73026943, g_loss: 1084.69653320 -- mean_d_loss: 7.08248806, mean_g_loss: 1004.50982666\n",
            "Epoch:  97 Step:   981  time: 1.318767 s d_loss: 6.11241198, g_loss: 1084.99169922 -- mean_d_loss: 7.07715797, mean_g_loss: 1004.95202637\n",
            "Epoch:  97 Step:   982  time: 1.306198 s d_loss: 2.60087848, g_loss: 882.13781738 -- mean_d_loss: 7.05269718, mean_g_loss: 1004.28088379\n",
            "Epoch:  97 Step:   983  time: 1.335340 s d_loss: 1.77055025, g_loss: 1053.48706055 -- mean_d_loss: 7.02398968, mean_g_loss: 1004.54833984\n",
            "Epoch:  97 Step:   984  time: 1.327875 s d_loss: 3.08390021, g_loss: 966.91662598 -- mean_d_loss: 7.00269127, mean_g_loss: 1004.34490967\n",
            "Epoch:  97 Step:   985  time: 1.322701 s d_loss: 1.52113044, g_loss: 831.87890625 -- mean_d_loss: 6.97322083, mean_g_loss: 1003.41766357\n",
            "Epoch:  97 Step:   986  time: 1.322083 s d_loss: 1.65081298, g_loss: 953.03356934 -- mean_d_loss: 6.94475842, mean_g_loss: 1003.14825439\n",
            "Epoch:  97 Step:   987  time: 1.299346 s d_loss: 1.77080512, g_loss: 959.86193848 -- mean_d_loss: 6.91723680, mean_g_loss: 1002.91796875\n",
            "Epoch:  97 Step:   988  time: 1.311236 s d_loss: 6.69138908, g_loss: 905.68701172 -- mean_d_loss: 6.91604233, mean_g_loss: 1002.40350342\n",
            "Epoch:  97 Step:   989  time: 1.334570 s d_loss: 1.48596597, g_loss: 1045.99719238 -- mean_d_loss: 6.88746262, mean_g_loss: 1002.63299561\n",
            "Epoch:  97 Step:   990  time: 1.311967 s d_loss: 1.82675982, g_loss: 1050.84790039 -- mean_d_loss: 6.86096716, mean_g_loss: 1002.88537598\n",
            "Epoch:  97 Step:   991  time: 1.338941 s d_loss: 2.39466715, g_loss: 979.61022949 -- mean_d_loss: 6.83770514, mean_g_loss: 1002.76416016\n",
            "Epoch:  97 Step:   992  time: 1.319632 s d_loss: 1.17906153, g_loss: 938.88439941 -- mean_d_loss: 6.80838585, mean_g_loss: 1002.43322754\n",
            "Epoch:  97 Step:   993  time: 1.318498 s d_loss: 28.86221313, g_loss: 1075.90209961 -- mean_d_loss: 6.92206526, mean_g_loss: 1002.81195068\n",
            "Epoch:  97 Step:   994  time: 1.318054 s d_loss: 1.83567023, g_loss: 986.41668701 -- mean_d_loss: 6.89598083, mean_g_loss: 1002.72790527\n",
            "Epoch:  97 Step:   995  time: 1.331268 s d_loss: 81.87837219, g_loss: 939.37554932 -- mean_d_loss: 7.27854443, mean_g_loss: 1002.40466309\n",
            "Epoch:  97 Step:   996  time: 1.331194 s d_loss: 4.75564051, g_loss: 988.29650879 -- mean_d_loss: 7.26573801, mean_g_loss: 1002.33306885\n",
            "Epoch:  97 Step:   997  time: 1.333285 s d_loss: 6.65917206, g_loss: 995.20513916 -- mean_d_loss: 7.26267433, mean_g_loss: 1002.29705811\n",
            "Epoch:  97 Step:   998  time: 1.317272 s d_loss: 43.20326614, g_loss: 1033.31762695 -- mean_d_loss: 7.44328022, mean_g_loss: 1002.45288086\n",
            "Epoch:  97 Step:   999  time: 1.346285 s d_loss: 74.33172607, g_loss: 984.58624268 -- mean_d_loss: 7.77772236, mean_g_loss: 1002.36358643\n",
            "Epoch:  97 Step:  1000  time: 1.296600 s d_loss: 4.92327023, g_loss: 1105.75439453 -- mean_d_loss: 4.92327023, mean_g_loss: 1105.75439453\n",
            "Epoch:  97 Step:  1001  time: 1.297401 s d_loss: 7.05746412, g_loss: 892.95202637 -- mean_d_loss: 5.99036694, mean_g_loss: 999.35321045\n",
            "Epoch:  97 Step:  1002  time: 1.309847 s d_loss: 6.10770321, g_loss: 1078.19897461 -- mean_d_loss: 6.02947855, mean_g_loss: 1025.63513184\n",
            "Epoch:  97 Step:  1003  time: 1.315102 s d_loss: 30.76485252, g_loss: 937.85742188 -- mean_d_loss: 12.21332169, mean_g_loss: 1003.69067383\n",
            "Epoch:  97 Step:  1004  time: 1.330696 s d_loss: 4.28701591, g_loss: 1010.04333496 -- mean_d_loss: 10.62806129, mean_g_loss: 1004.96124268\n",
            "Epoch:  97 Step:  1005  time: 1.320457 s d_loss: 26.38897133, g_loss: 1050.37548828 -- mean_d_loss: 13.25487900, mean_g_loss: 1012.53027344\n",
            "Epoch:  97 Step:  1006  time: 1.299642 s d_loss: 1.90995061, g_loss: 864.14611816 -- mean_d_loss: 11.63417530, mean_g_loss: 991.33251953\n",
            "Epoch:  97 Step:  1007  time: 1.321730 s d_loss: 18.45287895, g_loss: 1031.85363770 -- mean_d_loss: 12.48651314, mean_g_loss: 996.39764404\n",
            "Epoch:  97 Step:  1008  time: 1.325933 s d_loss: 2.01877260, g_loss: 905.84570312 -- mean_d_loss: 11.32343102, mean_g_loss: 986.33636475\n",
            "Epoch:  97 Step:  1009  time: 1.298063 s d_loss: 23.80270195, g_loss: 993.25329590 -- mean_d_loss: 12.57135868, mean_g_loss: 987.02801514\n",
            "Epoch:  97 Step:  1010  time: 1.295579 s d_loss: 2.99296093, g_loss: 978.16088867 -- mean_d_loss: 11.70059490, mean_g_loss: 986.22192383\n",
            "Epoch:  97 Step:  1011  time: 1.317491 s d_loss: 3.61386728, g_loss: 972.66992188 -- mean_d_loss: 11.02670002, mean_g_loss: 985.09259033\n",
            "Epoch:  97 Step:  1012  time: 1.291119 s d_loss: 18.55335808, g_loss: 1190.40026855 -- mean_d_loss: 11.60567379, mean_g_loss: 1000.88549805\n",
            "Epoch:  97 Step:  1013  time: 1.321399 s d_loss: 70.34969330, g_loss: 909.10717773 -- mean_d_loss: 15.80167484, mean_g_loss: 994.32995605\n",
            "Epoch:  97 Step:  1014  time: 1.322420 s d_loss: 2.75072026, g_loss: 888.13598633 -- mean_d_loss: 14.93161106, mean_g_loss: 987.25030518\n",
            "Epoch:  97 Step:  1015  time: 1.281042 s d_loss: 2.96001530, g_loss: 909.27514648 -- mean_d_loss: 14.18338680, mean_g_loss: 982.37689209\n",
            "Epoch:  97 Step:  1016  time: 1.320659 s d_loss: 59.70724106, g_loss: 1049.19653320 -- mean_d_loss: 16.86125946, mean_g_loss: 986.30743408\n",
            "Epoch:  97 Step:  1017  time: 1.309351 s d_loss: 6.49759388, g_loss: 988.51953125 -- mean_d_loss: 16.28549957, mean_g_loss: 986.43035889\n",
            "Epoch:  97 Step:  1018  time: 1.285730 s d_loss: 10.22339153, g_loss: 936.80523682 -- mean_d_loss: 15.96644211, mean_g_loss: 983.81848145\n",
            "Epoch:  97 Step:  1019  time: 1.304557 s d_loss: 4.67679262, g_loss: 925.47015381 -- mean_d_loss: 15.40195942, mean_g_loss: 980.90106201\n",
            "Epoch:  97 Step:  1020  time: 1.309068 s d_loss: 81.24006653, g_loss: 1044.54858398 -- mean_d_loss: 18.53710556, mean_g_loss: 983.93194580\n",
            "Epoch:  97 Step:  1021  time: 1.349651 s d_loss: 3.27166128, g_loss: 985.61547852 -- mean_d_loss: 17.84322357, mean_g_loss: 984.00842285\n",
            "Epoch:  97 Step:  1022  time: 1.342584 s d_loss: 3.63286352, g_loss: 1246.66210938 -- mean_d_loss: 17.22538185, mean_g_loss: 995.42816162\n",
            "Epoch:  97 Step:  1023  time: 1.289170 s d_loss: 21.61883736, g_loss: 982.24328613 -- mean_d_loss: 17.40844154, mean_g_loss: 994.87884521\n",
            "Epoch:  97 Step:  1024  time: 1.286211 s d_loss: 5.05829477, g_loss: 989.07177734 -- mean_d_loss: 16.91443634, mean_g_loss: 994.64654541\n",
            "Epoch:  97 Step:  1025  time: 1.310652 s d_loss: 4.13843203, g_loss: 924.88983154 -- mean_d_loss: 16.42305183, mean_g_loss: 991.96362305\n",
            "Epoch:  97 Step:  1026  time: 1.313467 s d_loss: 1.78664219, g_loss: 880.79852295 -- mean_d_loss: 15.88096237, mean_g_loss: 987.84643555\n",
            "Epoch:  97 Step:  1027  time: 1.272072 s d_loss: 1.97718155, g_loss: 1021.05065918 -- mean_d_loss: 15.38439846, mean_g_loss: 989.03228760\n",
            "Epoch:  97 Step:  1028  time: 1.318196 s d_loss: 6.88974905, g_loss: 1039.06152344 -- mean_d_loss: 15.09147930, mean_g_loss: 990.75738525\n",
            "Epoch:  97 Step:  1029  time: 1.311417 s d_loss: 7.79093885, g_loss: 921.37890625 -- mean_d_loss: 14.84812737, mean_g_loss: 988.44476318\n",
            "Epoch:  97 Step:  1030  time: 1.279780 s d_loss: 1.91490400, g_loss: 1046.80468750 -- mean_d_loss: 14.43092728, mean_g_loss: 990.32739258\n",
            "Epoch:  97 Step:  1031  time: 1.306808 s d_loss: 2.54466391, g_loss: 1031.55419922 -- mean_d_loss: 14.05948162, mean_g_loss: 991.61572266\n",
            "Epoch:  97 Step:  1032  time: 1.279035 s d_loss: 3.90606189, g_loss: 876.05090332 -- mean_d_loss: 13.75180244, mean_g_loss: 988.11376953\n",
            "Epoch:  97 Step:  1033  time: 1.280546 s d_loss: 2.20562935, g_loss: 1024.44384766 -- mean_d_loss: 13.41220856, mean_g_loss: 989.18231201\n",
            "Epoch:  97 Step:  1034  time: 1.336893 s d_loss: 7.26642370, g_loss: 1141.63403320 -- mean_d_loss: 13.23661518, mean_g_loss: 993.53808594\n",
            "Epoch:  97 Step:  1035  time: 1.280862 s d_loss: 12.37681866, g_loss: 1180.91247559 -- mean_d_loss: 13.21273232, mean_g_loss: 998.74291992\n",
            "Epoch:  97 Step:  1036  time: 1.300763 s d_loss: 4.08880901, g_loss: 1085.26245117 -- mean_d_loss: 12.96613979, mean_g_loss: 1001.08129883\n",
            "Epoch:  97 Step:  1037  time: 1.314208 s d_loss: 2.52599001, g_loss: 976.34997559 -- mean_d_loss: 12.69139862, mean_g_loss: 1000.43048096\n",
            "Epoch:  97 Step:  1038  time: 1.348911 s d_loss: 3.39785695, g_loss: 1151.15295410 -- mean_d_loss: 12.45310307, mean_g_loss: 1004.29516602\n",
            "Epoch:  97 Step:  1039  time: 1.302194 s d_loss: 3.07488489, g_loss: 1004.42822266 -- mean_d_loss: 12.21864796, mean_g_loss: 1004.29852295\n",
            "Epoch:  97 Step:  1040  time: 1.318896 s d_loss: 73.34494781, g_loss: 1047.26586914 -- mean_d_loss: 13.70953369, mean_g_loss: 1005.34649658\n",
            "Epoch:  97 Step:  1041  time: 1.332769 s d_loss: 8.75193691, g_loss: 978.56701660 -- mean_d_loss: 13.59149647, mean_g_loss: 1004.70886230\n",
            "Epoch:  97 Step:  1042  time: 1.304123 s d_loss: 30.47953606, g_loss: 894.46008301 -- mean_d_loss: 13.98424149, mean_g_loss: 1002.14495850\n",
            "Epoch:  97 Step:  1043  time: 1.296014 s d_loss: 4.00359583, g_loss: 1051.64160156 -- mean_d_loss: 13.75740910, mean_g_loss: 1003.26989746\n",
            "Epoch:  97 Step:  1044  time: 1.352150 s d_loss: 9.84681416, g_loss: 1069.21484375 -- mean_d_loss: 13.67050648, mean_g_loss: 1004.73535156\n",
            "Epoch:  97 Step:  1045  time: 1.310260 s d_loss: 3.89487195, g_loss: 989.66864014 -- mean_d_loss: 13.45799351, mean_g_loss: 1004.40777588\n",
            "Epoch:  97 Step:  1046  time: 1.307250 s d_loss: 41.17792892, g_loss: 1111.73034668 -- mean_d_loss: 14.04777908, mean_g_loss: 1006.69122314\n",
            "Epoch:  97 Step:  1047  time: 1.322316 s d_loss: 47.41223145, g_loss: 1161.70251465 -- mean_d_loss: 14.74287128, mean_g_loss: 1009.92065430\n",
            "Epoch:  97 Step:  1048  time: 1.329854 s d_loss: 2.83749294, g_loss: 1002.23956299 -- mean_d_loss: 14.49990368, mean_g_loss: 1009.76385498\n",
            "Epoch:  97 Step:  1049  time: 1.309903 s d_loss: 3.38250470, g_loss: 1070.07153320 -- mean_d_loss: 14.27755642, mean_g_loss: 1010.96997070\n",
            "Epoch:  97 Step:  1050  time: 1.309486 s d_loss: 1.23376584, g_loss: 926.18188477 -- mean_d_loss: 14.02179527, mean_g_loss: 1009.30749512\n",
            "Epoch:  97 Step:  1051  time: 1.307310 s d_loss: 1.46081710, g_loss: 1121.57531738 -- mean_d_loss: 13.78023815, mean_g_loss: 1011.46649170\n",
            "Epoch:  97 Step:  1052  time: 1.321877 s d_loss: 17.75023079, g_loss: 841.20892334 -- mean_d_loss: 13.85514355, mean_g_loss: 1008.25402832\n",
            "Epoch:  97 Step:  1053  time: 1.322891 s d_loss: 1.74821746, g_loss: 1048.89660645 -- mean_d_loss: 13.63094234, mean_g_loss: 1009.00671387\n",
            "Epoch:  97 Step:  1054  time: 1.319302 s d_loss: 1.65285516, g_loss: 1021.75708008 -- mean_d_loss: 13.41315842, mean_g_loss: 1009.23858643\n",
            "Epoch:  97 Step:  1055  time: 1.327410 s d_loss: 5.23167753, g_loss: 937.08508301 -- mean_d_loss: 13.26706028, mean_g_loss: 1007.95013428\n",
            "Epoch:  97 Step:  1056  time: 1.316789 s d_loss: 37.49860001, g_loss: 879.60534668 -- mean_d_loss: 13.69217491, mean_g_loss: 1005.69848633\n",
            "Epoch:  97 Step:  1057  time: 1.292063 s d_loss: 9.61781597, g_loss: 996.69195557 -- mean_d_loss: 13.62192726, mean_g_loss: 1005.54315186\n",
            "Epoch:  97 Step:  1058  time: 1.281834 s d_loss: 1.33487880, g_loss: 1030.06640625 -- mean_d_loss: 13.41367245, mean_g_loss: 1005.95880127\n",
            "Epoch:  97 Step:  1059  time: 1.333939 s d_loss: 2.18086481, g_loss: 1050.69519043 -- mean_d_loss: 13.22645855, mean_g_loss: 1006.70440674\n",
            "Epoch:  97 Step:  1060  time: 1.301967 s d_loss: 19.46542931, g_loss: 1025.99865723 -- mean_d_loss: 13.32873726, mean_g_loss: 1007.02075195\n",
            "Epoch:  97 Step:  1061  time: 1.297269 s d_loss: 4.63041019, g_loss: 924.20336914 -- mean_d_loss: 13.18844223, mean_g_loss: 1005.68499756\n",
            "Epoch:  97 Step:  1062  time: 1.309194 s d_loss: 2.04144597, g_loss: 1017.77801514 -- mean_d_loss: 13.01150608, mean_g_loss: 1005.87689209\n",
            "Epoch:  97 Step:  1063  time: 1.313548 s d_loss: 14.26229286, g_loss: 1030.26708984 -- mean_d_loss: 13.03104877, mean_g_loss: 1006.25799561\n",
            "Epoch:  97 Step:  1064  time: 1.319469 s d_loss: 18.11839485, g_loss: 1061.26464844 -- mean_d_loss: 13.10931587, mean_g_loss: 1007.10424805\n",
            "Epoch:  97 Step:  1065  time: 1.290648 s d_loss: 3.12726974, g_loss: 966.76501465 -- mean_d_loss: 12.95807266, mean_g_loss: 1006.49304199\n",
            "Epoch:  97 Step:  1066  time: 1.290237 s d_loss: 12.20976639, g_loss: 1179.61840820 -- mean_d_loss: 12.94690418, mean_g_loss: 1009.07696533\n",
            "Epoch:  97 Step:  1067  time: 1.327005 s d_loss: 14.41501808, g_loss: 1095.93737793 -- mean_d_loss: 12.96849442, mean_g_loss: 1010.35430908\n",
            "Epoch:  97 Step:  1068  time: 1.318350 s d_loss: 1.89607990, g_loss: 1181.10437012 -- mean_d_loss: 12.80802441, mean_g_loss: 1012.82891846\n",
            "Epoch:  97 Step:  1069  time: 1.327275 s d_loss: 6.52852058, g_loss: 994.35382080 -- mean_d_loss: 12.71831703, mean_g_loss: 1012.56494141\n",
            "Epoch:  97 Step:  1070  time: 1.303262 s d_loss: 2.76511049, g_loss: 1201.29589844 -- mean_d_loss: 12.57813072, mean_g_loss: 1015.22314453\n",
            "Epoch:  97 Step:  1071  time: 1.307058 s d_loss: 1.70080578, g_loss: 997.12939453 -- mean_d_loss: 12.42705727, mean_g_loss: 1014.97192383\n",
            "Epoch:  97 Step:  1072  time: 1.320077 s d_loss: 9.64348030, g_loss: 927.86621094 -- mean_d_loss: 12.38892651, mean_g_loss: 1013.77868652\n",
            "Epoch:  97 Step:  1073  time: 1.345876 s d_loss: 30.13950348, g_loss: 1170.27648926 -- mean_d_loss: 12.62879944, mean_g_loss: 1015.89349365\n",
            "Epoch:  97 Step:  1074  time: 1.283449 s d_loss: 6.73369741, g_loss: 1080.58483887 -- mean_d_loss: 12.55019760, mean_g_loss: 1016.75604248\n",
            "Epoch:  97 Step:  1075  time: 1.286297 s d_loss: 5.22330189, g_loss: 991.17938232 -- mean_d_loss: 12.45379162, mean_g_loss: 1016.41949463\n",
            "Epoch:  97 Step:  1076  time: 1.333493 s d_loss: 3.77247286, g_loss: 985.42492676 -- mean_d_loss: 12.34104729, mean_g_loss: 1016.01696777\n",
            "Epoch:  97 Step:  1077  time: 1.291097 s d_loss: 1.94060552, g_loss: 874.76245117 -- mean_d_loss: 12.20770836, mean_g_loss: 1014.20605469\n",
            "Epoch:  97 Step:  1078  time: 1.308757 s d_loss: 10.06067467, g_loss: 948.39337158 -- mean_d_loss: 12.18053055, mean_g_loss: 1013.37292480\n",
            "Epoch:  97 Step:  1079  time: 1.302888 s d_loss: 2.36415124, g_loss: 940.45367432 -- mean_d_loss: 12.05782509, mean_g_loss: 1012.46142578\n",
            "Epoch:  97 Step:  1080  time: 1.315101 s d_loss: 67.37898254, g_loss: 949.00189209 -- mean_d_loss: 12.74080276, mean_g_loss: 1011.67797852\n",
            "Epoch:  97 Step:  1081  time: 1.292203 s d_loss: 2.77676940, g_loss: 1021.63769531 -- mean_d_loss: 12.61928940, mean_g_loss: 1011.79943848\n",
            "Epoch:  97 Step:  1082  time: 1.317699 s d_loss: 1.71290743, g_loss: 1048.68408203 -- mean_d_loss: 12.48788738, mean_g_loss: 1012.24389648\n",
            "Epoch:  97 Step:  1083  time: 1.294329 s d_loss: 2.41359806, g_loss: 1098.25390625 -- mean_d_loss: 12.36795521, mean_g_loss: 1013.26788330\n",
            "Epoch:  97 Step:  1084  time: 1.331844 s d_loss: 5.01272726, g_loss: 997.99877930 -- mean_d_loss: 12.28142262, mean_g_loss: 1013.08825684\n",
            "Epoch:  97 Step:  1085  time: 1.325198 s d_loss: 11.15513992, g_loss: 1018.06280518 -- mean_d_loss: 12.26832581, mean_g_loss: 1013.14605713\n",
            "Epoch:  97 Step:  1086  time: 1.341063 s d_loss: 1.44452059, g_loss: 982.63861084 -- mean_d_loss: 12.14391518, mean_g_loss: 1012.79541016\n",
            "Epoch:  97 Step:  1087  time: 1.321267 s d_loss: 1.23874867, g_loss: 1044.29931641 -- mean_d_loss: 12.01999283, mean_g_loss: 1013.15338135\n",
            "Epoch:  97 Step:  1088  time: 1.330656 s d_loss: 9.04003048, g_loss: 1024.53002930 -- mean_d_loss: 11.98651028, mean_g_loss: 1013.28125000\n",
            "Epoch:  97 Step:  1089  time: 1.318802 s d_loss: 1.29883862, g_loss: 1063.88928223 -- mean_d_loss: 11.86775875, mean_g_loss: 1013.84356689\n",
            "Epoch:  97 Step:  1090  time: 1.326659 s d_loss: 1.40079427, g_loss: 1056.06481934 -- mean_d_loss: 11.75273609, mean_g_loss: 1014.30749512\n",
            "Epoch:  97 Step:  1091  time: 1.324398 s d_loss: 0.86297995, g_loss: 990.43286133 -- mean_d_loss: 11.63436985, mean_g_loss: 1014.04797363\n",
            "Epoch:  97 Step:  1092  time: 1.326656 s d_loss: 0.65155911, g_loss: 987.45666504 -- mean_d_loss: 11.51627636, mean_g_loss: 1013.76202393\n",
            "Epoch:  97 Step:  1093  time: 1.325676 s d_loss: 4.45727777, g_loss: 1017.95178223 -- mean_d_loss: 11.44118023, mean_g_loss: 1013.80657959\n",
            "Epoch:  97 Step:  1094  time: 1.320322 s d_loss: 23.91300964, g_loss: 943.44836426 -- mean_d_loss: 11.57246208, mean_g_loss: 1013.06597900\n",
            "Epoch:  97 Step:  1095  time: 1.319471 s d_loss: 1.53631508, g_loss: 965.14599609 -- mean_d_loss: 11.46791840, mean_g_loss: 1012.56683350\n",
            "Epoch:  97 Step:  1096  time: 1.315367 s d_loss: 1.10796273, g_loss: 1114.26867676 -- mean_d_loss: 11.36111450, mean_g_loss: 1013.61523438\n",
            "Epoch:  97 Step:  1097  time: 1.344545 s d_loss: 2.30767035, g_loss: 1006.33728027 -- mean_d_loss: 11.26873112, mean_g_loss: 1013.54095459\n",
            "Epoch:  97 Step:  1098  time: 1.357482 s d_loss: 0.93621314, g_loss: 1184.46093750 -- mean_d_loss: 11.16436195, mean_g_loss: 1015.26745605\n",
            "Epoch:  97 Step:  1099  time: 1.326053 s d_loss: 0.96045053, g_loss: 916.32763672 -- mean_d_loss: 11.06232262, mean_g_loss: 1014.27807617\n",
            "Epoch:  97 Step:  1100  time: 1.334742 s d_loss: 0.99171352, g_loss: 1025.98071289 -- mean_d_loss: 10.96261406, mean_g_loss: 1014.39392090\n",
            "Epoch:  97 Step:  1101  time: 1.321980 s d_loss: 2.05573201, g_loss: 1186.83190918 -- mean_d_loss: 10.87529182, mean_g_loss: 1016.08447266\n",
            "Epoch:  97 Step:  1102  time: 1.363215 s d_loss: 4.04550266, g_loss: 1203.24597168 -- mean_d_loss: 10.80898380, mean_g_loss: 1017.90155029\n",
            "Epoch:  97 Step:  1103  time: 1.324763 s d_loss: 4.75236702, g_loss: 1124.98327637 -- mean_d_loss: 10.75074673, mean_g_loss: 1018.93121338\n",
            "Epoch:  97 Step:  1104  time: 1.335052 s d_loss: 1.24082482, g_loss: 1077.79980469 -- mean_d_loss: 10.66017628, mean_g_loss: 1019.49182129\n",
            "Epoch:  97 Step:  1105  time: 1.285504 s d_loss: 1.17953539, g_loss: 1199.60742188 -- mean_d_loss: 10.57073593, mean_g_loss: 1021.19104004\n",
            "Epoch:  97 Step:  1106  time: 1.334278 s d_loss: 1.08876824, g_loss: 1024.32568359 -- mean_d_loss: 10.48211956, mean_g_loss: 1021.22033691\n",
            "Epoch:  97 Step:  1107  time: 1.304736 s d_loss: 2.05627346, g_loss: 924.43218994 -- mean_d_loss: 10.40410233, mean_g_loss: 1020.32415771\n",
            "Epoch:  97 Step:  1108  time: 1.342255 s d_loss: 1.66372526, g_loss: 1096.99877930 -- mean_d_loss: 10.32391548, mean_g_loss: 1021.02758789\n",
            "Epoch:  97 Step:  1109  time: 1.296307 s d_loss: 1.46750569, g_loss: 951.96002197 -- mean_d_loss: 10.24340248, mean_g_loss: 1020.39971924\n",
            "Epoch:  97 Step:  1110  time: 1.319737 s d_loss: 1.53316534, g_loss: 920.16906738 -- mean_d_loss: 10.16493225, mean_g_loss: 1019.49676514\n",
            "Epoch:  97 Step:  1111  time: 1.323739 s d_loss: 0.97612059, g_loss: 1033.78527832 -- mean_d_loss: 10.08288860, mean_g_loss: 1019.62438965\n",
            "Epoch:  97 Step:  1112  time: 1.339172 s d_loss: 1.92948866, g_loss: 1252.71630859 -- mean_d_loss: 10.01073456, mean_g_loss: 1021.68713379\n",
            "Epoch:  97 Step:  1113  time: 1.318577 s d_loss: 6.40993643, g_loss: 1270.98632812 -- mean_d_loss: 9.97914886, mean_g_loss: 1023.87396240\n",
            "Epoch:  97 Step:  1114  time: 1.311845 s d_loss: 1.34260678, g_loss: 1124.85107422 -- mean_d_loss: 9.90404892, mean_g_loss: 1024.75207520\n",
            "Epoch:  97 Step:  1115  time: 1.294656 s d_loss: 1.76423597, g_loss: 1110.84069824 -- mean_d_loss: 9.83387852, mean_g_loss: 1025.49426270\n",
            "Epoch:  97 Step:  1116  time: 1.330414 s d_loss: 2.26585174, g_loss: 1092.04809570 -- mean_d_loss: 9.76919460, mean_g_loss: 1026.06298828\n",
            "Epoch:  97 Step:  1117  time: 1.293634 s d_loss: 1.23479605, g_loss: 945.20886230 -- mean_d_loss: 9.69686794, mean_g_loss: 1025.37780762\n",
            "Epoch:  97 Step:  1118  time: 1.333033 s d_loss: 3.86801744, g_loss: 1144.31933594 -- mean_d_loss: 9.64788628, mean_g_loss: 1026.37731934\n",
            "Epoch:  97 Step:  1119  time: 1.337232 s d_loss: 3.30107546, g_loss: 1103.06091309 -- mean_d_loss: 9.59499645, mean_g_loss: 1027.01635742\n",
            "Epoch:  97 Step:  1120  time: 1.327351 s d_loss: 60.40994644, g_loss: 1060.02111816 -- mean_d_loss: 10.01495457, mean_g_loss: 1027.28918457\n",
            "Epoch:  97 Step:  1121  time: 1.319283 s d_loss: 9.49295139, g_loss: 923.01025391 -- mean_d_loss: 10.01067543, mean_g_loss: 1026.43444824\n",
            "Epoch:  97 Step:  1122  time: 1.289004 s d_loss: 74.44141388, g_loss: 1115.98889160 -- mean_d_loss: 10.53450203, mean_g_loss: 1027.16259766\n",
            "Epoch:  97 Step:  1123  time: 1.302406 s d_loss: 6.26509285, g_loss: 980.78918457 -- mean_d_loss: 10.50007153, mean_g_loss: 1026.78857422\n",
            "Epoch:  97 Step:  1124  time: 1.310920 s d_loss: 2.78322649, g_loss: 966.62518311 -- mean_d_loss: 10.43833733, mean_g_loss: 1026.30725098\n",
            "Epoch:  97 Step:  1125  time: 1.286030 s d_loss: 2.91350937, g_loss: 1082.73937988 -- mean_d_loss: 10.37861538, mean_g_loss: 1026.75512695\n",
            "Epoch:  97 Step:  1126  time: 1.315446 s d_loss: 2.55568647, g_loss: 1110.70715332 -- mean_d_loss: 10.31701756, mean_g_loss: 1027.41625977\n",
            "Epoch:  97 Step:  1127  time: 1.286099 s d_loss: 2.65472412, g_loss: 1115.31896973 -- mean_d_loss: 10.25715637, mean_g_loss: 1028.10290527\n",
            "Epoch:  97 Step:  1128  time: 1.306856 s d_loss: 16.41143799, g_loss: 1082.54138184 -- mean_d_loss: 10.30486393, mean_g_loss: 1028.52490234\n",
            "Epoch:  97 Step:  1129  time: 1.321510 s d_loss: 8.29438114, g_loss: 1035.67578125 -- mean_d_loss: 10.28939819, mean_g_loss: 1028.57995605\n",
            "Epoch:  97 Step:  1130  time: 1.319362 s d_loss: 25.77421379, g_loss: 1010.93981934 -- mean_d_loss: 10.40760326, mean_g_loss: 1028.44531250\n",
            "Epoch:  97 Step:  1131  time: 1.309656 s d_loss: 41.49652100, g_loss: 815.71923828 -- mean_d_loss: 10.64312553, mean_g_loss: 1026.83374023\n",
            "Epoch:  97 Step:  1132  time: 1.284947 s d_loss: 4.60255003, g_loss: 1007.17895508 -- mean_d_loss: 10.59770775, mean_g_loss: 1026.68591309\n",
            "Epoch:  97 Step:  1133  time: 1.317888 s d_loss: 85.89900208, g_loss: 899.45446777 -- mean_d_loss: 11.15965748, mean_g_loss: 1025.73632812\n",
            "Epoch:  97 Step:  1134  time: 1.333039 s d_loss: 43.23133087, g_loss: 1015.02099609 -- mean_d_loss: 11.39722538, mean_g_loss: 1025.65698242\n",
            "Epoch:  97 Step:  1135  time: 1.280027 s d_loss: 82.08861542, g_loss: 1023.07470703 -- mean_d_loss: 11.91701508, mean_g_loss: 1025.63793945\n",
            "Epoch:  97 Step:  1136  time: 1.294714 s d_loss: 13.94566441, g_loss: 1185.15917969 -- mean_d_loss: 11.93182373, mean_g_loss: 1026.80236816\n",
            "Epoch:  97 Step:  1137  time: 1.300375 s d_loss: 66.30123901, g_loss: 1145.69042969 -- mean_d_loss: 12.32580471, mean_g_loss: 1027.66381836\n",
            "Epoch:  97 Step:  1138  time: 1.293979 s d_loss: 29.60510826, g_loss: 1141.37915039 -- mean_d_loss: 12.45011616, mean_g_loss: 1028.48193359\n",
            "Epoch:  97 Step:  1139  time: 1.332081 s d_loss: 26.61892700, g_loss: 958.05273438 -- mean_d_loss: 12.55132198, mean_g_loss: 1027.97875977\n",
            "Epoch:  97 Step:  1140  time: 1.285208 s d_loss: 87.24444580, g_loss: 1050.79699707 -- mean_d_loss: 13.08105946, mean_g_loss: 1028.14062500\n",
            "Epoch:  97 Step:  1141  time: 1.287965 s d_loss: 10.17541027, g_loss: 1056.76367188 -- mean_d_loss: 13.06059742, mean_g_loss: 1028.34216309\n",
            "Epoch:  97 Step:  1142  time: 1.324070 s d_loss: 37.95430756, g_loss: 969.00463867 -- mean_d_loss: 13.23468018, mean_g_loss: 1027.92724609\n",
            "Epoch:  97 Step:  1143  time: 1.296947 s d_loss: 8.37380314, g_loss: 1221.28149414 -- mean_d_loss: 13.20092392, mean_g_loss: 1029.27001953\n",
            "Epoch:  97 Step:  1144  time: 1.315295 s d_loss: 36.55715561, g_loss: 1039.60961914 -- mean_d_loss: 13.36200047, mean_g_loss: 1029.34130859\n",
            "Epoch:  97 Step:  1145  time: 1.314686 s d_loss: 55.27197266, g_loss: 1064.44152832 -- mean_d_loss: 13.64905548, mean_g_loss: 1029.58166504\n",
            "Epoch:  97 Step:  1146  time: 1.310543 s d_loss: 4.53699207, g_loss: 1125.90722656 -- mean_d_loss: 13.58706856, mean_g_loss: 1030.23693848\n",
            "Epoch:  97 Step:  1147  time: 1.314183 s d_loss: 3.92322969, g_loss: 1200.32336426 -- mean_d_loss: 13.52177238, mean_g_loss: 1031.38623047\n",
            "Epoch:  97 Step:  1148  time: 1.313928 s d_loss: 5.64429522, g_loss: 948.08929443 -- mean_d_loss: 13.46890354, mean_g_loss: 1030.82714844\n",
            "Epoch:  97 Step:  1149  time: 1.322341 s d_loss: 4.30204773, g_loss: 1155.35620117 -- mean_d_loss: 13.40779018, mean_g_loss: 1031.65734863\n",
            "Epoch:  97 Step:  1150  time: 1.290998 s d_loss: 5.43055582, g_loss: 958.56298828 -- mean_d_loss: 13.35496140, mean_g_loss: 1031.17333984\n",
            "Epoch:  97 Step:  1151  time: 1.315518 s d_loss: 1.84794295, g_loss: 995.47717285 -- mean_d_loss: 13.27925682, mean_g_loss: 1030.93847656\n",
            "Epoch:  97 Step:  1152  time: 1.334497 s d_loss: 5.92326975, g_loss: 959.70562744 -- mean_d_loss: 13.23117828, mean_g_loss: 1030.47290039\n",
            "Epoch:  97 Step:  1153  time: 1.319782 s d_loss: 11.05183125, g_loss: 1181.85437012 -- mean_d_loss: 13.21702671, mean_g_loss: 1031.45593262\n",
            "Epoch:  97 Step:  1154  time: 1.296553 s d_loss: 4.49737501, g_loss: 1031.40649414 -- mean_d_loss: 13.16077042, mean_g_loss: 1031.45568848\n",
            "Epoch:  97 Step:  1155  time: 1.291598 s d_loss: 2.09939313, g_loss: 1122.36499023 -- mean_d_loss: 13.08986378, mean_g_loss: 1032.03833008\n",
            "Epoch:  97 Step:  1156  time: 1.342536 s d_loss: 39.05855560, g_loss: 888.86303711 -- mean_d_loss: 13.25527000, mean_g_loss: 1031.12634277\n",
            "Epoch:  97 Step:  1157  time: 1.313159 s d_loss: 57.44089127, g_loss: 1038.81872559 -- mean_d_loss: 13.53492641, mean_g_loss: 1031.17504883\n",
            "Epoch:  97 Step:  1158  time: 1.293701 s d_loss: 44.35289383, g_loss: 1045.16076660 -- mean_d_loss: 13.72874928, mean_g_loss: 1031.26293945\n",
            "Epoch:  97 Step:  1159  time: 1.319284 s d_loss: 75.58496857, g_loss: 1037.33728027 -- mean_d_loss: 14.11535072, mean_g_loss: 1031.30102539\n",
            "Epoch:  97 Step:  1160  time: 1.341062 s d_loss: 37.44057846, g_loss: 964.88824463 -- mean_d_loss: 14.26022816, mean_g_loss: 1030.88854980\n",
            "Epoch:  97 Step:  1161  time: 1.321366 s d_loss: 16.37353134, g_loss: 1071.74108887 -- mean_d_loss: 14.27327347, mean_g_loss: 1031.14062500\n",
            "Epoch:  97 Step:  1162  time: 1.298430 s d_loss: 35.11156082, g_loss: 1209.66967773 -- mean_d_loss: 14.40111542, mean_g_loss: 1032.23596191\n",
            "Epoch:  97 Step:  1163  time: 1.285234 s d_loss: 2.60708213, g_loss: 1080.50292969 -- mean_d_loss: 14.32920170, mean_g_loss: 1032.53015137\n",
            "Epoch:  97 Step:  1164  time: 1.305462 s d_loss: 32.96169662, g_loss: 932.23413086 -- mean_d_loss: 14.44212532, mean_g_loss: 1031.92236328\n",
            "Epoch:  97 Step:  1165  time: 1.283348 s d_loss: 5.94658422, g_loss: 1085.83544922 -- mean_d_loss: 14.39094734, mean_g_loss: 1032.24707031\n",
            "Epoch:  97 Step:  1166  time: 1.320088 s d_loss: 19.40968513, g_loss: 998.95922852 -- mean_d_loss: 14.42099953, mean_g_loss: 1032.04772949\n",
            "Epoch:  97 Step:  1167  time: 1.302813 s d_loss: 7.95205688, g_loss: 1117.52941895 -- mean_d_loss: 14.38249397, mean_g_loss: 1032.55651855\n",
            "Epoch:  97 Step:  1168  time: 1.309514 s d_loss: 52.88801193, g_loss: 1035.86804199 -- mean_d_loss: 14.61033726, mean_g_loss: 1032.57617188\n",
            "Epoch:  97 Step:  1169  time: 1.323082 s d_loss: 80.72655487, g_loss: 949.01562500 -- mean_d_loss: 14.99925613, mean_g_loss: 1032.08459473\n",
            "Epoch:  97 Step:  1170  time: 1.316829 s d_loss: 2.21151280, g_loss: 934.50628662 -- mean_d_loss: 14.92447376, mean_g_loss: 1031.51403809\n",
            "Epoch:  97 Step:  1171  time: 1.322405 s d_loss: 2.88367534, g_loss: 876.54125977 -- mean_d_loss: 14.85446930, mean_g_loss: 1030.61303711\n",
            "Epoch:  97 Step:  1172  time: 1.303521 s d_loss: 3.20746565, g_loss: 983.76892090 -- mean_d_loss: 14.78714561, mean_g_loss: 1030.34216309\n",
            "Epoch:  97 Step:  1173  time: 1.297061 s d_loss: 4.13108253, g_loss: 1171.35986328 -- mean_d_loss: 14.72590446, mean_g_loss: 1031.15270996\n",
            "Epoch:  97 Step:  1174  time: 1.312315 s d_loss: 1.35576808, g_loss: 946.20593262 -- mean_d_loss: 14.64950371, mean_g_loss: 1030.66723633\n",
            "Epoch:  97 Step:  1175  time: 1.321815 s d_loss: 11.75155640, g_loss: 955.89257812 -- mean_d_loss: 14.63303757, mean_g_loss: 1030.24230957\n",
            "Epoch:  97 Step:  1176  time: 1.294342 s d_loss: 1.93028164, g_loss: 1024.92846680 -- mean_d_loss: 14.56126976, mean_g_loss: 1030.21228027\n",
            "Epoch:  97 Step:  1177  time: 1.349231 s d_loss: 72.36865997, g_loss: 1088.89367676 -- mean_d_loss: 14.88603020, mean_g_loss: 1030.54199219\n",
            "Epoch:  97 Step:  1178  time: 1.325512 s d_loss: 17.29472542, g_loss: 1144.33068848 -- mean_d_loss: 14.89948654, mean_g_loss: 1031.17761230\n",
            "Epoch:  97 Step:  1179  time: 1.318439 s d_loss: 51.17284775, g_loss: 876.62896729 -- mean_d_loss: 15.10100460, mean_g_loss: 1030.31896973\n",
            "Epoch:  97 Step:  1180  time: 1.302027 s d_loss: 17.12184906, g_loss: 883.37524414 -- mean_d_loss: 15.11217022, mean_g_loss: 1029.50720215\n",
            "Epoch:  97 Step:  1181  time: 1.301059 s d_loss: 14.76334095, g_loss: 942.98071289 -- mean_d_loss: 15.11025333, mean_g_loss: 1029.03173828\n",
            "Epoch:  97 Step:  1182  time: 1.325976 s d_loss: 44.40305710, g_loss: 1033.71704102 -- mean_d_loss: 15.27032375, mean_g_loss: 1029.05737305\n",
            "Epoch:  97 Step:  1183  time: 1.347714 s d_loss: 5.87350035, g_loss: 983.51818848 -- mean_d_loss: 15.21925449, mean_g_loss: 1028.80981445\n",
            "Epoch:  97 Step:  1184  time: 1.308995 s d_loss: 31.98807144, g_loss: 1195.95397949 -- mean_d_loss: 15.30989647, mean_g_loss: 1029.71337891\n",
            "Epoch:  97 Step:  1185  time: 1.323667 s d_loss: 14.16710377, g_loss: 895.82299805 -- mean_d_loss: 15.30375195, mean_g_loss: 1028.99353027\n",
            "Epoch:  97 Step:  1186  time: 1.331257 s d_loss: 18.68843460, g_loss: 1111.76940918 -- mean_d_loss: 15.32185173, mean_g_loss: 1029.43615723\n",
            "Epoch:  97 Step:  1187  time: 1.304858 s d_loss: 12.61992931, g_loss: 1056.99841309 -- mean_d_loss: 15.30747986, mean_g_loss: 1029.58276367\n",
            "Epoch:  97 Step:  1188  time: 1.324995 s d_loss: 1.97426414, g_loss: 911.90026855 -- mean_d_loss: 15.23693371, mean_g_loss: 1028.96020508\n",
            "Epoch:  97 Step:  1189  time: 1.292806 s d_loss: 2.16777086, g_loss: 937.32019043 -- mean_d_loss: 15.16814899, mean_g_loss: 1028.47778320\n",
            "Epoch:  97 Step:  1190  time: 1.352969 s d_loss: 6.47915745, g_loss: 1193.54687500 -- mean_d_loss: 15.12265682, mean_g_loss: 1029.34204102\n",
            "Epoch:  97 Step:  1191  time: 1.350842 s d_loss: 1.85489559, g_loss: 1129.07678223 -- mean_d_loss: 15.05355453, mean_g_loss: 1029.86145020\n",
            "Epoch:  97 Step:  1192  time: 1.327502 s d_loss: 1.58278561, g_loss: 1019.46752930 -- mean_d_loss: 14.98375797, mean_g_loss: 1029.80761719\n",
            "Epoch:  97 Step:  1193  time: 1.327327 s d_loss: 2.98016214, g_loss: 1231.45959473 -- mean_d_loss: 14.92188358, mean_g_loss: 1030.84704590\n",
            "Epoch:  97 Step:  1194  time: 1.296573 s d_loss: 7.90718985, g_loss: 1028.21154785 -- mean_d_loss: 14.88591099, mean_g_loss: 1030.83361816\n",
            "Epoch:  97 Step:  1195  time: 1.320157 s d_loss: 5.18876362, g_loss: 901.52630615 -- mean_d_loss: 14.83643532, mean_g_loss: 1030.17382812\n",
            "Epoch:  97 Step:  1196  time: 1.333591 s d_loss: 10.81937408, g_loss: 1009.40795898 -- mean_d_loss: 14.81604481, mean_g_loss: 1030.06848145\n",
            "Epoch:  97 Step:  1197  time: 1.323709 s d_loss: 3.03125072, g_loss: 1001.29858398 -- mean_d_loss: 14.75652504, mean_g_loss: 1029.92309570\n",
            "Epoch:  97 Step:  1198  time: 1.344443 s d_loss: 2.67830801, g_loss: 1064.91308594 -- mean_d_loss: 14.69583035, mean_g_loss: 1030.09887695\n",
            "Epoch:  97 Step:  1199  time: 1.319157 s d_loss: 2.42498231, g_loss: 1225.51379395 -- mean_d_loss: 14.63447666, mean_g_loss: 1031.07604980\n",
            "Epoch:  97 Step:  1200  time: 1.286379 s d_loss: 1.44202232, g_loss: 1018.78430176 -- mean_d_loss: 1.44202232, mean_g_loss: 1018.78430176\n",
            "Epoch:  97 Step:  1201  time: 1.315600 s d_loss: 10.84692669, g_loss: 907.03027344 -- mean_d_loss: 6.14447451, mean_g_loss: 962.90728760\n",
            "Epoch:  97 Step:  1202  time: 1.329355 s d_loss: 4.93178844, g_loss: 1022.43652344 -- mean_d_loss: 5.74024582, mean_g_loss: 982.75030518\n",
            "Epoch:  97 Step:  1203  time: 1.317235 s d_loss: 1.41546237, g_loss: 1044.74560547 -- mean_d_loss: 4.65904999, mean_g_loss: 998.24914551\n",
            "Epoch:  97 Step:  1204  time: 1.303707 s d_loss: 27.09708595, g_loss: 1032.04003906 -- mean_d_loss: 9.14665699, mean_g_loss: 1005.00732422\n",
            "Epoch:  97 Step:  1205  time: 1.289133 s d_loss: 1.89571643, g_loss: 978.54785156 -- mean_d_loss: 7.93816710, mean_g_loss: 1000.59741211\n",
            "Epoch:  97 Step:  1206  time: 1.276819 s d_loss: 31.38650131, g_loss: 952.13659668 -- mean_d_loss: 11.28792858, mean_g_loss: 993.67443848\n",
            "Epoch:  97 Step:  1207  time: 1.326854 s d_loss: 1.31056333, g_loss: 1034.06469727 -- mean_d_loss: 10.04075813, mean_g_loss: 998.72326660\n",
            "Epoch:  97 Step:  1208  time: 1.310761 s d_loss: 3.42734075, g_loss: 1038.83276367 -- mean_d_loss: 9.30593395, mean_g_loss: 1003.17993164\n",
            "Epoch:  97 Step:  1209  time: 1.289097 s d_loss: 1.40873146, g_loss: 863.86682129 -- mean_d_loss: 8.51621342, mean_g_loss: 989.24865723\n",
            "Epoch:  97 Step:  1210  time: 1.309366 s d_loss: 6.78417587, g_loss: 1043.01538086 -- mean_d_loss: 8.35875511, mean_g_loss: 994.13653564\n",
            "Epoch:  97 Step:  1211  time: 1.314653 s d_loss: 1.12356997, g_loss: 1004.70178223 -- mean_d_loss: 7.75582314, mean_g_loss: 995.01702881\n",
            "Epoch:  97 Step:  1212  time: 1.294944 s d_loss: 1.43168116, g_loss: 845.78454590 -- mean_d_loss: 7.26935053, mean_g_loss: 983.53753662\n",
            "Epoch:  97 Step:  1213  time: 1.282935 s d_loss: 12.63081264, g_loss: 825.16381836 -- mean_d_loss: 7.65231228, mean_g_loss: 972.22515869\n",
            "Epoch:  97 Step:  1214  time: 1.307198 s d_loss: 2.73993731, g_loss: 1046.71594238 -- mean_d_loss: 7.32482052, mean_g_loss: 977.19122314\n",
            "Epoch:  97 Step:  1215  time: 1.283217 s d_loss: 74.76218414, g_loss: 1094.33264160 -- mean_d_loss: 11.53965569, mean_g_loss: 984.51257324\n",
            "Epoch:  97 Step:  1216  time: 1.325996 s d_loss: 3.71002150, g_loss: 993.38079834 -- mean_d_loss: 11.07908916, mean_g_loss: 985.03424072\n",
            "Epoch:  97 Step:  1217  time: 1.307862 s d_loss: 4.43768454, g_loss: 1103.41796875 -- mean_d_loss: 10.71012211, mean_g_loss: 991.61108398\n",
            "Epoch:  97 Step:  1218  time: 1.326643 s d_loss: 6.96472073, g_loss: 971.72674561 -- mean_d_loss: 10.51299572, mean_g_loss: 990.56457520\n",
            "Epoch:  97 Step:  1219  time: 1.327164 s d_loss: 10.82840347, g_loss: 1156.26965332 -- mean_d_loss: 10.52876568, mean_g_loss: 998.84979248\n",
            "Epoch:  97 Step:  1220  time: 1.295298 s d_loss: 23.85589409, g_loss: 994.46728516 -- mean_d_loss: 11.16339111, mean_g_loss: 998.64111328\n",
            "Epoch:  97 Step:  1221  time: 1.322258 s d_loss: 24.33514786, g_loss: 815.10833740 -- mean_d_loss: 11.76210690, mean_g_loss: 990.29864502\n",
            "Epoch:  97 Step:  1222  time: 1.313717 s d_loss: 60.80250931, g_loss: 1144.42102051 -- mean_d_loss: 13.89429951, mean_g_loss: 996.99963379\n",
            "Epoch:  97 Step:  1223  time: 1.308867 s d_loss: 2.46419621, g_loss: 977.29919434 -- mean_d_loss: 13.41804504, mean_g_loss: 996.17877197\n",
            "Epoch:  97 Step:  1224  time: 1.327251 s d_loss: 20.98017883, g_loss: 1112.90368652 -- mean_d_loss: 13.72052956, mean_g_loss: 1000.84783936\n",
            "Epoch:  97 Step:  1225  time: 1.279638 s d_loss: 15.44074059, g_loss: 943.52807617 -- mean_d_loss: 13.78669167, mean_g_loss: 998.64318848\n",
            "Epoch:  97 Step:  1226  time: 1.296767 s d_loss: 36.58055496, g_loss: 897.98254395 -- mean_d_loss: 14.63090897, mean_g_loss: 994.91497803\n",
            "Epoch:  97 Step:  1227  time: 1.324346 s d_loss: 3.54811811, g_loss: 1038.77307129 -- mean_d_loss: 14.23509502, mean_g_loss: 996.48138428\n",
            "Epoch:  97 Step:  1228  time: 1.330386 s d_loss: 1.87232959, g_loss: 863.85052490 -- mean_d_loss: 13.80879307, mean_g_loss: 991.90783691\n",
            "Epoch:  97 Step:  1229  time: 1.313426 s d_loss: 7.98948383, g_loss: 1074.88977051 -- mean_d_loss: 13.61481571, mean_g_loss: 994.67395020\n",
            "Epoch:  97 Step:  1230  time: 1.318127 s d_loss: 1.55560565, g_loss: 1032.92065430 -- mean_d_loss: 13.22580814, mean_g_loss: 995.90771484\n",
            "Epoch:  97 Step:  1231  time: 1.337403 s d_loss: 64.23054504, g_loss: 946.79071045 -- mean_d_loss: 14.81970596, mean_g_loss: 994.37280273\n",
            "Epoch:  97 Step:  1232  time: 1.327874 s d_loss: 5.19546366, g_loss: 930.93902588 -- mean_d_loss: 14.52806187, mean_g_loss: 992.45056152\n",
            "Epoch:  97 Step:  1233  time: 1.322572 s d_loss: 9.54132557, g_loss: 998.04248047 -- mean_d_loss: 14.38139343, mean_g_loss: 992.61499023\n",
            "Epoch:  97 Step:  1234  time: 1.325555 s d_loss: 2.30379128, g_loss: 954.96240234 -- mean_d_loss: 14.03631973, mean_g_loss: 991.53918457\n",
            "Epoch:  97 Step:  1235  time: 1.323613 s d_loss: 6.91142464, g_loss: 1041.00659180 -- mean_d_loss: 13.83840561, mean_g_loss: 992.91333008\n",
            "Epoch:  97 Step:  1236  time: 1.297989 s d_loss: 1.22541261, g_loss: 940.07995605 -- mean_d_loss: 13.49751377, mean_g_loss: 991.48535156\n",
            "Epoch:  97 Step:  1237  time: 1.289919 s d_loss: 21.09007835, g_loss: 925.97265625 -- mean_d_loss: 13.69731903, mean_g_loss: 989.76129150\n",
            "Epoch:  97 Step:  1238  time: 1.333426 s d_loss: 1.79018998, g_loss: 983.55267334 -- mean_d_loss: 13.39200687, mean_g_loss: 989.60205078\n",
            "Epoch:  97 Step:  1239  time: 1.302679 s d_loss: 5.35983944, g_loss: 1006.17950439 -- mean_d_loss: 13.19120312, mean_g_loss: 990.01647949\n",
            "Epoch:  97 Step:  1240  time: 1.306322 s d_loss: 1.24344575, g_loss: 1119.93725586 -- mean_d_loss: 12.89979553, mean_g_loss: 993.18530273\n",
            "Epoch:  97 Step:  1241  time: 1.322309 s d_loss: 1.50086403, g_loss: 962.03796387 -- mean_d_loss: 12.62839222, mean_g_loss: 992.44372559\n",
            "Epoch:  97 Step:  1242  time: 1.315003 s d_loss: 1.01633346, g_loss: 1096.72509766 -- mean_d_loss: 12.35834408, mean_g_loss: 994.86889648\n",
            "Epoch:  97 Step:  1243  time: 1.314584 s d_loss: 4.58964062, g_loss: 1090.23071289 -- mean_d_loss: 12.18178368, mean_g_loss: 997.03619385\n",
            "Epoch:  97 Step:  1244  time: 1.317584 s d_loss: 2.28327632, g_loss: 966.27709961 -- mean_d_loss: 11.96181679, mean_g_loss: 996.35266113\n",
            "Epoch:  97 Step:  1245  time: 1.326393 s d_loss: 32.03506470, g_loss: 1065.76757812 -- mean_d_loss: 12.39819050, mean_g_loss: 997.86175537\n",
            "Epoch:  97 Step:  1246  time: 1.301707 s d_loss: 1.25211966, g_loss: 1055.38623047 -- mean_d_loss: 12.16104031, mean_g_loss: 999.08569336\n",
            "Epoch:  97 Step:  1247  time: 1.299727 s d_loss: 60.54702377, g_loss: 1045.35437012 -- mean_d_loss: 13.16908169, mean_g_loss: 1000.04962158\n",
            "Epoch:  97 Step:  1248  time: 1.314924 s d_loss: 38.35144424, g_loss: 998.37963867 -- mean_d_loss: 13.68300724, mean_g_loss: 1000.01556396\n",
            "Epoch:  97 Step:  1249  time: 1.333114 s d_loss: 2.49667120, g_loss: 1033.94799805 -- mean_d_loss: 13.45928001, mean_g_loss: 1000.69421387\n",
            "Epoch:  97 Step:  1250  time: 1.331774 s d_loss: 3.46139050, g_loss: 937.10595703 -- mean_d_loss: 13.26324177, mean_g_loss: 999.44738770\n",
            "Epoch:  97 Step:  1251  time: 1.284541 s d_loss: 1.72157311, g_loss: 909.86596680 -- mean_d_loss: 13.04128647, mean_g_loss: 997.72467041\n",
            "Epoch:  97 Step:  1252  time: 1.300224 s d_loss: 2.18865657, g_loss: 1033.45861816 -- mean_d_loss: 12.83652020, mean_g_loss: 998.39886475\n",
            "Epoch:  97 Step:  1253  time: 1.316627 s d_loss: 1.45804250, g_loss: 957.19592285 -- mean_d_loss: 12.62580776, mean_g_loss: 997.63586426\n",
            "Epoch:  97 Step:  1254  time: 1.294508 s d_loss: 1.75285661, g_loss: 940.93524170 -- mean_d_loss: 12.42811871, mean_g_loss: 996.60491943\n",
            "Epoch:  97 Step:  1255  time: 1.319708 s d_loss: 2.83459210, g_loss: 994.24359131 -- mean_d_loss: 12.25680542, mean_g_loss: 996.56268311\n",
            "Epoch:  97 Step:  1256  time: 1.331494 s d_loss: 1.62764299, g_loss: 1067.70556641 -- mean_d_loss: 12.07032871, mean_g_loss: 997.81085205\n",
            "Epoch:  97 Step:  1257  time: 1.321307 s d_loss: 1.56965804, g_loss: 1171.60473633 -- mean_d_loss: 11.88928223, mean_g_loss: 1000.80731201\n",
            "Epoch:  97 Step:  1258  time: 1.324416 s d_loss: 8.94648075, g_loss: 1032.24682617 -- mean_d_loss: 11.83940411, mean_g_loss: 1001.34014893\n",
            "Epoch:  97 Step:  1259  time: 1.293413 s d_loss: 8.75301266, g_loss: 1136.42236328 -- mean_d_loss: 11.78796387, mean_g_loss: 1003.59155273\n",
            "Epoch:  97 Step:  1260  time: 1.326936 s d_loss: 1.91297972, g_loss: 1001.66589355 -- mean_d_loss: 11.62607861, mean_g_loss: 1003.55993652\n",
            "Epoch:  97 Step:  1261  time: 1.320006 s d_loss: 1.08125985, g_loss: 930.47198486 -- mean_d_loss: 11.45600033, mean_g_loss: 1002.38110352\n",
            "Epoch:  97 Step:  1262  time: 1.339184 s d_loss: 1.69185460, g_loss: 1044.59619141 -- mean_d_loss: 11.30101395, mean_g_loss: 1003.05120850\n",
            "Epoch:  97 Step:  1263  time: 1.324020 s d_loss: 34.94512939, g_loss: 1067.00659180 -- mean_d_loss: 11.67045307, mean_g_loss: 1004.05053711\n",
            "Epoch:  97 Step:  1264  time: 1.316354 s d_loss: 21.01290131, g_loss: 1111.79199219 -- mean_d_loss: 11.81418228, mean_g_loss: 1005.70812988\n",
            "Epoch:  97 Step:  1265  time: 1.285315 s d_loss: 39.85197449, g_loss: 1041.21740723 -- mean_d_loss: 12.23899841, mean_g_loss: 1006.24609375\n",
            "Epoch:  97 Step:  1266  time: 1.325454 s d_loss: 14.31114388, g_loss: 929.55627441 -- mean_d_loss: 12.26992607, mean_g_loss: 1005.10144043\n",
            "Epoch:  97 Step:  1267  time: 1.324267 s d_loss: 6.87977791, g_loss: 1013.85168457 -- mean_d_loss: 12.19065857, mean_g_loss: 1005.23010254\n",
            "Epoch:  97 Step:  1268  time: 1.300438 s d_loss: 21.45687866, g_loss: 913.38317871 -- mean_d_loss: 12.32495117, mean_g_loss: 1003.89898682\n",
            "Epoch:  97 Step:  1269  time: 1.316722 s d_loss: 1.29972529, g_loss: 1019.78448486 -- mean_d_loss: 12.16744804, mean_g_loss: 1004.12591553\n",
            "Epoch:  97 Step:  1270  time: 1.317135 s d_loss: 1.56102312, g_loss: 910.96234131 -- mean_d_loss: 12.01806164, mean_g_loss: 1002.81372070\n",
            "Epoch:  97 Step:  1271  time: 1.310395 s d_loss: 2.56141329, g_loss: 1236.60693359 -- mean_d_loss: 11.88671970, mean_g_loss: 1006.06085205\n",
            "Epoch:  97 Step:  1272  time: 1.313850 s d_loss: 1.72334313, g_loss: 1115.26049805 -- mean_d_loss: 11.74749470, mean_g_loss: 1007.55670166\n",
            "Epoch:  97 Step:  1273  time: 1.344381 s d_loss: 1.05192924, g_loss: 1091.86120605 -- mean_d_loss: 11.60296059, mean_g_loss: 1008.69592285\n",
            "Epoch:  97 Step:  1274  time: 1.334672 s d_loss: 1.74242210, g_loss: 868.57336426 -- mean_d_loss: 11.47148705, mean_g_loss: 1006.82757568\n",
            "Epoch:  97 Step:  1275  time: 1.292732 s d_loss: 22.46113777, g_loss: 1154.81115723 -- mean_d_loss: 11.61608696, mean_g_loss: 1008.77478027\n",
            "Epoch:  97 Step:  1276  time: 1.317523 s d_loss: 10.20029926, g_loss: 971.44628906 -- mean_d_loss: 11.59770107, mean_g_loss: 1008.28997803\n",
            "Epoch:  97 Step:  1277  time: 1.305856 s d_loss: 1.44181705, g_loss: 1000.27502441 -- mean_d_loss: 11.46749687, mean_g_loss: 1008.18719482\n",
            "Epoch:  97 Step:  1278  time: 1.319909 s d_loss: 1.41362762, g_loss: 989.35388184 -- mean_d_loss: 11.34023285, mean_g_loss: 1007.94879150\n",
            "Epoch:  97 Step:  1279  time: 1.308893 s d_loss: 7.47229195, g_loss: 899.95660400 -- mean_d_loss: 11.29188347, mean_g_loss: 1006.59881592\n",
            "Epoch:  97 Step:  1280  time: 1.315793 s d_loss: 1.43029594, g_loss: 947.78082275 -- mean_d_loss: 11.17013550, mean_g_loss: 1005.87268066\n",
            "Epoch:  97 Step:  1281  time: 1.289115 s d_loss: 3.29103494, g_loss: 998.58898926 -- mean_d_loss: 11.07404900, mean_g_loss: 1005.78381348\n",
            "Epoch:  97 Step:  1282  time: 1.307852 s d_loss: 1.08670521, g_loss: 1340.38574219 -- mean_d_loss: 10.95372009, mean_g_loss: 1009.81512451\n",
            "Epoch:  97 Step:  1283  time: 1.288753 s d_loss: 14.85199547, g_loss: 1182.84521484 -- mean_d_loss: 11.00012779, mean_g_loss: 1011.87500000\n",
            "Epoch:  97 Step:  1284  time: 1.315261 s d_loss: 47.31986237, g_loss: 1138.36926270 -- mean_d_loss: 11.42741871, mean_g_loss: 1013.36315918\n",
            "Epoch:  97 Step:  1285  time: 1.311856 s d_loss: 1.70993984, g_loss: 1179.32849121 -- mean_d_loss: 11.31442547, mean_g_loss: 1015.29296875\n",
            "Epoch:  97 Step:  1286  time: 1.324519 s d_loss: 1.72345877, g_loss: 851.72308350 -- mean_d_loss: 11.20418453, mean_g_loss: 1013.41290283\n",
            "Epoch:  97 Step:  1287  time: 1.289623 s d_loss: 34.90895081, g_loss: 1007.68054199 -- mean_d_loss: 11.47355652, mean_g_loss: 1013.34771729\n",
            "Epoch:  97 Step:  1288  time: 1.295462 s d_loss: 3.79759622, g_loss: 1073.99768066 -- mean_d_loss: 11.38731003, mean_g_loss: 1014.02923584\n",
            "Epoch:  97 Step:  1289  time: 1.319732 s d_loss: 1.76807129, g_loss: 980.96453857 -- mean_d_loss: 11.28042984, mean_g_loss: 1013.66180420\n",
            "Epoch:  97 Step:  1290  time: 1.328174 s d_loss: 2.89822268, g_loss: 1149.56164551 -- mean_d_loss: 11.18831730, mean_g_loss: 1015.15521240\n",
            "Epoch:  97 Step:  1291  time: 1.336662 s d_loss: 4.08885098, g_loss: 939.94830322 -- mean_d_loss: 11.11114883, mean_g_loss: 1014.33770752\n",
            "Epoch:  97 Step:  1292  time: 1.317919 s d_loss: 24.54467773, g_loss: 1064.75097656 -- mean_d_loss: 11.25559521, mean_g_loss: 1014.87976074\n",
            "Epoch:  97 Step:  1293  time: 1.317298 s d_loss: 8.75273991, g_loss: 1132.74670410 -- mean_d_loss: 11.22896862, mean_g_loss: 1016.13372803\n",
            "Epoch:  97 Step:  1294  time: 1.321357 s d_loss: 11.15644741, g_loss: 1011.00891113 -- mean_d_loss: 11.22820568, mean_g_loss: 1016.07977295\n",
            "Epoch:  97 Step:  1295  time: 1.316038 s d_loss: 34.10399628, g_loss: 971.02081299 -- mean_d_loss: 11.46649551, mean_g_loss: 1015.61041260\n",
            "Epoch:  97 Step:  1296  time: 1.326710 s d_loss: 1.39307594, g_loss: 886.11291504 -- mean_d_loss: 11.36264610, mean_g_loss: 1014.27539062\n",
            "Epoch:  97 Step:  1297  time: 1.322870 s d_loss: 5.12295389, g_loss: 1072.01770020 -- mean_d_loss: 11.29897499, mean_g_loss: 1014.86456299\n",
            "Epoch:  97 Step:  1298  time: 1.313040 s d_loss: 1.66594446, g_loss: 1033.07849121 -- mean_d_loss: 11.20167160, mean_g_loss: 1015.04852295\n",
            "Epoch:  97 Step:  1299  time: 1.280891 s d_loss: 1.44907773, g_loss: 1094.15551758 -- mean_d_loss: 11.10414505, mean_g_loss: 1015.83959961\n",
            "Epoch:  97 Step:  1300  time: 1.344653 s d_loss: 2.08041739, g_loss: 1148.04504395 -- mean_d_loss: 11.01480198, mean_g_loss: 1017.14862061\n",
            "Epoch:  97 Step:  1301  time: 1.314864 s d_loss: 4.44453382, g_loss: 923.64367676 -- mean_d_loss: 10.95038795, mean_g_loss: 1016.23187256\n",
            "Epoch:  97 Step:  1302  time: 1.336905 s d_loss: 22.57269478, g_loss: 1083.83801270 -- mean_d_loss: 11.06322670, mean_g_loss: 1016.88818359\n",
            "Epoch:  97 Step:  1303  time: 1.315444 s d_loss: 16.46697426, g_loss: 1143.51293945 -- mean_d_loss: 11.11518478, mean_g_loss: 1018.10577393\n",
            "Epoch:  97 Step:  1304  time: 1.303898 s d_loss: 1.70654118, g_loss: 844.13220215 -- mean_d_loss: 11.02557850, mean_g_loss: 1016.44891357\n",
            "Epoch:  97 Step:  1305  time: 1.327992 s d_loss: 48.70558548, g_loss: 901.33166504 -- mean_d_loss: 11.38105011, mean_g_loss: 1015.36285400\n",
            "Epoch:  97 Step:  1306  time: 1.323184 s d_loss: 3.52333570, g_loss: 1032.73559570 -- mean_d_loss: 11.30761337, mean_g_loss: 1015.52520752\n",
            "Epoch:  97 Step:  1307  time: 1.323821 s d_loss: 1.63117099, g_loss: 1039.35083008 -- mean_d_loss: 11.21801758, mean_g_loss: 1015.74578857\n",
            "Epoch:  97 Step:  1308  time: 1.343311 s d_loss: 9.16485310, g_loss: 1223.69946289 -- mean_d_loss: 11.19918060, mean_g_loss: 1017.65368652\n",
            "Epoch:  97 Step:  1309  time: 1.329593 s d_loss: 2.35515022, g_loss: 1062.49230957 -- mean_d_loss: 11.11878014, mean_g_loss: 1018.06127930\n",
            "Epoch:  97 Step:  1310  time: 1.333623 s d_loss: 1.17711735, g_loss: 997.05700684 -- mean_d_loss: 11.02921581, mean_g_loss: 1017.87207031\n",
            "Epoch:  97 Step:  1311  time: 1.331161 s d_loss: 4.13695526, g_loss: 947.32543945 -- mean_d_loss: 10.96767712, mean_g_loss: 1017.24218750\n",
            "Epoch:  97 Step:  1312  time: 1.325692 s d_loss: 1.10651076, g_loss: 1053.60864258 -- mean_d_loss: 10.88041115, mean_g_loss: 1017.56402588\n",
            "Epoch:  97 Step:  1313  time: 1.283388 s d_loss: 1.59281945, g_loss: 904.02172852 -- mean_d_loss: 10.79894066, mean_g_loss: 1016.56805420\n",
            "Epoch:  97 Step:  1314  time: 1.289081 s d_loss: 1.43702829, g_loss: 1042.54931641 -- mean_d_loss: 10.71753216, mean_g_loss: 1016.79394531\n",
            "Epoch:  97 Step:  1315  time: 1.323810 s d_loss: 2.03874874, g_loss: 1139.29980469 -- mean_d_loss: 10.64271450, mean_g_loss: 1017.85003662\n",
            "Epoch:  97 Step:  1316  time: 1.325524 s d_loss: 1.88990021, g_loss: 1047.72753906 -- mean_d_loss: 10.56790447, mean_g_loss: 1018.10534668\n",
            "Epoch:  97 Step:  1317  time: 1.323369 s d_loss: 0.77199978, g_loss: 922.13818359 -- mean_d_loss: 10.48488808, mean_g_loss: 1017.29211426\n",
            "Epoch:  97 Step:  1318  time: 1.292957 s d_loss: 10.05485630, g_loss: 1144.33508301 -- mean_d_loss: 10.48127365, mean_g_loss: 1018.35968018\n",
            "Epoch:  97 Step:  1319  time: 1.334377 s d_loss: 0.92917603, g_loss: 987.41809082 -- mean_d_loss: 10.40167332, mean_g_loss: 1018.10186768\n",
            "Epoch:  97 Step:  1320  time: 1.316949 s d_loss: 2.45500946, g_loss: 929.41680908 -- mean_d_loss: 10.33599758, mean_g_loss: 1017.36895752\n",
            "Epoch:  97 Step:  1321  time: 1.316684 s d_loss: 2.70978928, g_loss: 979.05651855 -- mean_d_loss: 10.27348900, mean_g_loss: 1017.05487061\n",
            "Epoch:  97 Step:  1322  time: 1.331758 s d_loss: 2.19615078, g_loss: 1052.46679688 -- mean_d_loss: 10.20781898, mean_g_loss: 1017.34277344\n",
            "Epoch:  97 Step:  1323  time: 1.313058 s d_loss: 45.61745071, g_loss: 1370.59155273 -- mean_d_loss: 10.49338055, mean_g_loss: 1020.19158936\n",
            "Epoch:  97 Step:  1324  time: 1.294189 s d_loss: 1.90030289, g_loss: 884.88830566 -- mean_d_loss: 10.42463589, mean_g_loss: 1019.10919189\n",
            "Epoch:  97 Step:  1325  time: 1.336058 s d_loss: 2.13357186, g_loss: 1029.19665527 -- mean_d_loss: 10.35883331, mean_g_loss: 1019.18920898\n",
            "Epoch:  97 Step:  1326  time: 1.317780 s d_loss: 54.89991760, g_loss: 1063.26647949 -- mean_d_loss: 10.70955086, mean_g_loss: 1019.53631592\n",
            "Epoch:  97 Step:  1327  time: 1.294528 s d_loss: 2.02684975, g_loss: 910.06408691 -- mean_d_loss: 10.64171696, mean_g_loss: 1018.68103027\n",
            "Epoch:  97 Step:  1328  time: 1.324590 s d_loss: 1.86466777, g_loss: 873.74243164 -- mean_d_loss: 10.57367706, mean_g_loss: 1017.55755615\n",
            "Epoch:  97 Step:  1329  time: 1.288204 s d_loss: 2.90778756, g_loss: 1026.79589844 -- mean_d_loss: 10.51470947, mean_g_loss: 1017.62860107\n",
            "Epoch:  97 Step:  1330  time: 1.327741 s d_loss: 0.96950155, g_loss: 1017.57189941 -- mean_d_loss: 10.44184494, mean_g_loss: 1017.62823486\n",
            "Epoch:  97 Step:  1331  time: 1.350534 s d_loss: 1.00463009, g_loss: 977.67321777 -- mean_d_loss: 10.37035084, mean_g_loss: 1017.32550049\n",
            "Epoch:  97 Step:  1332  time: 1.325568 s d_loss: 10.92691803, g_loss: 1026.09082031 -- mean_d_loss: 10.37453556, mean_g_loss: 1017.39141846\n",
            "Epoch:  97 Step:  1333  time: 1.319278 s d_loss: 57.11497498, g_loss: 1038.24291992 -- mean_d_loss: 10.72334480, mean_g_loss: 1017.54711914\n",
            "Epoch:  97 Step:  1334  time: 1.312674 s d_loss: 3.51983309, g_loss: 896.85131836 -- mean_d_loss: 10.66998482, mean_g_loss: 1016.65301514\n",
            "Epoch:  97 Step:  1335  time: 1.339197 s d_loss: 29.74562645, g_loss: 965.14636230 -- mean_d_loss: 10.81024742, mean_g_loss: 1016.27423096\n",
            "Epoch:  97 Step:  1336  time: 1.300074 s d_loss: 6.47026825, g_loss: 936.16601562 -- mean_d_loss: 10.77856827, mean_g_loss: 1015.68957520\n",
            "Epoch:  97 Step:  1337  time: 1.310275 s d_loss: 2.29022002, g_loss: 1022.83044434 -- mean_d_loss: 10.71705818, mean_g_loss: 1015.74127197\n",
            "Epoch:  97 Step:  1338  time: 1.320906 s d_loss: 1.31986165, g_loss: 871.34472656 -- mean_d_loss: 10.64945221, mean_g_loss: 1014.70245361\n",
            "Epoch:  97 Step:  1339  time: 1.318394 s d_loss: 1.28307450, g_loss: 928.01855469 -- mean_d_loss: 10.58254910, mean_g_loss: 1014.08325195\n",
            "Epoch:  97 Step:  1340  time: 1.324490 s d_loss: 8.21780396, g_loss: 1072.56018066 -- mean_d_loss: 10.56577778, mean_g_loss: 1014.49798584\n",
            "Epoch:  97 Step:  1341  time: 1.325371 s d_loss: 1.10297072, g_loss: 1047.95825195 -- mean_d_loss: 10.49913883, mean_g_loss: 1014.73358154\n",
            "Epoch:  97 Step:  1342  time: 1.330533 s d_loss: 34.24802017, g_loss: 963.54797363 -- mean_d_loss: 10.66521454, mean_g_loss: 1014.37567139\n",
            "Epoch:  97 Step:  1343  time: 1.308596 s d_loss: 33.79884338, g_loss: 931.44244385 -- mean_d_loss: 10.82586479, mean_g_loss: 1013.79968262\n",
            "Epoch:  97 Step:  1344  time: 1.310935 s d_loss: 1.24451816, g_loss: 991.80267334 -- mean_d_loss: 10.75978661, mean_g_loss: 1013.64794922\n",
            "Epoch:  97 Step:  1345  time: 1.324667 s d_loss: 4.67935658, g_loss: 887.75915527 -- mean_d_loss: 10.71813965, mean_g_loss: 1012.78576660\n",
            "Epoch:  97 Step:  1346  time: 1.299340 s d_loss: 6.74809742, g_loss: 853.44396973 -- mean_d_loss: 10.69113255, mean_g_loss: 1011.70172119\n",
            "Epoch:  97 Step:  1347  time: 1.329856 s d_loss: 10.71706581, g_loss: 1048.24987793 -- mean_d_loss: 10.69130707, mean_g_loss: 1011.94866943\n",
            "Epoch:  97 Step:  1348  time: 1.287816 s d_loss: 9.16321754, g_loss: 957.01708984 -- mean_d_loss: 10.68105125, mean_g_loss: 1011.58001709\n",
            "Epoch:  97 Step:  1349  time: 1.353162 s d_loss: 2.92088366, g_loss: 965.96264648 -- mean_d_loss: 10.62931728, mean_g_loss: 1011.27593994\n",
            "Epoch:  97 Step:  1350  time: 1.287836 s d_loss: 5.80000210, g_loss: 930.14605713 -- mean_d_loss: 10.59733486, mean_g_loss: 1010.73864746\n",
            "Epoch:  97 Step:  1351  time: 1.303232 s d_loss: 1.44875777, g_loss: 1016.10583496 -- mean_d_loss: 10.53714752, mean_g_loss: 1010.77392578\n",
            "Epoch:  97 Step:  1352  time: 1.345672 s d_loss: 1.30612803, g_loss: 1052.55468750 -- mean_d_loss: 10.47681427, mean_g_loss: 1011.04699707\n",
            "Epoch:  97 Step:  1353  time: 1.332633 s d_loss: 0.89054286, g_loss: 935.91503906 -- mean_d_loss: 10.41456509, mean_g_loss: 1010.55914307\n",
            "Epoch:  97 Step:  1354  time: 1.328878 s d_loss: 2.43275714, g_loss: 1088.01000977 -- mean_d_loss: 10.36306953, mean_g_loss: 1011.05889893\n",
            "Epoch:  97 Step:  1355  time: 1.334096 s d_loss: 1.00857365, g_loss: 946.47308350 -- mean_d_loss: 10.30310440, mean_g_loss: 1010.64483643\n",
            "Epoch:  97 Step:  1356  time: 1.317709 s d_loss: 0.97822493, g_loss: 1008.11511230 -- mean_d_loss: 10.24371052, mean_g_loss: 1010.62866211\n",
            "Epoch:  97 Step:  1357  time: 1.311143 s d_loss: 5.88264990, g_loss: 910.73510742 -- mean_d_loss: 10.21610928, mean_g_loss: 1009.99645996\n",
            "Epoch:  97 Step:  1358  time: 1.344401 s d_loss: 1.56033683, g_loss: 1084.52233887 -- mean_d_loss: 10.16167068, mean_g_loss: 1010.46508789\n",
            "Epoch:  97 Step:  1359  time: 1.311367 s d_loss: 1.22160649, g_loss: 1028.55712891 -- mean_d_loss: 10.10579491, mean_g_loss: 1010.57824707\n",
            "Epoch:  97 Step:  1360  time: 1.325259 s d_loss: 0.67041689, g_loss: 1013.34082031 -- mean_d_loss: 10.04718971, mean_g_loss: 1010.59539795\n",
            "Epoch:  97 Step:  1361  time: 1.334940 s d_loss: 0.94461054, g_loss: 966.70434570 -- mean_d_loss: 9.99100113, mean_g_loss: 1010.32446289\n",
            "Epoch:  97 Step:  1362  time: 1.315398 s d_loss: 1.95101178, g_loss: 1242.94470215 -- mean_d_loss: 9.94167614, mean_g_loss: 1011.75152588\n",
            "Epoch:  97 Step:  1363  time: 1.310588 s d_loss: 4.91115427, g_loss: 1009.41918945 -- mean_d_loss: 9.91100216, mean_g_loss: 1011.73730469\n",
            "Epoch:  97 Step:  1364  time: 1.316847 s d_loss: 0.89831728, g_loss: 966.07006836 -- mean_d_loss: 9.85637951, mean_g_loss: 1011.46051025\n",
            "Epoch:  97 Step:  1365  time: 1.319230 s d_loss: 1.07037449, g_loss: 1079.10058594 -- mean_d_loss: 9.80345249, mean_g_loss: 1011.86791992\n",
            "Epoch:  97 Step:  1366  time: 1.323578 s d_loss: 1.44295907, g_loss: 1173.17736816 -- mean_d_loss: 9.75338936, mean_g_loss: 1012.83386230\n",
            "Epoch:  97 Step:  1367  time: 1.287577 s d_loss: 1.15891778, g_loss: 927.34503174 -- mean_d_loss: 9.70223236, mean_g_loss: 1012.32495117\n",
            "Epoch:  97 Step:  1368  time: 1.303722 s d_loss: 45.30952835, g_loss: 1047.90551758 -- mean_d_loss: 9.91292667, mean_g_loss: 1012.53552246\n",
            "Epoch:  97 Step:  1369  time: 1.313434 s d_loss: 2.27988720, g_loss: 1037.76318359 -- mean_d_loss: 9.86802578, mean_g_loss: 1012.68389893\n",
            "Epoch:  97 Step:  1370  time: 1.310372 s d_loss: 3.47670007, g_loss: 958.41015625 -- mean_d_loss: 9.83065033, mean_g_loss: 1012.36651611\n",
            "Epoch:  97 Step:  1371  time: 1.314982 s d_loss: 0.99650121, g_loss: 967.48699951 -- mean_d_loss: 9.77928829, mean_g_loss: 1012.10552979\n",
            "Epoch:  97 Step:  1372  time: 1.285628 s d_loss: 2.85836005, g_loss: 1166.28771973 -- mean_d_loss: 9.73928356, mean_g_loss: 1012.99676514\n",
            "Epoch:  97 Step:  1373  time: 1.284129 s d_loss: 0.96431917, g_loss: 833.93023682 -- mean_d_loss: 9.68885231, mean_g_loss: 1011.96765137\n",
            "Epoch:  97 Step:  1374  time: 1.307062 s d_loss: 6.42306614, g_loss: 1175.76245117 -- mean_d_loss: 9.67019081, mean_g_loss: 1012.90368652\n",
            "Epoch:  97 Step:  1375  time: 1.311417 s d_loss: 0.92548859, g_loss: 978.59033203 -- mean_d_loss: 9.62050533, mean_g_loss: 1012.70874023\n",
            "Epoch:  97 Step:  1376  time: 1.322133 s d_loss: 0.75244606, g_loss: 1058.96545410 -- mean_d_loss: 9.57040310, mean_g_loss: 1012.97009277\n",
            "Epoch:  97 Step:  1377  time: 1.320625 s d_loss: 1.46562183, g_loss: 1207.45727539 -- mean_d_loss: 9.52487087, mean_g_loss: 1014.06268311\n",
            "Epoch:  97 Step:  1378  time: 1.308601 s d_loss: 1.06231642, g_loss: 1232.32788086 -- mean_d_loss: 9.47759342, mean_g_loss: 1015.28204346\n",
            "Epoch:  97 Step:  1379  time: 1.285634 s d_loss: 9.30303574, g_loss: 1085.14733887 -- mean_d_loss: 9.47662354, mean_g_loss: 1015.67016602\n",
            "Epoch:  97 Step:  1380  time: 1.308493 s d_loss: 1.40119803, g_loss: 948.38555908 -- mean_d_loss: 9.43200779, mean_g_loss: 1015.29840088\n",
            "Epoch:  97 Step:  1381  time: 1.311798 s d_loss: 1.05648220, g_loss: 1006.21276855 -- mean_d_loss: 9.38598919, mean_g_loss: 1015.24853516\n",
            "Epoch:  97 Step:  1382  time: 1.274341 s d_loss: 8.47798252, g_loss: 1002.63513184 -- mean_d_loss: 9.38102722, mean_g_loss: 1015.17962646\n",
            "Epoch:  97 Step:  1383  time: 1.322955 s d_loss: 24.61036301, g_loss: 981.38098145 -- mean_d_loss: 9.46379566, mean_g_loss: 1014.99591064\n",
            "Epoch:  97 Step:  1384  time: 1.323067 s d_loss: 0.88101375, g_loss: 848.10595703 -- mean_d_loss: 9.41740227, mean_g_loss: 1014.09381104\n",
            "Epoch:  97 Step:  1385  time: 1.278443 s d_loss: 1.58445907, g_loss: 1041.56237793 -- mean_d_loss: 9.37528896, mean_g_loss: 1014.24151611\n",
            "Epoch:  97 Step:  1386  time: 1.290045 s d_loss: 53.76653290, g_loss: 1030.80895996 -- mean_d_loss: 9.61267567, mean_g_loss: 1014.33013916\n",
            "Epoch:  97 Step:  1387  time: 1.299200 s d_loss: 11.44070816, g_loss: 1003.14160156 -- mean_d_loss: 9.62239933, mean_g_loss: 1014.27062988\n",
            "Epoch:  97 Step:  1388  time: 1.298711 s d_loss: 2.55368853, g_loss: 876.39611816 -- mean_d_loss: 9.58499813, mean_g_loss: 1013.54107666\n",
            "Epoch:  97 Step:  1389  time: 1.323974 s d_loss: 1.41034138, g_loss: 1014.97192383 -- mean_d_loss: 9.54197407, mean_g_loss: 1013.54858398\n",
            "Epoch:  97 Step:  1390  time: 1.296134 s d_loss: 1.10707009, g_loss: 943.20251465 -- mean_d_loss: 9.49781227, mean_g_loss: 1013.18029785\n",
            "Epoch:  97 Step:  1391  time: 1.329664 s d_loss: 1.70060682, g_loss: 1051.07055664 -- mean_d_loss: 9.45720196, mean_g_loss: 1013.37768555\n",
            "Epoch:  97 Step:  1392  time: 1.307495 s d_loss: 0.99544698, g_loss: 1087.09106445 -- mean_d_loss: 9.41335869, mean_g_loss: 1013.75964355\n",
            "Epoch:  97 Step:  1393  time: 1.329117 s d_loss: 1.05827391, g_loss: 1138.76000977 -- mean_d_loss: 9.37029076, mean_g_loss: 1014.40399170\n",
            "Epoch:  97 Step:  1394  time: 1.324543 s d_loss: 1.24819064, g_loss: 869.24890137 -- mean_d_loss: 9.32863903, mean_g_loss: 1013.65960693\n",
            "Epoch:  97 Step:  1395  time: 1.323638 s d_loss: 0.92341846, g_loss: 1073.91979980 -- mean_d_loss: 9.28575516, mean_g_loss: 1013.96710205\n",
            "Epoch:  97 Step:  1396  time: 1.308114 s d_loss: 1.15584660, g_loss: 883.03021240 -- mean_d_loss: 9.24448681, mean_g_loss: 1013.30242920\n",
            "Epoch:  97 Step:  1397  time: 1.330479 s d_loss: 31.43532944, g_loss: 1216.65832520 -- mean_d_loss: 9.35656166, mean_g_loss: 1014.32946777\n",
            "Epoch:  97 Step:  1398  time: 1.330676 s d_loss: 6.60144424, g_loss: 912.27734375 -- mean_d_loss: 9.34271717, mean_g_loss: 1013.81665039\n",
            "Epoch:  97 Step:  1399  time: 1.304370 s d_loss: 1.02825582, g_loss: 896.93249512 -- mean_d_loss: 9.30114460, mean_g_loss: 1013.23223877\n",
            "Epoch:  97 Step:  1400  time: 1.301887 s d_loss: 0.80895132, g_loss: 981.76513672 -- mean_d_loss: 0.80895132, mean_g_loss: 981.76513672\n",
            "Epoch:  97 Step:  1401  time: 1.326330 s d_loss: 24.99311066, g_loss: 969.69726562 -- mean_d_loss: 12.90103054, mean_g_loss: 975.73120117\n",
            "Epoch:  97 Step:  1402  time: 1.310236 s d_loss: 1.79154098, g_loss: 1042.78808594 -- mean_d_loss: 9.19786739, mean_g_loss: 998.08349609\n",
            "Epoch:  97 Step:  1403  time: 1.332452 s d_loss: 3.61631250, g_loss: 1025.85803223 -- mean_d_loss: 7.80247831, mean_g_loss: 1005.02709961\n",
            "Epoch:  97 Step:  1404  time: 1.336336 s d_loss: 2.39614511, g_loss: 979.18334961 -- mean_d_loss: 6.72121191, mean_g_loss: 999.85839844\n",
            "Epoch:  97 Step:  1405  time: 1.310776 s d_loss: 2.57560325, g_loss: 1042.32519531 -- mean_d_loss: 6.03027725, mean_g_loss: 1006.93621826\n",
            "Epoch:  97 Step:  1406  time: 1.329499 s d_loss: 1.70445061, g_loss: 1185.85705566 -- mean_d_loss: 5.41230249, mean_g_loss: 1032.49633789\n",
            "Epoch:  97 Step:  1407  time: 1.318011 s d_loss: 8.51153660, g_loss: 961.35498047 -- mean_d_loss: 5.79970646, mean_g_loss: 1023.60363770\n",
            "Epoch:  97 Step:  1408  time: 1.334676 s d_loss: 1.54939127, g_loss: 1050.21472168 -- mean_d_loss: 5.32744932, mean_g_loss: 1026.56042480\n",
            "Epoch:  97 Step:  1409  time: 1.342012 s d_loss: 1.25914788, g_loss: 1160.53735352 -- mean_d_loss: 4.92061901, mean_g_loss: 1039.95812988\n",
            "Epoch:  97 Step:  1410  time: 1.296046 s d_loss: 1.14440703, g_loss: 1103.82690430 -- mean_d_loss: 4.57732725, mean_g_loss: 1045.76440430\n",
            "Epoch:  97 Step:  1411  time: 1.338549 s d_loss: 1.23680174, g_loss: 1010.80773926 -- mean_d_loss: 4.29894972, mean_g_loss: 1042.85131836\n",
            "Epoch:  97 Step:  1412  time: 1.339963 s d_loss: 3.49775720, g_loss: 1017.97863770 -- mean_d_loss: 4.23731947, mean_g_loss: 1040.93798828\n",
            "Epoch:  97 Step:  1413  time: 1.336858 s d_loss: 1.07911825, g_loss: 856.89794922 -- mean_d_loss: 4.01173353, mean_g_loss: 1027.79223633\n",
            "Epoch:  97 Step:  1414  time: 1.340547 s d_loss: 9.90504074, g_loss: 968.04669189 -- mean_d_loss: 4.40462065, mean_g_loss: 1023.80926514\n",
            "Epoch:  97 Step:  1415  time: 1.326623 s d_loss: 0.97223902, g_loss: 997.95251465 -- mean_d_loss: 4.19009686, mean_g_loss: 1022.19317627\n",
            "Epoch:  97 Step:  1416  time: 1.307971 s d_loss: 11.44837856, g_loss: 1068.92773438 -- mean_d_loss: 4.61705446, mean_g_loss: 1024.94238281\n",
            "Epoch:  97 Step:  1417  time: 1.326998 s d_loss: 1.24143493, g_loss: 1233.81127930 -- mean_d_loss: 4.42952013, mean_g_loss: 1036.54614258\n",
            "Epoch:  97 Step:  1418  time: 1.321140 s d_loss: 1.36450887, g_loss: 1234.87280273 -- mean_d_loss: 4.26820374, mean_g_loss: 1046.98437500\n",
            "Epoch:  97 Step:  1419  time: 1.322860 s d_loss: 2.53924870, g_loss: 864.74523926 -- mean_d_loss: 4.18175602, mean_g_loss: 1037.87243652\n",
            "Epoch:  97 Step:  1420  time: 1.285532 s d_loss: 1.08478677, g_loss: 969.40734863 -- mean_d_loss: 4.03428125, mean_g_loss: 1034.61230469\n",
            "Epoch:  97 Step:  1421  time: 1.359668 s d_loss: 1.89412951, g_loss: 928.37829590 -- mean_d_loss: 3.93700123, mean_g_loss: 1029.78344727\n",
            "Epoch:  97 Step:  1422  time: 1.291508 s d_loss: 5.38318253, g_loss: 1042.73303223 -- mean_d_loss: 3.99987864, mean_g_loss: 1030.34643555\n",
            "Epoch:  97 Step:  1423  time: 1.302171 s d_loss: 1.35659611, g_loss: 999.17254639 -- mean_d_loss: 3.88974190, mean_g_loss: 1029.04748535\n",
            "Epoch:  97 Step:  1424  time: 1.350056 s d_loss: 0.93073279, g_loss: 909.21130371 -- mean_d_loss: 3.77138162, mean_g_loss: 1024.25402832\n",
            "Epoch:  97 Step:  1425  time: 1.297657 s d_loss: 16.78780174, g_loss: 1020.42590332 -- mean_d_loss: 4.27201319, mean_g_loss: 1024.10681152\n",
            "Epoch:  97 Step:  1426  time: 1.293159 s d_loss: 7.76693535, g_loss: 1022.41784668 -- mean_d_loss: 4.40145493, mean_g_loss: 1024.04431152\n",
            "Epoch:  97 Step:  1427  time: 1.299534 s d_loss: 1.27042329, g_loss: 917.63922119 -- mean_d_loss: 4.28963232, mean_g_loss: 1020.24407959\n",
            "Epoch:  97 Step:  1428  time: 1.347323 s d_loss: 2.51939631, g_loss: 1049.46179199 -- mean_d_loss: 4.22858953, mean_g_loss: 1021.25152588\n",
            "Epoch:  97 Step:  1429  time: 1.299355 s d_loss: 1.31761372, g_loss: 1098.24523926 -- mean_d_loss: 4.13155699, mean_g_loss: 1023.81805420\n",
            "Epoch:  97 Step:  1430  time: 1.321550 s d_loss: 2.38585734, g_loss: 1141.78588867 -- mean_d_loss: 4.07524395, mean_g_loss: 1027.62341309\n",
            "Epoch:  97 Step:  1431  time: 1.318228 s d_loss: 0.61910748, g_loss: 1025.09667969 -- mean_d_loss: 3.96723986, mean_g_loss: 1027.54443359\n",
            "Epoch:  97 Step:  1432  time: 1.301562 s d_loss: 8.79354477, g_loss: 974.23199463 -- mean_d_loss: 4.11349154, mean_g_loss: 1025.92883301\n",
            "Epoch:  97 Step:  1433  time: 1.294959 s d_loss: 4.91934347, g_loss: 939.35473633 -- mean_d_loss: 4.13719320, mean_g_loss: 1023.38256836\n",
            "Epoch:  97 Step:  1434  time: 1.310578 s d_loss: 0.98479003, g_loss: 1031.48950195 -- mean_d_loss: 4.04712439, mean_g_loss: 1023.61419678\n",
            "Epoch:  97 Step:  1435  time: 1.286875 s d_loss: 1.33850026, g_loss: 1000.92773438 -- mean_d_loss: 3.97188473, mean_g_loss: 1022.98394775\n",
            "Epoch:  97 Step:  1436  time: 1.300892 s d_loss: 1.44380987, g_loss: 962.06707764 -- mean_d_loss: 3.90355873, mean_g_loss: 1021.33752441\n",
            "Epoch:  97 Step:  1437  time: 1.316110 s d_loss: 10.28864193, g_loss: 1023.85754395 -- mean_d_loss: 4.07158709, mean_g_loss: 1021.40386963\n",
            "Epoch:  97 Step:  1438  time: 1.310233 s d_loss: 1.14731348, g_loss: 916.29119873 -- mean_d_loss: 3.99660540, mean_g_loss: 1018.70874023\n",
            "Epoch:  97 Step:  1439  time: 1.281324 s d_loss: 0.99709892, g_loss: 962.69714355 -- mean_d_loss: 3.92161798, mean_g_loss: 1017.30841064\n",
            "Epoch:  97 Step:  1440  time: 1.276570 s d_loss: 1.31342745, g_loss: 1034.54187012 -- mean_d_loss: 3.85800362, mean_g_loss: 1017.72875977\n",
            "Epoch:  97 Step:  1441  time: 1.296423 s d_loss: 1.45178282, g_loss: 1089.43530273 -- mean_d_loss: 3.80071259, mean_g_loss: 1019.43603516\n",
            "Epoch:  97 Step:  1442  time: 1.284429 s d_loss: 2.02228260, g_loss: 1034.45434570 -- mean_d_loss: 3.75935364, mean_g_loss: 1019.78521729\n",
            "Epoch:  97 Step:  1443  time: 1.310897 s d_loss: 1.08697104, g_loss: 929.78186035 -- mean_d_loss: 3.69861770, mean_g_loss: 1017.73968506\n",
            "Epoch:  97 Step:  1444  time: 1.308586 s d_loss: 1.20358336, g_loss: 1027.45336914 -- mean_d_loss: 3.64317250, mean_g_loss: 1017.95556641\n",
            "Epoch:  97 Step:  1445  time: 1.316834 s d_loss: 0.94946295, g_loss: 1233.45092773 -- mean_d_loss: 3.58461356, mean_g_loss: 1022.64019775\n",
            "Epoch:  97 Step:  1446  time: 1.314838 s d_loss: 0.69907546, g_loss: 1040.20715332 -- mean_d_loss: 3.52321935, mean_g_loss: 1023.01397705\n",
            "Epoch:  97 Step:  1447  time: 1.314712 s d_loss: 0.95963901, g_loss: 993.57476807 -- mean_d_loss: 3.46981144, mean_g_loss: 1022.40063477\n",
            "Epoch:  97 Step:  1448  time: 1.313708 s d_loss: 1.11949039, g_loss: 1052.20764160 -- mean_d_loss: 3.42184567, mean_g_loss: 1023.00891113\n",
            "Epoch:  97 Step:  1449  time: 1.301548 s d_loss: 1.66053557, g_loss: 927.79882812 -- mean_d_loss: 3.38661957, mean_g_loss: 1021.10467529\n",
            "Epoch:  97 Step:  1450  time: 1.314942 s d_loss: 0.70355672, g_loss: 1041.49792480 -- mean_d_loss: 3.33401036, mean_g_loss: 1021.50451660\n",
            "Epoch:  97 Step:  1451  time: 1.298848 s d_loss: 0.65122604, g_loss: 1001.46911621 -- mean_d_loss: 3.28241849, mean_g_loss: 1021.11920166\n",
            "Epoch:  97 Step:  1452  time: 1.308944 s d_loss: 1.17212629, g_loss: 971.23706055 -- mean_d_loss: 3.24260139, mean_g_loss: 1020.17803955\n",
            "Epoch:  97 Step:  1453  time: 1.322300 s d_loss: 1.16396523, g_loss: 1003.16802979 -- mean_d_loss: 3.20410824, mean_g_loss: 1019.86303711\n",
            "Epoch:  97 Step:  1454  time: 1.279706 s d_loss: 0.98879164, g_loss: 1156.95874023 -- mean_d_loss: 3.16382980, mean_g_loss: 1022.35565186\n",
            "Epoch:  97 Step:  1455  time: 1.316643 s d_loss: 0.68765432, g_loss: 1106.97216797 -- mean_d_loss: 3.11961222, mean_g_loss: 1023.86669922\n",
            "Epoch:  97 Step:  1456  time: 1.297458 s d_loss: 2.22645569, g_loss: 1086.58935547 -- mean_d_loss: 3.10394287, mean_g_loss: 1024.96716309\n",
            "Epoch:  97 Step:  1457  time: 1.297592 s d_loss: 5.41662073, g_loss: 1053.62121582 -- mean_d_loss: 3.14381671, mean_g_loss: 1025.46118164\n",
            "Epoch:  97 Step:  1458  time: 1.286004 s d_loss: 2.90059590, g_loss: 1155.94458008 -- mean_d_loss: 3.13969421, mean_g_loss: 1027.67272949\n",
            "Epoch:  97 Step:  1459  time: 1.328331 s d_loss: 10.24878502, g_loss: 1034.73706055 -- mean_d_loss: 3.25817895, mean_g_loss: 1027.79052734\n",
            "Epoch:  97 Step:  1460  time: 1.321600 s d_loss: 1.61812639, g_loss: 1000.66754150 -- mean_d_loss: 3.23129296, mean_g_loss: 1027.34582520\n",
            "Epoch:  97 Step:  1461  time: 1.312912 s d_loss: 0.84117645, g_loss: 971.91003418 -- mean_d_loss: 3.19274259, mean_g_loss: 1026.45178223\n",
            "Epoch:  97 Step:  1462  time: 1.296598 s d_loss: 0.96388155, g_loss: 935.11877441 -- mean_d_loss: 3.15736389, mean_g_loss: 1025.00195312\n",
            "Epoch:  97 Step:  1463  time: 1.309276 s d_loss: 1.46182775, g_loss: 1044.32763672 -- mean_d_loss: 3.13087106, mean_g_loss: 1025.30395508\n",
            "Epoch:  97 Step:  1464  time: 1.324984 s d_loss: 0.88531309, g_loss: 957.16369629 -- mean_d_loss: 3.09632397, mean_g_loss: 1024.25561523\n",
            "Epoch:  97 Step:  1465  time: 1.321448 s d_loss: 1.07268119, g_loss: 1048.79858398 -- mean_d_loss: 3.06566262, mean_g_loss: 1024.62744141\n",
            "Epoch:  97 Step:  1466  time: 1.342429 s d_loss: 0.88907909, g_loss: 972.62280273 -- mean_d_loss: 3.03317642, mean_g_loss: 1023.85131836\n",
            "Epoch:  97 Step:  1467  time: 1.294232 s d_loss: 0.79585236, g_loss: 970.75830078 -- mean_d_loss: 3.00027466, mean_g_loss: 1023.07055664\n",
            "Epoch:  97 Step:  1468  time: 1.312136 s d_loss: 0.80227840, g_loss: 1048.65148926 -- mean_d_loss: 2.96841955, mean_g_loss: 1023.44122314\n",
            "Epoch:  97 Step:  1469  time: 1.303394 s d_loss: 1.25586712, g_loss: 1080.91284180 -- mean_d_loss: 2.94395471, mean_g_loss: 1024.26232910\n",
            "Epoch:  97 Step:  1470  time: 1.332513 s d_loss: 0.86189622, g_loss: 907.86285400 -- mean_d_loss: 2.91462994, mean_g_loss: 1022.62280273\n",
            "Epoch:  97 Step:  1471  time: 1.346832 s d_loss: 0.89076442, g_loss: 1054.37036133 -- mean_d_loss: 2.88652062, mean_g_loss: 1023.06372070\n",
            "Epoch:  97 Step:  1472  time: 1.329539 s d_loss: 0.68881440, g_loss: 941.33520508 -- mean_d_loss: 2.85641503, mean_g_loss: 1021.94415283\n",
            "Epoch:  97 Step:  1473  time: 1.319394 s d_loss: 0.76691133, g_loss: 817.85327148 -- mean_d_loss: 2.82817841, mean_g_loss: 1019.18615723\n",
            "Epoch:  97 Step:  1474  time: 1.319570 s d_loss: 15.73969173, g_loss: 1033.66625977 -- mean_d_loss: 3.00033188, mean_g_loss: 1019.37915039\n",
            "Epoch:  97 Step:  1475  time: 1.330080 s d_loss: 1.38029170, g_loss: 1085.95983887 -- mean_d_loss: 2.97901559, mean_g_loss: 1020.25524902\n",
            "Epoch:  97 Step:  1476  time: 1.320315 s d_loss: 17.25312424, g_loss: 1042.63684082 -- mean_d_loss: 3.16439366, mean_g_loss: 1020.54595947\n",
            "Epoch:  97 Step:  1477  time: 1.317124 s d_loss: 0.91835582, g_loss: 946.94281006 -- mean_d_loss: 3.13559818, mean_g_loss: 1019.60235596\n",
            "Epoch:  97 Step:  1478  time: 1.364942 s d_loss: 5.00904989, g_loss: 928.27142334 -- mean_d_loss: 3.15931273, mean_g_loss: 1018.44628906\n",
            "Epoch:  97 Step:  1479  time: 1.303974 s d_loss: 0.98633945, g_loss: 877.21374512 -- mean_d_loss: 3.13215065, mean_g_loss: 1016.68084717\n",
            "Epoch:  97 Step:  1480  time: 1.351226 s d_loss: 0.81323630, g_loss: 1069.60559082 -- mean_d_loss: 3.10352206, mean_g_loss: 1017.33428955\n",
            "Epoch:  97 Step:  1481  time: 1.341710 s d_loss: 0.89315355, g_loss: 1092.16796875 -- mean_d_loss: 3.07656646, mean_g_loss: 1018.24694824\n",
            "Epoch:  97 Step:  1482  time: 1.328531 s d_loss: 0.79042733, g_loss: 1024.07653809 -- mean_d_loss: 3.04902244, mean_g_loss: 1018.31719971\n",
            "Epoch:  97 Step:  1483  time: 1.335337 s d_loss: 1.03937840, g_loss: 1195.23535156 -- mean_d_loss: 3.02509809, mean_g_loss: 1020.42333984\n",
            "Epoch:  97 Step:  1484  time: 1.299214 s d_loss: 0.77172917, g_loss: 1032.39379883 -- mean_d_loss: 2.99858785, mean_g_loss: 1020.56414795\n",
            "Epoch:  97 Step:  1485  time: 1.336706 s d_loss: 0.87687987, g_loss: 1065.89892578 -- mean_d_loss: 2.97391677, mean_g_loss: 1021.09130859\n",
            "Epoch:  97 Step:  1486  time: 1.332523 s d_loss: 1.65510166, g_loss: 1147.53344727 -- mean_d_loss: 2.95875812, mean_g_loss: 1022.54461670\n",
            "Epoch:  97 Step:  1487  time: 1.320144 s d_loss: 0.68446803, g_loss: 957.66210938 -- mean_d_loss: 2.93291402, mean_g_loss: 1021.80737305\n",
            "Epoch:  97 Step:  1488  time: 1.336964 s d_loss: 8.17109776, g_loss: 936.37670898 -- mean_d_loss: 2.99177027, mean_g_loss: 1020.84741211\n",
            "Epoch:  97 Step:  1489  time: 1.324178 s d_loss: 0.86063319, g_loss: 1094.61376953 -- mean_d_loss: 2.96809077, mean_g_loss: 1021.66711426\n",
            "Epoch:  97 Step:  1490  time: 1.284168 s d_loss: 0.64278394, g_loss: 817.31542969 -- mean_d_loss: 2.94253802, mean_g_loss: 1019.42144775\n",
            "Epoch:  97 Step:  1491  time: 1.302871 s d_loss: 0.66533536, g_loss: 1104.48217773 -- mean_d_loss: 2.91778588, mean_g_loss: 1020.34606934\n",
            "Epoch:  97 Step:  1492  time: 1.310430 s d_loss: 0.86133885, g_loss: 1158.01049805 -- mean_d_loss: 2.89567351, mean_g_loss: 1021.82629395\n",
            "Epoch:  97 Step:  1493  time: 1.313663 s d_loss: 0.73044300, g_loss: 1049.97729492 -- mean_d_loss: 2.87263918, mean_g_loss: 1022.12573242\n",
            "Epoch:  97 Step:  1494  time: 1.315512 s d_loss: 0.97558498, g_loss: 949.95623779 -- mean_d_loss: 2.85267019, mean_g_loss: 1021.36602783\n",
            "Epoch:  97 Step:  1495  time: 1.346583 s d_loss: 0.97957313, g_loss: 1175.98901367 -- mean_d_loss: 2.83315873, mean_g_loss: 1022.97674561\n",
            "Epoch:  97 Step:  1496  time: 1.315661 s d_loss: 0.92854577, g_loss: 1062.69238281 -- mean_d_loss: 2.81352377, mean_g_loss: 1023.38616943\n",
            "Epoch:  97 Step:  1497  time: 1.343146 s d_loss: 1.26702511, g_loss: 1136.73254395 -- mean_d_loss: 2.79774308, mean_g_loss: 1024.54284668\n",
            "Epoch:  97 Step:  1498  time: 1.322183 s d_loss: 0.60106707, g_loss: 998.80761719 -- mean_d_loss: 2.77555466, mean_g_loss: 1024.28283691\n",
            "Epoch:  97 Step:  1499  time: 1.321669 s d_loss: 1.40324831, g_loss: 1120.22717285 -- mean_d_loss: 2.76183176, mean_g_loss: 1025.24230957\n",
            "Epoch:  97 Step:  1500  time: 1.317290 s d_loss: 1.02150714, g_loss: 1095.87011719 -- mean_d_loss: 2.74460077, mean_g_loss: 1025.94152832\n",
            "Epoch:  97 Step:  1501  time: 1.337332 s d_loss: 0.85845816, g_loss: 1103.32788086 -- mean_d_loss: 2.72610927, mean_g_loss: 1026.70019531\n",
            "Epoch:  97 Step:  1502  time: 1.315226 s d_loss: 0.63999164, g_loss: 1282.66162109 -- mean_d_loss: 2.70585561, mean_g_loss: 1029.18530273\n",
            "Epoch:  97 Step:  1503  time: 1.314900 s d_loss: 0.58715051, g_loss: 962.88934326 -- mean_d_loss: 2.68548346, mean_g_loss: 1028.54785156\n",
            "Epoch:  97 Step:  1504  time: 1.301042 s d_loss: 0.81612986, g_loss: 1210.56713867 -- mean_d_loss: 2.66768003, mean_g_loss: 1030.28137207\n",
            "Epoch:  97 Step:  1505  time: 1.311602 s d_loss: 0.91034526, g_loss: 933.28454590 -- mean_d_loss: 2.65110135, mean_g_loss: 1029.36633301\n",
            "Epoch:  97 Step:  1506  time: 1.310422 s d_loss: 0.67166466, g_loss: 993.71643066 -- mean_d_loss: 2.63260198, mean_g_loss: 1029.03320312\n",
            "Epoch:  97 Step:  1507  time: 1.289871 s d_loss: 1.24253035, g_loss: 1002.40393066 -- mean_d_loss: 2.61973095, mean_g_loss: 1028.78662109\n",
            "Epoch:  97 Step:  1508  time: 1.325123 s d_loss: 4.52931166, g_loss: 1100.97912598 -- mean_d_loss: 2.63724995, mean_g_loss: 1029.44885254\n",
            "Epoch:  97 Step:  1509  time: 1.309234 s d_loss: 0.89146501, g_loss: 1038.53491211 -- mean_d_loss: 2.62137914, mean_g_loss: 1029.53149414\n",
            "Epoch:  97 Step:  1510  time: 1.306757 s d_loss: 0.78510737, g_loss: 923.85833740 -- mean_d_loss: 2.60483623, mean_g_loss: 1028.57946777\n",
            "Epoch:  97 Step:  1511  time: 1.325001 s d_loss: 0.75768638, g_loss: 1032.35534668 -- mean_d_loss: 2.58834386, mean_g_loss: 1028.61315918\n",
            "Epoch:  97 Step:  1512  time: 1.310673 s d_loss: 1.17625511, g_loss: 1011.45751953 -- mean_d_loss: 2.57584763, mean_g_loss: 1028.46130371\n",
            "Epoch:  97 Step:  1513  time: 1.307686 s d_loss: 0.77918279, g_loss: 992.20733643 -- mean_d_loss: 2.56008720, mean_g_loss: 1028.14331055\n",
            "Epoch:  97 Step:  1514  time: 1.323590 s d_loss: 1.39497626, g_loss: 1219.95825195 -- mean_d_loss: 2.54995584, mean_g_loss: 1029.81140137\n",
            "Epoch:  97 Step:  1515  time: 1.309700 s d_loss: 0.75239408, g_loss: 1012.64007568 -- mean_d_loss: 2.53445959, mean_g_loss: 1029.66333008\n",
            "Epoch:  97 Step:  1516  time: 1.307324 s d_loss: 0.65708834, g_loss: 909.65722656 -- mean_d_loss: 2.51841354, mean_g_loss: 1028.63757324\n",
            "Epoch:  97 Step:  1517  time: 1.323391 s d_loss: 27.65119171, g_loss: 1185.55432129 -- mean_d_loss: 2.73140311, mean_g_loss: 1029.96740723\n",
            "Epoch:  97 Step:  1518  time: 1.285387 s d_loss: 4.02412367, g_loss: 1104.21289062 -- mean_d_loss: 2.74226618, mean_g_loss: 1030.59130859\n",
            "Epoch:  97 Step:  1519  time: 1.288970 s d_loss: 13.87940884, g_loss: 1069.53955078 -- mean_d_loss: 2.83507562, mean_g_loss: 1030.91589355\n",
            "Epoch:  97 Step:  1520  time: 1.314263 s d_loss: 7.95302963, g_loss: 1169.33081055 -- mean_d_loss: 2.87737274, mean_g_loss: 1032.05981445\n",
            "Epoch:  97 Step:  1521  time: 1.307064 s d_loss: 5.40637779, g_loss: 881.04199219 -- mean_d_loss: 2.89810228, mean_g_loss: 1030.82189941\n",
            "Epoch:  97 Step:  1522  time: 1.282027 s d_loss: 0.93722039, g_loss: 1009.20178223 -- mean_d_loss: 2.88216019, mean_g_loss: 1030.64611816\n",
            "Epoch:  97 Step:  1523  time: 1.330958 s d_loss: 50.05216599, g_loss: 963.04150391 -- mean_d_loss: 3.26256347, mean_g_loss: 1030.10095215\n",
            "Epoch:  97 Step:  1524  time: 1.336877 s d_loss: 4.91236401, g_loss: 1110.61267090 -- mean_d_loss: 3.27576160, mean_g_loss: 1030.74499512\n",
            "Epoch:  97 Step:  1525  time: 1.354085 s d_loss: 2.46079135, g_loss: 1076.14184570 -- mean_d_loss: 3.26929355, mean_g_loss: 1031.10522461\n",
            "Epoch:  97 Step:  1526  time: 1.330863 s d_loss: 3.03512478, g_loss: 1203.40454102 -- mean_d_loss: 3.26744986, mean_g_loss: 1032.46203613\n",
            "Epoch:  97 Step:  1527  time: 1.316026 s d_loss: 1.08194518, g_loss: 1001.24432373 -- mean_d_loss: 3.25037551, mean_g_loss: 1032.21813965\n",
            "Epoch:  97 Step:  1528  time: 1.322433 s d_loss: 0.98220676, g_loss: 1054.02075195 -- mean_d_loss: 3.23279285, mean_g_loss: 1032.38708496\n",
            "Epoch:  97 Step:  1529  time: 1.289515 s d_loss: 40.17855072, g_loss: 985.91113281 -- mean_d_loss: 3.51699090, mean_g_loss: 1032.02954102\n",
            "Epoch:  97 Step:  1530  time: 1.339002 s d_loss: 1.74923778, g_loss: 1003.88098145 -- mean_d_loss: 3.50349665, mean_g_loss: 1031.81469727\n",
            "Epoch:  97 Step:  1531  time: 1.320725 s d_loss: 2.19658351, g_loss: 998.19287109 -- mean_d_loss: 3.49359584, mean_g_loss: 1031.55993652\n",
            "Epoch:  97 Step:  1532  time: 1.318989 s d_loss: 2.10563803, g_loss: 1050.12133789 -- mean_d_loss: 3.48316026, mean_g_loss: 1031.69946289\n",
            "Epoch:  97 Step:  1533  time: 1.305425 s d_loss: 2.21236610, g_loss: 1172.66040039 -- mean_d_loss: 3.47367668, mean_g_loss: 1032.75134277\n",
            "Epoch:  97 Step:  1534  time: 1.305176 s d_loss: 0.74930805, g_loss: 1071.50964355 -- mean_d_loss: 3.45349622, mean_g_loss: 1033.03857422\n",
            "Epoch:  97 Step:  1535  time: 1.295272 s d_loss: 2.18459129, g_loss: 1029.48156738 -- mean_d_loss: 3.44416618, mean_g_loss: 1033.01245117\n",
            "Epoch:  97 Step:  1536  time: 1.310231 s d_loss: 1.15844440, g_loss: 1068.91394043 -- mean_d_loss: 3.42748189, mean_g_loss: 1033.27441406\n",
            "Epoch:  97 Step:  1537  time: 1.324999 s d_loss: 31.25914192, g_loss: 1027.89538574 -- mean_d_loss: 3.62916088, mean_g_loss: 1033.23535156\n",
            "Epoch:  97 Step:  1538  time: 1.295563 s d_loss: 1.67139232, g_loss: 1027.01550293 -- mean_d_loss: 3.61507607, mean_g_loss: 1033.19067383\n",
            "Epoch:  97 Step:  1539  time: 1.315604 s d_loss: 1.85785723, g_loss: 1127.42370605 -- mean_d_loss: 3.60252452, mean_g_loss: 1033.86376953\n",
            "Epoch:  97 Step:  1540  time: 1.320137 s d_loss: 1.03907168, g_loss: 976.79473877 -- mean_d_loss: 3.58434391, mean_g_loss: 1033.45898438\n",
            "Epoch:  97 Step:  1541  time: 1.342316 s d_loss: 14.42760944, g_loss: 1037.07568359 -- mean_d_loss: 3.66070461, mean_g_loss: 1033.48449707\n",
            "Epoch:  97 Step:  1542  time: 1.326574 s d_loss: 1.47282970, g_loss: 1066.84887695 -- mean_d_loss: 3.64540505, mean_g_loss: 1033.71777344\n",
            "Epoch:  97 Step:  1543  time: 1.312379 s d_loss: 37.67117691, g_loss: 990.55322266 -- mean_d_loss: 3.88169527, mean_g_loss: 1033.41796875\n",
            "Epoch:  97 Step:  1544  time: 1.326951 s d_loss: 1.61789393, g_loss: 1023.60571289 -- mean_d_loss: 3.86608291, mean_g_loss: 1033.35034180\n",
            "Epoch:  97 Step:  1545  time: 1.314708 s d_loss: 1.00601959, g_loss: 916.91571045 -- mean_d_loss: 3.84649372, mean_g_loss: 1032.55285645\n",
            "Epoch:  97 Step:  1546  time: 1.329422 s d_loss: 1.02651024, g_loss: 1031.03588867 -- mean_d_loss: 3.82730985, mean_g_loss: 1032.54248047\n",
            "Epoch:  97 Step:  1547  time: 1.334167 s d_loss: 0.97860330, g_loss: 986.12170410 -- mean_d_loss: 3.80806184, mean_g_loss: 1032.22888184\n",
            "Epoch:  97 Step:  1548  time: 1.318057 s d_loss: 2.15043139, g_loss: 1114.45654297 -- mean_d_loss: 3.79693675, mean_g_loss: 1032.78076172\n",
            "Epoch:  97 Step:  1549  time: 1.312010 s d_loss: 0.78330469, g_loss: 962.73083496 -- mean_d_loss: 3.77684617, mean_g_loss: 1032.31372070\n",
            "Epoch:  97 Step:  1550  time: 1.276929 s d_loss: 0.74331814, g_loss: 926.06469727 -- mean_d_loss: 3.75675678, mean_g_loss: 1031.61010742\n",
            "Epoch:  97 Step:  1551  time: 1.292070 s d_loss: 0.87647933, g_loss: 1018.14575195 -- mean_d_loss: 3.73780751, mean_g_loss: 1031.52148438\n",
            "Epoch:  97 Step:  1552  time: 1.294947 s d_loss: 0.69644076, g_loss: 1108.71484375 -- mean_d_loss: 3.71792912, mean_g_loss: 1032.02600098\n",
            "Epoch:  97 Step:  1553  time: 1.290902 s d_loss: 1.06115365, g_loss: 1037.37597656 -- mean_d_loss: 3.70067716, mean_g_loss: 1032.06079102\n",
            "Epoch:  97 Step:  1554  time: 1.319489 s d_loss: 1.03637195, g_loss: 1034.78784180 -- mean_d_loss: 3.68348813, mean_g_loss: 1032.07836914\n",
            "Epoch:  97 Step:  1555  time: 1.315770 s d_loss: 1.12835741, g_loss: 1170.02014160 -- mean_d_loss: 3.66710925, mean_g_loss: 1032.96252441\n",
            "Epoch:  97 Step:  1556  time: 1.319433 s d_loss: 0.83624989, g_loss: 937.98681641 -- mean_d_loss: 3.64907813, mean_g_loss: 1032.35754395\n",
            "Epoch:  97 Step:  1557  time: 1.297262 s d_loss: 1.79705489, g_loss: 1170.09558105 -- mean_d_loss: 3.63735652, mean_g_loss: 1033.22937012\n",
            "Epoch:  97 Step:  1558  time: 1.315072 s d_loss: 0.98135233, g_loss: 1075.20288086 -- mean_d_loss: 3.62065196, mean_g_loss: 1033.49328613\n",
            "Epoch:  97 Step:  1559  time: 1.314155 s d_loss: 1.46817672, g_loss: 1148.04455566 -- mean_d_loss: 3.60719919, mean_g_loss: 1034.20922852\n",
            "Epoch:  97 Step:  1560  time: 1.314595 s d_loss: 0.87666970, g_loss: 1047.21752930 -- mean_d_loss: 3.59023905, mean_g_loss: 1034.29003906\n",
            "Epoch:  97 Step:  1561  time: 1.310504 s d_loss: 57.98679352, g_loss: 948.01660156 -- mean_d_loss: 3.92602038, mean_g_loss: 1033.75756836\n",
            "Epoch:  97 Step:  1562  time: 1.313886 s d_loss: 1.94380021, g_loss: 888.36352539 -- mean_d_loss: 3.91385961, mean_g_loss: 1032.86547852\n",
            "Epoch:  97 Step:  1563  time: 1.309923 s d_loss: 1.38041353, g_loss: 930.99792480 -- mean_d_loss: 3.89841175, mean_g_loss: 1032.24438477\n",
            "Epoch:  97 Step:  1564  time: 1.322683 s d_loss: 1.02949226, g_loss: 1007.75817871 -- mean_d_loss: 3.88102436, mean_g_loss: 1032.09606934\n",
            "Epoch:  97 Step:  1565  time: 1.322903 s d_loss: 4.10980606, g_loss: 1011.18170166 -- mean_d_loss: 3.88240242, mean_g_loss: 1031.97009277\n",
            "Epoch:  97 Step:  1566  time: 1.321032 s d_loss: 6.38992643, g_loss: 1033.74621582 -- mean_d_loss: 3.89741778, mean_g_loss: 1031.98071289\n",
            "Epoch:  97 Step:  1567  time: 1.338768 s d_loss: 3.03504634, g_loss: 925.20178223 -- mean_d_loss: 3.89228463, mean_g_loss: 1031.34509277\n",
            "Epoch:  97 Step:  1568  time: 1.315557 s d_loss: 1.80215359, g_loss: 1008.78564453 -- mean_d_loss: 3.87991667, mean_g_loss: 1031.21166992\n",
            "Epoch:  97 Step:  1569  time: 1.314057 s d_loss: 5.44423199, g_loss: 1196.71240234 -- mean_d_loss: 3.88911843, mean_g_loss: 1032.18518066\n",
            "Epoch:  97 Step:  1570  time: 1.307160 s d_loss: 8.69571209, g_loss: 1035.73706055 -- mean_d_loss: 3.91722751, mean_g_loss: 1032.20593262\n",
            "Epoch:  97 Step:  1571  time: 1.292620 s d_loss: 1.40584421, g_loss: 1007.54663086 -- mean_d_loss: 3.90262628, mean_g_loss: 1032.06262207\n",
            "Epoch:  97 Step:  1572  time: 1.337069 s d_loss: 3.02600169, g_loss: 1195.26928711 -- mean_d_loss: 3.89755893, mean_g_loss: 1033.00598145\n",
            "Epoch:  97 Step:  1573  time: 1.319129 s d_loss: 0.94889766, g_loss: 812.44085693 -- mean_d_loss: 3.88061285, mean_g_loss: 1031.73828125\n",
            "Epoch:  97 Step:  1574  time: 1.304571 s d_loss: 2.14975262, g_loss: 1234.01928711 -- mean_d_loss: 3.87072229, mean_g_loss: 1032.89416504\n",
            "Epoch:  97 Step:  1575  time: 1.305337 s d_loss: 2.86270285, g_loss: 1129.55273438 -- mean_d_loss: 3.86499500, mean_g_loss: 1033.44335938\n",
            "Epoch:  97 Step:  1576  time: 1.282689 s d_loss: 0.89576185, g_loss: 877.55871582 -- mean_d_loss: 3.84821963, mean_g_loss: 1032.56262207\n",
            "Epoch:  97 Step:  1577  time: 1.287011 s d_loss: 1.32417059, g_loss: 948.86773682 -- mean_d_loss: 3.83403969, mean_g_loss: 1032.09252930\n",
            "Epoch:  97 Step:  1578  time: 1.286826 s d_loss: 1.07981157, g_loss: 1161.39990234 -- mean_d_loss: 3.81865287, mean_g_loss: 1032.81494141\n",
            "Epoch:  97 Step:  1579  time: 1.327756 s d_loss: 0.98938596, g_loss: 1061.31958008 -- mean_d_loss: 3.80293489, mean_g_loss: 1032.97326660\n",
            "Epoch:  97 Step:  1580  time: 1.317815 s d_loss: 5.84688616, g_loss: 1101.21191406 -- mean_d_loss: 3.81422710, mean_g_loss: 1033.35034180\n",
            "Epoch:  97 Step:  1581  time: 1.323886 s d_loss: 0.93001735, g_loss: 1036.72119141 -- mean_d_loss: 3.79837966, mean_g_loss: 1033.36877441\n",
            "Epoch:  97 Step:  1582  time: 1.321724 s d_loss: 1.50659013, g_loss: 1006.23358154 -- mean_d_loss: 3.78585625, mean_g_loss: 1033.22058105\n",
            "Epoch:  97 Step:  1583  time: 1.291357 s d_loss: 0.82900542, g_loss: 968.19824219 -- mean_d_loss: 3.76978636, mean_g_loss: 1032.86718750\n",
            "Epoch:  97 Step:  1584  time: 1.360619 s d_loss: 0.74010277, g_loss: 1052.78173828 -- mean_d_loss: 3.75340962, mean_g_loss: 1032.97485352\n",
            "Epoch:  97 Step:  1585  time: 1.302224 s d_loss: 0.75869924, g_loss: 1072.35791016 -- mean_d_loss: 3.73730922, mean_g_loss: 1033.18652344\n",
            "Epoch:  97 Step:  1586  time: 1.340158 s d_loss: 1.07446063, g_loss: 960.81457520 -- mean_d_loss: 3.72306943, mean_g_loss: 1032.79956055\n",
            "Epoch:  97 Step:  1587  time: 1.306698 s d_loss: 12.21949196, g_loss: 950.78137207 -- mean_d_loss: 3.76826310, mean_g_loss: 1032.36328125\n",
            "Epoch:  97 Step:  1588  time: 1.293392 s d_loss: 1.58092344, g_loss: 939.78112793 -- mean_d_loss: 3.75669003, mean_g_loss: 1031.87341309\n",
            "Epoch:  97 Step:  1589  time: 1.326670 s d_loss: 0.90762579, g_loss: 1109.09265137 -- mean_d_loss: 3.74169493, mean_g_loss: 1032.27990723\n",
            "Epoch:  97 Step:  1590  time: 1.309509 s d_loss: 1.65261197, g_loss: 1020.91992188 -- mean_d_loss: 3.73075724, mean_g_loss: 1032.22033691\n",
            "Epoch:  97 Step:  1591  time: 1.320081 s d_loss: 1.00090706, g_loss: 1129.96276855 -- mean_d_loss: 3.71653938, mean_g_loss: 1032.72949219\n",
            "Epoch:  97 Step:  1592  time: 1.323311 s d_loss: 8.01965523, g_loss: 984.99548340 -- mean_d_loss: 3.73883533, mean_g_loss: 1032.48217773\n",
            "Epoch:  97 Step:  1593  time: 1.288214 s d_loss: 1.71898198, g_loss: 999.41870117 -- mean_d_loss: 3.72842383, mean_g_loss: 1032.31176758\n",
            "Epoch:  97 Step:  1594  time: 1.318991 s d_loss: 2.64980578, g_loss: 992.81903076 -- mean_d_loss: 3.72289228, mean_g_loss: 1032.10925293\n",
            "Epoch:  97 Step:  1595  time: 1.322864 s d_loss: 0.72424436, g_loss: 1093.46643066 -- mean_d_loss: 3.70759296, mean_g_loss: 1032.42224121\n",
            "Epoch:  97 Step:  1596  time: 1.324447 s d_loss: 2.42099571, g_loss: 1042.21374512 -- mean_d_loss: 3.70106220, mean_g_loss: 1032.47204590\n",
            "Epoch:  97 Step:  1597  time: 1.289412 s d_loss: 14.42236233, g_loss: 1051.21630859 -- mean_d_loss: 3.75521016, mean_g_loss: 1032.56665039\n",
            "Epoch:  97 Step:  1598  time: 1.301707 s d_loss: 51.38972855, g_loss: 917.54370117 -- mean_d_loss: 3.99457955, mean_g_loss: 1031.98864746\n",
            "Epoch:  97 Step:  1599  time: 1.311672 s d_loss: 1.13396680, g_loss: 947.70251465 -- mean_d_loss: 3.98027658, mean_g_loss: 1031.56726074\n",
            "Epoch:  97 Step:  1600  time: 1.287990 s d_loss: 14.10988331, g_loss: 879.65783691 -- mean_d_loss: 14.10988331, mean_g_loss: 879.65783691\n",
            "Epoch:  97 Step:  1601  time: 1.339659 s d_loss: 1.45596504, g_loss: 894.84729004 -- mean_d_loss: 7.78292418, mean_g_loss: 887.25256348\n",
            "Epoch:  97 Step:  1602  time: 1.329233 s d_loss: 2.02698493, g_loss: 997.26977539 -- mean_d_loss: 5.86427736, mean_g_loss: 923.92498779\n",
            "Epoch:  97 Step:  1603  time: 1.316715 s d_loss: 3.06761503, g_loss: 997.33856201 -- mean_d_loss: 5.16511202, mean_g_loss: 942.27838135\n",
            "Epoch:  97 Step:  1604  time: 1.304318 s d_loss: 0.93143094, g_loss: 963.76275635 -- mean_d_loss: 4.31837559, mean_g_loss: 946.57531738\n",
            "Epoch:  97 Step:  1605  time: 1.288374 s d_loss: 0.85100627, g_loss: 1057.09375000 -- mean_d_loss: 3.74048066, mean_g_loss: 964.99505615\n",
            "Epoch:  97 Step:  1606  time: 1.321736 s d_loss: 7.47066164, g_loss: 967.34924316 -- mean_d_loss: 4.27336359, mean_g_loss: 965.33135986\n",
            "Epoch:  97 Step:  1607  time: 1.316170 s d_loss: 4.31178856, g_loss: 987.08447266 -- mean_d_loss: 4.27816677, mean_g_loss: 968.05047607\n",
            "Epoch:  97 Step:  1608  time: 1.328300 s d_loss: 2.26938272, g_loss: 1090.41088867 -- mean_d_loss: 4.05496836, mean_g_loss: 981.64605713\n",
            "Epoch:  97 Step:  1609  time: 1.279050 s d_loss: 28.69532394, g_loss: 1063.60839844 -- mean_d_loss: 6.51900387, mean_g_loss: 989.84228516\n",
            "Epoch:  97 Step:  1610  time: 1.327181 s d_loss: 22.97716141, g_loss: 1034.52709961 -- mean_d_loss: 8.01520061, mean_g_loss: 993.90454102\n",
            "Epoch:  97 Step:  1611  time: 1.311102 s d_loss: 2.33437467, g_loss: 1146.45385742 -- mean_d_loss: 7.54179811, mean_g_loss: 1006.61700439\n",
            "Epoch:  97 Step:  1612  time: 1.309049 s d_loss: 15.70994759, g_loss: 1045.23071289 -- mean_d_loss: 8.17011738, mean_g_loss: 1009.58728027\n",
            "Epoch:  97 Step:  1613  time: 1.318348 s d_loss: 6.16467762, g_loss: 1142.54516602 -- mean_d_loss: 8.02687168, mean_g_loss: 1019.08428955\n",
            "Epoch:  97 Step:  1614  time: 1.319926 s d_loss: 7.18190622, g_loss: 1043.43530273 -- mean_d_loss: 7.97054100, mean_g_loss: 1020.70770264\n",
            "Epoch:  97 Step:  1615  time: 1.288564 s d_loss: 29.67134666, g_loss: 1106.76293945 -- mean_d_loss: 9.32684135, mean_g_loss: 1026.08618164\n",
            "Epoch:  97 Step:  1616  time: 1.322494 s d_loss: 11.72653198, g_loss: 1289.71887207 -- mean_d_loss: 9.46799946, mean_g_loss: 1041.59399414\n",
            "Epoch:  97 Step:  1617  time: 1.318364 s d_loss: 16.98413467, g_loss: 918.81134033 -- mean_d_loss: 9.88556290, mean_g_loss: 1034.77270508\n",
            "Epoch:  97 Step:  1618  time: 1.342117 s d_loss: 41.34708405, g_loss: 961.54309082 -- mean_d_loss: 11.54143143, mean_g_loss: 1030.91845703\n",
            "Epoch:  97 Step:  1619  time: 1.323642 s d_loss: 77.06477356, g_loss: 912.41015625 -- mean_d_loss: 14.81759930, mean_g_loss: 1024.99304199\n",
            "Epoch:  97 Step:  1620  time: 1.289771 s d_loss: 29.45820808, g_loss: 1002.82788086 -- mean_d_loss: 15.51477242, mean_g_loss: 1023.93762207\n",
            "Epoch:  97 Step:  1621  time: 1.318971 s d_loss: 20.55927467, g_loss: 961.97454834 -- mean_d_loss: 15.74406719, mean_g_loss: 1021.12109375\n",
            "Epoch:  97 Step:  1622  time: 1.319264 s d_loss: 8.39037609, g_loss: 1256.52307129 -- mean_d_loss: 15.42434120, mean_g_loss: 1031.35595703\n",
            "Epoch:  97 Step:  1623  time: 1.329377 s d_loss: 4.25818920, g_loss: 1191.49511719 -- mean_d_loss: 14.95908451, mean_g_loss: 1038.02844238\n",
            "Epoch:  97 Step:  1624  time: 1.325826 s d_loss: 3.86516118, g_loss: 1029.64208984 -- mean_d_loss: 14.51532841, mean_g_loss: 1037.69299316\n",
            "Epoch:  97 Step:  1625  time: 1.306891 s d_loss: 2.52666664, g_loss: 984.54467773 -- mean_d_loss: 14.05422592, mean_g_loss: 1035.64892578\n",
            "Epoch:  97 Step:  1626  time: 1.307946 s d_loss: 4.59532881, g_loss: 1154.80957031 -- mean_d_loss: 13.70389652, mean_g_loss: 1040.06225586\n",
            "Epoch:  97 Step:  1627  time: 1.336842 s d_loss: 35.18838120, g_loss: 900.55609131 -- mean_d_loss: 14.47119999, mean_g_loss: 1035.07983398\n",
            "Epoch:  97 Step:  1628  time: 1.288605 s d_loss: 11.40997791, g_loss: 882.09631348 -- mean_d_loss: 14.36564064, mean_g_loss: 1029.80456543\n",
            "Epoch:  97 Step:  1629  time: 1.300551 s d_loss: 3.35328197, g_loss: 1003.67413330 -- mean_d_loss: 13.99856186, mean_g_loss: 1028.93347168\n",
            "Epoch:  97 Step:  1630  time: 1.319139 s d_loss: 146.97686768, g_loss: 976.05908203 -- mean_d_loss: 18.28818512, mean_g_loss: 1027.22790527\n",
            "Epoch:  97 Step:  1631  time: 1.341187 s d_loss: 9.14845181, g_loss: 1040.16894531 -- mean_d_loss: 18.00256729, mean_g_loss: 1027.63232422\n",
            "Epoch:  97 Step:  1632  time: 1.297026 s d_loss: 4.73499346, g_loss: 1222.41040039 -- mean_d_loss: 17.60051918, mean_g_loss: 1033.53466797\n",
            "Epoch:  97 Step:  1633  time: 1.327376 s d_loss: 59.33913422, g_loss: 1322.98730469 -- mean_d_loss: 18.82812500, mean_g_loss: 1042.04797363\n",
            "Epoch:  97 Step:  1634  time: 1.282027 s d_loss: 28.89071655, g_loss: 1007.47210693 -- mean_d_loss: 19.11562920, mean_g_loss: 1041.06018066\n",
            "Epoch:  97 Step:  1635  time: 1.308871 s d_loss: 43.65442657, g_loss: 1158.04101562 -- mean_d_loss: 19.79726219, mean_g_loss: 1044.30969238\n",
            "Epoch:  97 Step:  1636  time: 1.319921 s d_loss: 11.67823887, g_loss: 1063.03417969 -- mean_d_loss: 19.57782745, mean_g_loss: 1044.81579590\n",
            "Epoch:  97 Step:  1637  time: 1.325967 s d_loss: 3.73256063, g_loss: 908.89282227 -- mean_d_loss: 19.16084671, mean_g_loss: 1041.23889160\n",
            "Epoch:  97 Step:  1638  time: 1.327958 s d_loss: 3.06168270, g_loss: 1046.51037598 -- mean_d_loss: 18.74804878, mean_g_loss: 1041.37414551\n",
            "Epoch:  97 Step:  1639  time: 1.317947 s d_loss: 2.33176088, g_loss: 947.24688721 -- mean_d_loss: 18.33764267, mean_g_loss: 1039.02087402\n",
            "Epoch:  97 Step:  1640  time: 1.345577 s d_loss: 2.24259090, g_loss: 1007.51867676 -- mean_d_loss: 17.94507980, mean_g_loss: 1038.25256348\n",
            "Epoch:  97 Step:  1641  time: 1.321149 s d_loss: 1.46732295, g_loss: 1266.82470703 -- mean_d_loss: 17.55275345, mean_g_loss: 1043.69470215\n",
            "Epoch:  97 Step:  1642  time: 1.339260 s d_loss: 4.06855154, g_loss: 904.30383301 -- mean_d_loss: 17.23916626, mean_g_loss: 1040.45312500\n",
            "Epoch:  97 Step:  1643  time: 1.293489 s d_loss: 47.18762970, g_loss: 989.82458496 -- mean_d_loss: 17.91981316, mean_g_loss: 1039.30249023\n",
            "Epoch:  97 Step:  1644  time: 1.338413 s d_loss: 3.41920352, g_loss: 1009.94152832 -- mean_d_loss: 17.59757805, mean_g_loss: 1038.65002441\n",
            "Epoch:  97 Step:  1645  time: 1.300876 s d_loss: 10.18704033, g_loss: 1070.90527344 -- mean_d_loss: 17.43647766, mean_g_loss: 1039.35119629\n",
            "Epoch:  97 Step:  1646  time: 1.318272 s d_loss: 1.80232310, g_loss: 938.19238281 -- mean_d_loss: 17.10383606, mean_g_loss: 1037.19885254\n",
            "Epoch:  97 Step:  1647  time: 1.318010 s d_loss: 2.07708836, g_loss: 971.21655273 -- mean_d_loss: 16.79077911, mean_g_loss: 1035.82421875\n",
            "Epoch:  97 Step:  1648  time: 1.344213 s d_loss: 1.58885384, g_loss: 925.23767090 -- mean_d_loss: 16.48053551, mean_g_loss: 1033.56738281\n",
            "Epoch:  97 Step:  1649  time: 1.337431 s d_loss: 1.68514347, g_loss: 1103.60925293 -- mean_d_loss: 16.18462753, mean_g_loss: 1034.96826172\n",
            "Epoch:  97 Step:  1650  time: 1.324530 s d_loss: 7.83811426, g_loss: 1088.30615234 -- mean_d_loss: 16.02097130, mean_g_loss: 1036.01403809\n",
            "Epoch:  97 Step:  1651  time: 1.323800 s d_loss: 3.68152952, g_loss: 1165.12548828 -- mean_d_loss: 15.78367424, mean_g_loss: 1038.49694824\n",
            "Epoch:  97 Step:  1652  time: 1.330441 s d_loss: 5.33278847, g_loss: 1022.40808105 -- mean_d_loss: 15.58648682, mean_g_loss: 1038.19335938\n",
            "Epoch:  97 Step:  1653  time: 1.324009 s d_loss: 6.39295387, g_loss: 807.64733887 -- mean_d_loss: 15.41623592, mean_g_loss: 1033.92395020\n",
            "Epoch:  97 Step:  1654  time: 1.315455 s d_loss: 1.40614486, g_loss: 929.41912842 -- mean_d_loss: 15.16150665, mean_g_loss: 1032.02380371\n",
            "Epoch:  97 Step:  1655  time: 1.298057 s d_loss: 1.14252687, g_loss: 828.20092773 -- mean_d_loss: 14.91116810, mean_g_loss: 1028.38415527\n",
            "Epoch:  97 Step:  1656  time: 1.309416 s d_loss: 1.00551796, g_loss: 1035.35351562 -- mean_d_loss: 14.66720867, mean_g_loss: 1028.50646973\n",
            "Epoch:  97 Step:  1657  time: 1.316508 s d_loss: 1.38570499, g_loss: 1078.81127930 -- mean_d_loss: 14.43821621, mean_g_loss: 1029.37377930\n",
            "Epoch:  97 Step:  1658  time: 1.316993 s d_loss: 1.13939488, g_loss: 1086.93078613 -- mean_d_loss: 14.21281338, mean_g_loss: 1030.34936523\n",
            "Epoch:  97 Step:  1659  time: 1.298309 s d_loss: 2.55045843, g_loss: 1059.38110352 -- mean_d_loss: 14.01844120, mean_g_loss: 1030.83325195\n",
            "Epoch:  97 Step:  1660  time: 1.324102 s d_loss: 0.67871094, g_loss: 1099.19335938 -- mean_d_loss: 13.79975700, mean_g_loss: 1031.95385742\n",
            "Epoch:  97 Step:  1661  time: 1.321090 s d_loss: 1.08951104, g_loss: 1066.19775391 -- mean_d_loss: 13.59475327, mean_g_loss: 1032.50622559\n",
            "Epoch:  97 Step:  1662  time: 1.320644 s d_loss: 1.66808116, g_loss: 1277.04675293 -- mean_d_loss: 13.40544128, mean_g_loss: 1036.38781738\n",
            "Epoch:  97 Step:  1663  time: 1.283888 s d_loss: 7.29404449, g_loss: 966.55090332 -- mean_d_loss: 13.30995083, mean_g_loss: 1035.29663086\n",
            "val: 0./dataset/val/2014-09-08 05_31_48.jpg\n",
            "val: 1./dataset/val/2014-12-07 05_00_46.jpg\n",
            "val: 2./dataset/val/2015-04-23 10_12_24.jpg\n",
            "val: 3./dataset/val/1.jpg\n",
            "val: 4./dataset/val/3.jpg\n",
            "val: 5./dataset/val/4.jpg\n",
            "val: 6./dataset/val/6.jpg\n",
            "val: 7./dataset/val/5.jpg\n",
            "val: 8./dataset/val/7.jpg\n",
            "val: 9./dataset/val/8.jpg\n",
            "val: 10./dataset/val/9.jpg\n",
            "val: 11./dataset/val/10.jpg\n",
            "val: 12./dataset/val/2.jpg\n",
            "val: 13./dataset/val/12.jpg\n",
            "val: 14./dataset/val/13.jpg\n",
            "val: 15./dataset/val/14.jpg\n",
            "val: 16./dataset/val/15.jpg\n",
            "val: 17./dataset/val/16.jpg\n",
            "val: 18./dataset/val/17.jpg\n",
            "val: 19./dataset/val/18.jpg\n",
            "val: 20./dataset/val/19.jpg\n",
            "val: 21./dataset/val/20.jpg\n",
            "val: 22./dataset/val/21.jpg\n",
            "val: 23./dataset/val/22.jpg\n",
            "val: 24./dataset/val/23.jpg\n",
            "val: 25./dataset/val/24.jpg\n",
            "val: 26./dataset/val/25.jpg\n",
            "val: 27./dataset/val/26.jpg\n",
            "val: 28./dataset/val/27.jpg\n",
            "val: 29./dataset/val/28.jpg\n",
            "val: 30./dataset/val/29.jpg\n",
            "val: 31./dataset/val/30.jpg\n",
            "val: 32./dataset/val/31.jpg\n",
            "val: 33./dataset/val/32.jpg\n",
            "val: 34./dataset/val/33.jpg\n",
            "val: 35./dataset/val/34.jpg\n",
            "val: 36./dataset/val/35.jpg\n",
            "val: 37./dataset/val/36.jpg\n",
            "val: 38./dataset/val/37.jpg\n",
            "val: 39./dataset/val/38.jpg\n",
            "val: 40./dataset/val/39.jpg\n",
            "val: 41./dataset/val/40.jpg\n",
            "val: 42./dataset/val/41.jpg\n",
            "val: 43./dataset/val/42.jpg\n",
            "val: 44./dataset/val/43.jpg\n",
            "val: 45./dataset/val/44.jpg\n",
            "val: 46./dataset/val/45.jpg\n",
            "val: 47./dataset/val/46.jpg\n",
            "val: 48./dataset/val/49.jpg\n",
            "val: 49./dataset/val/48.jpg\n",
            "val: 50./dataset/val/47.jpg\n",
            "val: 51./dataset/val/50.jpg\n",
            "val: 52./dataset/val/51.jpg\n",
            "val: 53./dataset/val/52.jpg\n",
            "val: 54./dataset/val/53.jpg\n",
            "val: 55./dataset/val/55.jpg\n",
            "val: 56./dataset/val/57.jpg\n",
            "val: 57./dataset/val/56.jpg\n",
            "val: 58./dataset/val/54.jpg\n",
            "val: 59./dataset/val/58.jpg\n",
            "val: 60./dataset/val/59.jpg\n",
            "val: 61./dataset/val/60.jpg\n",
            "val: 62./dataset/val/11.jpg\n",
            "val: 63./dataset/val/61.jpg\n",
            "val: 64./dataset/val/hww.jpg\n",
            "val: 65./dataset/val/lzl.jpg\n",
            "val: 66./dataset/val/wzy.jpg\n",
            "Epoch:  98 Step:     0  time: 1.288860 s d_loss: 2.06513786, g_loss: 1053.67846680 -- mean_d_loss: 13.13695335, mean_g_loss: 1035.57946777\n",
            "Epoch:  98 Step:     1  time: 1.308192 s d_loss: 1.95969772, g_loss: 873.92370605 -- mean_d_loss: 12.96760178, mean_g_loss: 1033.13012695\n",
            "Epoch:  98 Step:     2  time: 1.339561 s d_loss: 1.45610893, g_loss: 1022.45593262 -- mean_d_loss: 12.79578781, mean_g_loss: 1032.97070312\n",
            "Epoch:  98 Step:     3  time: 1.351445 s d_loss: 38.71933365, g_loss: 1084.51354980 -- mean_d_loss: 13.17701721, mean_g_loss: 1033.72875977\n",
            "Epoch:  98 Step:     4  time: 1.354542 s d_loss: 1.24988186, g_loss: 947.95886230 -- mean_d_loss: 13.00415993, mean_g_loss: 1032.48571777\n",
            "Epoch:  98 Step:     5  time: 1.344415 s d_loss: 2.53535581, g_loss: 1108.38549805 -- mean_d_loss: 12.85460567, mean_g_loss: 1033.56994629\n",
            "Epoch:  98 Step:     6  time: 1.347931 s d_loss: 1.62833929, g_loss: 1047.73388672 -- mean_d_loss: 12.69648933, mean_g_loss: 1033.76953125\n",
            "Epoch:  98 Step:     7  time: 1.343064 s d_loss: 21.32050323, g_loss: 907.35522461 -- mean_d_loss: 12.81626701, mean_g_loss: 1032.01367188\n",
            "Epoch:  98 Step:     8  time: 1.335154 s d_loss: 17.38629913, g_loss: 1258.93640137 -- mean_d_loss: 12.87887001, mean_g_loss: 1035.12219238\n",
            "Epoch:  98 Step:     9  time: 1.326873 s d_loss: 1.38899708, g_loss: 886.96020508 -- mean_d_loss: 12.72360134, mean_g_loss: 1033.11999512\n",
            "Epoch:  98 Step:    10  time: 1.354414 s d_loss: 4.88592386, g_loss: 1034.73925781 -- mean_d_loss: 12.61909866, mean_g_loss: 1033.14172363\n",
            "Epoch:  98 Step:    11  time: 1.362090 s d_loss: 8.18490410, g_loss: 923.76220703 -- mean_d_loss: 12.56075382, mean_g_loss: 1031.70251465\n",
            "Epoch:  98 Step:    12  time: 1.328087 s d_loss: 17.00465775, g_loss: 918.53851318 -- mean_d_loss: 12.61846733, mean_g_loss: 1030.23291016\n",
            "Epoch:  98 Step:    13  time: 1.340894 s d_loss: 2.05133271, g_loss: 857.10278320 -- mean_d_loss: 12.48299122, mean_g_loss: 1028.01318359\n",
            "Epoch:  98 Step:    14  time: 1.339819 s d_loss: 2.39117599, g_loss: 1008.84997559 -- mean_d_loss: 12.35524654, mean_g_loss: 1027.77062988\n",
            "Epoch:  98 Step:    15  time: 1.341924 s d_loss: 21.75299835, g_loss: 1016.12939453 -- mean_d_loss: 12.47271824, mean_g_loss: 1027.62524414\n",
            "Epoch:  98 Step:    16  time: 1.346878 s d_loss: 1.16704524, g_loss: 995.71411133 -- mean_d_loss: 12.33314228, mean_g_loss: 1027.23120117\n",
            "Epoch:  98 Step:    17  time: 1.340224 s d_loss: 0.78695071, g_loss: 1139.78076172 -- mean_d_loss: 12.19233418, mean_g_loss: 1028.60375977\n",
            "Epoch:  98 Step:    18  time: 1.342624 s d_loss: 3.68035340, g_loss: 1209.33276367 -- mean_d_loss: 12.08978081, mean_g_loss: 1030.78125000\n",
            "Epoch:  98 Step:    19  time: 1.342229 s d_loss: 15.58512306, g_loss: 1104.52905273 -- mean_d_loss: 12.13139153, mean_g_loss: 1031.65917969\n",
            "Epoch:  98 Step:    20  time: 1.332898 s d_loss: 39.24896622, g_loss: 957.92529297 -- mean_d_loss: 12.45042229, mean_g_loss: 1030.79174805\n",
            "Epoch:  98 Step:    21  time: 1.312126 s d_loss: 2.18655348, g_loss: 1061.40222168 -- mean_d_loss: 12.33107471, mean_g_loss: 1031.14758301\n",
            "Epoch:  98 Step:    22  time: 1.294003 s d_loss: 1.36561358, g_loss: 930.54956055 -- mean_d_loss: 12.20503426, mean_g_loss: 1029.99133301\n",
            "Epoch:  98 Step:    23  time: 1.317257 s d_loss: 38.53248215, g_loss: 962.40423584 -- mean_d_loss: 12.50421047, mean_g_loss: 1029.22326660\n",
            "Epoch:  98 Step:    24  time: 1.329902 s d_loss: 43.40783310, g_loss: 900.77429199 -- mean_d_loss: 12.85144138, mean_g_loss: 1027.78002930\n",
            "Epoch:  98 Step:    25  time: 1.311903 s d_loss: 3.37115288, g_loss: 1040.32312012 -- mean_d_loss: 12.74610424, mean_g_loss: 1027.91931152\n",
            "Epoch:  98 Step:    26  time: 1.332123 s d_loss: 6.60623932, g_loss: 935.92102051 -- mean_d_loss: 12.67863274, mean_g_loss: 1026.90844727\n",
            "Epoch:  98 Step:    27  time: 1.310735 s d_loss: 7.58497286, g_loss: 955.50610352 -- mean_d_loss: 12.62326717, mean_g_loss: 1026.13232422\n",
            "Epoch:  98 Step:    28  time: 1.277442 s d_loss: 2.61673856, g_loss: 966.39013672 -- mean_d_loss: 12.51566982, mean_g_loss: 1025.48986816\n",
            "Epoch:  98 Step:    29  time: 1.311686 s d_loss: 59.62449646, g_loss: 1142.47216797 -- mean_d_loss: 13.01682758, mean_g_loss: 1026.73437500\n",
            "Epoch:  98 Step:    30  time: 1.288065 s d_loss: 44.99712753, g_loss: 1112.96472168 -- mean_d_loss: 13.35346127, mean_g_loss: 1027.64196777\n",
            "Epoch:  98 Step:    31  time: 1.306840 s d_loss: 58.14206314, g_loss: 1045.14819336 -- mean_d_loss: 13.82001019, mean_g_loss: 1027.82434082\n",
            "Epoch:  98 Step:    32  time: 1.291575 s d_loss: 2.78204942, g_loss: 1007.33605957 -- mean_d_loss: 13.70621681, mean_g_loss: 1027.61315918\n",
            "Epoch:  98 Step:    33  time: 1.315987 s d_loss: 3.57505846, g_loss: 918.23181152 -- mean_d_loss: 13.60283756, mean_g_loss: 1026.49707031\n",
            "Epoch:  98 Step:    34  time: 1.281181 s d_loss: 2.69900966, g_loss: 876.18176270 -- mean_d_loss: 13.49269772, mean_g_loss: 1024.97863770\n",
            "Epoch:  98 Step:    35  time: 1.301363 s d_loss: 8.13104820, g_loss: 950.77172852 -- mean_d_loss: 13.43908215, mean_g_loss: 1024.23669434\n",
            "Epoch:  98 Step:    36  time: 1.306338 s d_loss: 10.92901421, g_loss: 999.59594727 -- mean_d_loss: 13.41422939, mean_g_loss: 1023.99267578\n",
            "Epoch:  98 Step:    37  time: 1.308928 s d_loss: 2.88580346, g_loss: 961.43304443 -- mean_d_loss: 13.31101036, mean_g_loss: 1023.37927246\n",
            "Epoch:  98 Step:    38  time: 1.287296 s d_loss: 1.80786562, g_loss: 896.45666504 -- mean_d_loss: 13.19932938, mean_g_loss: 1022.14697266\n",
            "Epoch:  98 Step:    39  time: 1.308981 s d_loss: 1.06696641, g_loss: 1001.43255615 -- mean_d_loss: 13.08267212, mean_g_loss: 1021.94781494\n",
            "Epoch:  98 Step:    40  time: 1.278480 s d_loss: 4.63194799, g_loss: 995.79455566 -- mean_d_loss: 13.00218868, mean_g_loss: 1021.69873047\n",
            "Epoch:  98 Step:    41  time: 1.291335 s d_loss: 1.58440387, g_loss: 997.14904785 -- mean_d_loss: 12.89447403, mean_g_loss: 1021.46710205\n",
            "Epoch:  98 Step:    42  time: 1.306507 s d_loss: 1.28237867, g_loss: 998.24035645 -- mean_d_loss: 12.78594875, mean_g_loss: 1021.25006104\n",
            "Epoch:  98 Step:    43  time: 1.303464 s d_loss: 17.32147408, g_loss: 1093.47729492 -- mean_d_loss: 12.82794571, mean_g_loss: 1021.91882324\n",
            "Epoch:  98 Step:    44  time: 1.309494 s d_loss: 16.13460922, g_loss: 1019.60998535 -- mean_d_loss: 12.85828209, mean_g_loss: 1021.89764404\n",
            "Epoch:  98 Step:    45  time: 1.303205 s d_loss: 1.31399310, g_loss: 1019.27893066 -- mean_d_loss: 12.75333405, mean_g_loss: 1021.87384033\n",
            "Epoch:  98 Step:    46  time: 1.329759 s d_loss: 1.60705853, g_loss: 925.01452637 -- mean_d_loss: 12.65291691, mean_g_loss: 1021.00128174\n",
            "Epoch:  98 Step:    47  time: 1.298072 s d_loss: 17.48164558, g_loss: 1071.55004883 -- mean_d_loss: 12.69603062, mean_g_loss: 1021.45257568\n",
            "Epoch:  98 Step:    48  time: 1.330490 s d_loss: 3.54048061, g_loss: 1096.72583008 -- mean_d_loss: 12.61500835, mean_g_loss: 1022.11871338\n",
            "Epoch:  98 Step:    49  time: 1.309820 s d_loss: 0.97097552, g_loss: 896.89532471 -- mean_d_loss: 12.51286793, mean_g_loss: 1021.02026367\n",
            "Epoch:  98 Step:    50  time: 1.310503 s d_loss: 63.89157486, g_loss: 1044.01391602 -- mean_d_loss: 12.95963955, mean_g_loss: 1021.22021484\n",
            "Epoch:  98 Step:    51  time: 1.301421 s d_loss: 4.23693752, g_loss: 900.61059570 -- mean_d_loss: 12.88444328, mean_g_loss: 1020.18048096\n",
            "Epoch:  98 Step:    52  time: 1.337497 s d_loss: 2.12146258, g_loss: 931.31420898 -- mean_d_loss: 12.79245186, mean_g_loss: 1019.42095947\n",
            "Epoch:  98 Step:    53  time: 1.309171 s d_loss: 2.40650916, g_loss: 852.89440918 -- mean_d_loss: 12.70443535, mean_g_loss: 1018.00964355\n",
            "Epoch:  98 Step:    54  time: 1.324575 s d_loss: 1.59467173, g_loss: 1072.26196289 -- mean_d_loss: 12.61107635, mean_g_loss: 1018.46557617\n",
            "Epoch:  98 Step:    55  time: 1.310140 s d_loss: 1.56943190, g_loss: 891.26342773 -- mean_d_loss: 12.51906300, mean_g_loss: 1017.40557861\n",
            "Epoch:  98 Step:    56  time: 1.321552 s d_loss: 0.77384037, g_loss: 1046.31359863 -- mean_d_loss: 12.42199516, mean_g_loss: 1017.64447021\n",
            "Epoch:  98 Step:    57  time: 1.329753 s d_loss: 2.87190104, g_loss: 1101.79467773 -- mean_d_loss: 12.34371567, mean_g_loss: 1018.33428955\n",
            "Epoch:  98 Step:    58  time: 1.341845 s d_loss: 3.22607064, g_loss: 1020.04260254 -- mean_d_loss: 12.26958847, mean_g_loss: 1018.34814453\n",
            "Epoch:  98 Step:    59  time: 1.300590 s d_loss: 1.28700376, g_loss: 1016.52954102 -- mean_d_loss: 12.18101978, mean_g_loss: 1018.33349609\n",
            "Epoch:  98 Step:    60  time: 1.294032 s d_loss: 7.11114740, g_loss: 1047.37841797 -- mean_d_loss: 12.14046097, mean_g_loss: 1018.56579590\n",
            "Epoch:  98 Step:    61  time: 1.313174 s d_loss: 1.23888636, g_loss: 939.48303223 -- mean_d_loss: 12.05394077, mean_g_loss: 1017.93817139\n",
            "Epoch:  98 Step:    62  time: 1.293404 s d_loss: 1.23322678, g_loss: 951.27667236 -- mean_d_loss: 11.96873856, mean_g_loss: 1017.41326904\n",
            "Epoch:  98 Step:    63  time: 1.299470 s d_loss: 1.41252494, g_loss: 1131.32141113 -- mean_d_loss: 11.88626766, mean_g_loss: 1018.30316162\n",
            "Epoch:  98 Step:    64  time: 1.322256 s d_loss: 0.80119884, g_loss: 979.09820557 -- mean_d_loss: 11.80033684, mean_g_loss: 1017.99926758\n",
            "Epoch:  98 Step:    65  time: 1.316717 s d_loss: 0.69831586, g_loss: 936.46453857 -- mean_d_loss: 11.71493626, mean_g_loss: 1017.37213135\n",
            "Epoch:  98 Step:    66  time: 1.284636 s d_loss: 1.10162342, g_loss: 1046.46972656 -- mean_d_loss: 11.63391876, mean_g_loss: 1017.59423828\n",
            "Epoch:  98 Step:    67  time: 1.314695 s d_loss: 1.08385181, g_loss: 974.47912598 -- mean_d_loss: 11.55399418, mean_g_loss: 1017.26763916\n",
            "Epoch:  98 Step:    68  time: 1.283786 s d_loss: 1.75307381, g_loss: 1201.83337402 -- mean_d_loss: 11.48030281, mean_g_loss: 1018.65533447\n",
            "Epoch:  98 Step:    69  time: 1.313988 s d_loss: 14.54601288, g_loss: 1097.91650391 -- mean_d_loss: 11.50318146, mean_g_loss: 1019.24682617\n",
            "Epoch:  98 Step:    70  time: 1.320121 s d_loss: 1.39667916, g_loss: 1109.24865723 -- mean_d_loss: 11.42831898, mean_g_loss: 1019.91351318\n",
            "Epoch:  98 Step:    71  time: 1.314047 s d_loss: 2.12238121, g_loss: 1119.44958496 -- mean_d_loss: 11.35989285, mean_g_loss: 1020.64544678\n",
            "Epoch:  98 Step:    72  time: 1.348475 s d_loss: 1.33003104, g_loss: 922.79492188 -- mean_d_loss: 11.28668213, mean_g_loss: 1019.93121338\n",
            "Epoch:  98 Step:    73  time: 1.332098 s d_loss: 2.12956572, g_loss: 1005.27917480 -- mean_d_loss: 11.22032642, mean_g_loss: 1019.82507324\n",
            "Epoch:  98 Step:    74  time: 1.317890 s d_loss: 1.37179565, g_loss: 892.98101807 -- mean_d_loss: 11.14947414, mean_g_loss: 1018.91253662\n",
            "Epoch:  98 Step:    75  time: 1.329809 s d_loss: 1.33953846, g_loss: 936.12792969 -- mean_d_loss: 11.07940197, mean_g_loss: 1018.32122803\n",
            "Epoch:  98 Step:    76  time: 1.315565 s d_loss: 3.69467187, g_loss: 1126.02050781 -- mean_d_loss: 11.02702904, mean_g_loss: 1019.08502197\n",
            "Epoch:  98 Step:    77  time: 1.297434 s d_loss: 2.44838548, g_loss: 907.62878418 -- mean_d_loss: 10.96661568, mean_g_loss: 1018.30004883\n",
            "Epoch:  98 Step:    78  time: 1.325835 s d_loss: 1.28508723, g_loss: 1003.42919922 -- mean_d_loss: 10.89891243, mean_g_loss: 1018.19604492\n",
            "Epoch:  98 Step:    79  time: 1.329247 s d_loss: 22.30086708, g_loss: 1060.54785156 -- mean_d_loss: 10.97809219, mean_g_loss: 1018.49011230\n",
            "Epoch:  98 Step:    80  time: 1.291452 s d_loss: 0.84552377, g_loss: 962.66772461 -- mean_d_loss: 10.90821362, mean_g_loss: 1018.10516357\n",
            "Epoch:  98 Step:    81  time: 1.314169 s d_loss: 0.92037427, g_loss: 1140.62182617 -- mean_d_loss: 10.83980370, mean_g_loss: 1018.94433594\n",
            "Epoch:  98 Step:    82  time: 1.323271 s d_loss: 1.11316276, g_loss: 1066.57153320 -- mean_d_loss: 10.77363586, mean_g_loss: 1019.26837158\n",
            "Epoch:  98 Step:    83  time: 1.324779 s d_loss: 1.19578671, g_loss: 1145.34777832 -- mean_d_loss: 10.70892048, mean_g_loss: 1020.12023926\n",
            "Epoch:  98 Step:    84  time: 1.304614 s d_loss: 1.13406479, g_loss: 1139.58300781 -- mean_d_loss: 10.64466000, mean_g_loss: 1020.92199707\n",
            "Epoch:  98 Step:    85  time: 1.293875 s d_loss: 1.48393834, g_loss: 1005.02758789 -- mean_d_loss: 10.58358765, mean_g_loss: 1020.81604004\n",
            "Epoch:  98 Step:    86  time: 1.324256 s d_loss: 1.23379362, g_loss: 1090.83764648 -- mean_d_loss: 10.52166843, mean_g_loss: 1021.27978516\n",
            "Epoch:  98 Step:    87  time: 1.288529 s d_loss: 1.46443486, g_loss: 1138.17834473 -- mean_d_loss: 10.46208191, mean_g_loss: 1022.04882812\n",
            "Epoch:  98 Step:    88  time: 1.330298 s d_loss: 1.07048118, g_loss: 891.26092529 -- mean_d_loss: 10.40069866, mean_g_loss: 1021.19403076\n",
            "Epoch:  98 Step:    89  time: 1.324028 s d_loss: 4.57354927, g_loss: 999.95141602 -- mean_d_loss: 10.36286068, mean_g_loss: 1021.05609131\n",
            "Epoch:  98 Step:    90  time: 1.291242 s d_loss: 1.27803743, g_loss: 1177.36706543 -- mean_d_loss: 10.30424881, mean_g_loss: 1022.06451416\n",
            "Epoch:  98 Step:    91  time: 1.303512 s d_loss: 1.14593935, g_loss: 1040.87585449 -- mean_d_loss: 10.24554253, mean_g_loss: 1022.18511963\n",
            "Epoch:  98 Step:    92  time: 1.319859 s d_loss: 3.53303671, g_loss: 1115.03259277 -- mean_d_loss: 10.20278740, mean_g_loss: 1022.77648926\n",
            "Epoch:  98 Step:    93  time: 1.323242 s d_loss: 0.73231143, g_loss: 911.25946045 -- mean_d_loss: 10.14284801, mean_g_loss: 1022.07067871\n",
            "Epoch:  98 Step:    94  time: 1.308008 s d_loss: 1.75818098, g_loss: 901.38311768 -- mean_d_loss: 10.09011364, mean_g_loss: 1021.31170654\n",
            "Epoch:  98 Step:    95  time: 1.329183 s d_loss: 1.03385627, g_loss: 1043.64282227 -- mean_d_loss: 10.03351212, mean_g_loss: 1021.45129395\n",
            "Epoch:  98 Step:    96  time: 1.341490 s d_loss: 0.67214638, g_loss: 958.71710205 -- mean_d_loss: 9.97536659, mean_g_loss: 1021.06164551\n",
            "Epoch:  98 Step:    97  time: 1.320179 s d_loss: 1.29985535, g_loss: 900.75762939 -- mean_d_loss: 9.92181396, mean_g_loss: 1020.31896973\n",
            "Epoch:  98 Step:    98  time: 1.317909 s d_loss: 2.17639256, g_loss: 875.20489502 -- mean_d_loss: 9.87429619, mean_g_loss: 1019.42871094\n",
            "Epoch:  98 Step:    99  time: 1.302787 s d_loss: 1.21053207, g_loss: 882.52856445 -- mean_d_loss: 9.82146835, mean_g_loss: 1018.59393311\n",
            "Epoch:  98 Step:   100  time: 1.303664 s d_loss: 1.07750857, g_loss: 939.12493896 -- mean_d_loss: 9.76847458, mean_g_loss: 1018.11230469\n",
            "Epoch:  98 Step:   101  time: 1.284049 s d_loss: 1.17067611, g_loss: 1165.17590332 -- mean_d_loss: 9.71668053, mean_g_loss: 1018.99822998\n",
            "Epoch:  98 Step:   102  time: 1.339740 s d_loss: 0.90837979, g_loss: 1013.35388184 -- mean_d_loss: 9.66393566, mean_g_loss: 1018.96441650\n",
            "Epoch:  98 Step:   103  time: 1.325692 s d_loss: 8.95333290, g_loss: 1161.73632812 -- mean_d_loss: 9.65970612, mean_g_loss: 1019.81427002\n",
            "Epoch:  98 Step:   104  time: 1.312240 s d_loss: 2.46519589, g_loss: 907.51025391 -- mean_d_loss: 9.61713505, mean_g_loss: 1019.14978027\n",
            "Epoch:  98 Step:   105  time: 1.318477 s d_loss: 27.77483368, g_loss: 985.82397461 -- mean_d_loss: 9.72394562, mean_g_loss: 1018.95379639\n",
            "Epoch:  98 Step:   106  time: 1.312028 s d_loss: 2.14598632, g_loss: 1102.92602539 -- mean_d_loss: 9.67962933, mean_g_loss: 1019.44482422\n",
            "Epoch:  98 Step:   107  time: 1.298247 s d_loss: 1.34868109, g_loss: 983.05749512 -- mean_d_loss: 9.63119411, mean_g_loss: 1019.23327637\n",
            "Epoch:  98 Step:   108  time: 1.318808 s d_loss: 1.08135402, g_loss: 966.73913574 -- mean_d_loss: 9.58177185, mean_g_loss: 1018.92980957\n",
            "Epoch:  98 Step:   109  time: 1.329087 s d_loss: 1.93088174, g_loss: 1115.83715820 -- mean_d_loss: 9.53780174, mean_g_loss: 1019.48681641\n",
            "Epoch:  98 Step:   110  time: 1.319300 s d_loss: 5.88315487, g_loss: 984.29266357 -- mean_d_loss: 9.51691818, mean_g_loss: 1019.28570557\n",
            "Epoch:  98 Step:   111  time: 1.321007 s d_loss: 0.98806149, g_loss: 941.63452148 -- mean_d_loss: 9.46845913, mean_g_loss: 1018.84454346\n",
            "Epoch:  98 Step:   112  time: 1.316883 s d_loss: 1.02202535, g_loss: 1158.68481445 -- mean_d_loss: 9.42073822, mean_g_loss: 1019.63464355\n",
            "Epoch:  98 Step:   113  time: 1.320037 s d_loss: 9.28655529, g_loss: 1030.24194336 -- mean_d_loss: 9.41998386, mean_g_loss: 1019.69415283\n",
            "Epoch:  98 Step:   114  time: 1.320129 s d_loss: 0.64285189, g_loss: 988.12622070 -- mean_d_loss: 9.37094975, mean_g_loss: 1019.51782227\n",
            "Epoch:  98 Step:   115  time: 1.312858 s d_loss: 1.00116527, g_loss: 969.64367676 -- mean_d_loss: 9.32445145, mean_g_loss: 1019.24072266\n",
            "Epoch:  98 Step:   116  time: 1.284616 s d_loss: 0.83601362, g_loss: 976.64471436 -- mean_d_loss: 9.27755451, mean_g_loss: 1019.00537109\n",
            "Epoch:  98 Step:   117  time: 1.282124 s d_loss: 0.79902267, g_loss: 1041.04516602 -- mean_d_loss: 9.23096943, mean_g_loss: 1019.12646484\n",
            "Epoch:  98 Step:   118  time: 1.300832 s d_loss: 0.84240103, g_loss: 1002.70025635 -- mean_d_loss: 9.18513012, mean_g_loss: 1019.03674316\n",
            "Epoch:  98 Step:   119  time: 1.297279 s d_loss: 0.67971468, g_loss: 931.41326904 -- mean_d_loss: 9.13890457, mean_g_loss: 1018.56048584\n",
            "Epoch:  98 Step:   120  time: 1.313783 s d_loss: 0.87017566, g_loss: 1019.88256836 -- mean_d_loss: 9.09420872, mean_g_loss: 1018.56756592\n",
            "Epoch:  98 Step:   121  time: 1.290274 s d_loss: 0.72013324, g_loss: 943.31994629 -- mean_d_loss: 9.04918671, mean_g_loss: 1018.16296387\n",
            "Epoch:  98 Step:   122  time: 1.293320 s d_loss: 13.89437580, g_loss: 817.29821777 -- mean_d_loss: 9.07509708, mean_g_loss: 1017.08880615\n",
            "Epoch:  98 Step:   123  time: 1.299525 s d_loss: 1.04823232, g_loss: 1055.76745605 -- mean_d_loss: 9.03240013, mean_g_loss: 1017.29455566\n",
            "Epoch:  98 Step:   124  time: 1.316431 s d_loss: 1.18922389, g_loss: 1052.22387695 -- mean_d_loss: 8.99090195, mean_g_loss: 1017.47930908\n",
            "Epoch:  98 Step:   125  time: 1.287995 s d_loss: 0.82600790, g_loss: 1103.53259277 -- mean_d_loss: 8.94792938, mean_g_loss: 1017.93225098\n",
            "Epoch:  98 Step:   126  time: 1.281042 s d_loss: 2.30725169, g_loss: 1012.43072510 -- mean_d_loss: 8.91316128, mean_g_loss: 1017.90344238\n",
            "Epoch:  98 Step:   127  time: 1.346181 s d_loss: 0.93463874, g_loss: 1156.18139648 -- mean_d_loss: 8.87160683, mean_g_loss: 1018.62371826\n",
            "Epoch:  98 Step:   128  time: 1.287713 s d_loss: 0.96598524, g_loss: 1082.68017578 -- mean_d_loss: 8.83064461, mean_g_loss: 1018.95562744\n",
            "Epoch:  98 Step:   129  time: 1.335458 s d_loss: 15.17108154, g_loss: 1008.88604736 -- mean_d_loss: 8.86332798, mean_g_loss: 1018.90374756\n",
            "Epoch:  98 Step:   130  time: 1.322678 s d_loss: 0.83706689, g_loss: 1046.86474609 -- mean_d_loss: 8.82216740, mean_g_loss: 1019.04711914\n",
            "Epoch:  98 Step:   131  time: 1.303888 s d_loss: 2.46182060, g_loss: 1009.43609619 -- mean_d_loss: 8.78971672, mean_g_loss: 1018.99810791\n",
            "Epoch:  98 Step:   132  time: 1.279570 s d_loss: 1.08142984, g_loss: 858.27197266 -- mean_d_loss: 8.75058842, mean_g_loss: 1018.18218994\n",
            "Epoch:  98 Step:   133  time: 1.314664 s d_loss: 1.36370969, g_loss: 923.24694824 -- mean_d_loss: 8.71328068, mean_g_loss: 1017.70275879\n",
            "Epoch:  98 Step:   134  time: 1.319072 s d_loss: 1.06262016, g_loss: 915.35144043 -- mean_d_loss: 8.67483521, mean_g_loss: 1017.18835449\n",
            "Epoch:  98 Step:   135  time: 1.324434 s d_loss: 1.51535678, g_loss: 1153.97106934 -- mean_d_loss: 8.63903809, mean_g_loss: 1017.87225342\n",
            "Epoch:  98 Step:   136  time: 1.315945 s d_loss: 1.11873806, g_loss: 959.31774902 -- mean_d_loss: 8.60162354, mean_g_loss: 1017.58093262\n",
            "Epoch:  98 Step:   137  time: 1.320186 s d_loss: 0.89110214, g_loss: 1286.15246582 -- mean_d_loss: 8.56345272, mean_g_loss: 1018.91052246\n",
            "Epoch:  98 Step:   138  time: 1.319019 s d_loss: 35.37022781, g_loss: 1105.77612305 -- mean_d_loss: 8.69550610, mean_g_loss: 1019.33843994\n",
            "Epoch:  98 Step:   139  time: 1.309051 s d_loss: 1.30622065, g_loss: 837.38092041 -- mean_d_loss: 8.65928459, mean_g_loss: 1018.44647217\n",
            "Epoch:  98 Step:   140  time: 1.287970 s d_loss: 7.83795023, g_loss: 1038.57482910 -- mean_d_loss: 8.65527725, mean_g_loss: 1018.54467773\n",
            "Epoch:  98 Step:   141  time: 1.293418 s d_loss: 2.08398581, g_loss: 1124.57299805 -- mean_d_loss: 8.62337780, mean_g_loss: 1019.05938721\n",
            "Epoch:  98 Step:   142  time: 1.309782 s d_loss: 1.24248588, g_loss: 1044.85766602 -- mean_d_loss: 8.58772182, mean_g_loss: 1019.18402100\n",
            "Epoch:  98 Step:   143  time: 1.289861 s d_loss: 1.47219455, g_loss: 905.86157227 -- mean_d_loss: 8.55351162, mean_g_loss: 1018.63922119\n",
            "Epoch:  98 Step:   144  time: 1.318844 s d_loss: 2.54636598, g_loss: 1098.60681152 -- mean_d_loss: 8.52476978, mean_g_loss: 1019.02185059\n",
            "Epoch:  98 Step:   145  time: 1.290948 s d_loss: 0.81648427, g_loss: 1017.98413086 -- mean_d_loss: 8.48806381, mean_g_loss: 1019.01690674\n",
            "Epoch:  98 Step:   146  time: 1.317238 s d_loss: 5.77973366, g_loss: 1041.67675781 -- mean_d_loss: 8.47522831, mean_g_loss: 1019.12426758\n",
            "Epoch:  98 Step:   147  time: 1.334439 s d_loss: 3.43885756, g_loss: 1232.03137207 -- mean_d_loss: 8.45147228, mean_g_loss: 1020.12854004\n",
            "Epoch:  98 Step:   148  time: 1.309684 s d_loss: 1.11161625, g_loss: 980.55566406 -- mean_d_loss: 8.41701221, mean_g_loss: 1019.94281006\n",
            "Epoch:  98 Step:   149  time: 1.292893 s d_loss: 5.51384068, g_loss: 1118.76489258 -- mean_d_loss: 8.40344620, mean_g_loss: 1020.40454102\n",
            "Epoch:  98 Step:   150  time: 1.339123 s d_loss: 1.35671139, g_loss: 1050.05126953 -- mean_d_loss: 8.37067032, mean_g_loss: 1020.54241943\n",
            "Epoch:  98 Step:   151  time: 1.305398 s d_loss: 2.18836236, g_loss: 936.24523926 -- mean_d_loss: 8.34204865, mean_g_loss: 1020.15222168\n",
            "Epoch:  98 Step:   152  time: 1.332342 s d_loss: 1.19875145, g_loss: 948.18859863 -- mean_d_loss: 8.30912971, mean_g_loss: 1019.82055664\n",
            "Epoch:  98 Step:   153  time: 1.315782 s d_loss: 7.05695343, g_loss: 967.08892822 -- mean_d_loss: 8.30338573, mean_g_loss: 1019.57867432\n",
            "Epoch:  98 Step:   154  time: 1.322300 s d_loss: 1.58549702, g_loss: 1025.46960449 -- mean_d_loss: 8.27271080, mean_g_loss: 1019.60559082\n",
            "Epoch:  98 Step:   155  time: 1.320408 s d_loss: 4.35950518, g_loss: 1086.57421875 -- mean_d_loss: 8.25492287, mean_g_loss: 1019.91003418\n",
            "Epoch:  98 Step:   156  time: 1.313524 s d_loss: 1.91025734, g_loss: 1179.88928223 -- mean_d_loss: 8.22621441, mean_g_loss: 1020.63391113\n",
            "Epoch:  98 Step:   157  time: 1.318629 s d_loss: 0.97117722, g_loss: 874.23449707 -- mean_d_loss: 8.19353390, mean_g_loss: 1019.97442627\n",
            "Epoch:  98 Step:   158  time: 1.308655 s d_loss: 1.47332013, g_loss: 1170.80273438 -- mean_d_loss: 8.16339874, mean_g_loss: 1020.65075684\n",
            "Epoch:  98 Step:   159  time: 1.323640 s d_loss: 1.04314268, g_loss: 996.74169922 -- mean_d_loss: 8.13161182, mean_g_loss: 1020.54400635\n",
            "Epoch:  98 Step:   160  time: 1.316034 s d_loss: 0.76184291, g_loss: 949.18542480 -- mean_d_loss: 8.09885693, mean_g_loss: 1020.22686768\n",
            "Epoch:  98 Step:   161  time: 1.314984 s d_loss: 1.37417233, g_loss: 1129.98205566 -- mean_d_loss: 8.06910133, mean_g_loss: 1020.71252441\n",
            "Epoch:  98 Step:   162  time: 1.297498 s d_loss: 0.87938911, g_loss: 846.39886475 -- mean_d_loss: 8.03742886, mean_g_loss: 1019.94464111\n",
            "Epoch:  98 Step:   163  time: 1.311730 s d_loss: 1.35664010, g_loss: 1115.71337891 -- mean_d_loss: 8.00812721, mean_g_loss: 1020.36474609\n",
            "Epoch:  98 Step:   164  time: 1.327144 s d_loss: 2.13626838, g_loss: 958.10467529 -- mean_d_loss: 7.98248577, mean_g_loss: 1020.09283447\n",
            "Epoch:  98 Step:   165  time: 1.303964 s d_loss: 43.98776627, g_loss: 873.01361084 -- mean_d_loss: 8.13903046, mean_g_loss: 1019.45336914\n",
            "Epoch:  98 Step:   166  time: 1.325272 s d_loss: 1.74012959, g_loss: 1153.24768066 -- mean_d_loss: 8.11133003, mean_g_loss: 1020.03259277\n",
            "Epoch:  98 Step:   167  time: 1.300106 s d_loss: 4.84018707, g_loss: 988.35522461 -- mean_d_loss: 8.09722996, mean_g_loss: 1019.89605713\n",
            "Epoch:  98 Step:   168  time: 1.329499 s d_loss: 1.39157093, g_loss: 1200.39953613 -- mean_d_loss: 8.06845093, mean_g_loss: 1020.67077637\n",
            "Epoch:  98 Step:   169  time: 1.313207 s d_loss: 1.43384826, g_loss: 1171.92443848 -- mean_d_loss: 8.04009724, mean_g_loss: 1021.31719971\n",
            "Epoch:  98 Step:   170  time: 1.314830 s d_loss: 0.95596969, g_loss: 1005.75390625 -- mean_d_loss: 8.00995255, mean_g_loss: 1021.25091553\n",
            "Epoch:  98 Step:   171  time: 1.332973 s d_loss: 2.60019231, g_loss: 937.98400879 -- mean_d_loss: 7.98702955, mean_g_loss: 1020.89813232\n",
            "Epoch:  98 Step:   172  time: 1.311066 s d_loss: 13.01480770, g_loss: 1056.79162598 -- mean_d_loss: 8.00824356, mean_g_loss: 1021.04956055\n",
            "Epoch:  98 Step:   173  time: 1.314230 s d_loss: 1.17450035, g_loss: 1006.29895020 -- mean_d_loss: 7.97953081, mean_g_loss: 1020.98760986\n",
            "Epoch:  98 Step:   174  time: 1.345922 s d_loss: 9.85071087, g_loss: 1028.10498047 -- mean_d_loss: 7.98736000, mean_g_loss: 1021.01739502\n",
            "Epoch:  98 Step:   175  time: 1.308584 s d_loss: 20.26340675, g_loss: 959.52868652 -- mean_d_loss: 8.03851032, mean_g_loss: 1020.76116943\n",
            "Epoch:  98 Step:   176  time: 1.289662 s d_loss: 10.53826618, g_loss: 915.72064209 -- mean_d_loss: 8.04888248, mean_g_loss: 1020.32531738\n",
            "Epoch:  98 Step:   177  time: 1.323295 s d_loss: 19.36175156, g_loss: 1033.97705078 -- mean_d_loss: 8.09562969, mean_g_loss: 1020.38177490\n",
            "Epoch:  98 Step:   178  time: 1.293998 s d_loss: 2.43648815, g_loss: 991.62133789 -- mean_d_loss: 8.07234097, mean_g_loss: 1020.26342773\n",
            "Epoch:  98 Step:   179  time: 1.335581 s d_loss: 4.49634266, g_loss: 1056.61633301 -- mean_d_loss: 8.05768490, mean_g_loss: 1020.41241455\n",
            "Epoch:  98 Step:   180  time: 1.332221 s d_loss: 1.97108769, g_loss: 1075.87890625 -- mean_d_loss: 8.03284168, mean_g_loss: 1020.63879395\n",
            "Epoch:  98 Step:   181  time: 1.287462 s d_loss: 0.85692966, g_loss: 967.57995605 -- mean_d_loss: 8.00367165, mean_g_loss: 1020.42309570\n",
            "Epoch:  98 Step:   182  time: 1.322785 s d_loss: 2.74038410, g_loss: 1224.74963379 -- mean_d_loss: 7.98236275, mean_g_loss: 1021.25030518\n",
            "Epoch:  98 Step:   183  time: 1.343357 s d_loss: 63.99914932, g_loss: 1142.39270020 -- mean_d_loss: 8.20823669, mean_g_loss: 1021.73876953\n",
            "Epoch:  98 Step:   184  time: 1.335760 s d_loss: 2.53947163, g_loss: 960.12658691 -- mean_d_loss: 8.18547058, mean_g_loss: 1021.49133301\n",
            "Epoch:  98 Step:   185  time: 1.353867 s d_loss: 4.20946789, g_loss: 978.15319824 -- mean_d_loss: 8.16956615, mean_g_loss: 1021.31799316\n",
            "Epoch:  98 Step:   186  time: 1.291710 s d_loss: 1.74569833, g_loss: 1139.63073730 -- mean_d_loss: 8.14397335, mean_g_loss: 1021.78936768\n",
            "Epoch:  98 Step:   187  time: 1.325983 s d_loss: 28.99648857, g_loss: 949.98913574 -- mean_d_loss: 8.22672176, mean_g_loss: 1021.50439453\n",
            "Epoch:  98 Step:   188  time: 1.313873 s d_loss: 19.04159927, g_loss: 905.24578857 -- mean_d_loss: 8.26946735, mean_g_loss: 1021.04492188\n",
            "Epoch:  98 Step:   189  time: 1.322030 s d_loss: 2.16690063, g_loss: 1172.17150879 -- mean_d_loss: 8.24544239, mean_g_loss: 1021.63989258\n",
            "Epoch:  98 Step:   190  time: 1.322467 s d_loss: 20.33321571, g_loss: 901.95831299 -- mean_d_loss: 8.29284477, mean_g_loss: 1021.17053223\n",
            "Epoch:  98 Step:   191  time: 1.314508 s d_loss: 49.57041168, g_loss: 1095.38842773 -- mean_d_loss: 8.45408535, mean_g_loss: 1021.46044922\n",
            "Epoch:  98 Step:   192  time: 1.306414 s d_loss: 3.89737749, g_loss: 1132.46679688 -- mean_d_loss: 8.43635559, mean_g_loss: 1021.89239502\n",
            "Epoch:  98 Step:   193  time: 1.338035 s d_loss: 1.34509480, g_loss: 986.64990234 -- mean_d_loss: 8.40887070, mean_g_loss: 1021.75579834\n",
            "Epoch:  98 Step:   194  time: 1.304612 s d_loss: 57.09360886, g_loss: 1080.30761719 -- mean_d_loss: 8.59684181, mean_g_loss: 1021.98187256\n",
            "Epoch:  98 Step:   195  time: 1.317007 s d_loss: 2.18364453, g_loss: 873.23364258 -- mean_d_loss: 8.57217503, mean_g_loss: 1021.40972900\n",
            "Epoch:  98 Step:   196  time: 1.300117 s d_loss: 2.43398738, g_loss: 1036.13977051 -- mean_d_loss: 8.54865742, mean_g_loss: 1021.46612549\n",
            "Epoch:  98 Step:   197  time: 1.319658 s d_loss: 3.67634392, g_loss: 1158.02465820 -- mean_d_loss: 8.53006077, mean_g_loss: 1021.98736572\n",
            "Epoch:  98 Step:   198  time: 1.309713 s d_loss: 1.96369839, g_loss: 860.74682617 -- mean_d_loss: 8.50509357, mean_g_loss: 1021.37426758\n",
            "Epoch:  98 Step:   199  time: 1.319622 s d_loss: 1.31496894, g_loss: 1041.41064453 -- mean_d_loss: 8.47785854, mean_g_loss: 1021.45019531\n",
            "Epoch:  98 Step:   200  time: 1.317019 s d_loss: 13.30477715, g_loss: 1088.74291992 -- mean_d_loss: 13.30477715, mean_g_loss: 1088.74291992\n",
            "Epoch:  98 Step:   201  time: 1.275953 s d_loss: 0.99328732, g_loss: 870.28002930 -- mean_d_loss: 7.14903212, mean_g_loss: 979.51147461\n",
            "Epoch:  98 Step:   202  time: 1.318502 s d_loss: 38.06099701, g_loss: 951.11340332 -- mean_d_loss: 17.45302010, mean_g_loss: 970.04541016\n",
            "Epoch:  98 Step:   203  time: 1.315325 s d_loss: 11.10104847, g_loss: 1047.33618164 -- mean_d_loss: 15.86502743, mean_g_loss: 989.36810303\n",
            "Epoch:  98 Step:   204  time: 1.327764 s d_loss: 4.34225368, g_loss: 982.22106934 -- mean_d_loss: 13.56047249, mean_g_loss: 987.93865967\n",
            "Epoch:  98 Step:   205  time: 1.332624 s d_loss: 11.55223370, g_loss: 1131.63671875 -- mean_d_loss: 13.22576523, mean_g_loss: 1011.88836670\n",
            "Epoch:  98 Step:   206  time: 1.293739 s d_loss: 3.41326261, g_loss: 953.08862305 -- mean_d_loss: 11.82397938, mean_g_loss: 1003.48840332\n",
            "Epoch:  98 Step:   207  time: 1.288327 s d_loss: 2.77637386, g_loss: 939.62475586 -- mean_d_loss: 10.69302845, mean_g_loss: 995.50549316\n",
            "Epoch:  98 Step:   208  time: 1.285075 s d_loss: 1.84732461, g_loss: 897.13903809 -- mean_d_loss: 9.71017265, mean_g_loss: 984.57586670\n",
            "Epoch:  98 Step:   209  time: 1.284990 s d_loss: 1.00957322, g_loss: 983.35345459 -- mean_d_loss: 8.84011269, mean_g_loss: 984.45361328\n",
            "Epoch:  98 Step:   210  time: 1.314810 s d_loss: 1.33497620, g_loss: 931.34765625 -- mean_d_loss: 8.15782833, mean_g_loss: 979.62579346\n",
            "Epoch:  98 Step:   211  time: 1.317354 s d_loss: 0.78705668, g_loss: 879.39965820 -- mean_d_loss: 7.54359674, mean_g_loss: 971.27362061\n",
            "Epoch:  98 Step:   212  time: 1.320759 s d_loss: 16.54191399, g_loss: 1036.83142090 -- mean_d_loss: 8.23577499, mean_g_loss: 976.31646729\n",
            "Epoch:  98 Step:   213  time: 1.288559 s d_loss: 1.26609266, g_loss: 1066.48876953 -- mean_d_loss: 7.73794079, mean_g_loss: 982.75738525\n",
            "Epoch:  98 Step:   214  time: 1.283015 s d_loss: 1.55514455, g_loss: 1153.57031250 -- mean_d_loss: 7.32575417, mean_g_loss: 994.14489746\n",
            "Epoch:  98 Step:   215  time: 1.280979 s d_loss: 0.85113370, g_loss: 937.33319092 -- mean_d_loss: 6.92109060, mean_g_loss: 990.59417725\n",
            "Epoch:  98 Step:   216  time: 1.327024 s d_loss: 0.97784173, g_loss: 1101.25366211 -- mean_d_loss: 6.57148790, mean_g_loss: 997.10351562\n",
            "Epoch:  98 Step:   217  time: 1.305136 s d_loss: 0.97313070, g_loss: 1054.32788086 -- mean_d_loss: 6.26046801, mean_g_loss: 1000.28265381\n",
            "Epoch:  98 Step:   218  time: 1.322731 s d_loss: 6.45275736, g_loss: 1063.48278809 -- mean_d_loss: 6.27058840, mean_g_loss: 1003.60894775\n",
            "Epoch:  98 Step:   219  time: 1.314336 s d_loss: 1.65807235, g_loss: 963.62957764 -- mean_d_loss: 6.03996277, mean_g_loss: 1001.60998535\n",
            "Epoch:  98 Step:   220  time: 1.320320 s d_loss: 1.21957755, g_loss: 1110.60668945 -- mean_d_loss: 5.81042051, mean_g_loss: 1006.80029297\n",
            "Epoch:  98 Step:   221  time: 1.321220 s d_loss: 2.47034097, g_loss: 1023.65747070 -- mean_d_loss: 5.65859890, mean_g_loss: 1007.56658936\n",
            "Epoch:  98 Step:   222  time: 1.307922 s d_loss: 2.19348073, g_loss: 953.90649414 -- mean_d_loss: 5.50794172, mean_g_loss: 1005.23352051\n",
            "Epoch:  98 Step:   223  time: 1.333387 s d_loss: 33.23871231, g_loss: 973.48913574 -- mean_d_loss: 6.66339064, mean_g_loss: 1003.91082764\n",
            "Epoch:  98 Step:   224  time: 1.325809 s d_loss: 1.87926781, g_loss: 1067.34582520 -- mean_d_loss: 6.47202587, mean_g_loss: 1006.44818115\n",
            "Epoch:  98 Step:   225  time: 1.330858 s d_loss: 1.75550604, g_loss: 1045.48437500 -- mean_d_loss: 6.29062128, mean_g_loss: 1007.94958496\n",
            "Epoch:  98 Step:   226  time: 1.310444 s d_loss: 1.36385095, g_loss: 958.59436035 -- mean_d_loss: 6.10814810, mean_g_loss: 1006.12158203\n",
            "Epoch:  98 Step:   227  time: 1.288368 s d_loss: 1.39682508, g_loss: 894.16418457 -- mean_d_loss: 5.93988657, mean_g_loss: 1002.12310791\n",
            "Epoch:  98 Step:   228  time: 1.321957 s d_loss: 1.14184821, g_loss: 845.50518799 -- mean_d_loss: 5.77443647, mean_g_loss: 996.72253418\n",
            "Epoch:  98 Step:   229  time: 1.331126 s d_loss: 1.11063790, g_loss: 996.94409180 -- mean_d_loss: 5.61897707, mean_g_loss: 996.72985840\n",
            "Epoch:  98 Step:   230  time: 1.293048 s d_loss: 24.18365288, g_loss: 1044.84301758 -- mean_d_loss: 6.21783733, mean_g_loss: 998.28192139\n",
            "Epoch:  98 Step:   231  time: 1.332266 s d_loss: 1.87572026, g_loss: 851.27880859 -- mean_d_loss: 6.08214617, mean_g_loss: 993.68811035\n",
            "Epoch:  98 Step:   232  time: 1.323390 s d_loss: 0.85469651, g_loss: 987.93688965 -- mean_d_loss: 5.92373848, mean_g_loss: 993.51385498\n",
            "Epoch:  98 Step:   233  time: 1.321124 s d_loss: 4.42516088, g_loss: 1051.98730469 -- mean_d_loss: 5.87966251, mean_g_loss: 995.23370361\n",
            "Epoch:  98 Step:   234  time: 1.322591 s d_loss: 1.08197296, g_loss: 1078.71337891 -- mean_d_loss: 5.74258566, mean_g_loss: 997.61883545\n",
            "Epoch:  98 Step:   235  time: 1.346953 s d_loss: 1.48267174, g_loss: 934.15466309 -- mean_d_loss: 5.62425423, mean_g_loss: 995.85601807\n",
            "Epoch:  98 Step:   236  time: 1.326173 s d_loss: 1.51652396, g_loss: 1240.78442383 -- mean_d_loss: 5.51323462, mean_g_loss: 1002.47570801\n",
            "Epoch:  98 Step:   237  time: 1.330096 s d_loss: 1.37018561, g_loss: 914.71960449 -- mean_d_loss: 5.40420675, mean_g_loss: 1000.16632080\n",
            "Epoch:  98 Step:   238  time: 1.330789 s d_loss: 1.02384698, g_loss: 868.76190186 -- mean_d_loss: 5.29189014, mean_g_loss: 996.79699707\n",
            "Epoch:  98 Step:   239  time: 1.331245 s d_loss: 1.20738018, g_loss: 931.85021973 -- mean_d_loss: 5.18977737, mean_g_loss: 995.17333984\n",
            "Epoch:  98 Step:   240  time: 1.325692 s d_loss: 1.33570743, g_loss: 997.08636475 -- mean_d_loss: 5.09577560, mean_g_loss: 995.21997070\n",
            "Epoch:  98 Step:   241  time: 1.329549 s d_loss: 0.84458083, g_loss: 978.53051758 -- mean_d_loss: 4.99455643, mean_g_loss: 994.82263184\n",
            "Epoch:  98 Step:   242  time: 1.326913 s d_loss: 1.21301854, g_loss: 1003.63861084 -- mean_d_loss: 4.90661383, mean_g_loss: 995.02758789\n",
            "Epoch:  98 Step:   243  time: 1.337238 s d_loss: 0.83140814, g_loss: 871.08581543 -- mean_d_loss: 4.81399536, mean_g_loss: 992.21075439\n",
            "Epoch:  98 Step:   244  time: 1.313613 s d_loss: 1.56737304, g_loss: 1081.27856445 -- mean_d_loss: 4.74184799, mean_g_loss: 994.19000244\n",
            "Epoch:  98 Step:   245  time: 1.323486 s d_loss: 0.70265490, g_loss: 948.53405762 -- mean_d_loss: 4.65403938, mean_g_loss: 993.19750977\n",
            "Epoch:  98 Step:   246  time: 1.297889 s d_loss: 9.42622566, g_loss: 1056.82836914 -- mean_d_loss: 4.75557518, mean_g_loss: 994.55139160\n",
            "Epoch:  98 Step:   247  time: 1.317566 s d_loss: 1.35550332, g_loss: 911.57006836 -- mean_d_loss: 4.68474054, mean_g_loss: 992.82257080\n",
            "Epoch:  98 Step:   248  time: 1.292021 s d_loss: 0.99980468, g_loss: 1083.59106445 -- mean_d_loss: 4.60953760, mean_g_loss: 994.67498779\n",
            "Epoch:  98 Step:   249  time: 1.327621 s d_loss: 0.78436452, g_loss: 900.49340820 -- mean_d_loss: 4.53303385, mean_g_loss: 992.79132080\n",
            "Epoch:  98 Step:   250  time: 1.312456 s d_loss: 0.83861691, g_loss: 898.65197754 -- mean_d_loss: 4.46059465, mean_g_loss: 990.94549561\n",
            "Epoch:  98 Step:   251  time: 1.295563 s d_loss: 0.91456985, g_loss: 920.39166260 -- mean_d_loss: 4.39240170, mean_g_loss: 989.58862305\n",
            "Epoch:  98 Step:   252  time: 1.289213 s d_loss: 1.23064697, g_loss: 1000.03613281 -- mean_d_loss: 4.33274603, mean_g_loss: 989.78576660\n",
            "Epoch:  98 Step:   253  time: 1.297026 s d_loss: 0.86240411, g_loss: 1118.82397461 -- mean_d_loss: 4.26848078, mean_g_loss: 992.17535400\n",
            "Epoch:  98 Step:   254  time: 1.286081 s d_loss: 2.02599907, g_loss: 925.39257812 -- mean_d_loss: 4.22770834, mean_g_loss: 990.96105957\n",
            "Epoch:  98 Step:   255  time: 1.289278 s d_loss: 0.90259373, g_loss: 904.75494385 -- mean_d_loss: 4.16833115, mean_g_loss: 989.42169189\n",
            "Epoch:  98 Step:   256  time: 1.308807 s d_loss: 0.86784118, g_loss: 1116.83520508 -- mean_d_loss: 4.11042786, mean_g_loss: 991.65698242\n",
            "Epoch:  98 Step:   257  time: 1.309924 s d_loss: 1.09250510, g_loss: 1021.07507324 -- mean_d_loss: 4.05839443, mean_g_loss: 992.16418457\n",
            "Epoch:  98 Step:   258  time: 1.328523 s d_loss: 12.46023083, g_loss: 1120.87915039 -- mean_d_loss: 4.20079851, mean_g_loss: 994.34582520\n",
            "Epoch:  98 Step:   259  time: 1.284132 s d_loss: 23.31537247, g_loss: 1030.49353027 -- mean_d_loss: 4.51937532, mean_g_loss: 994.94824219\n",
            "Epoch:  98 Step:   260  time: 1.284593 s d_loss: 1.35138845, g_loss: 1021.96197510 -- mean_d_loss: 4.46744061, mean_g_loss: 995.39105225\n",
            "Epoch:  98 Step:   261  time: 1.305553 s d_loss: 1.14260936, g_loss: 1035.09045410 -- mean_d_loss: 4.41381454, mean_g_loss: 996.03137207\n",
            "Epoch:  98 Step:   262  time: 1.329516 s d_loss: 1.35945761, g_loss: 1048.80700684 -- mean_d_loss: 4.36533260, mean_g_loss: 996.86907959\n",
            "Epoch:  98 Step:   263  time: 1.287254 s d_loss: 1.33842981, g_loss: 1029.54565430 -- mean_d_loss: 4.31803751, mean_g_loss: 997.37969971\n",
            "Epoch:  98 Step:   264  time: 1.306109 s d_loss: 2.54420567, g_loss: 924.59307861 -- mean_d_loss: 4.29074812, mean_g_loss: 996.25988770\n",
            "Epoch:  98 Step:   265  time: 1.294254 s d_loss: 1.18509269, g_loss: 1142.48583984 -- mean_d_loss: 4.24369240, mean_g_loss: 998.47552490\n",
            "Epoch:  98 Step:   266  time: 1.276638 s d_loss: 0.77781206, g_loss: 1019.70642090 -- mean_d_loss: 4.19196272, mean_g_loss: 998.79229736\n",
            "Epoch:  98 Step:   267  time: 1.308994 s d_loss: 0.90620339, g_loss: 973.78601074 -- mean_d_loss: 4.14364243, mean_g_loss: 998.42462158\n",
            "Epoch:  98 Step:   268  time: 1.322916 s d_loss: 12.94085979, g_loss: 1131.47229004 -- mean_d_loss: 4.27113867, mean_g_loss: 1000.35278320\n",
            "Epoch:  98 Step:   269  time: 1.294086 s d_loss: 37.46640015, g_loss: 982.30767822 -- mean_d_loss: 4.74535656, mean_g_loss: 1000.09497070\n",
            "Epoch:  98 Step:   270  time: 1.316767 s d_loss: 1.95250261, g_loss: 1014.32592773 -- mean_d_loss: 4.70602083, mean_g_loss: 1000.29547119\n",
            "Epoch:  98 Step:   271  time: 1.312505 s d_loss: 1.91156971, g_loss: 1099.42724609 -- mean_d_loss: 4.66720867, mean_g_loss: 1001.67230225\n",
            "Epoch:  98 Step:   272  time: 1.299307 s d_loss: 1.91104126, g_loss: 931.84869385 -- mean_d_loss: 4.62945318, mean_g_loss: 1000.71588135\n",
            "Epoch:  98 Step:   273  time: 1.346450 s d_loss: 1.34054291, g_loss: 970.96453857 -- mean_d_loss: 4.58500814, mean_g_loss: 1000.31378174\n",
            "Epoch:  98 Step:   274  time: 1.326467 s d_loss: 1.09142697, g_loss: 965.99310303 -- mean_d_loss: 4.53842735, mean_g_loss: 999.85614014\n",
            "Epoch:  98 Step:   275  time: 1.314070 s d_loss: 1.18799782, g_loss: 985.58203125 -- mean_d_loss: 4.49434280, mean_g_loss: 999.66839600\n",
            "Epoch:  98 Step:   276  time: 1.322947 s d_loss: 1.30581474, g_loss: 1128.27502441 -- mean_d_loss: 4.45293331, mean_g_loss: 1001.33856201\n",
            "Epoch:  98 Step:   277  time: 1.312675 s d_loss: 0.66772878, g_loss: 1120.77221680 -- mean_d_loss: 4.40440464, mean_g_loss: 1002.86981201\n",
            "Epoch:  98 Step:   278  time: 1.319299 s d_loss: 1.50175166, g_loss: 1107.20910645 -- mean_d_loss: 4.36766243, mean_g_loss: 1004.19055176\n",
            "Epoch:  98 Step:   279  time: 1.310725 s d_loss: 1.14794290, g_loss: 1216.79467773 -- mean_d_loss: 4.32741594, mean_g_loss: 1006.84814453\n",
            "Epoch:  98 Step:   280  time: 1.320945 s d_loss: 1.04372895, g_loss: 941.98022461 -- mean_d_loss: 4.28687668, mean_g_loss: 1006.04724121\n",
            "Epoch:  98 Step:   281  time: 1.319567 s d_loss: 0.97564161, g_loss: 1085.96582031 -- mean_d_loss: 4.24649572, mean_g_loss: 1007.02191162\n",
            "Epoch:  98 Step:   282  time: 1.343975 s d_loss: 0.88778663, g_loss: 1042.25463867 -- mean_d_loss: 4.20602942, mean_g_loss: 1007.44647217\n",
            "Epoch:  98 Step:   283  time: 1.287406 s d_loss: 1.35373795, g_loss: 1052.41198730 -- mean_d_loss: 4.17207336, mean_g_loss: 1007.98175049\n",
            "Epoch:  98 Step:   284  time: 1.321405 s d_loss: 0.76924378, g_loss: 982.20190430 -- mean_d_loss: 4.13204002, mean_g_loss: 1007.67846680\n",
            "Epoch:  98 Step:   285  time: 1.317009 s d_loss: 0.89491528, g_loss: 977.42590332 -- mean_d_loss: 4.09439945, mean_g_loss: 1007.32678223\n",
            "Epoch:  98 Step:   286  time: 1.353440 s d_loss: 1.10335195, g_loss: 1062.62377930 -- mean_d_loss: 4.06001949, mean_g_loss: 1007.96240234\n",
            "Epoch:  98 Step:   287  time: 1.318535 s d_loss: 0.71657670, g_loss: 1059.89147949 -- mean_d_loss: 4.02202606, mean_g_loss: 1008.55249023\n",
            "Epoch:  98 Step:   288  time: 1.298172 s d_loss: 0.90066707, g_loss: 928.59594727 -- mean_d_loss: 3.98695469, mean_g_loss: 1007.65405273\n",
            "Epoch:  98 Step:   289  time: 1.293046 s d_loss: 0.73563355, g_loss: 928.76715088 -- mean_d_loss: 3.95082879, mean_g_loss: 1006.77752686\n",
            "Epoch:  98 Step:   290  time: 1.313287 s d_loss: 0.74834388, g_loss: 913.54534912 -- mean_d_loss: 3.91563678, mean_g_loss: 1005.75299072\n",
            "Epoch:  98 Step:   291  time: 1.320471 s d_loss: 1.05228984, g_loss: 1105.27270508 -- mean_d_loss: 3.88451314, mean_g_loss: 1006.83477783\n",
            "Epoch:  98 Step:   292  time: 1.325050 s d_loss: 2.89444613, g_loss: 1280.03454590 -- mean_d_loss: 3.87386727, mean_g_loss: 1009.77233887\n",
            "Epoch:  98 Step:   293  time: 1.340459 s d_loss: 5.97588682, g_loss: 1005.68957520 -- mean_d_loss: 3.89622927, mean_g_loss: 1009.72888184\n",
            "Epoch:  98 Step:   294  time: 1.319762 s d_loss: 2.63405633, g_loss: 1005.46142578 -- mean_d_loss: 3.88294315, mean_g_loss: 1009.68395996\n",
            "Epoch:  98 Step:   295  time: 1.338332 s d_loss: 3.00906444, g_loss: 988.61425781 -- mean_d_loss: 3.87384033, mean_g_loss: 1009.46453857\n",
            "Epoch:  98 Step:   296  time: 1.331983 s d_loss: 1.18560076, g_loss: 987.02929688 -- mean_d_loss: 3.84612656, mean_g_loss: 1009.23327637\n",
            "Epoch:  98 Step:   297  time: 1.339543 s d_loss: 1.03939915, g_loss: 1136.69836426 -- mean_d_loss: 3.81748652, mean_g_loss: 1010.53387451\n",
            "Epoch:  98 Step:   298  time: 1.332878 s d_loss: 0.87468785, g_loss: 1053.71618652 -- mean_d_loss: 3.78776145, mean_g_loss: 1010.97009277\n",
            "Epoch:  98 Step:   299  time: 1.327032 s d_loss: 1.33378720, g_loss: 1057.67492676 -- mean_d_loss: 3.76322174, mean_g_loss: 1011.43713379\n",
            "Epoch:  98 Step:   300  time: 1.309712 s d_loss: 0.80938226, g_loss: 955.05474854 -- mean_d_loss: 3.73397589, mean_g_loss: 1010.87884521\n",
            "Epoch:  98 Step:   301  time: 1.337612 s d_loss: 0.87450057, g_loss: 1186.78662109 -- mean_d_loss: 3.70594192, mean_g_loss: 1012.60345459\n",
            "Epoch:  98 Step:   302  time: 1.323125 s d_loss: 3.72599149, g_loss: 1104.96118164 -- mean_d_loss: 3.70613647, mean_g_loss: 1013.50012207\n",
            "Epoch:  98 Step:   303  time: 1.300163 s d_loss: 2.41862917, g_loss: 947.74584961 -- mean_d_loss: 3.69375658, mean_g_loss: 1012.86785889\n",
            "Epoch:  98 Step:   304  time: 1.292228 s d_loss: 1.78666675, g_loss: 1000.00946045 -- mean_d_loss: 3.67559385, mean_g_loss: 1012.74536133\n",
            "Epoch:  98 Step:   305  time: 1.310457 s d_loss: 1.37662768, g_loss: 915.34112549 -- mean_d_loss: 3.65390539, mean_g_loss: 1011.82647705\n",
            "Epoch:  98 Step:   306  time: 1.315792 s d_loss: 1.48152244, g_loss: 1016.78643799 -- mean_d_loss: 3.63360286, mean_g_loss: 1011.87286377\n",
            "Epoch:  98 Step:   307  time: 1.318318 s d_loss: 2.29122829, g_loss: 1092.28930664 -- mean_d_loss: 3.62117338, mean_g_loss: 1012.61749268\n",
            "Epoch:  98 Step:   308  time: 1.336720 s d_loss: 2.05886030, g_loss: 1013.46527100 -- mean_d_loss: 3.60684037, mean_g_loss: 1012.62530518\n",
            "Epoch:  98 Step:   309  time: 1.319819 s d_loss: 0.76488787, g_loss: 1026.61926270 -- mean_d_loss: 3.58100438, mean_g_loss: 1012.75250244\n",
            "Epoch:  98 Step:   310  time: 1.300743 s d_loss: 0.94660437, g_loss: 1018.48266602 -- mean_d_loss: 3.55727100, mean_g_loss: 1012.80413818\n",
            "Epoch:  98 Step:   311  time: 1.317405 s d_loss: 0.68951815, g_loss: 1012.04809570 -- mean_d_loss: 3.53166604, mean_g_loss: 1012.79736328\n",
            "Epoch:  98 Step:   312  time: 1.310491 s d_loss: 0.77596873, g_loss: 905.24426270 -- mean_d_loss: 3.50727940, mean_g_loss: 1011.84552002\n",
            "Epoch:  98 Step:   313  time: 1.304637 s d_loss: 0.83385575, g_loss: 893.36315918 -- mean_d_loss: 3.48382831, mean_g_loss: 1010.80621338\n",
            "Epoch:  98 Step:   314  time: 1.319217 s d_loss: 0.93950135, g_loss: 1376.11035156 -- mean_d_loss: 3.46170378, mean_g_loss: 1013.98272705\n",
            "Epoch:  98 Step:   315  time: 1.318354 s d_loss: 1.02649438, g_loss: 1135.84228516 -- mean_d_loss: 3.44071054, mean_g_loss: 1015.03326416\n",
            "Epoch:  98 Step:   316  time: 1.313163 s d_loss: 1.25050080, g_loss: 990.56823730 -- mean_d_loss: 3.42199087, mean_g_loss: 1014.82415771\n",
            "Epoch:  98 Step:   317  time: 1.348294 s d_loss: 1.55222595, g_loss: 973.48486328 -- mean_d_loss: 3.40614533, mean_g_loss: 1014.47387695\n",
            "Epoch:  98 Step:   318  time: 1.304873 s d_loss: 1.08928704, g_loss: 933.92395020 -- mean_d_loss: 3.38667583, mean_g_loss: 1013.79693604\n",
            "Epoch:  98 Step:   319  time: 1.307559 s d_loss: 1.45539963, g_loss: 1074.32690430 -- mean_d_loss: 3.37058210, mean_g_loss: 1014.30139160\n",
            "Epoch:  98 Step:   320  time: 1.324662 s d_loss: 0.73913556, g_loss: 1011.15386963 -- mean_d_loss: 3.34883451, mean_g_loss: 1014.27539062\n",
            "Epoch:  98 Step:   321  time: 1.321978 s d_loss: 0.89368373, g_loss: 929.15576172 -- mean_d_loss: 3.32871032, mean_g_loss: 1013.57769775\n",
            "Epoch:  98 Step:   322  time: 1.330064 s d_loss: 1.15218449, g_loss: 961.49328613 -- mean_d_loss: 3.31101513, mean_g_loss: 1013.15423584\n",
            "Epoch:  98 Step:   323  time: 1.291276 s d_loss: 0.71459132, g_loss: 1086.55700684 -- mean_d_loss: 3.29007626, mean_g_loss: 1013.74615479\n",
            "Epoch:  98 Step:   324  time: 1.328115 s d_loss: 1.24464822, g_loss: 1088.10290527 -- mean_d_loss: 3.27371287, mean_g_loss: 1014.34100342\n",
            "Epoch:  98 Step:   325  time: 1.322228 s d_loss: 0.73647887, g_loss: 976.41253662 -- mean_d_loss: 3.25357604, mean_g_loss: 1014.03997803\n",
            "Epoch:  98 Step:   326  time: 1.345190 s d_loss: 0.85433125, g_loss: 987.40832520 -- mean_d_loss: 3.23468447, mean_g_loss: 1013.83026123\n",
            "Epoch:  98 Step:   327  time: 1.283245 s d_loss: 0.98064083, g_loss: 1016.31958008 -- mean_d_loss: 3.21707487, mean_g_loss: 1013.84973145\n",
            "Epoch:  98 Step:   328  time: 1.304519 s d_loss: 0.58902854, g_loss: 1075.33422852 -- mean_d_loss: 3.19670224, mean_g_loss: 1014.32635498\n",
            "Epoch:  98 Step:   329  time: 1.318881 s d_loss: 0.67303377, g_loss: 1005.48535156 -- mean_d_loss: 3.17728949, mean_g_loss: 1014.25842285\n",
            "Epoch:  98 Step:   330  time: 1.320194 s d_loss: 0.69889748, g_loss: 998.18151855 -- mean_d_loss: 3.15837049, mean_g_loss: 1014.13574219\n",
            "Epoch:  98 Step:   331  time: 1.315036 s d_loss: 2.39033651, g_loss: 1123.72204590 -- mean_d_loss: 3.15255213, mean_g_loss: 1014.96588135\n",
            "Epoch:  98 Step:   332  time: 1.291804 s d_loss: 0.71910000, g_loss: 1001.81933594 -- mean_d_loss: 3.13425541, mean_g_loss: 1014.86700439\n",
            "Epoch:  98 Step:   333  time: 1.331462 s d_loss: 10.99125481, g_loss: 974.70495605 -- mean_d_loss: 3.19288945, mean_g_loss: 1014.56726074\n",
            "Epoch:  98 Step:   334  time: 1.356220 s d_loss: 6.12815475, g_loss: 808.11425781 -- mean_d_loss: 3.21463227, mean_g_loss: 1013.03796387\n",
            "Epoch:  98 Step:   335  time: 1.295922 s d_loss: 0.98547310, g_loss: 1046.42749023 -- mean_d_loss: 3.19824123, mean_g_loss: 1013.28344727\n",
            "Epoch:  98 Step:   336  time: 1.293925 s d_loss: 1.32979834, g_loss: 997.71435547 -- mean_d_loss: 3.18460298, mean_g_loss: 1013.16979980\n",
            "Epoch:  98 Step:   337  time: 1.312794 s d_loss: 1.46989453, g_loss: 965.07739258 -- mean_d_loss: 3.17217779, mean_g_loss: 1012.82135010\n",
            "Epoch:  98 Step:   338  time: 1.297398 s d_loss: 0.82167894, g_loss: 917.96484375 -- mean_d_loss: 3.15526772, mean_g_loss: 1012.13891602\n",
            "Epoch:  98 Step:   339  time: 1.326862 s d_loss: 0.64953679, g_loss: 1028.27368164 -- mean_d_loss: 3.13736963, mean_g_loss: 1012.25421143\n",
            "Epoch:  98 Step:   340  time: 1.334558 s d_loss: 0.84170783, g_loss: 941.95385742 -- mean_d_loss: 3.12108827, mean_g_loss: 1011.75567627\n",
            "Epoch:  98 Step:   341  time: 1.292891 s d_loss: 0.91109467, g_loss: 1093.74353027 -- mean_d_loss: 3.10552502, mean_g_loss: 1012.33306885\n",
            "Epoch:  98 Step:   342  time: 1.346117 s d_loss: 0.52578545, g_loss: 1052.03466797 -- mean_d_loss: 3.08748484, mean_g_loss: 1012.61065674\n",
            "Epoch:  98 Step:   343  time: 1.313751 s d_loss: 0.81110775, g_loss: 1148.65246582 -- mean_d_loss: 3.07167673, mean_g_loss: 1013.55541992\n",
            "Epoch:  98 Step:   344  time: 1.327636 s d_loss: 0.71303225, g_loss: 1022.67675781 -- mean_d_loss: 3.05541015, mean_g_loss: 1013.61834717\n",
            "Epoch:  98 Step:   345  time: 1.310095 s d_loss: 0.58273417, g_loss: 982.71240234 -- mean_d_loss: 3.03847408, mean_g_loss: 1013.40667725\n",
            "Epoch:  98 Step:   346  time: 1.351074 s d_loss: 1.53939128, g_loss: 1041.67126465 -- mean_d_loss: 3.02827621, mean_g_loss: 1013.59893799\n",
            "Epoch:  98 Step:   347  time: 1.323760 s d_loss: 0.61495453, g_loss: 1040.18701172 -- mean_d_loss: 3.01197004, mean_g_loss: 1013.77862549\n",
            "Epoch:  98 Step:   348  time: 1.338187 s d_loss: 1.13681984, g_loss: 964.20166016 -- mean_d_loss: 2.99938512, mean_g_loss: 1013.44586182\n",
            "Epoch:  98 Step:   349  time: 1.318589 s d_loss: 1.03064311, g_loss: 1058.02111816 -- mean_d_loss: 2.98626018, mean_g_loss: 1013.74304199\n",
            "Epoch:  98 Step:   350  time: 1.297528 s d_loss: 1.31336772, g_loss: 1011.89172363 -- mean_d_loss: 2.97518134, mean_g_loss: 1013.73077393\n",
            "Epoch:  98 Step:   351  time: 1.304175 s d_loss: 0.68361121, g_loss: 1226.77856445 -- mean_d_loss: 2.96010518, mean_g_loss: 1015.13238525\n",
            "Epoch:  98 Step:   352  time: 1.322538 s d_loss: 0.77266717, g_loss: 986.90539551 -- mean_d_loss: 2.94580841, mean_g_loss: 1014.94793701\n",
            "Epoch:  98 Step:   353  time: 1.302446 s d_loss: 0.94890720, g_loss: 1131.37890625 -- mean_d_loss: 2.93284154, mean_g_loss: 1015.70391846\n",
            "Epoch:  98 Step:   354  time: 1.307090 s d_loss: 0.60797781, g_loss: 922.89404297 -- mean_d_loss: 2.91784239, mean_g_loss: 1015.10516357\n",
            "Epoch:  98 Step:   355  time: 1.309044 s d_loss: 1.83350420, g_loss: 1096.03784180 -- mean_d_loss: 2.91089129, mean_g_loss: 1015.62390137\n",
            "Epoch:  98 Step:   356  time: 1.333783 s d_loss: 0.79455775, g_loss: 929.09381104 -- mean_d_loss: 2.89741158, mean_g_loss: 1015.07275391\n",
            "Epoch:  98 Step:   357  time: 1.314414 s d_loss: 0.90834296, g_loss: 977.53369141 -- mean_d_loss: 2.88482261, mean_g_loss: 1014.83514404\n",
            "Epoch:  98 Step:   358  time: 1.327439 s d_loss: 0.59063220, g_loss: 1042.54931641 -- mean_d_loss: 2.87039375, mean_g_loss: 1015.00946045\n",
            "Epoch:  98 Step:   359  time: 1.335602 s d_loss: 1.31701028, g_loss: 895.87951660 -- mean_d_loss: 2.86068511, mean_g_loss: 1014.26483154\n",
            "Epoch:  98 Step:   360  time: 1.326722 s d_loss: 0.73771381, g_loss: 840.74969482 -- mean_d_loss: 2.84749889, mean_g_loss: 1013.18713379\n",
            "Epoch:  98 Step:   361  time: 1.289123 s d_loss: 3.83989453, g_loss: 1058.22778320 -- mean_d_loss: 2.85362482, mean_g_loss: 1013.46520996\n",
            "Epoch:  98 Step:   362  time: 1.344373 s d_loss: 0.98628193, g_loss: 1152.46594238 -- mean_d_loss: 2.84216881, mean_g_loss: 1014.31799316\n",
            "Epoch:  98 Step:   363  time: 1.321220 s d_loss: 1.43449771, g_loss: 1109.10571289 -- mean_d_loss: 2.83358550, mean_g_loss: 1014.89593506\n",
            "Epoch:  98 Step:   364  time: 1.288685 s d_loss: 0.98464042, g_loss: 951.30743408 -- mean_d_loss: 2.82237983, mean_g_loss: 1014.51062012\n",
            "Epoch:  98 Step:   365  time: 1.292472 s d_loss: 0.80933446, g_loss: 1008.09509277 -- mean_d_loss: 2.81025290, mean_g_loss: 1014.47192383\n",
            "Epoch:  98 Step:   366  time: 1.310039 s d_loss: 1.38170433, g_loss: 970.65881348 -- mean_d_loss: 2.80169868, mean_g_loss: 1014.20959473\n",
            "Epoch:  98 Step:   367  time: 1.312751 s d_loss: 0.76192826, g_loss: 1033.90686035 -- mean_d_loss: 2.78955722, mean_g_loss: 1014.32684326\n",
            "Epoch:  98 Step:   368  time: 1.317002 s d_loss: 20.09210968, g_loss: 1199.23303223 -- mean_d_loss: 2.89193916, mean_g_loss: 1015.42095947\n",
            "Epoch:  98 Step:   369  time: 1.309017 s d_loss: 1.09534824, g_loss: 1047.00512695 -- mean_d_loss: 2.88137102, mean_g_loss: 1015.60668945\n",
            "Epoch:  98 Step:   370  time: 1.310755 s d_loss: 0.90715599, g_loss: 976.06628418 -- mean_d_loss: 2.86982584, mean_g_loss: 1015.37542725\n",
            "Epoch:  98 Step:   371  time: 1.276780 s d_loss: 0.83679450, g_loss: 942.67431641 -- mean_d_loss: 2.85800600, mean_g_loss: 1014.95275879\n",
            "Epoch:  98 Step:   372  time: 1.326193 s d_loss: 0.71511537, g_loss: 1037.97668457 -- mean_d_loss: 2.84561944, mean_g_loss: 1015.08587646\n",
            "Epoch:  98 Step:   373  time: 1.326491 s d_loss: 0.88980103, g_loss: 1073.84851074 -- mean_d_loss: 2.83437896, mean_g_loss: 1015.42358398\n",
            "Epoch:  98 Step:   374  time: 1.314174 s d_loss: 0.68333983, g_loss: 971.67657471 -- mean_d_loss: 2.82208729, mean_g_loss: 1015.17358398\n",
            "Epoch:  98 Step:   375  time: 1.297606 s d_loss: 0.60392863, g_loss: 911.54541016 -- mean_d_loss: 2.80948424, mean_g_loss: 1014.58477783\n",
            "Epoch:  98 Step:   376  time: 1.307288 s d_loss: 0.88550121, g_loss: 963.31921387 -- mean_d_loss: 2.79861426, mean_g_loss: 1014.29510498\n",
            "Epoch:  98 Step:   377  time: 1.298258 s d_loss: 1.04559577, g_loss: 949.64416504 -- mean_d_loss: 2.78876591, mean_g_loss: 1013.93188477\n",
            "Epoch:  98 Step:   378  time: 1.324440 s d_loss: 6.55865908, g_loss: 854.01806641 -- mean_d_loss: 2.80982661, mean_g_loss: 1013.03851318\n",
            "Epoch:  98 Step:   379  time: 1.321113 s d_loss: 1.10477722, g_loss: 1166.52258301 -- mean_d_loss: 2.80035424, mean_g_loss: 1013.89117432\n",
            "Epoch:  98 Step:   380  time: 1.318942 s d_loss: 1.29940760, g_loss: 981.24969482 -- mean_d_loss: 2.79206157, mean_g_loss: 1013.71081543\n",
            "Epoch:  98 Step:   381  time: 1.349998 s d_loss: 0.89956617, g_loss: 1055.55554199 -- mean_d_loss: 2.78166342, mean_g_loss: 1013.94073486\n",
            "Epoch:  98 Step:   382  time: 1.353877 s d_loss: 0.85181731, g_loss: 1096.68896484 -- mean_d_loss: 2.77111769, mean_g_loss: 1014.39294434\n",
            "Epoch:  98 Step:   383  time: 1.296877 s d_loss: 0.98605734, g_loss: 1084.30969238 -- mean_d_loss: 2.76141620, mean_g_loss: 1014.77294922\n",
            "Epoch:  98 Step:   384  time: 1.322814 s d_loss: 0.64815021, g_loss: 869.39062500 -- mean_d_loss: 2.74999332, mean_g_loss: 1013.98706055\n",
            "Epoch:  98 Step:   385  time: 1.326918 s d_loss: 0.71171105, g_loss: 961.84039307 -- mean_d_loss: 2.73903465, mean_g_loss: 1013.70672607\n",
            "Epoch:  98 Step:   386  time: 1.338949 s d_loss: 0.65466547, g_loss: 945.97656250 -- mean_d_loss: 2.72788835, mean_g_loss: 1013.34460449\n",
            "Epoch:  98 Step:   387  time: 1.312057 s d_loss: 1.25537264, g_loss: 1046.38867188 -- mean_d_loss: 2.72005582, mean_g_loss: 1013.52038574\n",
            "Epoch:  98 Step:   388  time: 1.324467 s d_loss: 0.86127913, g_loss: 1338.12622070 -- mean_d_loss: 2.71022081, mean_g_loss: 1015.23785400\n",
            "Epoch:  98 Step:   389  time: 1.321237 s d_loss: 0.68420422, g_loss: 985.06530762 -- mean_d_loss: 2.69955754, mean_g_loss: 1015.07904053\n",
            "Epoch:  98 Step:   390  time: 1.300911 s d_loss: 0.81140262, g_loss: 990.98236084 -- mean_d_loss: 2.68967199, mean_g_loss: 1014.95288086\n",
            "Epoch:  98 Step:   391  time: 1.334554 s d_loss: 0.82158417, g_loss: 1140.36694336 -- mean_d_loss: 2.67994237, mean_g_loss: 1015.60601807\n",
            "Epoch:  98 Step:   392  time: 1.338708 s d_loss: 0.66362834, g_loss: 1055.39965820 -- mean_d_loss: 2.66949534, mean_g_loss: 1015.81225586\n",
            "Epoch:  98 Step:   393  time: 1.321249 s d_loss: 11.60130596, g_loss: 983.19769287 -- mean_d_loss: 2.71553564, mean_g_loss: 1015.64416504\n",
            "Epoch:  98 Step:   394  time: 1.310741 s d_loss: 1.26563847, g_loss: 997.25970459 -- mean_d_loss: 2.70810008, mean_g_loss: 1015.54992676\n",
            "Epoch:  98 Step:   395  time: 1.348563 s d_loss: 1.63703907, g_loss: 1322.74645996 -- mean_d_loss: 2.70263553, mean_g_loss: 1017.11724854\n",
            "Epoch:  98 Step:   396  time: 1.341873 s d_loss: 0.79497617, g_loss: 1056.24230957 -- mean_d_loss: 2.69295192, mean_g_loss: 1017.31591797\n",
            "Epoch:  98 Step:   397  time: 1.289619 s d_loss: 0.87185705, g_loss: 1022.62475586 -- mean_d_loss: 2.68375468, mean_g_loss: 1017.34271240\n",
            "Epoch:  98 Step:   398  time: 1.294854 s d_loss: 1.06886566, g_loss: 1109.96484375 -- mean_d_loss: 2.67563963, mean_g_loss: 1017.80816650\n",
            "Epoch:  98 Step:   399  time: 1.332650 s d_loss: 0.93764424, g_loss: 989.45245361 -- mean_d_loss: 2.66694951, mean_g_loss: 1017.66638184\n",
            "Epoch:  98 Step:   400  time: 1.316081 s d_loss: 1.11827385, g_loss: 1044.56384277 -- mean_d_loss: 1.11827385, mean_g_loss: 1044.56384277\n",
            "Epoch:  98 Step:   401  time: 1.339567 s d_loss: 1.33791602, g_loss: 1109.15893555 -- mean_d_loss: 1.22809494, mean_g_loss: 1076.86132812\n",
            "Epoch:  98 Step:   402  time: 1.317408 s d_loss: 0.67595309, g_loss: 1024.45715332 -- mean_d_loss: 1.04404771, mean_g_loss: 1059.39318848\n",
            "Epoch:  98 Step:   403  time: 1.289594 s d_loss: 0.53584552, g_loss: 964.60595703 -- mean_d_loss: 0.91699713, mean_g_loss: 1035.69641113\n",
            "Epoch:  98 Step:   404  time: 1.312043 s d_loss: 0.86847293, g_loss: 933.22937012 -- mean_d_loss: 0.90729225, mean_g_loss: 1015.20300293\n",
            "Epoch:  98 Step:   405  time: 1.321811 s d_loss: 0.79435450, g_loss: 1131.43725586 -- mean_d_loss: 0.88846928, mean_g_loss: 1034.57531738\n",
            "Epoch:  98 Step:   406  time: 1.337650 s d_loss: 0.91930878, g_loss: 969.70056152 -- mean_d_loss: 0.89287490, mean_g_loss: 1025.30749512\n",
            "Epoch:  98 Step:   407  time: 1.349113 s d_loss: 1.44515967, g_loss: 1087.74072266 -- mean_d_loss: 0.96191049, mean_g_loss: 1033.11169434\n",
            "Epoch:  98 Step:   408  time: 1.330959 s d_loss: 0.57696015, g_loss: 989.08624268 -- mean_d_loss: 0.91913825, mean_g_loss: 1028.21997070\n",
            "Epoch:  98 Step:   409  time: 1.293358 s d_loss: 0.68232149, g_loss: 916.84191895 -- mean_d_loss: 0.89545661, mean_g_loss: 1017.08215332\n",
            "Epoch:  98 Step:   410  time: 1.330951 s d_loss: 0.81976390, g_loss: 942.90557861 -- mean_d_loss: 0.88857549, mean_g_loss: 1010.33880615\n",
            "Epoch:  98 Step:   411  time: 1.345159 s d_loss: 0.97410232, g_loss: 1074.41931152 -- mean_d_loss: 0.89570266, mean_g_loss: 1015.67877197\n",
            "Epoch:  98 Step:   412  time: 1.329138 s d_loss: 0.90134650, g_loss: 1059.78112793 -- mean_d_loss: 0.89613682, mean_g_loss: 1019.07128906\n",
            "Epoch:  98 Step:   413  time: 1.330888 s d_loss: 0.73769754, g_loss: 948.83789062 -- mean_d_loss: 0.88481969, mean_g_loss: 1014.05462646\n",
            "Epoch:  98 Step:   414  time: 1.326009 s d_loss: 2.07942438, g_loss: 1024.58996582 -- mean_d_loss: 0.96446002, mean_g_loss: 1014.75695801\n",
            "Epoch:  98 Step:   415  time: 1.323638 s d_loss: 1.48599422, g_loss: 1059.25610352 -- mean_d_loss: 0.99705589, mean_g_loss: 1017.53814697\n",
            "Epoch:  98 Step:   416  time: 1.294502 s d_loss: 0.76695484, g_loss: 911.44531250 -- mean_d_loss: 0.98352051, mean_g_loss: 1011.29736328\n",
            "Epoch:  98 Step:   417  time: 1.344089 s d_loss: 0.69738770, g_loss: 887.94311523 -- mean_d_loss: 0.96762425, mean_g_loss: 1004.44433594\n",
            "Epoch:  98 Step:   418  time: 1.340019 s d_loss: 1.12322080, g_loss: 958.21044922 -- mean_d_loss: 0.97581351, mean_g_loss: 1002.01098633\n",
            "Epoch:  98 Step:   419  time: 1.323309 s d_loss: 0.87118661, g_loss: 974.07727051 -- mean_d_loss: 0.97058219, mean_g_loss: 1000.61437988\n",
            "Epoch:  98 Step:   420  time: 1.324671 s d_loss: 0.60041159, g_loss: 913.85546875 -- mean_d_loss: 0.95295507, mean_g_loss: 996.48297119\n",
            "Epoch:  98 Step:   421  time: 1.322321 s d_loss: 0.71542561, g_loss: 955.05969238 -- mean_d_loss: 0.94215828, mean_g_loss: 994.60015869\n",
            "Epoch:  98 Step:   422  time: 1.323637 s d_loss: 0.77278954, g_loss: 964.97119141 -- mean_d_loss: 0.93479437, mean_g_loss: 993.31188965\n",
            "Epoch:  98 Step:   423  time: 1.318744 s d_loss: 0.63158339, g_loss: 1026.34472656 -- mean_d_loss: 0.92216063, mean_g_loss: 994.68829346\n",
            "Epoch:  98 Step:   424  time: 1.300814 s d_loss: 2.15512872, g_loss: 1102.80297852 -- mean_d_loss: 0.97147936, mean_g_loss: 999.01287842\n",
            "Epoch:  98 Step:   425  time: 1.310995 s d_loss: 0.85053742, g_loss: 1076.46936035 -- mean_d_loss: 0.96682775, mean_g_loss: 1001.99194336\n",
            "Epoch:  98 Step:   426  time: 1.334934 s d_loss: 18.71007156, g_loss: 1076.56323242 -- mean_d_loss: 1.62398505, mean_g_loss: 1004.75384521\n",
            "Epoch:  98 Step:   427  time: 1.299949 s d_loss: 2.59488583, g_loss: 1074.54797363 -- mean_d_loss: 1.65866005, mean_g_loss: 1007.24652100\n",
            "Epoch:  98 Step:   428  time: 1.298422 s d_loss: 1.05479884, g_loss: 1035.95617676 -- mean_d_loss: 1.63783729, mean_g_loss: 1008.23651123\n",
            "Epoch:  98 Step:   429  time: 1.319086 s d_loss: 0.99951798, g_loss: 1022.07922363 -- mean_d_loss: 1.61655998, mean_g_loss: 1008.69799805\n",
            "Epoch:  98 Step:   430  time: 1.298836 s d_loss: 65.44541931, g_loss: 1067.75573730 -- mean_d_loss: 3.67555523, mean_g_loss: 1010.60308838\n",
            "Epoch:  98 Step:   431  time: 1.298532 s d_loss: 2.84816837, g_loss: 1128.13989258 -- mean_d_loss: 3.64969945, mean_g_loss: 1014.27612305\n",
            "Epoch:  98 Step:   432  time: 1.284070 s d_loss: 3.37918711, g_loss: 920.79077148 -- mean_d_loss: 3.64150214, mean_g_loss: 1011.44317627\n",
            "Epoch:  98 Step:   433  time: 1.343968 s d_loss: 10.83761787, g_loss: 974.21807861 -- mean_d_loss: 3.85315251, mean_g_loss: 1010.34832764\n",
            "Epoch:  98 Step:   434  time: 1.319774 s d_loss: 0.96298003, g_loss: 1022.70208740 -- mean_d_loss: 3.77057624, mean_g_loss: 1010.70135498\n",
            "Epoch:  98 Step:   435  time: 1.323904 s d_loss: 0.98161370, g_loss: 919.81628418 -- mean_d_loss: 3.69310498, mean_g_loss: 1008.17675781\n",
            "Epoch:  98 Step:   436  time: 1.321495 s d_loss: 7.08012676, g_loss: 1077.12158203 -- mean_d_loss: 3.78464603, mean_g_loss: 1010.04010010\n",
            "Epoch:  98 Step:   437  time: 1.315319 s d_loss: 0.85581243, g_loss: 865.52612305 -- mean_d_loss: 3.70757174, mean_g_loss: 1006.23712158\n",
            "Epoch:  98 Step:   438  time: 1.306335 s d_loss: 3.06581378, g_loss: 1132.77319336 -- mean_d_loss: 3.69111633, mean_g_loss: 1009.48168945\n",
            "Epoch:  98 Step:   439  time: 1.322981 s d_loss: 1.16143048, g_loss: 890.36102295 -- mean_d_loss: 3.62787437, mean_g_loss: 1006.50360107\n",
            "Epoch:  98 Step:   440  time: 1.301850 s d_loss: 1.21957004, g_loss: 1239.15185547 -- mean_d_loss: 3.56913543, mean_g_loss: 1012.17797852\n",
            "Epoch:  98 Step:   441  time: 1.297232 s d_loss: 0.66986918, g_loss: 968.35815430 -- mean_d_loss: 3.50010538, mean_g_loss: 1011.13464355\n",
            "Epoch:  98 Step:   442  time: 1.286751 s d_loss: 1.00984144, g_loss: 997.40490723 -- mean_d_loss: 3.44219232, mean_g_loss: 1010.81542969\n",
            "Epoch:  98 Step:   443  time: 1.302001 s d_loss: 0.85618496, g_loss: 1021.74035645 -- mean_d_loss: 3.38341928, mean_g_loss: 1011.06372070\n",
            "Epoch:  98 Step:   444  time: 1.319187 s d_loss: 1.00283015, g_loss: 907.47045898 -- mean_d_loss: 3.33051729, mean_g_loss: 1008.76165771\n",
            "Epoch:  98 Step:   445  time: 1.321990 s d_loss: 0.78390175, g_loss: 1084.02429199 -- mean_d_loss: 3.27515602, mean_g_loss: 1010.39776611\n",
            "Epoch:  98 Step:   446  time: 1.325372 s d_loss: 1.11114991, g_loss: 1131.01611328 -- mean_d_loss: 3.22911334, mean_g_loss: 1012.96411133\n",
            "Epoch:  98 Step:   447  time: 1.322904 s d_loss: 3.69644260, g_loss: 981.28613281 -- mean_d_loss: 3.23884940, mean_g_loss: 1012.30413818\n",
            "Epoch:  98 Step:   448  time: 1.320531 s d_loss: 0.82599562, g_loss: 1089.64599609 -- mean_d_loss: 3.18960738, mean_g_loss: 1013.88250732\n",
            "Epoch:  98 Step:   449  time: 1.332691 s d_loss: 6.50056934, g_loss: 1195.97180176 -- mean_d_loss: 3.25582647, mean_g_loss: 1017.52429199\n",
            "Epoch:  98 Step:   450  time: 1.316587 s d_loss: 1.02463531, g_loss: 1114.08374023 -- mean_d_loss: 3.21207738, mean_g_loss: 1019.41760254\n",
            "Epoch:  98 Step:   451  time: 1.325279 s d_loss: 1.11109877, g_loss: 1075.36401367 -- mean_d_loss: 3.17167401, mean_g_loss: 1020.49346924\n",
            "Epoch:  98 Step:   452  time: 1.323165 s d_loss: 3.96535349, g_loss: 1169.02441406 -- mean_d_loss: 3.18664885, mean_g_loss: 1023.29589844\n",
            "Epoch:  98 Step:   453  time: 1.351409 s d_loss: 0.79749638, g_loss: 990.27886963 -- mean_d_loss: 3.14240551, mean_g_loss: 1022.68444824\n",
            "Epoch:  98 Step:   454  time: 1.295609 s d_loss: 2.88370490, g_loss: 1098.84289551 -- mean_d_loss: 3.13770175, mean_g_loss: 1024.06921387\n",
            "Epoch:  98 Step:   455  time: 1.311606 s d_loss: 1.25290966, g_loss: 1164.47216797 -- mean_d_loss: 3.10404468, mean_g_loss: 1026.57641602\n",
            "Epoch:  98 Step:   456  time: 1.288705 s d_loss: 0.82323462, g_loss: 1059.30834961 -- mean_d_loss: 3.06403065, mean_g_loss: 1027.15063477\n",
            "Epoch:  98 Step:   457  time: 1.337599 s d_loss: 1.39733577, g_loss: 825.94091797 -- mean_d_loss: 3.03529453, mean_g_loss: 1023.68151855\n",
            "Epoch:  98 Step:   458  time: 1.327958 s d_loss: 1.37295032, g_loss: 985.39831543 -- mean_d_loss: 3.00711942, mean_g_loss: 1023.03265381\n",
            "Epoch:  98 Step:   459  time: 1.302934 s d_loss: 1.70544684, g_loss: 948.15295410 -- mean_d_loss: 2.98542476, mean_g_loss: 1021.78460693\n",
            "Epoch:  98 Step:   460  time: 1.290587 s d_loss: 2.49733996, g_loss: 920.88208008 -- mean_d_loss: 2.97742343, mean_g_loss: 1020.13049316\n",
            "Epoch:  98 Step:   461  time: 1.305119 s d_loss: 35.33354568, g_loss: 1066.07055664 -- mean_d_loss: 3.49929643, mean_g_loss: 1020.87145996\n",
            "Epoch:  98 Step:   462  time: 1.319990 s d_loss: 1.11929047, g_loss: 1098.22863770 -- mean_d_loss: 3.46151853, mean_g_loss: 1022.09936523\n",
            "Epoch:  98 Step:   463  time: 1.317774 s d_loss: 1.03461027, g_loss: 1057.81469727 -- mean_d_loss: 3.42359805, mean_g_loss: 1022.65747070\n",
            "Epoch:  98 Step:   464  time: 1.326745 s d_loss: 1.19727409, g_loss: 1074.42163086 -- mean_d_loss: 3.38934708, mean_g_loss: 1023.45385742\n",
            "Epoch:  98 Step:   465  time: 1.330678 s d_loss: 1.66216898, g_loss: 1077.72717285 -- mean_d_loss: 3.36317778, mean_g_loss: 1024.27612305\n",
            "Epoch:  98 Step:   466  time: 1.335077 s d_loss: 6.20324183, g_loss: 972.63854980 -- mean_d_loss: 3.40556669, mean_g_loss: 1023.50549316\n",
            "Epoch:  98 Step:   467  time: 1.334620 s d_loss: 22.63825607, g_loss: 1029.19165039 -- mean_d_loss: 3.68840051, mean_g_loss: 1023.58917236\n",
            "Epoch:  98 Step:   468  time: 1.322663 s d_loss: 1.45947385, g_loss: 1165.03320312 -- mean_d_loss: 3.65609717, mean_g_loss: 1025.63903809\n",
            "Epoch:  98 Step:   469  time: 1.305857 s d_loss: 4.34850645, g_loss: 1037.15832520 -- mean_d_loss: 3.66598868, mean_g_loss: 1025.80358887\n",
            "Epoch:  98 Step:   470  time: 1.336772 s d_loss: 1.08086276, g_loss: 1078.20898438 -- mean_d_loss: 3.62957859, mean_g_loss: 1026.54174805\n",
            "Epoch:  98 Step:   471  time: 1.299983 s d_loss: 18.17207718, g_loss: 1077.76538086 -- mean_d_loss: 3.83155775, mean_g_loss: 1027.25317383\n",
            "Epoch:  98 Step:   472  time: 1.323185 s d_loss: 2.72594142, g_loss: 1045.38623047 -- mean_d_loss: 3.81641245, mean_g_loss: 1027.50146484\n",
            "Epoch:  98 Step:   473  time: 1.321562 s d_loss: 1.44910872, g_loss: 798.61267090 -- mean_d_loss: 3.78442168, mean_g_loss: 1024.40832520\n",
            "Epoch:  98 Step:   474  time: 1.325274 s d_loss: 3.26247430, g_loss: 1017.54351807 -- mean_d_loss: 3.77746248, mean_g_loss: 1024.31689453\n",
            "Epoch:  98 Step:   475  time: 1.301152 s d_loss: 0.63828117, g_loss: 886.91564941 -- mean_d_loss: 3.73615742, mean_g_loss: 1022.50897217\n",
            "Epoch:  98 Step:   476  time: 1.297830 s d_loss: 0.83621156, g_loss: 978.40655518 -- mean_d_loss: 3.69849586, mean_g_loss: 1021.93615723\n",
            "Epoch:  98 Step:   477  time: 1.336107 s d_loss: 1.29906893, g_loss: 897.39044189 -- mean_d_loss: 3.66773391, mean_g_loss: 1020.33941650\n",
            "Epoch:  98 Step:   478  time: 1.296896 s d_loss: 0.81545264, g_loss: 905.63903809 -- mean_d_loss: 3.63162923, mean_g_loss: 1018.88757324\n",
            "Epoch:  98 Step:   479  time: 1.326707 s d_loss: 0.94156998, g_loss: 1007.28051758 -- mean_d_loss: 3.59800339, mean_g_loss: 1018.74249268\n",
            "Epoch:  98 Step:   480  time: 1.325234 s d_loss: 0.86788130, g_loss: 909.48181152 -- mean_d_loss: 3.56429839, mean_g_loss: 1017.39361572\n",
            "Epoch:  98 Step:   481  time: 1.329361 s d_loss: 0.89046252, g_loss: 1002.35650635 -- mean_d_loss: 3.53169060, mean_g_loss: 1017.21026611\n",
            "Epoch:  98 Step:   482  time: 1.301404 s d_loss: 0.92720318, g_loss: 1073.82202148 -- mean_d_loss: 3.50031137, mean_g_loss: 1017.89233398\n",
            "Epoch:  98 Step:   483  time: 1.293346 s d_loss: 1.10470009, g_loss: 956.13098145 -- mean_d_loss: 3.47179222, mean_g_loss: 1017.15710449\n",
            "Epoch:  98 Step:   484  time: 1.325679 s d_loss: 0.77644777, g_loss: 945.59143066 -- mean_d_loss: 3.44008255, mean_g_loss: 1016.31518555\n",
            "Epoch:  98 Step:   485  time: 1.342646 s d_loss: 0.84673870, g_loss: 914.37658691 -- mean_d_loss: 3.40992737, mean_g_loss: 1015.12982178\n",
            "Epoch:  98 Step:   486  time: 1.327891 s d_loss: 1.22043288, g_loss: 1025.05078125 -- mean_d_loss: 3.38476062, mean_g_loss: 1015.24389648\n",
            "Epoch:  98 Step:   487  time: 1.312747 s d_loss: 0.88564616, g_loss: 1103.52001953 -- mean_d_loss: 3.35636163, mean_g_loss: 1016.24707031\n",
            "Epoch:  98 Step:   488  time: 1.292546 s d_loss: 7.99851179, g_loss: 1007.13751221 -- mean_d_loss: 3.40852070, mean_g_loss: 1016.14477539\n",
            "Epoch:  98 Step:   489  time: 1.307150 s d_loss: 1.26239896, g_loss: 937.80255127 -- mean_d_loss: 3.38467479, mean_g_loss: 1015.27429199\n",
            "Epoch:  98 Step:   490  time: 1.289981 s d_loss: 1.43097806, g_loss: 944.03479004 -- mean_d_loss: 3.36320543, mean_g_loss: 1014.49139404\n",
            "Epoch:  98 Step:   491  time: 1.315054 s d_loss: 0.95481628, g_loss: 1125.61865234 -- mean_d_loss: 3.33702707, mean_g_loss: 1015.69927979\n",
            "Epoch:  98 Step:   492  time: 1.299358 s d_loss: 0.85997689, g_loss: 862.36779785 -- mean_d_loss: 3.31039238, mean_g_loss: 1014.05059814\n",
            "Epoch:  98 Step:   493  time: 1.320790 s d_loss: 0.63156503, g_loss: 1151.37512207 -- mean_d_loss: 3.28189421, mean_g_loss: 1015.51147461\n",
            "Epoch:  98 Step:   494  time: 1.287715 s d_loss: 0.73635083, g_loss: 935.20141602 -- mean_d_loss: 3.25509906, mean_g_loss: 1014.66613770\n",
            "Epoch:  98 Step:   495  time: 1.353661 s d_loss: 2.34806061, g_loss: 924.40917969 -- mean_d_loss: 3.24565053, mean_g_loss: 1013.72589111\n",
            "Epoch:  98 Step:   496  time: 1.319247 s d_loss: 1.38855338, g_loss: 1041.93969727 -- mean_d_loss: 3.22650528, mean_g_loss: 1014.01672363\n",
            "Epoch:  98 Step:   497  time: 1.315415 s d_loss: 0.67727822, g_loss: 983.46453857 -- mean_d_loss: 3.20049262, mean_g_loss: 1013.70495605\n",
            "Epoch:  98 Step:   498  time: 1.293810 s d_loss: 0.93483353, g_loss: 901.92639160 -- mean_d_loss: 3.17760730, mean_g_loss: 1012.57592773\n",
            "Epoch:  98 Step:   499  time: 1.313862 s d_loss: 0.56912303, g_loss: 1048.39746094 -- mean_d_loss: 3.15152264, mean_g_loss: 1012.93414307\n",
            "Epoch:  98 Step:   500  time: 1.329312 s d_loss: 0.78666371, g_loss: 1001.39526367 -- mean_d_loss: 3.12810802, mean_g_loss: 1012.81994629\n",
            "Epoch:  98 Step:   501  time: 1.295141 s d_loss: 0.84887576, g_loss: 1218.34814453 -- mean_d_loss: 3.10576248, mean_g_loss: 1014.83496094\n",
            "Epoch:  98 Step:   502  time: 1.287477 s d_loss: 2.63574719, g_loss: 935.81488037 -- mean_d_loss: 3.10119915, mean_g_loss: 1014.06774902\n",
            "Epoch:  98 Step:   503  time: 1.324142 s d_loss: 1.02035594, g_loss: 995.15832520 -- mean_d_loss: 3.08119106, mean_g_loss: 1013.88586426\n",
            "Epoch:  98 Step:   504  time: 1.311579 s d_loss: 2.28640938, g_loss: 1177.34350586 -- mean_d_loss: 3.07362175, mean_g_loss: 1015.44262695\n",
            "Epoch:  98 Step:   505  time: 1.306768 s d_loss: 2.25963736, g_loss: 1140.90991211 -- mean_d_loss: 3.06594276, mean_g_loss: 1016.62628174\n",
            "Epoch:  98 Step:   506  time: 1.357539 s d_loss: 1.24337888, g_loss: 908.40435791 -- mean_d_loss: 3.04890943, mean_g_loss: 1015.61486816\n",
            "Epoch:  98 Step:   507  time: 1.316254 s d_loss: 0.80514359, g_loss: 979.09216309 -- mean_d_loss: 3.02813387, mean_g_loss: 1015.27667236\n",
            "Epoch:  98 Step:   508  time: 1.298481 s d_loss: 1.09977245, g_loss: 1012.14050293 -- mean_d_loss: 3.01044226, mean_g_loss: 1015.24792480\n",
            "Epoch:  98 Step:   509  time: 1.323510 s d_loss: 0.77677613, g_loss: 977.02734375 -- mean_d_loss: 2.99013615, mean_g_loss: 1014.90045166\n",
            "Epoch:  98 Step:   510  time: 1.330807 s d_loss: 0.66909599, g_loss: 1089.81542969 -- mean_d_loss: 2.96922588, mean_g_loss: 1015.57531738\n",
            "Epoch:  98 Step:   511  time: 1.307736 s d_loss: 0.53857172, g_loss: 973.25921631 -- mean_d_loss: 2.94752359, mean_g_loss: 1015.19744873\n",
            "Epoch:  98 Step:   512  time: 1.317422 s d_loss: 0.77314162, g_loss: 1085.61926270 -- mean_d_loss: 2.92828131, mean_g_loss: 1015.82067871\n",
            "Epoch:  98 Step:   513  time: 1.323709 s d_loss: 1.31264651, g_loss: 891.94921875 -- mean_d_loss: 2.91410899, mean_g_loss: 1014.73413086\n",
            "Epoch:  98 Step:   514  time: 1.281232 s d_loss: 2.16347599, g_loss: 1015.09954834 -- mean_d_loss: 2.90758181, mean_g_loss: 1014.73730469\n",
            "Epoch:  98 Step:   515  time: 1.322944 s d_loss: 1.15133214, g_loss: 990.43591309 -- mean_d_loss: 2.89244175, mean_g_loss: 1014.52783203\n",
            "Epoch:  98 Step:   516  time: 1.332924 s d_loss: 1.44226921, g_loss: 1014.01013184 -- mean_d_loss: 2.88004708, mean_g_loss: 1014.52337646\n",
            "Epoch:  98 Step:   517  time: 1.309005 s d_loss: 0.58923513, g_loss: 1046.85437012 -- mean_d_loss: 2.86063337, mean_g_loss: 1014.79736328\n",
            "Epoch:  98 Step:   518  time: 1.330328 s d_loss: 0.78671968, g_loss: 1223.99560547 -- mean_d_loss: 2.84320545, mean_g_loss: 1016.55529785\n",
            "Epoch:  98 Step:   519  time: 1.301534 s d_loss: 2.56442094, g_loss: 897.60192871 -- mean_d_loss: 2.84088230, mean_g_loss: 1015.56402588\n",
            "Epoch:  98 Step:   520  time: 1.315860 s d_loss: 0.75865120, g_loss: 997.60375977 -- mean_d_loss: 2.82367373, mean_g_loss: 1015.41552734\n",
            "Epoch:  98 Step:   521  time: 1.325595 s d_loss: 0.56028163, g_loss: 988.64208984 -- mean_d_loss: 2.80512118, mean_g_loss: 1015.19610596\n",
            "Epoch:  98 Step:   522  time: 1.317426 s d_loss: 0.81504595, g_loss: 1010.73059082 -- mean_d_loss: 2.78894162, mean_g_loss: 1015.15979004\n",
            "Epoch:  98 Step:   523  time: 1.306545 s d_loss: 0.78087115, g_loss: 896.66430664 -- mean_d_loss: 2.77274776, mean_g_loss: 1014.20422363\n",
            "Epoch:  98 Step:   524  time: 1.305768 s d_loss: 0.78758430, g_loss: 1016.94885254 -- mean_d_loss: 2.75686646, mean_g_loss: 1014.22613525\n",
            "Epoch:  98 Step:   525  time: 1.321542 s d_loss: 0.73814404, g_loss: 1042.26708984 -- mean_d_loss: 2.74084496, mean_g_loss: 1014.44866943\n",
            "Epoch:  98 Step:   526  time: 1.318459 s d_loss: 1.93260658, g_loss: 1046.63610840 -- mean_d_loss: 2.73448086, mean_g_loss: 1014.70208740\n",
            "Epoch:  98 Step:   527  time: 1.291893 s d_loss: 0.69829738, g_loss: 1215.54528809 -- mean_d_loss: 2.71857333, mean_g_loss: 1016.27117920\n",
            "Epoch:  98 Step:   528  time: 1.349873 s d_loss: 0.70834696, g_loss: 888.33264160 -- mean_d_loss: 2.70299006, mean_g_loss: 1015.27941895\n",
            "Epoch:  98 Step:   529  time: 1.321627 s d_loss: 0.82634395, g_loss: 1059.00366211 -- mean_d_loss: 2.68855453, mean_g_loss: 1015.61572266\n",
            "Epoch:  98 Step:   530  time: 1.291313 s d_loss: 1.50773382, g_loss: 935.10009766 -- mean_d_loss: 2.67954040, mean_g_loss: 1015.00109863\n",
            "Epoch:  98 Step:   531  time: 1.335766 s d_loss: 0.65182841, g_loss: 957.76123047 -- mean_d_loss: 2.66417909, mean_g_loss: 1014.56744385\n",
            "Epoch:  98 Step:   532  time: 1.330186 s d_loss: 0.80984950, g_loss: 982.77648926 -- mean_d_loss: 2.65023661, mean_g_loss: 1014.32849121\n",
            "Epoch:  98 Step:   533  time: 1.282920 s d_loss: 0.75705117, g_loss: 1003.05255127 -- mean_d_loss: 2.63610840, mean_g_loss: 1014.24426270\n",
            "Epoch:  98 Step:   534  time: 1.306210 s d_loss: 0.77996540, g_loss: 1034.98657227 -- mean_d_loss: 2.62235928, mean_g_loss: 1014.39788818\n",
            "Epoch:  98 Step:   535  time: 1.319927 s d_loss: 2.69531131, g_loss: 1046.38269043 -- mean_d_loss: 2.62289572, mean_g_loss: 1014.63305664\n",
            "Epoch:  98 Step:   536  time: 1.327724 s d_loss: 0.96169877, g_loss: 1148.07690430 -- mean_d_loss: 2.61077023, mean_g_loss: 1015.60711670\n",
            "Epoch:  98 Step:   537  time: 1.297584 s d_loss: 41.56209946, g_loss: 1047.98144531 -- mean_d_loss: 2.89302611, mean_g_loss: 1015.84173584\n",
            "Epoch:  98 Step:   538  time: 1.333211 s d_loss: 1.71776855, g_loss: 1208.69555664 -- mean_d_loss: 2.88457108, mean_g_loss: 1017.22918701\n",
            "Epoch:  98 Step:   539  time: 1.332819 s d_loss: 11.52503490, g_loss: 940.19812012 -- mean_d_loss: 2.94628859, mean_g_loss: 1016.67901611\n",
            "Epoch:  98 Step:   540  time: 1.315296 s d_loss: 12.32686806, g_loss: 948.62341309 -- mean_d_loss: 3.01281762, mean_g_loss: 1016.19635010\n",
            "Epoch:  98 Step:   541  time: 1.335484 s d_loss: 2.55116987, g_loss: 979.59375000 -- mean_d_loss: 3.00956655, mean_g_loss: 1015.93859863\n",
            "Epoch:  98 Step:   542  time: 1.324206 s d_loss: 1.00502121, g_loss: 1101.08959961 -- mean_d_loss: 2.99554896, mean_g_loss: 1016.53411865\n",
            "Epoch:  98 Step:   543  time: 1.329263 s d_loss: 4.61997557, g_loss: 1015.22259521 -- mean_d_loss: 3.00682950, mean_g_loss: 1016.52496338\n",
            "Epoch:  98 Step:   544  time: 1.296204 s d_loss: 3.28639364, g_loss: 1097.23937988 -- mean_d_loss: 3.00875759, mean_g_loss: 1017.08154297\n",
            "Epoch:  98 Step:   545  time: 1.322652 s d_loss: 1.74411464, g_loss: 1191.02087402 -- mean_d_loss: 3.00009584, mean_g_loss: 1018.27288818\n",
            "Epoch:  98 Step:   546  time: 1.312180 s d_loss: 0.93466234, g_loss: 942.39721680 -- mean_d_loss: 2.98604512, mean_g_loss: 1017.75671387\n",
            "Epoch:  98 Step:   547  time: 1.324080 s d_loss: 1.10151970, g_loss: 1022.00158691 -- mean_d_loss: 2.97331190, mean_g_loss: 1017.78533936\n",
            "Epoch:  98 Step:   548  time: 1.341324 s d_loss: 0.75195897, g_loss: 1024.19250488 -- mean_d_loss: 2.95840359, mean_g_loss: 1017.82830811\n",
            "Epoch:  98 Step:   549  time: 1.325606 s d_loss: 0.71071172, g_loss: 1165.56457520 -- mean_d_loss: 2.94341898, mean_g_loss: 1018.81323242\n",
            "Epoch:  98 Step:   550  time: 1.327672 s d_loss: 0.88331783, g_loss: 997.61145020 -- mean_d_loss: 2.92977595, mean_g_loss: 1018.67279053\n",
            "Epoch:  98 Step:   551  time: 1.325203 s d_loss: 0.48876208, g_loss: 972.58734131 -- mean_d_loss: 2.91371679, mean_g_loss: 1018.36962891\n",
            "Epoch:  98 Step:   552  time: 1.321812 s d_loss: 1.35337567, g_loss: 1099.11096191 -- mean_d_loss: 2.90351844, mean_g_loss: 1018.89733887\n",
            "Epoch:  98 Step:   553  time: 1.323780 s d_loss: 2.42368269, g_loss: 1041.25634766 -- mean_d_loss: 2.90040255, mean_g_loss: 1019.04254150\n",
            "Epoch:  98 Step:   554  time: 1.318034 s d_loss: 1.75452495, g_loss: 1095.28857422 -- mean_d_loss: 2.89300966, mean_g_loss: 1019.53436279\n",
            "Epoch:  98 Step:   555  time: 1.334723 s d_loss: 0.79169714, g_loss: 989.61688232 -- mean_d_loss: 2.87953973, mean_g_loss: 1019.34252930\n",
            "Epoch:  98 Step:   556  time: 1.324871 s d_loss: 1.11697543, g_loss: 954.30041504 -- mean_d_loss: 2.86831307, mean_g_loss: 1018.92822266\n",
            "Epoch:  98 Step:   557  time: 1.303963 s d_loss: 3.61752081, g_loss: 940.26757812 -- mean_d_loss: 2.87305498, mean_g_loss: 1018.43035889\n",
            "Epoch:  98 Step:   558  time: 1.314976 s d_loss: 20.50257492, g_loss: 1144.92712402 -- mean_d_loss: 2.98393250, mean_g_loss: 1019.22595215\n",
            "Epoch:  98 Step:   559  time: 1.315322 s d_loss: 1.50451040, g_loss: 1079.00952148 -- mean_d_loss: 2.97468615, mean_g_loss: 1019.59960938\n",
            "Epoch:  98 Step:   560  time: 1.303353 s d_loss: 1.19823813, g_loss: 1014.99047852 -- mean_d_loss: 2.96365213, mean_g_loss: 1019.57092285\n",
            "Epoch:  98 Step:   561  time: 1.331451 s d_loss: 1.93917620, g_loss: 1170.84082031 -- mean_d_loss: 2.95732832, mean_g_loss: 1020.50469971\n",
            "Epoch:  98 Step:   562  time: 1.323286 s d_loss: 1.53869617, g_loss: 992.10253906 -- mean_d_loss: 2.94862509, mean_g_loss: 1020.33050537\n",
            "Epoch:  98 Step:   563  time: 1.308916 s d_loss: 1.41530561, g_loss: 956.68859863 -- mean_d_loss: 2.93927550, mean_g_loss: 1019.94244385\n",
            "Epoch:  98 Step:   564  time: 1.327830 s d_loss: 5.26229763, g_loss: 1108.80480957 -- mean_d_loss: 2.95335460, mean_g_loss: 1020.48107910\n",
            "Epoch:  98 Step:   565  time: 1.344949 s d_loss: 1.12660408, g_loss: 949.36730957 -- mean_d_loss: 2.94235015, mean_g_loss: 1020.05273438\n",
            "Epoch:  98 Step:   566  time: 1.332765 s d_loss: 0.84450763, g_loss: 973.39941406 -- mean_d_loss: 2.92978811, mean_g_loss: 1019.77337646\n",
            "Epoch:  98 Step:   567  time: 1.344117 s d_loss: 0.84087378, g_loss: 970.46032715 -- mean_d_loss: 2.91735411, mean_g_loss: 1019.47979736\n",
            "Epoch:  98 Step:   568  time: 1.296933 s d_loss: 0.66299760, g_loss: 930.54846191 -- mean_d_loss: 2.90401483, mean_g_loss: 1018.95361328\n",
            "Epoch:  98 Step:   569  time: 1.299649 s d_loss: 0.74633521, g_loss: 927.41369629 -- mean_d_loss: 2.89132261, mean_g_loss: 1018.41510010\n",
            "Epoch:  98 Step:   570  time: 1.319174 s d_loss: 2.57481813, g_loss: 994.61926270 -- mean_d_loss: 2.88947177, mean_g_loss: 1018.27593994\n",
            "Epoch:  98 Step:   571  time: 1.303925 s d_loss: 1.33117402, g_loss: 958.13244629 -- mean_d_loss: 2.88041186, mean_g_loss: 1017.92620850\n",
            "Epoch:  98 Step:   572  time: 1.306100 s d_loss: 0.71434671, g_loss: 1055.67749023 -- mean_d_loss: 2.86789131, mean_g_loss: 1018.14440918\n",
            "Epoch:  98 Step:   573  time: 1.338833 s d_loss: 0.64130718, g_loss: 918.75439453 -- mean_d_loss: 2.85509491, mean_g_loss: 1017.57318115\n",
            "Epoch:  98 Step:   574  time: 1.325996 s d_loss: 48.62275696, g_loss: 1094.52331543 -- mean_d_loss: 3.11662412, mean_g_loss: 1018.01287842\n",
            "Epoch:  98 Step:   575  time: 1.323540 s d_loss: 2.51726890, g_loss: 969.06518555 -- mean_d_loss: 3.11321878, mean_g_loss: 1017.73474121\n",
            "Epoch:  98 Step:   576  time: 1.328665 s d_loss: 1.51663625, g_loss: 916.87023926 -- mean_d_loss: 3.10419869, mean_g_loss: 1017.16491699\n",
            "Epoch:  98 Step:   577  time: 1.326366 s d_loss: 1.66947210, g_loss: 1027.71166992 -- mean_d_loss: 3.09613872, mean_g_loss: 1017.22418213\n",
            "Epoch:  98 Step:   578  time: 1.351599 s d_loss: 0.99266946, g_loss: 1014.35339355 -- mean_d_loss: 3.08438730, mean_g_loss: 1017.20819092\n",
            "Epoch:  98 Step:   579  time: 1.308220 s d_loss: 4.14729786, g_loss: 989.69097900 -- mean_d_loss: 3.09029245, mean_g_loss: 1017.05529785\n",
            "Epoch:  98 Step:   580  time: 1.313679 s d_loss: 48.99885941, g_loss: 1003.06286621 -- mean_d_loss: 3.34393072, mean_g_loss: 1016.97796631\n",
            "Epoch:  98 Step:   581  time: 1.293795 s d_loss: 2.30295014, g_loss: 926.73657227 -- mean_d_loss: 3.33821130, mean_g_loss: 1016.48211670\n",
            "Epoch:  98 Step:   582  time: 1.334702 s d_loss: 1.49832654, g_loss: 869.70812988 -- mean_d_loss: 3.32815742, mean_g_loss: 1015.68005371\n",
            "Epoch:  98 Step:   583  time: 1.323621 s d_loss: 1.11521447, g_loss: 925.62451172 -- mean_d_loss: 3.31613064, mean_g_loss: 1015.19061279\n",
            "Epoch:  98 Step:   584  time: 1.329073 s d_loss: 1.14430010, g_loss: 945.78979492 -- mean_d_loss: 3.30439091, mean_g_loss: 1014.81555176\n",
            "Epoch:  98 Step:   585  time: 1.321983 s d_loss: 0.78349572, g_loss: 954.07653809 -- mean_d_loss: 3.29083776, mean_g_loss: 1014.48901367\n",
            "Epoch:  98 Step:   586  time: 1.332009 s d_loss: 0.93012911, g_loss: 930.68713379 -- mean_d_loss: 3.27821350, mean_g_loss: 1014.04083252\n",
            "Epoch:  98 Step:   587  time: 1.302586 s d_loss: 1.23940969, g_loss: 1134.66442871 -- mean_d_loss: 3.26736879, mean_g_loss: 1014.68249512\n",
            "Epoch:  98 Step:   588  time: 1.303533 s d_loss: 0.81781268, g_loss: 910.14208984 -- mean_d_loss: 3.25440812, mean_g_loss: 1014.12939453\n",
            "Epoch:  98 Step:   589  time: 1.317372 s d_loss: 0.69803202, g_loss: 1061.35766602 -- mean_d_loss: 3.24095368, mean_g_loss: 1014.37799072\n",
            "Epoch:  98 Step:   590  time: 1.292464 s d_loss: 0.69544923, g_loss: 857.98565674 -- mean_d_loss: 3.22762632, mean_g_loss: 1013.55914307\n",
            "Epoch:  98 Step:   591  time: 1.326778 s d_loss: 0.72990876, g_loss: 808.83026123 -- mean_d_loss: 3.21461749, mean_g_loss: 1012.49285889\n",
            "Epoch:  98 Step:   592  time: 1.332001 s d_loss: 0.64786637, g_loss: 993.14947510 -- mean_d_loss: 3.20131826, mean_g_loss: 1012.39263916\n",
            "Epoch:  98 Step:   593  time: 1.324646 s d_loss: 1.11917043, g_loss: 1059.82189941 -- mean_d_loss: 3.19058537, mean_g_loss: 1012.63714600\n",
            "Epoch:  98 Step:   594  time: 1.316949 s d_loss: 0.87228143, g_loss: 1013.45935059 -- mean_d_loss: 3.17869663, mean_g_loss: 1012.64135742\n",
            "Epoch:  98 Step:   595  time: 1.335046 s d_loss: 13.32249641, g_loss: 964.55303955 -- mean_d_loss: 3.23045063, mean_g_loss: 1012.39599609\n",
            "Epoch:  98 Step:   596  time: 1.289598 s d_loss: 1.35382032, g_loss: 901.13525391 -- mean_d_loss: 3.22092462, mean_g_loss: 1011.83123779\n",
            "Epoch:  98 Step:   597  time: 1.286863 s d_loss: 1.59631848, g_loss: 1037.71582031 -- mean_d_loss: 3.21271944, mean_g_loss: 1011.96197510\n",
            "Epoch:  98 Step:   598  time: 1.350782 s d_loss: 2.64324689, g_loss: 998.96832275 -- mean_d_loss: 3.20985794, mean_g_loss: 1011.89666748\n",
            "Epoch:  98 Step:   599  time: 1.312608 s d_loss: 1.41638947, g_loss: 1200.56237793 -- mean_d_loss: 3.20089054, mean_g_loss: 1012.84002686\n",
            "Epoch:  98 Step:   600  time: 1.290999 s d_loss: 0.93623447, g_loss: 1015.38598633 -- mean_d_loss: 0.93623447, mean_g_loss: 1015.38598633\n",
            "Epoch:  98 Step:   601  time: 1.319368 s d_loss: 0.85616440, g_loss: 1030.98791504 -- mean_d_loss: 0.89619946, mean_g_loss: 1023.18695068\n",
            "Epoch:  98 Step:   602  time: 1.329477 s d_loss: 43.05852509, g_loss: 1009.11730957 -- mean_d_loss: 14.95030880, mean_g_loss: 1018.49707031\n",
            "Epoch:  98 Step:   603  time: 1.331016 s d_loss: 6.25427628, g_loss: 1007.62268066 -- mean_d_loss: 12.77630043, mean_g_loss: 1015.77844238\n",
            "Epoch:  98 Step:   604  time: 1.308977 s d_loss: 8.54170513, g_loss: 1067.14721680 -- mean_d_loss: 11.92938137, mean_g_loss: 1026.05212402\n",
            "Epoch:  98 Step:   605  time: 1.314958 s d_loss: 1.54781914, g_loss: 975.11987305 -- mean_d_loss: 10.19912052, mean_g_loss: 1017.56347656\n",
            "Epoch:  98 Step:   606  time: 1.310403 s d_loss: 5.54267216, g_loss: 963.34893799 -- mean_d_loss: 9.53391361, mean_g_loss: 1009.81854248\n",
            "Epoch:  98 Step:   607  time: 1.307139 s d_loss: 7.43117189, g_loss: 1041.17065430 -- mean_d_loss: 9.27107143, mean_g_loss: 1013.73754883\n",
            "Epoch:  98 Step:   608  time: 1.332392 s d_loss: 1.66076529, g_loss: 935.78131104 -- mean_d_loss: 8.42548180, mean_g_loss: 1005.07574463\n",
            "Epoch:  98 Step:   609  time: 1.308491 s d_loss: 5.37186718, g_loss: 1058.38464355 -- mean_d_loss: 8.12012005, mean_g_loss: 1010.40661621\n",
            "Epoch:  98 Step:   610  time: 1.314559 s d_loss: 1.12277973, g_loss: 988.33190918 -- mean_d_loss: 7.48399830, mean_g_loss: 1008.39984131\n",
            "Epoch:  98 Step:   611  time: 1.321931 s d_loss: 1.12999833, g_loss: 1071.82165527 -- mean_d_loss: 6.95449829, mean_g_loss: 1013.68499756\n",
            "Epoch:  98 Step:   612  time: 1.323501 s d_loss: 17.21432495, g_loss: 906.04260254 -- mean_d_loss: 7.74371576, mean_g_loss: 1005.40484619\n",
            "Epoch:  98 Step:   613  time: 1.294106 s d_loss: 4.92800093, g_loss: 960.12951660 -- mean_d_loss: 7.54259348, mean_g_loss: 1002.17089844\n",
            "Epoch:  98 Step:   614  time: 1.318629 s d_loss: 1.12025881, g_loss: 976.49328613 -- mean_d_loss: 7.11443806, mean_g_loss: 1000.45904541\n",
            "Epoch:  98 Step:   615  time: 1.309626 s d_loss: 0.95971835, g_loss: 1005.44622803 -- mean_d_loss: 6.72976780, mean_g_loss: 1000.77075195\n",
            "Epoch:  98 Step:   616  time: 1.298225 s d_loss: 0.87855309, g_loss: 988.82995605 -- mean_d_loss: 6.38557863, mean_g_loss: 1000.06835938\n",
            "Epoch:  98 Step:   617  time: 1.296709 s d_loss: 0.71738124, g_loss: 946.50683594 -- mean_d_loss: 6.07067919, mean_g_loss: 997.09265137\n",
            "Epoch:  98 Step:   618  time: 1.328446 s d_loss: 47.16487503, g_loss: 1011.57196045 -- mean_d_loss: 8.23353195, mean_g_loss: 997.85473633\n",
            "Epoch:  98 Step:   619  time: 1.315099 s d_loss: 2.27432418, g_loss: 852.46057129 -- mean_d_loss: 7.93557119, mean_g_loss: 990.58508301\n",
            "Epoch:  98 Step:   620  time: 1.293905 s d_loss: 6.87375498, g_loss: 1070.39709473 -- mean_d_loss: 7.88500834, mean_g_loss: 994.38562012\n",
            "Epoch:  98 Step:   621  time: 1.335836 s d_loss: 1.72535825, g_loss: 1042.80773926 -- mean_d_loss: 7.60502434, mean_g_loss: 996.58666992\n",
            "Epoch:  98 Step:   622  time: 1.325672 s d_loss: 1.19093728, g_loss: 1099.39392090 -- mean_d_loss: 7.32615042, mean_g_loss: 1001.05657959\n",
            "Epoch:  98 Step:   623  time: 1.321711 s d_loss: 0.70976734, g_loss: 1031.52111816 -- mean_d_loss: 7.05046797, mean_g_loss: 1002.32592773\n",
            "Epoch:  98 Step:   624  time: 1.296930 s d_loss: 1.00630283, g_loss: 1044.58447266 -- mean_d_loss: 6.80870104, mean_g_loss: 1004.01623535\n",
            "Epoch:  98 Step:   625  time: 1.318499 s d_loss: 1.34223270, g_loss: 1071.19213867 -- mean_d_loss: 6.59845257, mean_g_loss: 1006.59991455\n",
            "Epoch:  98 Step:   626  time: 1.302058 s d_loss: 8.65062523, g_loss: 1126.99279785 -- mean_d_loss: 6.67445898, mean_g_loss: 1011.05889893\n",
            "Epoch:  98 Step:   627  time: 1.289577 s d_loss: 1.49726510, g_loss: 993.62872314 -- mean_d_loss: 6.48955917, mean_g_loss: 1010.43640137\n",
            "Epoch:  98 Step:   628  time: 1.298262 s d_loss: 1.34324861, g_loss: 1039.39599609 -- mean_d_loss: 6.31209993, mean_g_loss: 1011.43499756\n",
            "Epoch:  98 Step:   629  time: 1.321189 s d_loss: 1.64466071, g_loss: 1026.63671875 -- mean_d_loss: 6.15651846, mean_g_loss: 1011.94171143\n",
            "Epoch:  98 Step:   630  time: 1.302800 s d_loss: 1.15321970, g_loss: 909.74084473 -- mean_d_loss: 5.99512148, mean_g_loss: 1008.64489746\n",
            "Epoch:  98 Step:   631  time: 1.287961 s d_loss: 7.08296347, g_loss: 917.14147949 -- mean_d_loss: 6.02911663, mean_g_loss: 1005.78540039\n",
            "Epoch:  98 Step:   632  time: 1.349338 s d_loss: 3.63647032, g_loss: 927.44158936 -- mean_d_loss: 5.95661211, mean_g_loss: 1003.41131592\n",
            "Epoch:  98 Step:   633  time: 1.326081 s d_loss: 18.46602058, g_loss: 974.59509277 -- mean_d_loss: 6.32453585, mean_g_loss: 1002.56378174\n",
            "Epoch:  98 Step:   634  time: 1.324481 s d_loss: 1.56759298, g_loss: 1050.22790527 -- mean_d_loss: 6.18862343, mean_g_loss: 1003.92553711\n",
            "Epoch:  98 Step:   635  time: 1.339428 s d_loss: 0.97681624, g_loss: 1012.89202881 -- mean_d_loss: 6.04385138, mean_g_loss: 1004.17456055\n",
            "Epoch:  98 Step:   636  time: 1.330678 s d_loss: 0.97353375, g_loss: 925.12561035 -- mean_d_loss: 5.90681601, mean_g_loss: 1002.03808594\n",
            "Epoch:  98 Step:   637  time: 1.325648 s d_loss: 1.14591718, g_loss: 985.43835449 -- mean_d_loss: 5.78152895, mean_g_loss: 1001.60125732\n",
            "Epoch:  98 Step:   638  time: 1.333242 s d_loss: 1.14610648, g_loss: 909.03771973 -- mean_d_loss: 5.66267204, mean_g_loss: 999.22784424\n",
            "Epoch:  98 Step:   639  time: 1.324230 s d_loss: 0.82276028, g_loss: 1073.25244141 -- mean_d_loss: 5.54167414, mean_g_loss: 1001.07849121\n",
            "Epoch:  98 Step:   640  time: 1.312836 s d_loss: 1.00315297, g_loss: 1055.52746582 -- mean_d_loss: 5.43097878, mean_g_loss: 1002.40655518\n",
            "Epoch:  98 Step:   641  time: 1.342345 s d_loss: 0.93313372, g_loss: 1183.95458984 -- mean_d_loss: 5.32388687, mean_g_loss: 1006.72906494\n",
            "Epoch:  98 Step:   642  time: 1.313653 s d_loss: 2.00545883, g_loss: 857.23461914 -- mean_d_loss: 5.24671459, mean_g_loss: 1003.25244141\n",
            "Epoch:  98 Step:   643  time: 1.349295 s d_loss: 1.09677017, g_loss: 941.77404785 -- mean_d_loss: 5.15239763, mean_g_loss: 1001.85522461\n",
            "Epoch:  98 Step:   644  time: 1.321286 s d_loss: 1.13357043, g_loss: 1059.10986328 -- mean_d_loss: 5.06309032, mean_g_loss: 1003.12750244\n",
            "Epoch:  98 Step:   645  time: 1.320573 s d_loss: 2.87841034, g_loss: 902.39483643 -- mean_d_loss: 5.01559734, mean_g_loss: 1000.93768311\n",
            "Epoch:  98 Step:   646  time: 1.329331 s d_loss: 3.36850762, g_loss: 950.23077393 -- mean_d_loss: 4.98055267, mean_g_loss: 999.85876465\n",
            "Epoch:  98 Step:   647  time: 1.336067 s d_loss: 6.17841291, g_loss: 1099.66088867 -- mean_d_loss: 5.00550795, mean_g_loss: 1001.93798828\n",
            "Epoch:  98 Step:   648  time: 1.341008 s d_loss: 1.30598950, g_loss: 1009.14965820 -- mean_d_loss: 4.93000746, mean_g_loss: 1002.08514404\n",
            "Epoch:  98 Step:   649  time: 1.281895 s d_loss: 2.04717135, g_loss: 1161.01403809 -- mean_d_loss: 4.87235069, mean_g_loss: 1005.26373291\n",
            "Epoch:  98 Step:   650  time: 1.331494 s d_loss: 2.93937612, g_loss: 1118.17272949 -- mean_d_loss: 4.83444929, mean_g_loss: 1007.47766113\n",
            "Epoch:  98 Step:   651  time: 1.330140 s d_loss: 0.93051302, g_loss: 956.24584961 -- mean_d_loss: 4.75937366, mean_g_loss: 1006.49243164\n",
            "Epoch:  98 Step:   652  time: 1.332167 s d_loss: 1.15054440, g_loss: 1031.31030273 -- mean_d_loss: 4.69128227, mean_g_loss: 1006.96063232\n",
            "Epoch:  98 Step:   653  time: 1.284953 s d_loss: 2.11635590, g_loss: 1036.45959473 -- mean_d_loss: 4.64359856, mean_g_loss: 1007.50695801\n",
            "Epoch:  98 Step:   654  time: 1.289816 s d_loss: 0.74328440, g_loss: 1121.27941895 -- mean_d_loss: 4.57268381, mean_g_loss: 1009.57556152\n",
            "Epoch:  98 Step:   655  time: 1.299766 s d_loss: 0.73510766, g_loss: 1081.47900391 -- mean_d_loss: 4.50415564, mean_g_loss: 1010.85955811\n",
            "Epoch:  98 Step:   656  time: 1.297293 s d_loss: 7.26355553, g_loss: 928.73864746 -- mean_d_loss: 4.55256605, mean_g_loss: 1009.41888428\n",
            "Epoch:  98 Step:   657  time: 1.326100 s d_loss: 1.59495556, g_loss: 997.89123535 -- mean_d_loss: 4.50157309, mean_g_loss: 1009.22009277\n",
            "Epoch:  98 Step:   658  time: 1.328965 s d_loss: 1.16434979, g_loss: 979.59631348 -- mean_d_loss: 4.44500971, mean_g_loss: 1008.71801758\n",
            "Epoch:  98 Step:   659  time: 1.299728 s d_loss: 1.21507621, g_loss: 1022.52539062 -- mean_d_loss: 4.39117765, mean_g_loss: 1008.94818115\n",
            "Epoch:  98 Step:   660  time: 1.294143 s d_loss: 0.96047127, g_loss: 1122.72705078 -- mean_d_loss: 4.33493710, mean_g_loss: 1010.81341553\n",
            "Epoch:  98 Step:   661  time: 1.313572 s d_loss: 1.07964897, g_loss: 1017.18414307 -- mean_d_loss: 4.28243208, mean_g_loss: 1010.91613770\n",
            "Epoch:  98 Step:   662  time: 1.323932 s d_loss: 1.00161386, g_loss: 922.91455078 -- mean_d_loss: 4.23035574, mean_g_loss: 1009.51928711\n",
            "Epoch:  98 Step:   663  time: 1.336656 s d_loss: 0.91064698, g_loss: 997.98181152 -- mean_d_loss: 4.17848539, mean_g_loss: 1009.33898926\n",
            "Epoch:  98 Step:   664  time: 1.331210 s d_loss: 0.87911355, g_loss: 1086.44531250 -- mean_d_loss: 4.12772608, mean_g_loss: 1010.52526855\n",
            "Epoch:  98 Step:   665  time: 1.286706 s d_loss: 1.18665636, g_loss: 1255.15979004 -- mean_d_loss: 4.08316422, mean_g_loss: 1014.23175049\n",
            "Epoch:  98 Step:   666  time: 1.310790 s d_loss: 10.95304203, g_loss: 1057.49914551 -- mean_d_loss: 4.18569946, mean_g_loss: 1014.87756348\n",
            "Epoch:  98 Step:   667  time: 1.335352 s d_loss: 2.50324130, g_loss: 978.39001465 -- mean_d_loss: 4.16095734, mean_g_loss: 1014.34100342\n",
            "Epoch:  98 Step:   668  time: 1.334439 s d_loss: 1.08009601, g_loss: 960.08056641 -- mean_d_loss: 4.11630726, mean_g_loss: 1013.55456543\n",
            "Epoch:  98 Step:   669  time: 1.329487 s d_loss: 4.51137209, g_loss: 1023.40454102 -- mean_d_loss: 4.12195110, mean_g_loss: 1013.69531250\n",
            "Epoch:  98 Step:   670  time: 1.330194 s d_loss: 1.32151449, g_loss: 889.39990234 -- mean_d_loss: 4.08250856, mean_g_loss: 1011.94464111\n",
            "Epoch:  98 Step:   671  time: 1.320417 s d_loss: 1.15789986, g_loss: 954.10449219 -- mean_d_loss: 4.04188871, mean_g_loss: 1011.14129639\n",
            "Epoch:  98 Step:   672  time: 1.297921 s d_loss: 0.93535542, g_loss: 870.07629395 -- mean_d_loss: 3.99933362, mean_g_loss: 1009.20892334\n",
            "Epoch:  98 Step:   673  time: 1.303656 s d_loss: 3.12516189, g_loss: 1173.04345703 -- mean_d_loss: 3.98752046, mean_g_loss: 1011.42291260\n",
            "Epoch:  98 Step:   674  time: 1.311020 s d_loss: 2.60552287, g_loss: 901.06823730 -- mean_d_loss: 3.96909380, mean_g_loss: 1009.95153809\n",
            "Epoch:  98 Step:   675  time: 1.292237 s d_loss: 2.70225763, g_loss: 1187.24865723 -- mean_d_loss: 3.95242500, mean_g_loss: 1012.28442383\n",
            "Epoch:  98 Step:   676  time: 1.294984 s d_loss: 2.44114780, g_loss: 1121.59155273 -- mean_d_loss: 3.93279839, mean_g_loss: 1013.70404053\n",
            "Epoch:  98 Step:   677  time: 1.318567 s d_loss: 1.36544108, g_loss: 1150.93408203 -- mean_d_loss: 3.89988351, mean_g_loss: 1015.46343994\n",
            "Epoch:  98 Step:   678  time: 1.328409 s d_loss: 1.64544487, g_loss: 1011.03009033 -- mean_d_loss: 3.87134647, mean_g_loss: 1015.40734863\n",
            "Epoch:  98 Step:   679  time: 1.283057 s d_loss: 0.95507532, g_loss: 1046.08227539 -- mean_d_loss: 3.83489299, mean_g_loss: 1015.79083252\n",
            "Epoch:  98 Step:   680  time: 1.333124 s d_loss: 2.02915382, g_loss: 1032.01904297 -- mean_d_loss: 3.81259990, mean_g_loss: 1015.99114990\n",
            "Epoch:  98 Step:   681  time: 1.321573 s d_loss: 1.18371630, g_loss: 971.66003418 -- mean_d_loss: 3.78054023, mean_g_loss: 1015.45043945\n",
            "Epoch:  98 Step:   682  time: 1.330449 s d_loss: 0.73313034, g_loss: 1049.05517578 -- mean_d_loss: 3.74382448, mean_g_loss: 1015.85534668\n",
            "Epoch:  98 Step:   683  time: 1.310466 s d_loss: 1.68300891, g_loss: 1164.47814941 -- mean_d_loss: 3.71929097, mean_g_loss: 1017.62463379\n",
            "Epoch:  98 Step:   684  time: 1.311423 s d_loss: 1.15499890, g_loss: 1095.63513184 -- mean_d_loss: 3.68912292, mean_g_loss: 1018.54235840\n",
            "Epoch:  98 Step:   685  time: 1.324349 s d_loss: 0.92720616, g_loss: 1027.19812012 -- mean_d_loss: 3.65700769, mean_g_loss: 1018.64300537\n",
            "Epoch:  98 Step:   686  time: 1.325080 s d_loss: 1.04861104, g_loss: 1019.08868408 -- mean_d_loss: 3.62702608, mean_g_loss: 1018.64807129\n",
            "Epoch:  98 Step:   687  time: 1.285645 s d_loss: 0.77342629, g_loss: 1074.61010742 -- mean_d_loss: 3.59459901, mean_g_loss: 1019.28399658\n",
            "Epoch:  98 Step:   688  time: 1.324914 s d_loss: 0.64076453, g_loss: 1070.68908691 -- mean_d_loss: 3.56140995, mean_g_loss: 1019.86157227\n",
            "Epoch:  98 Step:   689  time: 1.317005 s d_loss: 0.75770569, g_loss: 1104.16552734 -- mean_d_loss: 3.53025794, mean_g_loss: 1020.79827881\n",
            "Epoch:  98 Step:   690  time: 1.319772 s d_loss: 1.14550591, g_loss: 929.04809570 -- mean_d_loss: 3.50405169, mean_g_loss: 1019.78997803\n",
            "Epoch:  98 Step:   691  time: 1.294784 s d_loss: 0.82005686, g_loss: 1007.93365479 -- mean_d_loss: 3.47487807, mean_g_loss: 1019.66119385\n",
            "Epoch:  98 Step:   692  time: 1.292598 s d_loss: 0.87827122, g_loss: 997.84698486 -- mean_d_loss: 3.44695759, mean_g_loss: 1019.42657471\n",
            "Epoch:  98 Step:   693  time: 1.322777 s d_loss: 0.63131535, g_loss: 944.43817139 -- mean_d_loss: 3.41700387, mean_g_loss: 1018.62884521\n",
            "Epoch:  98 Step:   694  time: 1.313764 s d_loss: 8.37902832, g_loss: 1032.40722656 -- mean_d_loss: 3.46923566, mean_g_loss: 1018.77386475\n",
            "Epoch:  98 Step:   695  time: 1.304521 s d_loss: 2.12300277, g_loss: 926.04382324 -- mean_d_loss: 3.45521259, mean_g_loss: 1017.80792236\n",
            "Epoch:  98 Step:   696  time: 1.298312 s d_loss: 18.35246658, g_loss: 1023.51269531 -- mean_d_loss: 3.60879254, mean_g_loss: 1017.86676025\n",
            "Epoch:  98 Step:   697  time: 1.311141 s d_loss: 1.32340860, g_loss: 1055.07861328 -- mean_d_loss: 3.58547235, mean_g_loss: 1018.24652100\n",
            "Epoch:  98 Step:   698  time: 1.327043 s d_loss: 1.29580820, g_loss: 844.85388184 -- mean_d_loss: 3.56234431, mean_g_loss: 1016.49505615\n",
            "Epoch:  98 Step:   699  time: 1.305346 s d_loss: 1.18583548, g_loss: 1081.58789062 -- mean_d_loss: 3.53857899, mean_g_loss: 1017.14593506\n",
            "Epoch:  98 Step:   700  time: 1.328449 s d_loss: 1.16605151, g_loss: 1041.44165039 -- mean_d_loss: 3.51508856, mean_g_loss: 1017.38653564\n",
            "Epoch:  98 Step:   701  time: 1.325902 s d_loss: 0.98297793, g_loss: 1065.68017578 -- mean_d_loss: 3.49026394, mean_g_loss: 1017.85998535\n",
            "Epoch:  98 Step:   702  time: 1.340857 s d_loss: 3.00364399, g_loss: 1061.01623535 -- mean_d_loss: 3.48553944, mean_g_loss: 1018.27899170\n",
            "Epoch:  98 Step:   703  time: 1.308727 s d_loss: 0.87032455, g_loss: 927.55773926 -- mean_d_loss: 3.46039319, mean_g_loss: 1017.40661621\n",
            "Epoch:  98 Step:   704  time: 1.282588 s d_loss: 2.03755569, g_loss: 1036.48486328 -- mean_d_loss: 3.44684243, mean_g_loss: 1017.58831787\n",
            "Epoch:  98 Step:   705  time: 1.326848 s d_loss: 1.07020891, g_loss: 1178.95019531 -- mean_d_loss: 3.42442155, mean_g_loss: 1019.11065674\n",
            "Epoch:  98 Step:   706  time: 1.278826 s d_loss: 1.02456343, g_loss: 1073.57275391 -- mean_d_loss: 3.40199304, mean_g_loss: 1019.61956787\n",
            "Epoch:  98 Step:   707  time: 1.299968 s d_loss: 0.82328647, g_loss: 929.95764160 -- mean_d_loss: 3.37811589, mean_g_loss: 1018.78942871\n",
            "Epoch:  98 Step:   708  time: 1.321121 s d_loss: 0.76037782, g_loss: 918.29235840 -- mean_d_loss: 3.35409999, mean_g_loss: 1017.86743164\n",
            "Epoch:  98 Step:   709  time: 1.331053 s d_loss: 0.83392078, g_loss: 1072.72888184 -- mean_d_loss: 3.33118916, mean_g_loss: 1018.36614990\n",
            "Epoch:  98 Step:   710  time: 1.297372 s d_loss: 0.66175872, g_loss: 881.42248535 -- mean_d_loss: 3.30714035, mean_g_loss: 1017.13238525\n",
            "Epoch:  98 Step:   711  time: 1.312385 s d_loss: 46.00764084, g_loss: 1044.63281250 -- mean_d_loss: 3.68839478, mean_g_loss: 1017.37792969\n",
            "Epoch:  98 Step:   712  time: 1.319549 s d_loss: 1.65408194, g_loss: 865.88171387 -- mean_d_loss: 3.67039204, mean_g_loss: 1016.03729248\n",
            "Epoch:  98 Step:   713  time: 1.293030 s d_loss: 2.03079271, g_loss: 890.41247559 -- mean_d_loss: 3.65600967, mean_g_loss: 1014.93530273\n",
            "Epoch:  98 Step:   714  time: 1.298168 s d_loss: 4.14892340, g_loss: 1029.83300781 -- mean_d_loss: 3.66029572, mean_g_loss: 1015.06488037\n",
            "Epoch:  98 Step:   715  time: 1.322668 s d_loss: 4.13089561, g_loss: 1082.25708008 -- mean_d_loss: 3.66435266, mean_g_loss: 1015.64410400\n",
            "Epoch:  98 Step:   716  time: 1.330367 s d_loss: 3.65640903, g_loss: 1041.68469238 -- mean_d_loss: 3.66428471, mean_g_loss: 1015.86669922\n",
            "Epoch:  98 Step:   717  time: 1.314727 s d_loss: 1.33513629, g_loss: 937.66442871 -- mean_d_loss: 3.64454627, mean_g_loss: 1015.20397949\n",
            "Epoch:  98 Step:   718  time: 1.324820 s d_loss: 1.11830139, g_loss: 1024.89929199 -- mean_d_loss: 3.62331724, mean_g_loss: 1015.28546143\n",
            "Epoch:  98 Step:   719  time: 1.303727 s d_loss: 0.90797138, g_loss: 940.89923096 -- mean_d_loss: 3.60068917, mean_g_loss: 1014.66558838\n",
            "Epoch:  98 Step:   720  time: 1.289892 s d_loss: 3.24755692, g_loss: 1223.29272461 -- mean_d_loss: 3.59777069, mean_g_loss: 1016.38970947\n",
            "Epoch:  98 Step:   721  time: 1.343615 s d_loss: 0.83274209, g_loss: 927.77990723 -- mean_d_loss: 3.57510662, mean_g_loss: 1015.66345215\n",
            "Epoch:  98 Step:   722  time: 1.329603 s d_loss: 1.13914955, g_loss: 1059.23266602 -- mean_d_loss: 3.55530214, mean_g_loss: 1016.01763916\n",
            "Epoch:  98 Step:   723  time: 1.328795 s d_loss: 1.12460101, g_loss: 1100.92907715 -- mean_d_loss: 3.53569961, mean_g_loss: 1016.70245361\n",
            "Epoch:  98 Step:   724  time: 1.325102 s d_loss: 0.96615803, g_loss: 1053.57470703 -- mean_d_loss: 3.51514339, mean_g_loss: 1016.99743652\n",
            "Epoch:  98 Step:   725  time: 1.323689 s d_loss: 0.55360168, g_loss: 1056.79846191 -- mean_d_loss: 3.49163890, mean_g_loss: 1017.31329346\n",
            "Epoch:  98 Step:   726  time: 1.324124 s d_loss: 1.74005091, g_loss: 1231.07702637 -- mean_d_loss: 3.47784686, mean_g_loss: 1018.99652100\n",
            "Epoch:  98 Step:   727  time: 1.286731 s d_loss: 0.97317207, g_loss: 1031.16967773 -- mean_d_loss: 3.45827913, mean_g_loss: 1019.09161377\n",
            "Epoch:  98 Step:   728  time: 1.342991 s d_loss: 1.03017771, g_loss: 887.04705811 -- mean_d_loss: 3.43945670, mean_g_loss: 1018.06805420\n",
            "Epoch:  98 Step:   729  time: 1.312473 s d_loss: 1.23913121, g_loss: 1064.91247559 -- mean_d_loss: 3.42253113, mean_g_loss: 1018.42834473\n",
            "Epoch:  98 Step:   730  time: 1.289448 s d_loss: 0.79254782, g_loss: 918.60882568 -- mean_d_loss: 3.40245485, mean_g_loss: 1017.66638184\n",
            "Epoch:  98 Step:   731  time: 1.314813 s d_loss: 1.21608913, g_loss: 1080.97680664 -- mean_d_loss: 3.38589144, mean_g_loss: 1018.14605713\n",
            "Epoch:  98 Step:   732  time: 1.334726 s d_loss: 0.54318261, g_loss: 908.65954590 -- mean_d_loss: 3.36451769, mean_g_loss: 1017.32281494\n",
            "Epoch:  98 Step:   733  time: 1.329085 s d_loss: 0.84487200, g_loss: 941.60607910 -- mean_d_loss: 3.34571457, mean_g_loss: 1016.75781250\n",
            "Epoch:  98 Step:   734  time: 1.305904 s d_loss: 0.66796732, g_loss: 1067.26049805 -- mean_d_loss: 3.32587934, mean_g_loss: 1017.13195801\n",
            "Epoch:  98 Step:   735  time: 1.321062 s d_loss: 1.07780397, g_loss: 1058.77416992 -- mean_d_loss: 3.30934930, mean_g_loss: 1017.43817139\n",
            "Epoch:  98 Step:   736  time: 1.322645 s d_loss: 0.59617853, g_loss: 895.07702637 -- mean_d_loss: 3.28954530, mean_g_loss: 1016.54504395\n",
            "Epoch:  98 Step:   737  time: 1.291558 s d_loss: 0.65424389, g_loss: 1040.48620605 -- mean_d_loss: 3.27044868, mean_g_loss: 1016.71850586\n",
            "Epoch:  98 Step:   738  time: 1.320257 s d_loss: 0.60779959, g_loss: 1035.29174805 -- mean_d_loss: 3.25129294, mean_g_loss: 1016.85217285\n",
            "Epoch:  98 Step:   739  time: 1.325167 s d_loss: 0.68072385, g_loss: 993.16589355 -- mean_d_loss: 3.23293185, mean_g_loss: 1016.68304443\n",
            "Epoch:  98 Step:   740  time: 1.333362 s d_loss: 0.98142117, g_loss: 1188.83935547 -- mean_d_loss: 3.21696353, mean_g_loss: 1017.90405273\n",
            "Epoch:  98 Step:   741  time: 1.322794 s d_loss: 0.66456026, g_loss: 1161.27844238 -- mean_d_loss: 3.19898868, mean_g_loss: 1018.91375732\n",
            "Epoch:  98 Step:   742  time: 1.310782 s d_loss: 1.64148736, g_loss: 1116.77258301 -- mean_d_loss: 3.18809724, mean_g_loss: 1019.59802246\n",
            "Epoch:  98 Step:   743  time: 1.345399 s d_loss: 0.75485098, g_loss: 1002.81866455 -- mean_d_loss: 3.17119956, mean_g_loss: 1019.48144531\n",
            "Epoch:  98 Step:   744  time: 1.343162 s d_loss: 0.85469818, g_loss: 1129.23107910 -- mean_d_loss: 3.15522385, mean_g_loss: 1020.23834229\n",
            "Epoch:  98 Step:   745  time: 1.312588 s d_loss: 0.97668624, g_loss: 904.32727051 -- mean_d_loss: 3.14030218, mean_g_loss: 1019.44445801\n",
            "Epoch:  98 Step:   746  time: 1.299659 s d_loss: 0.77926844, g_loss: 931.94036865 -- mean_d_loss: 3.12424088, mean_g_loss: 1018.84918213\n",
            "Epoch:  98 Step:   747  time: 1.324627 s d_loss: 0.64927590, g_loss: 1251.78955078 -- mean_d_loss: 3.10751796, mean_g_loss: 1020.42315674\n",
            "Epoch:  98 Step:   748  time: 1.334905 s d_loss: 0.78980935, g_loss: 881.74316406 -- mean_d_loss: 3.09196281, mean_g_loss: 1019.49243164\n",
            "Epoch:  98 Step:   749  time: 1.326488 s d_loss: 0.80378354, g_loss: 958.31445312 -- mean_d_loss: 3.07670808, mean_g_loss: 1019.08459473\n",
            "Epoch:  98 Step:   750  time: 1.319734 s d_loss: 1.32520378, g_loss: 1027.08740234 -- mean_d_loss: 3.06510878, mean_g_loss: 1019.13763428\n",
            "Epoch:  98 Step:   751  time: 1.316574 s d_loss: 0.78692687, g_loss: 1066.25671387 -- mean_d_loss: 3.05012059, mean_g_loss: 1019.44757080\n",
            "Epoch:  98 Step:   752  time: 1.337472 s d_loss: 1.13683164, g_loss: 999.23022461 -- mean_d_loss: 3.03761554, mean_g_loss: 1019.31549072\n",
            "Epoch:  98 Step:   753  time: 1.329643 s d_loss: 1.18304062, g_loss: 1037.36926270 -- mean_d_loss: 3.02557302, mean_g_loss: 1019.43273926\n",
            "Epoch:  98 Step:   754  time: 1.322314 s d_loss: 1.13138080, g_loss: 1107.04626465 -- mean_d_loss: 3.01335239, mean_g_loss: 1019.99798584\n",
            "Epoch:  98 Step:   755  time: 1.299089 s d_loss: 0.76388854, g_loss: 1126.01245117 -- mean_d_loss: 2.99893260, mean_g_loss: 1020.67761230\n",
            "Epoch:  98 Step:   756  time: 1.318913 s d_loss: 1.20862234, g_loss: 1028.01367188 -- mean_d_loss: 2.98752928, mean_g_loss: 1020.72430420\n",
            "Epoch:  98 Step:   757  time: 1.320113 s d_loss: 0.70185405, g_loss: 1129.45971680 -- mean_d_loss: 2.97306299, mean_g_loss: 1021.41247559\n",
            "Epoch:  98 Step:   758  time: 1.288147 s d_loss: 34.33818817, g_loss: 1004.70831299 -- mean_d_loss: 3.17032790, mean_g_loss: 1021.30737305\n",
            "Epoch:  98 Step:   759  time: 1.322082 s d_loss: 0.89256048, g_loss: 995.31372070 -- mean_d_loss: 3.15609193, mean_g_loss: 1021.14489746\n",
            "Epoch:  98 Step:   760  time: 1.338178 s d_loss: 5.62122154, g_loss: 993.41748047 -- mean_d_loss: 3.17140317, mean_g_loss: 1020.97271729\n",
            "Epoch:  98 Step:   761  time: 1.337084 s d_loss: 0.93815339, g_loss: 949.64959717 -- mean_d_loss: 3.15761757, mean_g_loss: 1020.53253174\n",
            "Epoch:  98 Step:   762  time: 1.279399 s d_loss: 6.83434868, g_loss: 937.93664551 -- mean_d_loss: 3.18017435, mean_g_loss: 1020.02575684\n",
            "Epoch:  98 Step:   763  time: 1.329015 s d_loss: 1.93385613, g_loss: 983.69494629 -- mean_d_loss: 3.17257476, mean_g_loss: 1019.80419922\n",
            "Epoch:  98 Step:   764  time: 1.298561 s d_loss: 1.34449470, g_loss: 1003.77648926 -- mean_d_loss: 3.16149521, mean_g_loss: 1019.70709229\n",
            "Epoch:  98 Step:   765  time: 1.335280 s d_loss: 1.19093335, g_loss: 1124.75659180 -- mean_d_loss: 3.14962435, mean_g_loss: 1020.33990479\n",
            "Epoch:  98 Step:   766  time: 1.327968 s d_loss: 0.84291756, g_loss: 1014.43365479 -- mean_d_loss: 3.13581157, mean_g_loss: 1020.30456543\n",
            "Epoch:  98 Step:   767  time: 1.327610 s d_loss: 0.99780935, g_loss: 1100.56372070 -- mean_d_loss: 3.12308550, mean_g_loss: 1020.78228760\n",
            "Epoch:  98 Step:   768  time: 1.332775 s d_loss: 0.89957893, g_loss: 1022.42718506 -- mean_d_loss: 3.10992861, mean_g_loss: 1020.79199219\n",
            "Epoch:  98 Step:   769  time: 1.345489 s d_loss: 0.76476127, g_loss: 1014.87329102 -- mean_d_loss: 3.09613371, mean_g_loss: 1020.75714111\n",
            "Epoch:  98 Step:   770  time: 1.319762 s d_loss: 0.64448512, g_loss: 1042.19262695 -- mean_d_loss: 3.08179641, mean_g_loss: 1020.88250732\n",
            "Epoch:  98 Step:   771  time: 1.322238 s d_loss: 1.02632189, g_loss: 974.32519531 -- mean_d_loss: 3.06984591, mean_g_loss: 1020.61181641\n",
            "Epoch:  98 Step:   772  time: 1.321836 s d_loss: 0.59116095, g_loss: 1005.15368652 -- mean_d_loss: 3.05551839, mean_g_loss: 1020.52246094\n",
            "Epoch:  98 Step:   773  time: 1.291318 s d_loss: 0.68372786, g_loss: 953.50988770 -- mean_d_loss: 3.04188728, mean_g_loss: 1020.13739014\n",
            "Epoch:  98 Step:   774  time: 1.301141 s d_loss: 0.89238167, g_loss: 941.87945557 -- mean_d_loss: 3.02960443, mean_g_loss: 1019.69018555\n",
            "Epoch:  98 Step:   775  time: 1.324602 s d_loss: 0.74730313, g_loss: 1079.47802734 -- mean_d_loss: 3.01663685, mean_g_loss: 1020.02990723\n",
            "Epoch:  98 Step:   776  time: 1.315906 s d_loss: 1.02595949, g_loss: 1164.01245117 -- mean_d_loss: 3.00539017, mean_g_loss: 1020.84338379\n",
            "Epoch:  98 Step:   777  time: 1.323992 s d_loss: 43.51617813, g_loss: 968.07714844 -- mean_d_loss: 3.23297882, mean_g_loss: 1020.54693604\n",
            "Epoch:  98 Step:   778  time: 1.292129 s d_loss: 1.43764377, g_loss: 824.78466797 -- mean_d_loss: 3.22294879, mean_g_loss: 1019.45330811\n",
            "Epoch:  98 Step:   779  time: 1.324234 s d_loss: 1.45562375, g_loss: 1167.78906250 -- mean_d_loss: 3.21313047, mean_g_loss: 1020.27740479\n",
            "Epoch:  98 Step:   780  time: 1.332735 s d_loss: 1.28896141, g_loss: 1039.37976074 -- mean_d_loss: 3.20249939, mean_g_loss: 1020.38293457\n",
            "Epoch:  98 Step:   781  time: 1.348553 s d_loss: 1.12276125, g_loss: 951.52087402 -- mean_d_loss: 3.19107223, mean_g_loss: 1020.00457764\n",
            "Epoch:  98 Step:   782  time: 1.336953 s d_loss: 1.02850044, g_loss: 1046.86389160 -- mean_d_loss: 3.17925501, mean_g_loss: 1020.15130615\n",
            "Epoch:  98 Step:   783  time: 1.291295 s d_loss: 0.99489254, g_loss: 1024.69580078 -- mean_d_loss: 3.16738319, mean_g_loss: 1020.17602539\n",
            "Epoch:  98 Step:   784  time: 1.290687 s d_loss: 0.77874362, g_loss: 975.18981934 -- mean_d_loss: 3.15447164, mean_g_loss: 1019.93286133\n",
            "Epoch:  98 Step:   785  time: 1.319808 s d_loss: 1.13350832, g_loss: 1090.70629883 -- mean_d_loss: 3.14360619, mean_g_loss: 1020.31335449\n",
            "Epoch:  98 Step:   786  time: 1.330683 s d_loss: 0.56108266, g_loss: 864.08374023 -- mean_d_loss: 3.12979603, mean_g_loss: 1019.47784424\n",
            "Epoch:  98 Step:   787  time: 1.323323 s d_loss: 7.08398819, g_loss: 1392.26208496 -- mean_d_loss: 3.15082884, mean_g_loss: 1021.46075439\n",
            "Epoch:  98 Step:   788  time: 1.290725 s d_loss: 1.24188221, g_loss: 926.48175049 -- mean_d_loss: 3.14072871, mean_g_loss: 1020.95825195\n",
            "Epoch:  98 Step:   789  time: 1.327510 s d_loss: 0.89553910, g_loss: 991.23767090 -- mean_d_loss: 3.12891197, mean_g_loss: 1020.80181885\n",
            "Epoch:  98 Step:   790  time: 1.324697 s d_loss: 0.79087275, g_loss: 961.17926025 -- mean_d_loss: 3.11667109, mean_g_loss: 1020.48962402\n",
            "Epoch:  98 Step:   791  time: 1.306060 s d_loss: 1.09035897, g_loss: 953.39855957 -- mean_d_loss: 3.10611725, mean_g_loss: 1020.14019775\n",
            "Epoch:  98 Step:   792  time: 1.350239 s d_loss: 0.86284709, g_loss: 932.16784668 -- mean_d_loss: 3.09449410, mean_g_loss: 1019.68444824\n",
            "Epoch:  98 Step:   793  time: 1.340672 s d_loss: 0.80012459, g_loss: 839.78540039 -- mean_d_loss: 3.08266735, mean_g_loss: 1018.75708008\n",
            "Epoch:  98 Step:   794  time: 1.297565 s d_loss: 0.98135346, g_loss: 935.13977051 -- mean_d_loss: 3.07189131, mean_g_loss: 1018.32830811\n",
            "Epoch:  98 Step:   795  time: 1.331805 s d_loss: 1.04080713, g_loss: 1093.96557617 -- mean_d_loss: 3.06152868, mean_g_loss: 1018.71423340\n",
            "Epoch:  98 Step:   796  time: 1.337411 s d_loss: 38.07108688, g_loss: 1002.41662598 -- mean_d_loss: 3.23924232, mean_g_loss: 1018.63153076\n",
            "Epoch:  98 Step:   797  time: 1.359744 s d_loss: 1.42455637, g_loss: 980.39184570 -- mean_d_loss: 3.23007727, mean_g_loss: 1018.43835449\n",
            "Epoch:  98 Step:   798  time: 1.312150 s d_loss: 1.37732816, g_loss: 1004.36151123 -- mean_d_loss: 3.22076702, mean_g_loss: 1018.36761475\n",
            "Epoch:  98 Step:   799  time: 1.293493 s d_loss: 1.26601720, g_loss: 945.20806885 -- mean_d_loss: 3.21099305, mean_g_loss: 1018.00177002\n",
            "Epoch:  98 Step:   800  time: 1.317868 s d_loss: 1.46993566, g_loss: 1077.63586426 -- mean_d_loss: 1.46993566, mean_g_loss: 1077.63586426\n",
            "Epoch:  98 Step:   801  time: 1.294865 s d_loss: 0.78881127, g_loss: 1153.94287109 -- mean_d_loss: 1.12937343, mean_g_loss: 1115.78930664\n",
            "Epoch:  98 Step:   802  time: 1.295207 s d_loss: 1.94069040, g_loss: 948.47943115 -- mean_d_loss: 1.39981234, mean_g_loss: 1060.01940918\n",
            "Epoch:  98 Step:   803  time: 1.326511 s d_loss: 1.29898751, g_loss: 1010.42626953 -- mean_d_loss: 1.37460613, mean_g_loss: 1047.62109375\n",
            "Epoch:  98 Step:   804  time: 1.292584 s d_loss: 0.84566838, g_loss: 955.66625977 -- mean_d_loss: 1.26881862, mean_g_loss: 1029.23010254\n",
            "Epoch:  98 Step:   805  time: 1.310410 s d_loss: 6.00107002, g_loss: 901.88684082 -- mean_d_loss: 2.05752730, mean_g_loss: 1008.00616455\n",
            "Epoch:  98 Step:   806  time: 1.283965 s d_loss: 1.51241767, g_loss: 870.39819336 -- mean_d_loss: 1.97965443, mean_g_loss: 988.34796143\n",
            "Epoch:  98 Step:   807  time: 1.302363 s d_loss: 3.43649960, g_loss: 987.95892334 -- mean_d_loss: 2.16176009, mean_g_loss: 988.29931641\n",
            "Epoch:  98 Step:   808  time: 1.295504 s d_loss: 0.84014988, g_loss: 1068.92724609 -- mean_d_loss: 2.01491451, mean_g_loss: 997.25805664\n",
            "Epoch:  98 Step:   809  time: 1.342829 s d_loss: 0.89488202, g_loss: 975.72717285 -- mean_d_loss: 1.90291142, mean_g_loss: 995.10498047\n",
            "Epoch:  98 Step:   810  time: 1.311807 s d_loss: 1.50996399, g_loss: 1054.57727051 -- mean_d_loss: 1.86718893, mean_g_loss: 1000.51153564\n",
            "Epoch:  98 Step:   811  time: 1.314801 s d_loss: 0.76274717, g_loss: 1034.44311523 -- mean_d_loss: 1.77515209, mean_g_loss: 1003.33917236\n",
            "Epoch:  98 Step:   812  time: 1.314011 s d_loss: 0.89821303, g_loss: 1077.90600586 -- mean_d_loss: 1.70769513, mean_g_loss: 1009.07513428\n",
            "Epoch:  98 Step:   813  time: 1.307273 s d_loss: 0.79314917, g_loss: 1048.85168457 -- mean_d_loss: 1.64237046, mean_g_loss: 1011.91632080\n",
            "Epoch:  98 Step:   814  time: 1.330386 s d_loss: 0.74649340, g_loss: 829.52850342 -- mean_d_loss: 1.58264542, mean_g_loss: 999.75708008\n",
            "Epoch:  98 Step:   815  time: 1.299762 s d_loss: 1.17494226, g_loss: 926.86083984 -- mean_d_loss: 1.55716395, mean_g_loss: 995.20104980\n",
            "Epoch:  98 Step:   816  time: 1.328384 s d_loss: 0.79816765, g_loss: 937.97247314 -- mean_d_loss: 1.51251709, mean_g_loss: 991.83465576\n",
            "Epoch:  98 Step:   817  time: 1.314946 s d_loss: 1.12740266, g_loss: 1016.50848389 -- mean_d_loss: 1.49112189, mean_g_loss: 993.20538330\n",
            "Epoch:  98 Step:   818  time: 1.306160 s d_loss: 61.67409897, g_loss: 981.32434082 -- mean_d_loss: 4.65864706, mean_g_loss: 992.58007812\n",
            "Epoch:  98 Step:   819  time: 1.315921 s d_loss: 3.25526571, g_loss: 849.87707520 -- mean_d_loss: 4.58847809, mean_g_loss: 985.44494629\n",
            "Epoch:  98 Step:   820  time: 1.319335 s d_loss: 4.57586384, g_loss: 1024.71972656 -- mean_d_loss: 4.58787775, mean_g_loss: 987.31512451\n",
            "Epoch:  98 Step:   821  time: 1.305003 s d_loss: 4.21480465, g_loss: 1061.96362305 -- mean_d_loss: 4.57091951, mean_g_loss: 990.70819092\n",
            "Epoch:  98 Step:   822  time: 1.285694 s d_loss: 2.00264907, g_loss: 865.45037842 -- mean_d_loss: 4.45925570, mean_g_loss: 985.26220703\n",
            "Epoch:  98 Step:   823  time: 1.308735 s d_loss: 1.24473500, g_loss: 927.41845703 -- mean_d_loss: 4.32531738, mean_g_loss: 982.85205078\n",
            "Epoch:  98 Step:   824  time: 1.287576 s d_loss: 1.31539094, g_loss: 920.50921631 -- mean_d_loss: 4.20492029, mean_g_loss: 980.35833740\n",
            "Epoch:  98 Step:   825  time: 1.288733 s d_loss: 8.43788052, g_loss: 1171.58776855 -- mean_d_loss: 4.36772633, mean_g_loss: 987.71331787\n",
            "Epoch:  98 Step:   826  time: 1.314206 s d_loss: 1.97591853, g_loss: 931.83789062 -- mean_d_loss: 4.27914095, mean_g_loss: 985.64385986\n",
            "Epoch:  98 Step:   827  time: 1.336260 s d_loss: 1.22929215, g_loss: 893.28186035 -- mean_d_loss: 4.17021799, mean_g_loss: 982.34521484\n",
            "Epoch:  98 Step:   828  time: 1.302538 s d_loss: 29.19111061, g_loss: 1093.97619629 -- mean_d_loss: 5.03300762, mean_g_loss: 986.19458008\n",
            "Epoch:  98 Step:   829  time: 1.299333 s d_loss: 3.47555828, g_loss: 1021.13769531 -- mean_d_loss: 4.98109245, mean_g_loss: 987.35937500\n",
            "Epoch:  98 Step:   830  time: 1.293185 s d_loss: 6.08478403, g_loss: 875.70880127 -- mean_d_loss: 5.01669502, mean_g_loss: 983.75775146\n",
            "Epoch:  98 Step:   831  time: 1.311867 s d_loss: 2.71237659, g_loss: 1121.94042969 -- mean_d_loss: 4.94468498, mean_g_loss: 988.07592773\n",
            "Epoch:  98 Step:   832  time: 1.321073 s d_loss: 2.00475645, g_loss: 947.80584717 -- mean_d_loss: 4.85559654, mean_g_loss: 986.85565186\n",
            "Epoch:  98 Step:   833  time: 1.295521 s d_loss: 2.72274518, g_loss: 1090.34851074 -- mean_d_loss: 4.79286575, mean_g_loss: 989.89959717\n",
            "Epoch:  98 Step:   834  time: 1.286939 s d_loss: 0.92156482, g_loss: 1336.46264648 -- mean_d_loss: 4.68225718, mean_g_loss: 999.80133057\n",
            "Epoch:  98 Step:   835  time: 1.334184 s d_loss: 0.73021871, g_loss: 939.29260254 -- mean_d_loss: 4.57247829, mean_g_loss: 998.12054443\n",
            "Epoch:  98 Step:   836  time: 1.295265 s d_loss: 0.72183436, g_loss: 1038.93896484 -- mean_d_loss: 4.46840668, mean_g_loss: 999.22369385\n",
            "Epoch:  98 Step:   837  time: 1.323001 s d_loss: 0.56919736, g_loss: 1112.90832520 -- mean_d_loss: 4.36579609, mean_g_loss: 1002.21545410\n",
            "Epoch:  98 Step:   838  time: 1.299058 s d_loss: 4.80171633, g_loss: 1028.51074219 -- mean_d_loss: 4.37697363, mean_g_loss: 1002.88970947\n",
            "Epoch:  98 Step:   839  time: 1.293833 s d_loss: 0.99815738, g_loss: 962.42883301 -- mean_d_loss: 4.29250288, mean_g_loss: 1001.87823486\n",
            "Epoch:  98 Step:   840  time: 1.304731 s d_loss: 3.79207277, g_loss: 998.61535645 -- mean_d_loss: 4.28029728, mean_g_loss: 1001.79870605\n",
            "Epoch:  98 Step:   841  time: 1.339926 s d_loss: 4.58621883, g_loss: 915.39935303 -- mean_d_loss: 4.28758097, mean_g_loss: 999.74151611\n",
            "Epoch:  98 Step:   842  time: 1.337622 s d_loss: 1.59901500, g_loss: 1131.32421875 -- mean_d_loss: 4.22505617, mean_g_loss: 1002.80157471\n",
            "Epoch:  98 Step:   843  time: 1.345188 s d_loss: 1.02195096, g_loss: 994.05371094 -- mean_d_loss: 4.15225840, mean_g_loss: 1002.60278320\n",
            "Epoch:  98 Step:   844  time: 1.324641 s d_loss: 4.88443708, g_loss: 1058.56127930 -- mean_d_loss: 4.16852903, mean_g_loss: 1003.84637451\n",
            "Epoch:  98 Step:   845  time: 1.334994 s d_loss: 3.69157767, g_loss: 1052.48364258 -- mean_d_loss: 4.15816021, mean_g_loss: 1004.90368652\n",
            "Epoch:  98 Step:   846  time: 1.346723 s d_loss: 21.24956894, g_loss: 1060.37512207 -- mean_d_loss: 4.52180719, mean_g_loss: 1006.08392334\n",
            "Epoch:  98 Step:   847  time: 1.320589 s d_loss: 1.01957846, g_loss: 888.17260742 -- mean_d_loss: 4.44884443, mean_g_loss: 1003.62744141\n",
            "Epoch:  98 Step:   848  time: 1.320535 s d_loss: 0.96988398, g_loss: 1072.53588867 -- mean_d_loss: 4.37784481, mean_g_loss: 1005.03369141\n",
            "Epoch:  98 Step:   849  time: 1.308862 s d_loss: 0.77403027, g_loss: 1043.51245117 -- mean_d_loss: 4.30576897, mean_g_loss: 1005.80328369\n",
            "Epoch:  98 Step:   850  time: 1.331338 s d_loss: 1.15130115, g_loss: 987.85583496 -- mean_d_loss: 4.24391651, mean_g_loss: 1005.45135498\n",
            "Epoch:  98 Step:   851  time: 1.302490 s d_loss: 1.79237533, g_loss: 1117.25024414 -- mean_d_loss: 4.19677162, mean_g_loss: 1007.60131836\n",
            "Epoch:  98 Step:   852  time: 1.299014 s d_loss: 17.20926476, g_loss: 859.82739258 -- mean_d_loss: 4.44229031, mean_g_loss: 1004.81317139\n",
            "Epoch:  98 Step:   853  time: 1.292991 s d_loss: 1.25286412, g_loss: 1172.44287109 -- mean_d_loss: 4.38322687, mean_g_loss: 1007.91741943\n",
            "Epoch:  98 Step:   854  time: 1.324786 s d_loss: 1.11736631, g_loss: 1121.61169434 -- mean_d_loss: 4.32384777, mean_g_loss: 1009.98455811\n",
            "Epoch:  98 Step:   855  time: 1.292943 s d_loss: 1.18377244, g_loss: 1018.87780762 -- mean_d_loss: 4.26777506, mean_g_loss: 1010.14343262\n",
            "Epoch:  98 Step:   856  time: 1.308869 s d_loss: 6.67385864, g_loss: 921.27624512 -- mean_d_loss: 4.30998707, mean_g_loss: 1008.58435059\n",
            "Epoch:  98 Step:   857  time: 1.298340 s d_loss: 1.50742400, g_loss: 959.48394775 -- mean_d_loss: 4.26166677, mean_g_loss: 1007.73779297\n",
            "Epoch:  98 Step:   858  time: 1.349102 s d_loss: 0.95254111, g_loss: 1025.52172852 -- mean_d_loss: 4.20558023, mean_g_loss: 1008.03924561\n",
            "Epoch:  98 Step:   859  time: 1.333733 s d_loss: 1.08061838, g_loss: 1085.71423340 -- mean_d_loss: 4.15349722, mean_g_loss: 1009.33386230\n",
            "Epoch:  98 Step:   860  time: 1.323470 s d_loss: 0.92615658, g_loss: 997.61413574 -- mean_d_loss: 4.10059023, mean_g_loss: 1009.14172363\n",
            "Epoch:  98 Step:   861  time: 1.325519 s d_loss: 1.05467641, g_loss: 1040.56750488 -- mean_d_loss: 4.05146265, mean_g_loss: 1009.64855957\n",
            "Epoch:  98 Step:   862  time: 1.293447 s d_loss: 0.83534133, g_loss: 963.20507812 -- mean_d_loss: 4.00041294, mean_g_loss: 1008.91131592\n",
            "Epoch:  98 Step:   863  time: 1.325394 s d_loss: 0.91108149, g_loss: 1155.91748047 -- mean_d_loss: 3.95214224, mean_g_loss: 1011.20831299\n",
            "Epoch:  98 Step:   864  time: 1.311773 s d_loss: 0.90225053, g_loss: 1049.04565430 -- mean_d_loss: 3.90522075, mean_g_loss: 1011.79040527\n",
            "Epoch:  98 Step:   865  time: 1.294059 s d_loss: 0.60992718, g_loss: 847.78784180 -- mean_d_loss: 3.85529208, mean_g_loss: 1009.30554199\n",
            "Epoch:  98 Step:   866  time: 1.334819 s d_loss: 0.63928574, g_loss: 947.55914307 -- mean_d_loss: 3.80729198, mean_g_loss: 1008.38397217\n",
            "Epoch:  98 Step:   867  time: 1.316447 s d_loss: 1.33372736, g_loss: 1145.55834961 -- mean_d_loss: 3.77091622, mean_g_loss: 1010.40118408\n",
            "Epoch:  98 Step:   868  time: 1.296247 s d_loss: 0.62576902, g_loss: 1125.77038574 -- mean_d_loss: 3.72533417, mean_g_loss: 1012.07324219\n",
            "Epoch:  98 Step:   869  time: 1.317622 s d_loss: 0.77440643, g_loss: 926.59704590 -- mean_d_loss: 3.68317819, mean_g_loss: 1010.85211182\n",
            "Epoch:  98 Step:   870  time: 1.282848 s d_loss: 0.74385405, g_loss: 963.38818359 -- mean_d_loss: 3.64177942, mean_g_loss: 1010.18365479\n",
            "Epoch:  98 Step:   871  time: 1.323401 s d_loss: 0.53913695, g_loss: 1011.53881836 -- mean_d_loss: 3.59868717, mean_g_loss: 1010.20245361\n",
            "Epoch:  98 Step:   872  time: 1.279279 s d_loss: 0.69732851, g_loss: 1175.98266602 -- mean_d_loss: 3.55894232, mean_g_loss: 1012.47344971\n",
            "Epoch:  98 Step:   873  time: 1.322418 s d_loss: 1.08512926, g_loss: 1138.80676270 -- mean_d_loss: 3.52551270, mean_g_loss: 1014.18066406\n",
            "Epoch:  98 Step:   874  time: 1.292650 s d_loss: 4.91123104, g_loss: 1036.61425781 -- mean_d_loss: 3.54398894, mean_g_loss: 1014.47979736\n",
            "Epoch:  98 Step:   875  time: 1.309306 s d_loss: 0.78788215, g_loss: 1003.09667969 -- mean_d_loss: 3.50772405, mean_g_loss: 1014.32995605\n",
            "Epoch:  98 Step:   876  time: 1.297261 s d_loss: 0.80016339, g_loss: 1033.56286621 -- mean_d_loss: 3.47256112, mean_g_loss: 1014.57977295\n",
            "Epoch:  98 Step:   877  time: 1.315022 s d_loss: 0.70070297, g_loss: 1216.68041992 -- mean_d_loss: 3.43702459, mean_g_loss: 1017.17077637\n",
            "Epoch:  98 Step:   878  time: 1.325436 s d_loss: 0.83416903, g_loss: 1088.98107910 -- mean_d_loss: 3.40407705, mean_g_loss: 1018.07983398\n",
            "Epoch:  98 Step:   879  time: 1.319332 s d_loss: 0.73521817, g_loss: 1111.53356934 -- mean_d_loss: 3.37071657, mean_g_loss: 1019.24792480\n",
            "Epoch:  98 Step:   880  time: 1.307571 s d_loss: 0.70636559, g_loss: 1030.06042480 -- mean_d_loss: 3.33782315, mean_g_loss: 1019.38146973\n",
            "Epoch:  98 Step:   881  time: 1.288761 s d_loss: 0.80726522, g_loss: 1014.11340332 -- mean_d_loss: 3.30696249, mean_g_loss: 1019.31726074\n",
            "Epoch:  98 Step:   882  time: 1.324297 s d_loss: 0.69958621, g_loss: 1004.00885010 -- mean_d_loss: 3.27554846, mean_g_loss: 1019.13281250\n",
            "Epoch:  98 Step:   883  time: 1.294783 s d_loss: 0.93641275, g_loss: 1002.37084961 -- mean_d_loss: 3.24770141, mean_g_loss: 1018.93322754\n",
            "Epoch:  98 Step:   884  time: 1.315717 s d_loss: 1.09137595, g_loss: 963.28466797 -- mean_d_loss: 3.22233272, mean_g_loss: 1018.27850342\n",
            "Epoch:  98 Step:   885  time: 1.291062 s d_loss: 18.53809357, g_loss: 933.26098633 -- mean_d_loss: 3.40042281, mean_g_loss: 1017.28985596\n",
            "Epoch:  98 Step:   886  time: 1.303655 s d_loss: 1.16090214, g_loss: 1037.97607422 -- mean_d_loss: 3.37468123, mean_g_loss: 1017.52764893\n",
            "Epoch:  98 Step:   887  time: 1.317280 s d_loss: 0.76864058, g_loss: 1013.93017578 -- mean_d_loss: 3.34506702, mean_g_loss: 1017.48675537\n",
            "Epoch:  98 Step:   888  time: 1.315486 s d_loss: 0.99485248, g_loss: 876.93994141 -- mean_d_loss: 3.31866002, mean_g_loss: 1015.90759277\n",
            "Epoch:  98 Step:   889  time: 1.290435 s d_loss: 0.80878180, g_loss: 893.15563965 -- mean_d_loss: 3.29077244, mean_g_loss: 1014.54364014\n",
            "Epoch:  98 Step:   890  time: 1.323370 s d_loss: 1.94165564, g_loss: 1048.88195801 -- mean_d_loss: 3.27594709, mean_g_loss: 1014.92102051\n",
            "Epoch:  98 Step:   891  time: 1.337892 s d_loss: 0.64894313, g_loss: 968.75695801 -- mean_d_loss: 3.24739265, mean_g_loss: 1014.41925049\n",
            "Epoch:  98 Step:   892  time: 1.316368 s d_loss: 1.51524115, g_loss: 1077.10888672 -- mean_d_loss: 3.22876740, mean_g_loss: 1015.09332275\n",
            "Epoch:  98 Step:   893  time: 1.316445 s d_loss: 0.99087059, g_loss: 1067.63696289 -- mean_d_loss: 3.20495987, mean_g_loss: 1015.65234375\n",
            "Epoch:  98 Step:   894  time: 1.294168 s d_loss: 41.14392471, g_loss: 927.62768555 -- mean_d_loss: 3.60431743, mean_g_loss: 1014.72576904\n",
            "Epoch:  98 Step:   895  time: 1.349352 s d_loss: 1.75369799, g_loss: 1167.73388672 -- mean_d_loss: 3.58504009, mean_g_loss: 1016.31958008\n",
            "Epoch:  98 Step:   896  time: 1.320036 s d_loss: 8.14406586, g_loss: 1024.51098633 -- mean_d_loss: 3.63204050, mean_g_loss: 1016.40399170\n",
            "Epoch:  98 Step:   897  time: 1.289779 s d_loss: 3.04075265, g_loss: 1020.96655273 -- mean_d_loss: 3.62600684, mean_g_loss: 1016.45056152\n",
            "Epoch:  98 Step:   898  time: 1.284986 s d_loss: 0.82990956, g_loss: 1092.85876465 -- mean_d_loss: 3.59776330, mean_g_loss: 1017.22235107\n",
            "Epoch:  98 Step:   899  time: 1.307861 s d_loss: 1.06036448, g_loss: 1047.18981934 -- mean_d_loss: 3.57238913, mean_g_loss: 1017.52203369\n",
            "Epoch:  98 Step:   900  time: 1.320277 s d_loss: 0.79241073, g_loss: 1038.00756836 -- mean_d_loss: 3.54486465, mean_g_loss: 1017.72485352\n",
            "Epoch:  98 Step:   901  time: 1.311388 s d_loss: 0.74658519, g_loss: 985.14575195 -- mean_d_loss: 3.51743054, mean_g_loss: 1017.40545654\n",
            "Epoch:  98 Step:   902  time: 1.324896 s d_loss: 0.65402144, g_loss: 1182.56408691 -- mean_d_loss: 3.48963046, mean_g_loss: 1019.00897217\n",
            "Epoch:  98 Step:   903  time: 1.323080 s d_loss: 0.80956763, g_loss: 969.00402832 -- mean_d_loss: 3.46386075, mean_g_loss: 1018.52819824\n",
            "Epoch:  98 Step:   904  time: 1.318741 s d_loss: 0.50016302, g_loss: 970.01568604 -- mean_d_loss: 3.43563485, mean_g_loss: 1018.06616211\n",
            "Epoch:  98 Step:   905  time: 1.314044 s d_loss: 0.63848352, g_loss: 1035.29394531 -- mean_d_loss: 3.40924668, mean_g_loss: 1018.22869873\n",
            "Epoch:  98 Step:   906  time: 1.292712 s d_loss: 0.57395786, g_loss: 883.93200684 -- mean_d_loss: 3.38274860, mean_g_loss: 1016.97357178\n",
            "Epoch:  98 Step:   907  time: 1.309668 s d_loss: 0.67319715, g_loss: 1146.66210938 -- mean_d_loss: 3.35766006, mean_g_loss: 1018.17437744\n",
            "Epoch:  98 Step:   908  time: 1.344023 s d_loss: 0.78508872, g_loss: 1053.32849121 -- mean_d_loss: 3.33405852, mean_g_loss: 1018.49694824\n",
            "Epoch:  98 Step:   909  time: 1.340324 s d_loss: 0.72845250, g_loss: 951.18188477 -- mean_d_loss: 3.31037116, mean_g_loss: 1017.88494873\n",
            "Epoch:  98 Step:   910  time: 1.291245 s d_loss: 1.17355716, g_loss: 1093.20520020 -- mean_d_loss: 3.29112077, mean_g_loss: 1018.56347656\n",
            "Epoch:  98 Step:   911  time: 1.324104 s d_loss: 0.66875118, g_loss: 908.02746582 -- mean_d_loss: 3.26770663, mean_g_loss: 1017.57659912\n",
            "Epoch:  98 Step:   912  time: 1.316646 s d_loss: 4.40759802, g_loss: 958.70983887 -- mean_d_loss: 3.27779412, mean_g_loss: 1017.05566406\n",
            "Epoch:  98 Step:   913  time: 1.306062 s d_loss: 2.13226533, g_loss: 1067.47192383 -- mean_d_loss: 3.26774573, mean_g_loss: 1017.49786377\n",
            "Epoch:  98 Step:   914  time: 1.328708 s d_loss: 0.89544964, g_loss: 1078.00366211 -- mean_d_loss: 3.24711704, mean_g_loss: 1018.02398682\n",
            "Epoch:  98 Step:   915  time: 1.311875 s d_loss: 0.73256946, g_loss: 859.81005859 -- mean_d_loss: 3.22544003, mean_g_loss: 1016.66009521\n",
            "Epoch:  98 Step:   916  time: 1.292055 s d_loss: 0.82219267, g_loss: 1057.82568359 -- mean_d_loss: 3.20489955, mean_g_loss: 1017.01196289\n",
            "Epoch:  98 Step:   917  time: 1.318848 s d_loss: 3.71494031, g_loss: 1205.63867188 -- mean_d_loss: 3.20922184, mean_g_loss: 1018.61047363\n",
            "Epoch:  98 Step:   918  time: 1.313522 s d_loss: 1.02154601, g_loss: 986.30041504 -- mean_d_loss: 3.19083786, mean_g_loss: 1018.33892822\n",
            "Epoch:  98 Step:   919  time: 1.317315 s d_loss: 1.73710239, g_loss: 1106.75671387 -- mean_d_loss: 3.17872334, mean_g_loss: 1019.07580566\n",
            "Epoch:  98 Step:   920  time: 1.322229 s d_loss: 0.65299785, g_loss: 1040.71289062 -- mean_d_loss: 3.15784955, mean_g_loss: 1019.25457764\n",
            "Epoch:  98 Step:   921  time: 1.295989 s d_loss: 1.14144015, g_loss: 1141.37536621 -- mean_d_loss: 3.14132166, mean_g_loss: 1020.25555420\n",
            "Epoch:  98 Step:   922  time: 1.288015 s d_loss: 1.03589511, g_loss: 1182.59008789 -- mean_d_loss: 3.12420440, mean_g_loss: 1021.57537842\n",
            "Epoch:  98 Step:   923  time: 1.345262 s d_loss: 1.89036536, g_loss: 1100.86096191 -- mean_d_loss: 3.11425376, mean_g_loss: 1022.21478271\n",
            "Epoch:  98 Step:   924  time: 1.278040 s d_loss: 0.81771994, g_loss: 910.15869141 -- mean_d_loss: 3.09588170, mean_g_loss: 1021.31829834\n",
            "Epoch:  98 Step:   925  time: 1.333173 s d_loss: 1.19118917, g_loss: 1148.35473633 -- mean_d_loss: 3.08076501, mean_g_loss: 1022.32653809\n",
            "Epoch:  98 Step:   926  time: 1.317913 s d_loss: 0.99325091, g_loss: 979.18579102 -- mean_d_loss: 3.06432796, mean_g_loss: 1021.98681641\n",
            "Epoch:  98 Step:   927  time: 1.319582 s d_loss: 1.19278240, g_loss: 938.34240723 -- mean_d_loss: 3.04970646, mean_g_loss: 1021.33337402\n",
            "Epoch:  98 Step:   928  time: 1.340341 s d_loss: 0.98849195, g_loss: 1041.78710938 -- mean_d_loss: 3.03372812, mean_g_loss: 1021.49188232\n",
            "Epoch:  98 Step:   929  time: 1.302619 s d_loss: 0.79882467, g_loss: 1113.53112793 -- mean_d_loss: 3.01653647, mean_g_loss: 1022.19989014\n",
            "Epoch:  98 Step:   930  time: 1.308908 s d_loss: 0.85121238, g_loss: 1101.36474609 -- mean_d_loss: 3.00000739, mean_g_loss: 1022.80413818\n",
            "Epoch:  98 Step:   931  time: 1.322521 s d_loss: 0.76849961, g_loss: 1011.09899902 -- mean_d_loss: 2.98310208, mean_g_loss: 1022.71545410\n",
            "Epoch:  98 Step:   932  time: 1.303550 s d_loss: 0.93540043, g_loss: 969.80834961 -- mean_d_loss: 2.96770573, mean_g_loss: 1022.31768799\n",
            "Epoch:  98 Step:   933  time: 1.324977 s d_loss: 0.54507309, g_loss: 997.41552734 -- mean_d_loss: 2.94962645, mean_g_loss: 1022.13189697\n",
            "Epoch:  98 Step:   934  time: 1.326078 s d_loss: 0.95814651, g_loss: 1017.99133301 -- mean_d_loss: 2.93487477, mean_g_loss: 1022.10113525\n",
            "Epoch:  98 Step:   935  time: 1.315236 s d_loss: 23.60169792, g_loss: 940.68292236 -- mean_d_loss: 3.08683658, mean_g_loss: 1021.50250244\n",
            "Epoch:  98 Step:   936  time: 1.319593 s d_loss: 20.56571388, g_loss: 861.40954590 -- mean_d_loss: 3.21441960, mean_g_loss: 1020.33392334\n",
            "Epoch:  98 Step:   937  time: 1.334419 s d_loss: 1.69182026, g_loss: 982.22991943 -- mean_d_loss: 3.20338631, mean_g_loss: 1020.05786133\n",
            "Epoch:  98 Step:   938  time: 1.288641 s d_loss: 1.74966359, g_loss: 972.23022461 -- mean_d_loss: 3.19292808, mean_g_loss: 1019.71380615\n",
            "Epoch:  98 Step:   939  time: 1.315552 s d_loss: 1.65135801, g_loss: 927.63830566 -- mean_d_loss: 3.18191671, mean_g_loss: 1019.05615234\n",
            "Epoch:  98 Step:   940  time: 1.321239 s d_loss: 1.99962473, g_loss: 1112.79724121 -- mean_d_loss: 3.17353177, mean_g_loss: 1019.72094727\n",
            "Epoch:  98 Step:   941  time: 1.323442 s d_loss: 0.99953061, g_loss: 1023.29711914 -- mean_d_loss: 3.15822196, mean_g_loss: 1019.74615479\n",
            "Epoch:  98 Step:   942  time: 1.321096 s d_loss: 54.46039963, g_loss: 1146.49414062 -- mean_d_loss: 3.51697850, mean_g_loss: 1020.63256836\n",
            "Epoch:  98 Step:   943  time: 1.334044 s d_loss: 2.23107553, g_loss: 1011.40039062 -- mean_d_loss: 3.50804853, mean_g_loss: 1020.56848145\n",
            "Epoch:  98 Step:   944  time: 1.328424 s d_loss: 1.96047592, g_loss: 992.42163086 -- mean_d_loss: 3.49737573, mean_g_loss: 1020.37432861\n",
            "Epoch:  98 Step:   945  time: 1.328886 s d_loss: 4.10844088, g_loss: 1048.24475098 -- mean_d_loss: 3.50156093, mean_g_loss: 1020.56530762\n",
            "Epoch:  98 Step:   946  time: 1.330680 s d_loss: 1.26296258, g_loss: 812.68780518 -- mean_d_loss: 3.48633218, mean_g_loss: 1019.15112305\n",
            "Epoch:  98 Step:   947  time: 1.289343 s d_loss: 0.97296113, g_loss: 933.15570068 -- mean_d_loss: 3.46935010, mean_g_loss: 1018.57012939\n",
            "Epoch:  98 Step:   948  time: 1.341862 s d_loss: 9.70722580, g_loss: 1012.85974121 -- mean_d_loss: 3.51121497, mean_g_loss: 1018.53179932\n",
            "Epoch:  98 Step:   949  time: 1.355620 s d_loss: 1.50873470, g_loss: 932.18731689 -- mean_d_loss: 3.49786496, mean_g_loss: 1017.95611572\n",
            "Epoch:  98 Step:   950  time: 1.334568 s d_loss: 1.07647073, g_loss: 1092.27929688 -- mean_d_loss: 3.48182940, mean_g_loss: 1018.44836426\n",
            "Epoch:  98 Step:   951  time: 1.330632 s d_loss: 0.95927769, g_loss: 1086.80029297 -- mean_d_loss: 3.46523356, mean_g_loss: 1018.89801025\n",
            "Epoch:  98 Step:   952  time: 1.328557 s d_loss: 0.73212838, g_loss: 1089.19543457 -- mean_d_loss: 3.44737005, mean_g_loss: 1019.35754395\n",
            "Epoch:  98 Step:   953  time: 1.324893 s d_loss: 0.81220078, g_loss: 1127.30419922 -- mean_d_loss: 3.43025851, mean_g_loss: 1020.05847168\n",
            "Epoch:  98 Step:   954  time: 1.330896 s d_loss: 0.60621208, g_loss: 1088.54455566 -- mean_d_loss: 3.41203880, mean_g_loss: 1020.50030518\n",
            "Epoch:  98 Step:   955  time: 1.323850 s d_loss: 0.70526463, g_loss: 950.62243652 -- mean_d_loss: 3.39468765, mean_g_loss: 1020.05236816\n",
            "Epoch:  98 Step:   956  time: 1.319576 s d_loss: 1.10022461, g_loss: 999.49633789 -- mean_d_loss: 3.38007331, mean_g_loss: 1019.92144775\n",
            "Epoch:  98 Step:   957  time: 1.324396 s d_loss: 0.78747571, g_loss: 1004.61431885 -- mean_d_loss: 3.36366439, mean_g_loss: 1019.82458496\n",
            "Epoch:  98 Step:   958  time: 1.326731 s d_loss: 0.67192847, g_loss: 998.95764160 -- mean_d_loss: 3.34673524, mean_g_loss: 1019.69329834\n",
            "Epoch:  98 Step:   959  time: 1.287550 s d_loss: 0.56774676, g_loss: 915.39428711 -- mean_d_loss: 3.32936668, mean_g_loss: 1019.04138184\n",
            "Epoch:  98 Step:   960  time: 1.324556 s d_loss: 0.89208519, g_loss: 967.95208740 -- mean_d_loss: 3.31422830, mean_g_loss: 1018.72406006\n",
            "Epoch:  98 Step:   961  time: 1.304567 s d_loss: 9.95578384, g_loss: 1160.72387695 -- mean_d_loss: 3.35522580, mean_g_loss: 1019.60058594\n",
            "Epoch:  98 Step:   962  time: 1.314491 s d_loss: 0.95102632, g_loss: 957.45666504 -- mean_d_loss: 3.34047627, mean_g_loss: 1019.21929932\n",
            "Epoch:  98 Step:   963  time: 1.314746 s d_loss: 0.66644061, g_loss: 1125.27258301 -- mean_d_loss: 3.32417107, mean_g_loss: 1019.86596680\n",
            "Epoch:  98 Step:   964  time: 1.311729 s d_loss: 1.30656552, g_loss: 1126.31542969 -- mean_d_loss: 3.31194329, mean_g_loss: 1020.51110840\n",
            "Epoch:  98 Step:   965  time: 1.317427 s d_loss: 0.79625368, g_loss: 1005.29962158 -- mean_d_loss: 3.29678869, mean_g_loss: 1020.41943359\n",
            "Epoch:  98 Step:   966  time: 1.321358 s d_loss: 1.33334816, g_loss: 1057.82568359 -- mean_d_loss: 3.28503156, mean_g_loss: 1020.64343262\n",
            "Epoch:  98 Step:   967  time: 1.312124 s d_loss: 0.71843469, g_loss: 992.80047607 -- mean_d_loss: 3.26975441, mean_g_loss: 1020.47766113\n",
            "Epoch:  98 Step:   968  time: 1.345245 s d_loss: 1.69307196, g_loss: 1001.81213379 -- mean_d_loss: 3.26042461, mean_g_loss: 1020.36724854\n",
            "Epoch:  98 Step:   969  time: 1.293315 s d_loss: 1.37459254, g_loss: 897.68127441 -- mean_d_loss: 3.24933147, mean_g_loss: 1019.64556885\n",
            "Epoch:  98 Step:   970  time: 1.306811 s d_loss: 1.00746214, g_loss: 1039.32373047 -- mean_d_loss: 3.23622108, mean_g_loss: 1019.76068115\n",
            "Epoch:  98 Step:   971  time: 1.334433 s d_loss: 0.57213694, g_loss: 1081.74780273 -- mean_d_loss: 3.22073221, mean_g_loss: 1020.12109375\n",
            "Epoch:  98 Step:   972  time: 1.291920 s d_loss: 1.10161185, g_loss: 930.28540039 -- mean_d_loss: 3.20848298, mean_g_loss: 1019.60180664\n",
            "Epoch:  98 Step:   973  time: 1.325038 s d_loss: 3.35387158, g_loss: 979.67871094 -- mean_d_loss: 3.20931864, mean_g_loss: 1019.37231445\n",
            "Epoch:  98 Step:   974  time: 1.326079 s d_loss: 0.92166704, g_loss: 997.97302246 -- mean_d_loss: 3.19624662, mean_g_loss: 1019.25000000\n",
            "Epoch:  98 Step:   975  time: 1.324559 s d_loss: 0.86541843, g_loss: 1128.13256836 -- mean_d_loss: 3.18300319, mean_g_loss: 1019.86859131\n",
            "Epoch:  98 Step:   976  time: 1.322167 s d_loss: 0.65899515, g_loss: 956.74841309 -- mean_d_loss: 3.16874313, mean_g_loss: 1019.51202393\n",
            "Epoch:  98 Step:   977  time: 1.318632 s d_loss: 0.84622955, g_loss: 1053.29943848 -- mean_d_loss: 3.15569544, mean_g_loss: 1019.70178223\n",
            "Epoch:  98 Step:   978  time: 1.312857 s d_loss: 0.66851705, g_loss: 1121.09375000 -- mean_d_loss: 3.14180064, mean_g_loss: 1020.26824951\n",
            "Epoch:  98 Step:   979  time: 1.300128 s d_loss: 0.67867154, g_loss: 1134.41467285 -- mean_d_loss: 3.12811661, mean_g_loss: 1020.90240479\n",
            "Epoch:  98 Step:   980  time: 1.324020 s d_loss: 0.81659472, g_loss: 1047.11462402 -- mean_d_loss: 3.11534572, mean_g_loss: 1021.04724121\n",
            "Epoch:  98 Step:   981  time: 1.285780 s d_loss: 0.69190991, g_loss: 978.92138672 -- mean_d_loss: 3.10203004, mean_g_loss: 1020.81573486\n",
            "Epoch:  98 Step:   982  time: 1.319421 s d_loss: 1.01571047, g_loss: 953.67419434 -- mean_d_loss: 3.09062910, mean_g_loss: 1020.44885254\n",
            "Epoch:  98 Step:   983  time: 1.323227 s d_loss: 0.84235287, g_loss: 1006.77148438 -- mean_d_loss: 3.07841039, mean_g_loss: 1020.37451172\n",
            "Epoch:  98 Step:   984  time: 1.344282 s d_loss: 0.66334367, g_loss: 1116.57910156 -- mean_d_loss: 3.06535578, mean_g_loss: 1020.89453125\n",
            "Epoch:  98 Step:   985  time: 1.316510 s d_loss: 0.85579985, g_loss: 910.05743408 -- mean_d_loss: 3.05347633, mean_g_loss: 1020.29864502\n",
            "Epoch:  98 Step:   986  time: 1.313179 s d_loss: 0.65845072, g_loss: 1237.31030273 -- mean_d_loss: 3.04066873, mean_g_loss: 1021.45916748\n",
            "Epoch:  98 Step:   987  time: 1.344997 s d_loss: 1.33091116, g_loss: 1050.35485840 -- mean_d_loss: 3.03157425, mean_g_loss: 1021.61285400\n",
            "Epoch:  98 Step:   988  time: 1.315661 s d_loss: 0.72672439, g_loss: 1032.97058105 -- mean_d_loss: 3.01937938, mean_g_loss: 1021.67297363\n",
            "Epoch:  98 Step:   989  time: 1.350338 s d_loss: 0.86975217, g_loss: 1109.56335449 -- mean_d_loss: 3.00806570, mean_g_loss: 1022.13549805\n",
            "Epoch:  98 Step:   990  time: 1.298897 s d_loss: 0.91647184, g_loss: 966.86901855 -- mean_d_loss: 2.99711466, mean_g_loss: 1021.84619141\n",
            "Epoch:  98 Step:   991  time: 1.294178 s d_loss: 0.77995759, g_loss: 1125.24853516 -- mean_d_loss: 2.98556709, mean_g_loss: 1022.38476562\n",
            "Epoch:  98 Step:   992  time: 1.323903 s d_loss: 0.60976940, g_loss: 1025.60571289 -- mean_d_loss: 2.97325706, mean_g_loss: 1022.40148926\n",
            "Epoch:  98 Step:   993  time: 1.342601 s d_loss: 0.71685880, g_loss: 1050.09924316 -- mean_d_loss: 2.96162629, mean_g_loss: 1022.54418945\n",
            "Epoch:  98 Step:   994  time: 1.310356 s d_loss: 0.48010239, g_loss: 1024.86474609 -- mean_d_loss: 2.94890046, mean_g_loss: 1022.55609131\n",
            "Epoch:  98 Step:   995  time: 1.315529 s d_loss: 40.95475388, g_loss: 912.17211914 -- mean_d_loss: 3.14280796, mean_g_loss: 1021.99291992\n",
            "Epoch:  98 Step:   996  time: 1.323296 s d_loss: 1.18384445, g_loss: 900.11846924 -- mean_d_loss: 3.13286400, mean_g_loss: 1021.37426758\n",
            "Epoch:  98 Step:   997  time: 1.313882 s d_loss: 2.40427637, g_loss: 982.13513184 -- mean_d_loss: 3.12918425, mean_g_loss: 1021.17614746\n",
            "Epoch:  98 Step:   998  time: 1.283065 s d_loss: 1.57109845, g_loss: 993.07360840 -- mean_d_loss: 3.12135482, mean_g_loss: 1021.03491211\n",
            "Epoch:  98 Step:   999  time: 1.331861 s d_loss: 1.38285220, g_loss: 912.01354980 -- mean_d_loss: 3.11266232, mean_g_loss: 1020.48986816\n",
            "Epoch:  98 Step:  1000  time: 1.313572 s d_loss: 0.93897986, g_loss: 1090.00561523 -- mean_d_loss: 0.93897986, mean_g_loss: 1090.00561523\n",
            "Epoch:  98 Step:  1001  time: 1.331664 s d_loss: 22.74926949, g_loss: 938.96008301 -- mean_d_loss: 11.84412479, mean_g_loss: 1014.48284912\n",
            "Epoch:  98 Step:  1002  time: 1.328194 s d_loss: 1.89293134, g_loss: 1109.92736816 -- mean_d_loss: 8.52706051, mean_g_loss: 1046.29772949\n",
            "Epoch:  98 Step:  1003  time: 1.354601 s d_loss: 1.80782759, g_loss: 1079.32287598 -- mean_d_loss: 6.84725189, mean_g_loss: 1054.55395508\n",
            "Epoch:  98 Step:  1004  time: 1.320851 s d_loss: 0.91023690, g_loss: 937.25817871 -- mean_d_loss: 5.65984869, mean_g_loss: 1031.09484863\n",
            "Epoch:  98 Step:  1005  time: 1.330445 s d_loss: 1.00152516, g_loss: 994.24676514 -- mean_d_loss: 4.88346148, mean_g_loss: 1024.95349121\n",
            "Epoch:  98 Step:  1006  time: 1.305641 s d_loss: 6.44229412, g_loss: 928.27105713 -- mean_d_loss: 5.10615206, mean_g_loss: 1011.14166260\n",
            "Epoch:  98 Step:  1007  time: 1.333209 s d_loss: 0.85950977, g_loss: 1052.38598633 -- mean_d_loss: 4.57532167, mean_g_loss: 1016.29724121\n",
            "Epoch:  98 Step:  1008  time: 1.334132 s d_loss: 0.99563408, g_loss: 903.05126953 -- mean_d_loss: 4.17757845, mean_g_loss: 1003.71441650\n",
            "Epoch:  98 Step:  1009  time: 1.323590 s d_loss: 1.02408302, g_loss: 1146.58203125 -- mean_d_loss: 3.86222887, mean_g_loss: 1018.00115967\n",
            "Epoch:  98 Step:  1010  time: 1.287041 s d_loss: 1.97704005, g_loss: 1145.54687500 -- mean_d_loss: 3.69084787, mean_g_loss: 1029.59619141\n",
            "Epoch:  98 Step:  1011  time: 1.317708 s d_loss: 0.81498104, g_loss: 1181.75708008 -- mean_d_loss: 3.45119214, mean_g_loss: 1042.27624512\n",
            "Epoch:  98 Step:  1012  time: 1.328053 s d_loss: 0.84811789, g_loss: 1017.97460938 -- mean_d_loss: 3.25095582, mean_g_loss: 1040.40698242\n",
            "Epoch:  98 Step:  1013  time: 1.308348 s d_loss: 0.80425960, g_loss: 1128.22741699 -- mean_d_loss: 3.07619166, mean_g_loss: 1046.67980957\n",
            "Epoch:  98 Step:  1014  time: 1.318081 s d_loss: 2.78032088, g_loss: 984.66333008 -- mean_d_loss: 3.05646682, mean_g_loss: 1042.54541016\n",
            "Epoch:  98 Step:  1015  time: 1.302116 s d_loss: 1.02398324, g_loss: 1011.12487793 -- mean_d_loss: 2.92943668, mean_g_loss: 1040.58154297\n",
            "Epoch:  98 Step:  1016  time: 1.321002 s d_loss: 2.23877549, g_loss: 1227.12060547 -- mean_d_loss: 2.88880968, mean_g_loss: 1051.55444336\n",
            "Epoch:  98 Step:  1017  time: 1.320883 s d_loss: 1.31361234, g_loss: 1024.45434570 -- mean_d_loss: 2.80129886, mean_g_loss: 1050.04895020\n",
            "Epoch:  98 Step:  1018  time: 1.331625 s d_loss: 0.93775815, g_loss: 834.23309326 -- mean_d_loss: 2.70321774, mean_g_loss: 1038.69018555\n",
            "Epoch:  98 Step:  1019  time: 1.323601 s d_loss: 0.97867823, g_loss: 1026.38793945 -- mean_d_loss: 2.61699080, mean_g_loss: 1038.07507324\n",
            "Epoch:  98 Step:  1020  time: 1.330204 s d_loss: 0.75355411, g_loss: 937.02056885 -- mean_d_loss: 2.52825594, mean_g_loss: 1033.26306152\n",
            "Epoch:  98 Step:  1021  time: 1.296156 s d_loss: 11.55376434, g_loss: 972.58593750 -- mean_d_loss: 2.93850636, mean_g_loss: 1030.50500488\n",
            "Epoch:  98 Step:  1022  time: 1.316818 s d_loss: 0.92229748, g_loss: 960.04370117 -- mean_d_loss: 2.85084510, mean_g_loss: 1027.44140625\n",
            "Epoch:  98 Step:  1023  time: 1.317941 s d_loss: 0.92621320, g_loss: 1035.18750000 -- mean_d_loss: 2.77065206, mean_g_loss: 1027.76416016\n",
            "Epoch:  98 Step:  1024  time: 1.303219 s d_loss: 0.89690429, g_loss: 1020.14868164 -- mean_d_loss: 2.69570231, mean_g_loss: 1027.45947266\n",
            "Epoch:  98 Step:  1025  time: 1.322118 s d_loss: 0.95461208, g_loss: 1016.07434082 -- mean_d_loss: 2.62873721, mean_g_loss: 1027.02160645\n",
            "Epoch:  98 Step:  1026  time: 1.315054 s d_loss: 0.82960486, g_loss: 868.89416504 -- mean_d_loss: 2.56210279, mean_g_loss: 1021.16510010\n",
            "Epoch:  98 Step:  1027  time: 1.315708 s d_loss: 0.74201918, g_loss: 1090.17321777 -- mean_d_loss: 2.49709964, mean_g_loss: 1023.62969971\n",
            "Epoch:  98 Step:  1028  time: 1.304687 s d_loss: 1.20344734, g_loss: 1143.78784180 -- mean_d_loss: 2.45249104, mean_g_loss: 1027.77307129\n",
            "Epoch:  98 Step:  1029  time: 1.321967 s d_loss: 0.71715933, g_loss: 1005.67150879 -- mean_d_loss: 2.39464664, mean_g_loss: 1027.03637695\n",
            "Epoch:  98 Step:  1030  time: 1.302450 s d_loss: 24.70668983, g_loss: 959.38818359 -- mean_d_loss: 3.11438990, mean_g_loss: 1024.85412598\n",
            "Epoch:  98 Step:  1031  time: 1.326394 s d_loss: 1.09020197, g_loss: 1034.80419922 -- mean_d_loss: 3.05113411, mean_g_loss: 1025.16503906\n",
            "Epoch:  98 Step:  1032  time: 1.338267 s d_loss: 1.24194622, g_loss: 972.80383301 -- mean_d_loss: 2.99631023, mean_g_loss: 1023.57836914\n",
            "Epoch:  98 Step:  1033  time: 1.316849 s d_loss: 1.02868760, g_loss: 1102.01586914 -- mean_d_loss: 2.93843889, mean_g_loss: 1025.88537598\n",
            "Epoch:  98 Step:  1034  time: 1.330575 s d_loss: 1.31685352, g_loss: 1099.13940430 -- mean_d_loss: 2.89210796, mean_g_loss: 1027.97839355\n",
            "Epoch:  98 Step:  1035  time: 1.320346 s d_loss: 0.86066699, g_loss: 935.85992432 -- mean_d_loss: 2.83567905, mean_g_loss: 1025.41943359\n",
            "Epoch:  98 Step:  1036  time: 1.295976 s d_loss: 2.71796203, g_loss: 1074.42321777 -- mean_d_loss: 2.83249736, mean_g_loss: 1026.74389648\n",
            "Epoch:  98 Step:  1037  time: 1.295698 s d_loss: 1.06473947, g_loss: 1122.04711914 -- mean_d_loss: 2.78597760, mean_g_loss: 1029.25183105\n",
            "Epoch:  98 Step:  1038  time: 1.317852 s d_loss: 0.98773593, g_loss: 972.91772461 -- mean_d_loss: 2.73986888, mean_g_loss: 1027.80737305\n",
            "Epoch:  98 Step:  1039  time: 1.354128 s d_loss: 36.04938507, g_loss: 1009.98431396 -- mean_d_loss: 3.57260656, mean_g_loss: 1027.36181641\n",
            "Epoch:  98 Step:  1040  time: 1.315347 s d_loss: 1.09658599, g_loss: 994.16198730 -- mean_d_loss: 3.51221585, mean_g_loss: 1026.55200195\n",
            "Epoch:  98 Step:  1041  time: 1.304555 s d_loss: 3.58702087, g_loss: 1046.20227051 -- mean_d_loss: 3.51399708, mean_g_loss: 1027.01989746\n",
            "Epoch:  98 Step:  1042  time: 1.291688 s d_loss: 2.52194953, g_loss: 902.88452148 -- mean_d_loss: 3.49092603, mean_g_loss: 1024.13293457\n",
            "Epoch:  98 Step:  1043  time: 1.293953 s d_loss: 63.00714493, g_loss: 1094.14953613 -- mean_d_loss: 4.84356737, mean_g_loss: 1025.72424316\n",
            "Epoch:  98 Step:  1044  time: 1.356017 s d_loss: 2.58773041, g_loss: 996.03308105 -- mean_d_loss: 4.79343748, mean_g_loss: 1025.06445312\n",
            "Epoch:  98 Step:  1045  time: 1.305871 s d_loss: 3.15381813, g_loss: 1068.67529297 -- mean_d_loss: 4.75779343, mean_g_loss: 1026.01245117\n",
            "Epoch:  98 Step:  1046  time: 1.327403 s d_loss: 1.92044866, g_loss: 1135.23779297 -- mean_d_loss: 4.69742489, mean_g_loss: 1028.33642578\n",
            "Epoch:  98 Step:  1047  time: 1.316202 s d_loss: 2.98690963, g_loss: 1072.04650879 -- mean_d_loss: 4.66178894, mean_g_loss: 1029.24707031\n",
            "Epoch:  98 Step:  1048  time: 1.350963 s d_loss: 3.17730880, g_loss: 1110.17602539 -- mean_d_loss: 4.63149357, mean_g_loss: 1030.89868164\n",
            "Epoch:  98 Step:  1049  time: 1.348267 s d_loss: 15.47873497, g_loss: 1091.29736328 -- mean_d_loss: 4.84843826, mean_g_loss: 1032.10668945\n",
            "Epoch:  98 Step:  1050  time: 1.320295 s d_loss: 1.78173971, g_loss: 946.65930176 -- mean_d_loss: 4.78830671, mean_g_loss: 1030.43127441\n",
            "Epoch:  98 Step:  1051  time: 1.327016 s d_loss: 1.56723213, g_loss: 999.95886230 -- mean_d_loss: 4.72636318, mean_g_loss: 1029.84521484\n",
            "Epoch:  98 Step:  1052  time: 1.342682 s d_loss: 1.51034546, g_loss: 976.62060547 -- mean_d_loss: 4.66568327, mean_g_loss: 1028.84094238\n",
            "Epoch:  98 Step:  1053  time: 1.311765 s d_loss: 3.55088043, g_loss: 973.20117188 -- mean_d_loss: 4.64503860, mean_g_loss: 1027.81066895\n",
            "Epoch:  98 Step:  1054  time: 1.318376 s d_loss: 62.38284683, g_loss: 1157.14074707 -- mean_d_loss: 5.69481707, mean_g_loss: 1030.16210938\n",
            "Epoch:  98 Step:  1055  time: 1.330772 s d_loss: 3.17941070, g_loss: 898.11840820 -- mean_d_loss: 5.64989901, mean_g_loss: 1027.80407715\n",
            "Epoch:  98 Step:  1056  time: 1.325350 s d_loss: 4.83770323, g_loss: 918.36889648 -- mean_d_loss: 5.63565016, mean_g_loss: 1025.88415527\n",
            "Epoch:  98 Step:  1057  time: 1.322947 s d_loss: 1.74664855, g_loss: 944.39843750 -- mean_d_loss: 5.56859827, mean_g_loss: 1024.47924805\n",
            "Epoch:  98 Step:  1058  time: 1.320559 s d_loss: 1.63319230, g_loss: 999.19171143 -- mean_d_loss: 5.50189638, mean_g_loss: 1024.05065918\n",
            "Epoch:  98 Step:  1059  time: 1.320332 s d_loss: 0.87043446, g_loss: 905.68444824 -- mean_d_loss: 5.42470503, mean_g_loss: 1022.07788086\n",
            "Epoch:  98 Step:  1060  time: 1.358868 s d_loss: 1.11854529, g_loss: 1323.21557617 -- mean_d_loss: 5.35411215, mean_g_loss: 1027.01452637\n",
            "Epoch:  98 Step:  1061  time: 1.304862 s d_loss: 3.28141189, g_loss: 1000.59204102 -- mean_d_loss: 5.32068110, mean_g_loss: 1026.58837891\n",
            "Epoch:  98 Step:  1062  time: 1.323459 s d_loss: 1.29114306, g_loss: 1003.10388184 -- mean_d_loss: 5.25672007, mean_g_loss: 1026.21569824\n",
            "Epoch:  98 Step:  1063  time: 1.328302 s d_loss: 2.08777833, g_loss: 983.00939941 -- mean_d_loss: 5.20720530, mean_g_loss: 1025.54052734\n",
            "Epoch:  98 Step:  1064  time: 1.326079 s d_loss: 0.97196358, g_loss: 965.72869873 -- mean_d_loss: 5.14204741, mean_g_loss: 1024.62036133\n",
            "Epoch:  98 Step:  1065  time: 1.306623 s d_loss: 1.37382555, g_loss: 954.27612305 -- mean_d_loss: 5.08495331, mean_g_loss: 1023.55444336\n",
            "Epoch:  98 Step:  1066  time: 1.307659 s d_loss: 1.75886917, g_loss: 929.97717285 -- mean_d_loss: 5.03531075, mean_g_loss: 1022.15777588\n",
            "Epoch:  98 Step:  1067  time: 1.301222 s d_loss: 0.94550961, g_loss: 832.32434082 -- mean_d_loss: 4.97516632, mean_g_loss: 1019.36614990\n",
            "Epoch:  98 Step:  1068  time: 1.318130 s d_loss: 2.41787791, g_loss: 1053.05981445 -- mean_d_loss: 4.93810415, mean_g_loss: 1019.85449219\n",
            "Epoch:  98 Step:  1069  time: 1.318571 s d_loss: 1.63026929, g_loss: 915.87573242 -- mean_d_loss: 4.89084959, mean_g_loss: 1018.36907959\n",
            "Epoch:  98 Step:  1070  time: 1.324951 s d_loss: 0.74474531, g_loss: 1101.14782715 -- mean_d_loss: 4.83245373, mean_g_loss: 1019.53497314\n",
            "Epoch:  98 Step:  1071  time: 1.339495 s d_loss: 1.00027096, g_loss: 1044.69763184 -- mean_d_loss: 4.77922916, mean_g_loss: 1019.88446045\n",
            "Epoch:  98 Step:  1072  time: 1.335925 s d_loss: 1.72193003, g_loss: 1170.69775391 -- mean_d_loss: 4.73734808, mean_g_loss: 1021.95031738\n",
            "Epoch:  98 Step:  1073  time: 1.308036 s d_loss: 1.00837898, g_loss: 1008.16418457 -- mean_d_loss: 4.68695688, mean_g_loss: 1021.76403809\n",
            "Epoch:  98 Step:  1074  time: 1.314293 s d_loss: 0.92341518, g_loss: 1039.80981445 -- mean_d_loss: 4.63677597, mean_g_loss: 1022.00469971\n",
            "Epoch:  98 Step:  1075  time: 1.283577 s d_loss: 0.93657374, g_loss: 1084.50207520 -- mean_d_loss: 4.58808947, mean_g_loss: 1022.82696533\n",
            "Epoch:  98 Step:  1076  time: 1.314778 s d_loss: 1.47561455, g_loss: 1025.43591309 -- mean_d_loss: 4.54766750, mean_g_loss: 1022.86090088\n",
            "Epoch:  98 Step:  1077  time: 1.295825 s d_loss: 0.90192002, g_loss: 960.93280029 -- mean_d_loss: 4.50092745, mean_g_loss: 1022.06689453\n",
            "Epoch:  98 Step:  1078  time: 1.319802 s d_loss: 44.03943253, g_loss: 1044.11535645 -- mean_d_loss: 5.00141478, mean_g_loss: 1022.34600830\n",
            "Epoch:  98 Step:  1079  time: 1.318191 s d_loss: 1.26429307, g_loss: 1064.52636719 -- mean_d_loss: 4.95470047, mean_g_loss: 1022.87322998\n",
            "Epoch:  98 Step:  1080  time: 1.317548 s d_loss: 3.64661121, g_loss: 950.61352539 -- mean_d_loss: 4.93855095, mean_g_loss: 1021.98120117\n",
            "Epoch:  98 Step:  1081  time: 1.326172 s d_loss: 4.66457462, g_loss: 1133.95751953 -- mean_d_loss: 4.93521023, mean_g_loss: 1023.34680176\n",
            "Epoch:  98 Step:  1082  time: 1.307097 s d_loss: 4.24953318, g_loss: 1004.50311279 -- mean_d_loss: 4.92694902, mean_g_loss: 1023.11975098\n",
            "Epoch:  98 Step:  1083  time: 1.321658 s d_loss: 59.78888702, g_loss: 1012.32849121 -- mean_d_loss: 5.58006716, mean_g_loss: 1022.99127197\n",
            "Epoch:  98 Step:  1084  time: 1.299786 s d_loss: 3.49308157, g_loss: 904.86535645 -- mean_d_loss: 5.55551434, mean_g_loss: 1021.60156250\n",
            "Epoch:  98 Step:  1085  time: 1.312664 s d_loss: 2.96971250, g_loss: 1041.01965332 -- mean_d_loss: 5.52544689, mean_g_loss: 1021.82739258\n",
            "Epoch:  98 Step:  1086  time: 1.295599 s d_loss: 1.87954652, g_loss: 959.27911377 -- mean_d_loss: 5.48354006, mean_g_loss: 1021.10845947\n",
            "Epoch:  98 Step:  1087  time: 1.289740 s d_loss: 1.09496653, g_loss: 1059.23461914 -- mean_d_loss: 5.43367004, mean_g_loss: 1021.54174805\n",
            "Epoch:  98 Step:  1088  time: 1.308764 s d_loss: 0.83303410, g_loss: 902.22229004 -- mean_d_loss: 5.38197756, mean_g_loss: 1020.20098877\n",
            "Epoch:  98 Step:  1089  time: 1.334097 s d_loss: 15.20431614, g_loss: 978.68420410 -- mean_d_loss: 5.49111462, mean_g_loss: 1019.73974609\n",
            "Epoch:  98 Step:  1090  time: 1.316937 s d_loss: 37.68838120, g_loss: 1125.81396484 -- mean_d_loss: 5.84493065, mean_g_loss: 1020.90539551\n",
            "Epoch:  98 Step:  1091  time: 1.291990 s d_loss: 2.19458723, g_loss: 958.21368408 -- mean_d_loss: 5.80525255, mean_g_loss: 1020.22393799\n",
            "Epoch:  98 Step:  1092  time: 1.340136 s d_loss: 3.78628683, g_loss: 1122.63964844 -- mean_d_loss: 5.78354359, mean_g_loss: 1021.32519531\n",
            "Epoch:  98 Step:  1093  time: 1.329044 s d_loss: 56.91906738, g_loss: 985.38488770 -- mean_d_loss: 6.32753849, mean_g_loss: 1020.94281006\n",
            "Epoch:  98 Step:  1094  time: 1.313402 s d_loss: 3.85354805, g_loss: 907.43078613 -- mean_d_loss: 6.30149698, mean_g_loss: 1019.74792480\n",
            "Epoch:  98 Step:  1095  time: 1.312255 s d_loss: 4.28268719, g_loss: 870.83325195 -- mean_d_loss: 6.28046799, mean_g_loss: 1018.19677734\n",
            "Epoch:  98 Step:  1096  time: 1.313467 s d_loss: 6.66324472, g_loss: 1057.50891113 -- mean_d_loss: 6.28441429, mean_g_loss: 1018.60205078\n",
            "Epoch:  98 Step:  1097  time: 1.323026 s d_loss: 2.51092482, g_loss: 1148.56518555 -- mean_d_loss: 6.24590921, mean_g_loss: 1019.92816162\n",
            "Epoch:  98 Step:  1098  time: 1.320551 s d_loss: 3.41485953, g_loss: 1047.61523438 -- mean_d_loss: 6.21731281, mean_g_loss: 1020.20788574\n",
            "Epoch:  98 Step:  1099  time: 1.321412 s d_loss: 6.06019831, g_loss: 1022.14910889 -- mean_d_loss: 6.21574163, mean_g_loss: 1020.22729492\n",
            "Epoch:  98 Step:  1100  time: 1.323312 s d_loss: 0.90107250, g_loss: 856.36694336 -- mean_d_loss: 6.16312122, mean_g_loss: 1018.60485840\n",
            "Epoch:  98 Step:  1101  time: 1.292972 s d_loss: 0.99136847, g_loss: 1159.32617188 -- mean_d_loss: 6.11241770, mean_g_loss: 1019.98455811\n",
            "Epoch:  98 Step:  1102  time: 1.310402 s d_loss: 0.81724048, g_loss: 900.37512207 -- mean_d_loss: 6.06100845, mean_g_loss: 1018.82324219\n",
            "Epoch:  98 Step:  1103  time: 1.339897 s d_loss: 22.04080200, g_loss: 1032.56591797 -- mean_d_loss: 6.21466064, mean_g_loss: 1018.95538330\n",
            "Epoch:  98 Step:  1104  time: 1.320131 s d_loss: 1.22684288, g_loss: 979.41333008 -- mean_d_loss: 6.16715765, mean_g_loss: 1018.57879639\n",
            "Epoch:  98 Step:  1105  time: 1.329911 s d_loss: 1.49614441, g_loss: 1090.81176758 -- mean_d_loss: 6.12309170, mean_g_loss: 1019.26025391\n",
            "Epoch:  98 Step:  1106  time: 1.292387 s d_loss: 6.81449556, g_loss: 1184.53051758 -- mean_d_loss: 6.12955379, mean_g_loss: 1020.80480957\n",
            "Epoch:  98 Step:  1107  time: 1.316951 s d_loss: 2.05763555, g_loss: 994.59539795 -- mean_d_loss: 6.09185076, mean_g_loss: 1020.56213379\n",
            "Epoch:  98 Step:  1108  time: 1.315197 s d_loss: 1.75461853, g_loss: 1024.38745117 -- mean_d_loss: 6.05205965, mean_g_loss: 1020.59729004\n",
            "Epoch:  98 Step:  1109  time: 1.293148 s d_loss: 14.87399673, g_loss: 1139.10644531 -- mean_d_loss: 6.13225937, mean_g_loss: 1021.67462158\n",
            "Epoch:  98 Step:  1110  time: 1.288912 s d_loss: 2.12050104, g_loss: 837.48913574 -- mean_d_loss: 6.09611702, mean_g_loss: 1020.01531982\n",
            "Epoch:  98 Step:  1111  time: 1.294038 s d_loss: 7.59999561, g_loss: 1047.66882324 -- mean_d_loss: 6.10954428, mean_g_loss: 1020.26226807\n",
            "Epoch:  98 Step:  1112  time: 1.321399 s d_loss: 2.38314247, g_loss: 1001.86535645 -- mean_d_loss: 6.07656717, mean_g_loss: 1020.09948730\n",
            "Epoch:  98 Step:  1113  time: 1.326615 s d_loss: 2.20908761, g_loss: 980.54528809 -- mean_d_loss: 6.04264212, mean_g_loss: 1019.75256348\n",
            "Epoch:  98 Step:  1114  time: 1.329044 s d_loss: 1.45774317, g_loss: 972.66345215 -- mean_d_loss: 6.00277376, mean_g_loss: 1019.34307861\n",
            "Epoch:  98 Step:  1115  time: 1.324036 s d_loss: 4.02405596, g_loss: 1206.86254883 -- mean_d_loss: 5.98571587, mean_g_loss: 1020.95959473\n",
            "Epoch:  98 Step:  1116  time: 1.318421 s d_loss: 3.68148994, g_loss: 994.88037109 -- mean_d_loss: 5.96602154, mean_g_loss: 1020.73669434\n",
            "Epoch:  98 Step:  1117  time: 1.313983 s d_loss: 3.16761231, g_loss: 1032.48937988 -- mean_d_loss: 5.94230604, mean_g_loss: 1020.83636475\n",
            "Epoch:  98 Step:  1118  time: 1.294167 s d_loss: 3.09833550, g_loss: 1089.68786621 -- mean_d_loss: 5.91840744, mean_g_loss: 1021.41491699\n",
            "Epoch:  98 Step:  1119  time: 1.335335 s d_loss: 2.04299736, g_loss: 1213.01501465 -- mean_d_loss: 5.88611174, mean_g_loss: 1023.01159668\n",
            "Epoch:  98 Step:  1120  time: 1.307344 s d_loss: 1.45733166, g_loss: 1006.82659912 -- mean_d_loss: 5.84951067, mean_g_loss: 1022.87786865\n",
            "Epoch:  98 Step:  1121  time: 1.315775 s d_loss: 1.08908439, g_loss: 1065.07373047 -- mean_d_loss: 5.81049061, mean_g_loss: 1023.22369385\n",
            "Epoch:  98 Step:  1122  time: 1.342962 s d_loss: 1.07908154, g_loss: 1019.91479492 -- mean_d_loss: 5.77202415, mean_g_loss: 1023.19677734\n",
            "Epoch:  98 Step:  1123  time: 1.335057 s d_loss: 0.75852257, g_loss: 1124.78808594 -- mean_d_loss: 5.73159313, mean_g_loss: 1024.01611328\n",
            "Epoch:  98 Step:  1124  time: 1.331121 s d_loss: 1.01216221, g_loss: 1035.72875977 -- mean_d_loss: 5.69383717, mean_g_loss: 1024.10974121\n",
            "Epoch:  98 Step:  1125  time: 1.332926 s d_loss: 0.71180040, g_loss: 1049.34301758 -- mean_d_loss: 5.65429735, mean_g_loss: 1024.31005859\n",
            "Epoch:  98 Step:  1126  time: 1.325837 s d_loss: 0.92278665, g_loss: 1168.37597656 -- mean_d_loss: 5.61704159, mean_g_loss: 1025.44433594\n",
            "Epoch:  98 Step:  1127  time: 1.311088 s d_loss: 0.87827295, g_loss: 911.88214111 -- mean_d_loss: 5.58001995, mean_g_loss: 1024.55712891\n",
            "Epoch:  98 Step:  1128  time: 1.301893 s d_loss: 0.76248717, g_loss: 1271.54504395 -- mean_d_loss: 5.54267502, mean_g_loss: 1026.47180176\n",
            "Epoch:  98 Step:  1129  time: 1.288170 s d_loss: 1.23942840, g_loss: 1202.37207031 -- mean_d_loss: 5.50957298, mean_g_loss: 1027.82482910\n",
            "Epoch:  98 Step:  1130  time: 1.310250 s d_loss: 1.07277381, g_loss: 889.84655762 -- mean_d_loss: 5.47570419, mean_g_loss: 1026.77160645\n",
            "Epoch:  98 Step:  1131  time: 1.352612 s d_loss: 0.77316153, g_loss: 1019.30261230 -- mean_d_loss: 5.44007874, mean_g_loss: 1026.71496582\n",
            "Epoch:  98 Step:  1132  time: 1.330018 s d_loss: 0.79391354, g_loss: 929.45410156 -- mean_d_loss: 5.40514517, mean_g_loss: 1025.98364258\n",
            "Epoch:  98 Step:  1133  time: 1.317372 s d_loss: 0.89877760, g_loss: 1161.27905273 -- mean_d_loss: 5.37151575, mean_g_loss: 1026.99340820\n",
            "Epoch:  98 Step:  1134  time: 1.325022 s d_loss: 0.56262881, g_loss: 941.60571289 -- mean_d_loss: 5.33589411, mean_g_loss: 1026.36083984\n",
            "Epoch:  98 Step:  1135  time: 1.322392 s d_loss: 0.73600507, g_loss: 1074.84277344 -- mean_d_loss: 5.30207157, mean_g_loss: 1026.71740723\n",
            "Epoch:  98 Step:  1136  time: 1.325028 s d_loss: 0.70394236, g_loss: 1063.81982422 -- mean_d_loss: 5.26850843, mean_g_loss: 1026.98815918\n",
            "Epoch:  98 Step:  1137  time: 1.314575 s d_loss: 0.73735225, g_loss: 1005.78845215 -- mean_d_loss: 5.23567390, mean_g_loss: 1026.83447266\n",
            "Epoch:  98 Step:  1138  time: 1.301385 s d_loss: 0.92870849, g_loss: 1087.10412598 -- mean_d_loss: 5.20468855, mean_g_loss: 1027.26806641\n",
            "Epoch:  98 Step:  1139  time: 1.304653 s d_loss: 2.96996951, g_loss: 1134.41931152 -- mean_d_loss: 5.18872643, mean_g_loss: 1028.03344727\n",
            "Epoch:  98 Step:  1140  time: 1.332455 s d_loss: 0.72103029, g_loss: 968.37304688 -- mean_d_loss: 5.15704060, mean_g_loss: 1027.61035156\n",
            "Epoch:  98 Step:  1141  time: 1.327073 s d_loss: 0.91802430, g_loss: 1100.26025391 -- mean_d_loss: 5.12718821, mean_g_loss: 1028.12207031\n",
            "Epoch:  98 Step:  1142  time: 1.321114 s d_loss: 1.34810722, g_loss: 1003.99768066 -- mean_d_loss: 5.10076094, mean_g_loss: 1027.95336914\n",
            "Epoch:  98 Step:  1143  time: 1.289899 s d_loss: 1.16568601, g_loss: 1301.09008789 -- mean_d_loss: 5.07343435, mean_g_loss: 1029.85009766\n",
            "Epoch:  98 Step:  1144  time: 1.319020 s d_loss: 0.53979707, g_loss: 1042.79492188 -- mean_d_loss: 5.04216766, mean_g_loss: 1029.93945312\n",
            "Epoch:  98 Step:  1145  time: 1.314814 s d_loss: 0.70844084, g_loss: 946.38891602 -- mean_d_loss: 5.01248455, mean_g_loss: 1029.36718750\n",
            "Epoch:  98 Step:  1146  time: 1.323615 s d_loss: 9.11510754, g_loss: 976.38763428 -- mean_d_loss: 5.04039383, mean_g_loss: 1029.00683594\n",
            "Epoch:  98 Step:  1147  time: 1.293427 s d_loss: 0.82390994, g_loss: 1046.60754395 -- mean_d_loss: 5.01190376, mean_g_loss: 1029.12573242\n",
            "Epoch:  98 Step:  1148  time: 1.320913 s d_loss: 1.35536253, g_loss: 1095.39624023 -- mean_d_loss: 4.98736334, mean_g_loss: 1029.57043457\n",
            "Epoch:  98 Step:  1149  time: 1.315238 s d_loss: 0.87925518, g_loss: 942.27038574 -- mean_d_loss: 4.95997620, mean_g_loss: 1028.98840332\n",
            "Epoch:  98 Step:  1150  time: 1.289196 s d_loss: 11.49125767, g_loss: 1041.35034180 -- mean_d_loss: 5.00322962, mean_g_loss: 1029.07031250\n",
            "Epoch:  98 Step:  1151  time: 1.279025 s d_loss: 0.98455602, g_loss: 1087.28771973 -- mean_d_loss: 4.97679090, mean_g_loss: 1029.45324707\n",
            "Epoch:  98 Step:  1152  time: 1.317493 s d_loss: 1.09122097, g_loss: 1032.75708008 -- mean_d_loss: 4.95139503, mean_g_loss: 1029.47473145\n",
            "Epoch:  98 Step:  1153  time: 1.288213 s d_loss: 0.84042293, g_loss: 969.49987793 -- mean_d_loss: 4.92470026, mean_g_loss: 1029.08532715\n",
            "Epoch:  98 Step:  1154  time: 1.309605 s d_loss: 0.61532491, g_loss: 808.23303223 -- mean_d_loss: 4.89689779, mean_g_loss: 1027.66052246\n",
            "Epoch:  98 Step:  1155  time: 1.318254 s d_loss: 0.86766487, g_loss: 1000.01184082 -- mean_d_loss: 4.87106943, mean_g_loss: 1027.48327637\n",
            "Epoch:  98 Step:  1156  time: 1.331215 s d_loss: 1.00637519, g_loss: 996.17431641 -- mean_d_loss: 4.84645367, mean_g_loss: 1027.28381348\n",
            "Epoch:  98 Step:  1157  time: 1.305801 s d_loss: 0.73492068, g_loss: 996.23010254 -- mean_d_loss: 4.82043123, mean_g_loss: 1027.08728027\n",
            "Epoch:  98 Step:  1158  time: 1.318671 s d_loss: 1.04712772, g_loss: 1036.81738281 -- mean_d_loss: 4.79669952, mean_g_loss: 1027.14843750\n",
            "Epoch:  98 Step:  1159  time: 1.318225 s d_loss: 0.71266133, g_loss: 1069.20983887 -- mean_d_loss: 4.77117443, mean_g_loss: 1027.41137695\n",
            "Epoch:  98 Step:  1160  time: 1.337652 s d_loss: 1.42003548, g_loss: 852.34600830 -- mean_d_loss: 4.75035954, mean_g_loss: 1026.32397461\n",
            "Epoch:  98 Step:  1161  time: 1.318305 s d_loss: 0.60284364, g_loss: 899.28601074 -- mean_d_loss: 4.72475767, mean_g_loss: 1025.53979492\n",
            "Epoch:  98 Step:  1162  time: 1.334594 s d_loss: 0.78284281, g_loss: 1148.80847168 -- mean_d_loss: 4.70057440, mean_g_loss: 1026.29602051\n",
            "Epoch:  98 Step:  1163  time: 1.274788 s d_loss: 0.65280747, g_loss: 967.28637695 -- mean_d_loss: 4.67589283, mean_g_loss: 1025.93615723\n",
            "Epoch:  98 Step:  1164  time: 1.288926 s d_loss: 0.79192722, g_loss: 912.40930176 -- mean_d_loss: 4.65235376, mean_g_loss: 1025.24804688\n",
            "Epoch:  98 Step:  1165  time: 1.328949 s d_loss: 0.76236695, g_loss: 1074.39123535 -- mean_d_loss: 4.62892008, mean_g_loss: 1025.54418945\n",
            "Epoch:  98 Step:  1166  time: 1.322201 s d_loss: 0.71620727, g_loss: 1023.54968262 -- mean_d_loss: 4.60549068, mean_g_loss: 1025.53222656\n",
            "Epoch:  98 Step:  1167  time: 1.343919 s d_loss: 0.68554753, g_loss: 1291.81982422 -- mean_d_loss: 4.58215761, mean_g_loss: 1027.11718750\n",
            "Epoch:  98 Step:  1168  time: 1.293361 s d_loss: 0.76831543, g_loss: 999.10839844 -- mean_d_loss: 4.55959034, mean_g_loss: 1026.95141602\n",
            "Epoch:  98 Step:  1169  time: 1.286214 s d_loss: 3.65126395, g_loss: 1052.42675781 -- mean_d_loss: 4.55424738, mean_g_loss: 1027.10131836\n",
            "Epoch:  98 Step:  1170  time: 1.316172 s d_loss: 1.12220299, g_loss: 918.34930420 -- mean_d_loss: 4.53417683, mean_g_loss: 1026.46533203\n",
            "Epoch:  98 Step:  1171  time: 1.298322 s d_loss: 0.88135689, g_loss: 977.35766602 -- mean_d_loss: 4.51293945, mean_g_loss: 1026.17980957\n",
            "Epoch:  98 Step:  1172  time: 1.307473 s d_loss: 0.71667731, g_loss: 875.30578613 -- mean_d_loss: 4.49099588, mean_g_loss: 1025.30773926\n",
            "Epoch:  98 Step:  1173  time: 1.316754 s d_loss: 0.62544411, g_loss: 986.89184570 -- mean_d_loss: 4.46878004, mean_g_loss: 1025.08691406\n",
            "Epoch:  98 Step:  1174  time: 1.317059 s d_loss: 0.69291669, g_loss: 1072.97851562 -- mean_d_loss: 4.44720364, mean_g_loss: 1025.36059570\n",
            "Epoch:  98 Step:  1175  time: 1.320785 s d_loss: 1.18731892, g_loss: 1073.93188477 -- mean_d_loss: 4.42868137, mean_g_loss: 1025.63659668\n",
            "Epoch:  98 Step:  1176  time: 1.334796 s d_loss: 0.72612107, g_loss: 1025.14538574 -- mean_d_loss: 4.40776300, mean_g_loss: 1025.63378906\n",
            "Epoch:  98 Step:  1177  time: 1.319382 s d_loss: 0.65801287, g_loss: 1167.60327148 -- mean_d_loss: 4.38669729, mean_g_loss: 1026.43139648\n",
            "Epoch:  98 Step:  1178  time: 1.331978 s d_loss: 31.17211533, g_loss: 1002.74658203 -- mean_d_loss: 4.53633642, mean_g_loss: 1026.29919434\n",
            "Epoch:  98 Step:  1179  time: 1.316170 s d_loss: 1.34708202, g_loss: 1055.68017578 -- mean_d_loss: 4.51861858, mean_g_loss: 1026.46240234\n",
            "Epoch:  98 Step:  1180  time: 1.308907 s d_loss: 1.35365939, g_loss: 905.16259766 -- mean_d_loss: 4.50113249, mean_g_loss: 1025.79223633\n",
            "Epoch:  98 Step:  1181  time: 1.318979 s d_loss: 1.57264578, g_loss: 999.10552979 -- mean_d_loss: 4.48504162, mean_g_loss: 1025.64562988\n",
            "Epoch:  98 Step:  1182  time: 1.285665 s d_loss: 0.80243242, g_loss: 975.72070312 -- mean_d_loss: 4.46491814, mean_g_loss: 1025.37280273\n",
            "Epoch:  98 Step:  1183  time: 1.331345 s d_loss: 3.06927681, g_loss: 1028.27856445 -- mean_d_loss: 4.45733309, mean_g_loss: 1025.38854980\n",
            "Epoch:  98 Step:  1184  time: 1.291275 s d_loss: 0.66054797, g_loss: 1104.61755371 -- mean_d_loss: 4.43681002, mean_g_loss: 1025.81689453\n",
            "Epoch:  98 Step:  1185  time: 1.318557 s d_loss: 0.85505801, g_loss: 1045.86169434 -- mean_d_loss: 4.41755295, mean_g_loss: 1025.92468262\n",
            "Epoch:  98 Step:  1186  time: 1.322352 s d_loss: 0.73911071, g_loss: 914.92736816 -- mean_d_loss: 4.39788246, mean_g_loss: 1025.33105469\n",
            "Epoch:  98 Step:  1187  time: 1.283121 s d_loss: 0.63363296, g_loss: 937.20922852 -- mean_d_loss: 4.37785959, mean_g_loss: 1024.86230469\n",
            "Epoch:  98 Step:  1188  time: 1.325932 s d_loss: 0.72999424, g_loss: 999.89746094 -- mean_d_loss: 4.35855865, mean_g_loss: 1024.73010254\n",
            "Epoch:  98 Step:  1189  time: 1.326076 s d_loss: 0.73183054, g_loss: 1046.60266113 -- mean_d_loss: 4.33947039, mean_g_loss: 1024.84533691\n",
            "Epoch:  98 Step:  1190  time: 1.322813 s d_loss: 2.61053658, g_loss: 990.44738770 -- mean_d_loss: 4.33041859, mean_g_loss: 1024.66528320\n",
            "Epoch:  98 Step:  1191  time: 1.301355 s d_loss: 0.73974919, g_loss: 1033.99157715 -- mean_d_loss: 4.31171703, mean_g_loss: 1024.71374512\n",
            "Epoch:  98 Step:  1192  time: 1.314678 s d_loss: 1.05968261, g_loss: 998.31652832 -- mean_d_loss: 4.29486704, mean_g_loss: 1024.57702637\n",
            "Epoch:  98 Step:  1193  time: 1.320470 s d_loss: 0.70761812, g_loss: 1040.59179688 -- mean_d_loss: 4.27637625, mean_g_loss: 1024.65954590\n",
            "Epoch:  98 Step:  1194  time: 1.321694 s d_loss: 0.99724901, g_loss: 1081.35034180 -- mean_d_loss: 4.25956011, mean_g_loss: 1024.95019531\n",
            "Epoch:  98 Step:  1195  time: 1.326073 s d_loss: 0.67262906, g_loss: 894.39685059 -- mean_d_loss: 4.24125957, mean_g_loss: 1024.28417969\n",
            "Epoch:  98 Step:  1196  time: 1.344842 s d_loss: 35.10615921, g_loss: 1145.09716797 -- mean_d_loss: 4.39793396, mean_g_loss: 1024.89733887\n",
            "Epoch:  98 Step:  1197  time: 1.324479 s d_loss: 2.07329011, g_loss: 1001.14129639 -- mean_d_loss: 4.38619328, mean_g_loss: 1024.77734375\n",
            "Epoch:  98 Step:  1198  time: 1.328384 s d_loss: 0.97266442, g_loss: 988.70983887 -- mean_d_loss: 4.36904001, mean_g_loss: 1024.59606934\n",
            "Epoch:  98 Step:  1199  time: 1.301869 s d_loss: 8.67319775, g_loss: 1079.64025879 -- mean_d_loss: 4.39056110, mean_g_loss: 1024.87133789\n",
            "Epoch:  98 Step:  1200  time: 1.298775 s d_loss: 0.96936238, g_loss: 989.84008789 -- mean_d_loss: 0.96936238, mean_g_loss: 989.84008789\n",
            "Epoch:  98 Step:  1201  time: 1.328798 s d_loss: 0.96883506, g_loss: 1122.21154785 -- mean_d_loss: 0.96909869, mean_g_loss: 1056.02587891\n",
            "Epoch:  98 Step:  1202  time: 1.336552 s d_loss: 0.68566293, g_loss: 1095.22448730 -- mean_d_loss: 0.87462014, mean_g_loss: 1069.09216309\n",
            "Epoch:  98 Step:  1203  time: 1.286464 s d_loss: 1.84967482, g_loss: 1063.35241699 -- mean_d_loss: 1.11838377, mean_g_loss: 1067.65722656\n",
            "Epoch:  98 Step:  1204  time: 1.320292 s d_loss: 1.54379356, g_loss: 990.51757812 -- mean_d_loss: 1.20346570, mean_g_loss: 1052.22924805\n",
            "Epoch:  98 Step:  1205  time: 1.326348 s d_loss: 0.55976748, g_loss: 946.74932861 -- mean_d_loss: 1.09618270, mean_g_loss: 1034.64929199\n",
            "Epoch:  98 Step:  1206  time: 1.316758 s d_loss: 6.02106714, g_loss: 1088.53076172 -- mean_d_loss: 1.79973769, mean_g_loss: 1042.34667969\n",
            "Epoch:  98 Step:  1207  time: 1.284994 s d_loss: 1.09092414, g_loss: 1083.59472656 -- mean_d_loss: 1.71113598, mean_g_loss: 1047.50268555\n",
            "Epoch:  98 Step:  1208  time: 1.329890 s d_loss: 1.74119961, g_loss: 941.24243164 -- mean_d_loss: 1.71447635, mean_g_loss: 1035.69592285\n",
            "Epoch:  98 Step:  1209  time: 1.300990 s d_loss: 0.72883981, g_loss: 1039.32141113 -- mean_d_loss: 1.61591268, mean_g_loss: 1036.05847168\n",
            "Epoch:  98 Step:  1210  time: 1.283789 s d_loss: 0.67689008, g_loss: 917.71313477 -- mean_d_loss: 1.53054690, mean_g_loss: 1025.29980469\n",
            "Epoch:  98 Step:  1211  time: 1.339860 s d_loss: 0.72489244, g_loss: 1179.10241699 -- mean_d_loss: 1.46340895, mean_g_loss: 1038.11669922\n",
            "Epoch:  98 Step:  1212  time: 1.319613 s d_loss: 1.03841186, g_loss: 987.30096436 -- mean_d_loss: 1.43071687, mean_g_loss: 1034.20776367\n",
            "Epoch:  98 Step:  1213  time: 1.311877 s d_loss: 0.52351898, g_loss: 978.73199463 -- mean_d_loss: 1.36591709, mean_g_loss: 1030.24523926\n",
            "Epoch:  98 Step:  1214  time: 1.288939 s d_loss: 0.61867148, g_loss: 1166.14233398 -- mean_d_loss: 1.31610072, mean_g_loss: 1039.30505371\n",
            "Epoch:  98 Step:  1215  time: 1.317401 s d_loss: 0.46119189, g_loss: 1094.22607422 -- mean_d_loss: 1.26266885, mean_g_loss: 1042.73767090\n",
            "Epoch:  98 Step:  1216  time: 1.324785 s d_loss: 0.46416318, g_loss: 1097.41259766 -- mean_d_loss: 1.21569788, mean_g_loss: 1045.95385742\n",
            "Epoch:  98 Step:  1217  time: 1.310245 s d_loss: 7.17653704, g_loss: 1124.34948730 -- mean_d_loss: 1.54685557, mean_g_loss: 1050.30908203\n",
            "Epoch:  98 Step:  1218  time: 1.326593 s d_loss: 1.03750861, g_loss: 1033.69531250 -- mean_d_loss: 1.52004778, mean_g_loss: 1049.43469238\n",
            "Epoch:  98 Step:  1219  time: 1.293808 s d_loss: 0.79011482, g_loss: 1101.04028320 -- mean_d_loss: 1.48355126, mean_g_loss: 1052.01501465\n",
            "Epoch:  98 Step:  1220  time: 1.329368 s d_loss: 0.82792473, g_loss: 996.23095703 -- mean_d_loss: 1.45233095, mean_g_loss: 1049.35864258\n",
            "Epoch:  98 Step:  1221  time: 1.312362 s d_loss: 0.62123340, g_loss: 953.30743408 -- mean_d_loss: 1.41455376, mean_g_loss: 1044.99267578\n",
            "Epoch:  98 Step:  1222  time: 1.290976 s d_loss: 0.94142330, g_loss: 1027.22521973 -- mean_d_loss: 1.39398277, mean_g_loss: 1044.22009277\n",
            "Epoch:  98 Step:  1223  time: 1.315523 s d_loss: 0.96874976, g_loss: 1206.66625977 -- mean_d_loss: 1.37626469, mean_g_loss: 1050.98864746\n",
            "Epoch:  98 Step:  1224  time: 1.301055 s d_loss: 0.68297684, g_loss: 1034.62316895 -- mean_d_loss: 1.34853315, mean_g_loss: 1050.33410645\n",
            "Epoch:  98 Step:  1225  time: 1.341347 s d_loss: 5.32839441, g_loss: 1038.25988770 -- mean_d_loss: 1.50160480, mean_g_loss: 1049.86962891\n",
            "Epoch:  98 Step:  1226  time: 1.335505 s d_loss: 0.75675845, g_loss: 1028.97436523 -- mean_d_loss: 1.47401798, mean_g_loss: 1049.09582520\n",
            "Epoch:  98 Step:  1227  time: 1.353710 s d_loss: 0.91682345, g_loss: 1038.99047852 -- mean_d_loss: 1.45411813, mean_g_loss: 1048.73486328\n",
            "Epoch:  98 Step:  1228  time: 1.327881 s d_loss: 0.75614560, g_loss: 862.09716797 -- mean_d_loss: 1.43005013, mean_g_loss: 1042.29907227\n",
            "Epoch:  98 Step:  1229  time: 1.285352 s d_loss: 0.73092312, g_loss: 1117.34790039 -- mean_d_loss: 1.40674591, mean_g_loss: 1044.80065918\n",
            "Epoch:  98 Step:  1230  time: 1.321749 s d_loss: 1.29261863, g_loss: 970.63513184 -- mean_d_loss: 1.40306437, mean_g_loss: 1042.40832520\n",
            "Epoch:  98 Step:  1231  time: 1.304990 s d_loss: 0.62650621, g_loss: 960.46850586 -- mean_d_loss: 1.37879694, mean_g_loss: 1039.84765625\n",
            "Epoch:  98 Step:  1232  time: 1.322001 s d_loss: 0.77096939, g_loss: 1007.69909668 -- mean_d_loss: 1.36037791, mean_g_loss: 1038.87341309\n",
            "Epoch:  98 Step:  1233  time: 1.310890 s d_loss: 0.86155683, g_loss: 1079.09497070 -- mean_d_loss: 1.34570670, mean_g_loss: 1040.05639648\n",
            "Epoch:  98 Step:  1234  time: 1.288988 s d_loss: 0.75067294, g_loss: 937.35845947 -- mean_d_loss: 1.32870567, mean_g_loss: 1037.12219238\n",
            "Epoch:  98 Step:  1235  time: 1.303207 s d_loss: 0.81802130, g_loss: 1051.81530762 -- mean_d_loss: 1.31452000, mean_g_loss: 1037.53039551\n",
            "Epoch:  98 Step:  1236  time: 1.341272 s d_loss: 0.52145177, g_loss: 1037.14465332 -- mean_d_loss: 1.29308569, mean_g_loss: 1037.51989746\n",
            "Epoch:  98 Step:  1237  time: 1.315378 s d_loss: 0.63420224, g_loss: 1000.79461670 -- mean_d_loss: 1.27574658, mean_g_loss: 1036.55346680\n",
            "Epoch:  98 Step:  1238  time: 1.321528 s d_loss: 0.74202299, g_loss: 996.01245117 -- mean_d_loss: 1.26206136, mean_g_loss: 1035.51391602\n",
            "Epoch:  98 Step:  1239  time: 1.302109 s d_loss: 1.47654116, g_loss: 997.79882812 -- mean_d_loss: 1.26742339, mean_g_loss: 1034.57104492\n",
            "Epoch:  98 Step:  1240  time: 1.325692 s d_loss: 0.77003765, g_loss: 891.76385498 -- mean_d_loss: 1.25529206, mean_g_loss: 1031.08801270\n",
            "Epoch:  98 Step:  1241  time: 1.326350 s d_loss: 0.64825749, g_loss: 968.36456299 -- mean_d_loss: 1.24083877, mean_g_loss: 1029.59460449\n",
            "Epoch:  98 Step:  1242  time: 1.310151 s d_loss: 0.60621822, g_loss: 936.47839355 -- mean_d_loss: 1.22608018, mean_g_loss: 1027.42907715\n",
            "Epoch:  98 Step:  1243  time: 1.311746 s d_loss: 6.47828579, g_loss: 1008.85809326 -- mean_d_loss: 1.34544849, mean_g_loss: 1027.00695801\n",
            "Epoch:  98 Step:  1244  time: 1.318329 s d_loss: 1.32070744, g_loss: 1001.11505127 -- mean_d_loss: 1.34489870, mean_g_loss: 1026.43164062\n",
            "Epoch:  98 Step:  1245  time: 1.333571 s d_loss: 1.08172119, g_loss: 971.09411621 -- mean_d_loss: 1.33917749, mean_g_loss: 1025.22863770\n",
            "Epoch:  98 Step:  1246  time: 1.321416 s d_loss: 1.97382820, g_loss: 1035.53674316 -- mean_d_loss: 1.35268068, mean_g_loss: 1025.44787598\n",
            "Epoch:  98 Step:  1247  time: 1.321586 s d_loss: 0.95635009, g_loss: 954.49670410 -- mean_d_loss: 1.34442377, mean_g_loss: 1023.96972656\n",
            "Epoch:  98 Step:  1248  time: 1.294670 s d_loss: 0.70993245, g_loss: 946.41638184 -- mean_d_loss: 1.33147490, mean_g_loss: 1022.38702393\n",
            "Epoch:  98 Step:  1249  time: 1.289119 s d_loss: 0.72004944, g_loss: 1032.18103027 -- mean_d_loss: 1.31924641, mean_g_loss: 1022.58288574\n",
            "Epoch:  98 Step:  1250  time: 1.312961 s d_loss: 0.71880722, g_loss: 1089.74829102 -- mean_d_loss: 1.30747294, mean_g_loss: 1023.89990234\n",
            "Epoch:  98 Step:  1251  time: 1.326364 s d_loss: 0.68807155, g_loss: 1015.56811523 -- mean_d_loss: 1.29556143, mean_g_loss: 1023.73962402\n",
            "Epoch:  98 Step:  1252  time: 1.286173 s d_loss: 0.65671790, g_loss: 965.93762207 -- mean_d_loss: 1.28350770, mean_g_loss: 1022.64904785\n",
            "Epoch:  98 Step:  1253  time: 1.321723 s d_loss: 0.55984908, g_loss: 1278.68432617 -- mean_d_loss: 1.27010667, mean_g_loss: 1027.39038086\n",
            "Epoch:  98 Step:  1254  time: 1.317395 s d_loss: 0.46144721, g_loss: 1031.21765137 -- mean_d_loss: 1.25540388, mean_g_loss: 1027.45996094\n",
            "Epoch:  98 Step:  1255  time: 1.326371 s d_loss: 0.54236561, g_loss: 1005.92352295 -- mean_d_loss: 1.24267101, mean_g_loss: 1027.07543945\n",
            "Epoch:  98 Step:  1256  time: 1.319914 s d_loss: 0.69725072, g_loss: 1195.01965332 -- mean_d_loss: 1.23310220, mean_g_loss: 1030.02185059\n",
            "Epoch:  98 Step:  1257  time: 1.326178 s d_loss: 0.69445789, g_loss: 1053.96716309 -- mean_d_loss: 1.22381520, mean_g_loss: 1030.43469238\n",
            "Epoch:  98 Step:  1258  time: 1.321654 s d_loss: 0.46844727, g_loss: 1092.91333008 -- mean_d_loss: 1.21101236, mean_g_loss: 1031.49365234\n",
            "Epoch:  98 Step:  1259  time: 1.327120 s d_loss: 0.58742231, g_loss: 830.23394775 -- mean_d_loss: 1.20061922, mean_g_loss: 1028.13928223\n",
            "Epoch:  98 Step:  1260  time: 1.316791 s d_loss: 0.55144781, g_loss: 977.57739258 -- mean_d_loss: 1.18997705, mean_g_loss: 1027.31042480\n",
            "Epoch:  98 Step:  1261  time: 1.299293 s d_loss: 0.64004201, g_loss: 1099.01428223 -- mean_d_loss: 1.18110716, mean_g_loss: 1028.46704102\n",
            "Epoch:  98 Step:  1262  time: 1.320542 s d_loss: 20.14604378, g_loss: 1010.04803467 -- mean_d_loss: 1.48213792, mean_g_loss: 1028.17456055\n",
            "Epoch:  98 Step:  1263  time: 1.285674 s d_loss: 0.69263297, g_loss: 947.35644531 -- mean_d_loss: 1.46980190, mean_g_loss: 1026.91186523\n",
            "Epoch:  98 Step:  1264  time: 1.321217 s d_loss: 0.82955837, g_loss: 940.06811523 -- mean_d_loss: 1.45995200, mean_g_loss: 1025.57580566\n",
            "Epoch:  98 Step:  1265  time: 1.325219 s d_loss: 1.13087714, g_loss: 1044.50878906 -- mean_d_loss: 1.45496595, mean_g_loss: 1025.86267090\n",
            "Epoch:  98 Step:  1266  time: 1.317026 s d_loss: 0.66646969, g_loss: 1010.53552246 -- mean_d_loss: 1.44319749, mean_g_loss: 1025.63403320\n",
            "Epoch:  98 Step:  1267  time: 1.316228 s d_loss: 0.73797727, g_loss: 993.94604492 -- mean_d_loss: 1.43282652, mean_g_loss: 1025.16796875\n",
            "Epoch:  98 Step:  1268  time: 1.318945 s d_loss: 0.67380154, g_loss: 908.11169434 -- mean_d_loss: 1.42182624, mean_g_loss: 1023.47149658\n",
            "Epoch:  98 Step:  1269  time: 1.306507 s d_loss: 1.29457653, g_loss: 1107.66748047 -- mean_d_loss: 1.42000842, mean_g_loss: 1024.67419434\n",
            "Epoch:  98 Step:  1270  time: 1.321349 s d_loss: 0.71232241, g_loss: 1007.64923096 -- mean_d_loss: 1.41004109, mean_g_loss: 1024.43444824\n",
            "Epoch:  98 Step:  1271  time: 1.318374 s d_loss: 0.94791335, g_loss: 1195.03735352 -- mean_d_loss: 1.40362263, mean_g_loss: 1026.80395508\n",
            "Epoch:  98 Step:  1272  time: 1.314398 s d_loss: 0.51455188, g_loss: 854.78344727 -- mean_d_loss: 1.39144349, mean_g_loss: 1024.44750977\n",
            "Epoch:  98 Step:  1273  time: 1.293958 s d_loss: 0.52995276, g_loss: 929.16796875 -- mean_d_loss: 1.37980175, mean_g_loss: 1023.15985107\n",
            "Epoch:  98 Step:  1274  time: 1.309933 s d_loss: 0.47200450, g_loss: 1066.84240723 -- mean_d_loss: 1.36769783, mean_g_loss: 1023.74230957\n",
            "Epoch:  98 Step:  1275  time: 1.322098 s d_loss: 0.58735412, g_loss: 998.51660156 -- mean_d_loss: 1.35743022, mean_g_loss: 1023.41033936\n",
            "Epoch:  98 Step:  1276  time: 1.282543 s d_loss: 0.89576423, g_loss: 902.30554199 -- mean_d_loss: 1.35143459, mean_g_loss: 1021.83758545\n",
            "Epoch:  98 Step:  1277  time: 1.338929 s d_loss: 0.84409535, g_loss: 952.58917236 -- mean_d_loss: 1.34493017, mean_g_loss: 1020.94970703\n",
            "Epoch:  98 Step:  1278  time: 1.348655 s d_loss: 0.80501747, g_loss: 1028.77111816 -- mean_d_loss: 1.33809590, mean_g_loss: 1021.04876709\n",
            "Epoch:  98 Step:  1279  time: 1.326423 s d_loss: 2.88972902, g_loss: 921.76623535 -- mean_d_loss: 1.35749125, mean_g_loss: 1019.80773926\n",
            "Epoch:  98 Step:  1280  time: 1.280160 s d_loss: 0.62753242, g_loss: 1118.85253906 -- mean_d_loss: 1.34847951, mean_g_loss: 1021.03045654\n",
            "Epoch:  98 Step:  1281  time: 1.284894 s d_loss: 0.96948677, g_loss: 927.46813965 -- mean_d_loss: 1.34385765, mean_g_loss: 1019.88946533\n",
            "Epoch:  98 Step:  1282  time: 1.300944 s d_loss: 0.66436940, g_loss: 887.89636230 -- mean_d_loss: 1.33567107, mean_g_loss: 1018.29925537\n",
            "Epoch:  98 Step:  1283  time: 1.328451 s d_loss: 0.61894602, g_loss: 1036.72778320 -- mean_d_loss: 1.32713854, mean_g_loss: 1018.51861572\n",
            "Epoch:  98 Step:  1284  time: 1.324958 s d_loss: 0.51548666, g_loss: 973.41796875 -- mean_d_loss: 1.31758976, mean_g_loss: 1017.98803711\n",
            "Epoch:  98 Step:  1285  time: 1.333779 s d_loss: 0.45204547, g_loss: 1013.97961426 -- mean_d_loss: 1.30752528, mean_g_loss: 1017.94140625\n",
            "Epoch:  98 Step:  1286  time: 1.302285 s d_loss: 0.89788377, g_loss: 1078.65417480 -- mean_d_loss: 1.30281675, mean_g_loss: 1018.63928223\n",
            "Epoch:  98 Step:  1287  time: 1.333214 s d_loss: 0.60519081, g_loss: 958.84521484 -- mean_d_loss: 1.29488921, mean_g_loss: 1017.95977783\n",
            "Epoch:  98 Step:  1288  time: 1.314552 s d_loss: 0.76671261, g_loss: 1186.79907227 -- mean_d_loss: 1.28895462, mean_g_loss: 1019.85681152\n",
            "Epoch:  98 Step:  1289  time: 1.312043 s d_loss: 0.58138025, g_loss: 882.94555664 -- mean_d_loss: 1.28109276, mean_g_loss: 1018.33557129\n",
            "Epoch:  98 Step:  1290  time: 1.312055 s d_loss: 0.70926112, g_loss: 991.55914307 -- mean_d_loss: 1.27480888, mean_g_loss: 1018.04138184\n",
            "Epoch:  98 Step:  1291  time: 1.332243 s d_loss: 0.55276006, g_loss: 1001.90228271 -- mean_d_loss: 1.26696050, mean_g_loss: 1017.86590576\n",
            "Epoch:  98 Step:  1292  time: 1.315079 s d_loss: 19.78683662, g_loss: 1215.57373047 -- mean_d_loss: 1.46609890, mean_g_loss: 1019.99176025\n",
            "Epoch:  98 Step:  1293  time: 1.298045 s d_loss: 0.85193813, g_loss: 940.66992188 -- mean_d_loss: 1.45956540, mean_g_loss: 1019.14794922\n",
            "Epoch:  98 Step:  1294  time: 1.316689 s d_loss: 1.02078044, g_loss: 848.00927734 -- mean_d_loss: 1.45494664, mean_g_loss: 1017.34643555\n",
            "Epoch:  98 Step:  1295  time: 1.320135 s d_loss: 2.25978494, g_loss: 1055.91210938 -- mean_d_loss: 1.46333027, mean_g_loss: 1017.74822998\n",
            "Epoch:  98 Step:  1296  time: 1.336737 s d_loss: 0.90599936, g_loss: 1225.10681152 -- mean_d_loss: 1.45758462, mean_g_loss: 1019.88592529\n",
            "Epoch:  98 Step:  1297  time: 1.301094 s d_loss: 0.67145401, g_loss: 889.28674316 -- mean_d_loss: 1.44956291, mean_g_loss: 1018.55334473\n",
            "Epoch:  98 Step:  1298  time: 1.334969 s d_loss: 0.76586002, g_loss: 992.12329102 -- mean_d_loss: 1.44265676, mean_g_loss: 1018.28637695\n",
            "Epoch:  98 Step:  1299  time: 1.316081 s d_loss: 1.07622170, g_loss: 1189.54077148 -- mean_d_loss: 1.43899226, mean_g_loss: 1019.99890137\n",
            "Epoch:  98 Step:  1300  time: 1.322804 s d_loss: 1.04639983, g_loss: 1001.36389160 -- mean_d_loss: 1.43510532, mean_g_loss: 1019.81445312\n",
            "Epoch:  98 Step:  1301  time: 1.319046 s d_loss: 1.43440652, g_loss: 905.16845703 -- mean_d_loss: 1.43509841, mean_g_loss: 1018.69049072\n",
            "Epoch:  98 Step:  1302  time: 1.342489 s d_loss: 4.72965097, g_loss: 996.27258301 -- mean_d_loss: 1.46708429, mean_g_loss: 1018.47283936\n",
            "Epoch:  98 Step:  1303  time: 1.301960 s d_loss: 0.82493424, g_loss: 874.13061523 -- mean_d_loss: 1.46090972, mean_g_loss: 1017.08496094\n",
            "Epoch:  98 Step:  1304  time: 1.313134 s d_loss: 0.77827621, g_loss: 897.65795898 -- mean_d_loss: 1.45440853, mean_g_loss: 1015.94757080\n",
            "Epoch:  98 Step:  1305  time: 1.314711 s d_loss: 1.00512540, g_loss: 956.10815430 -- mean_d_loss: 1.45016992, mean_g_loss: 1015.38305664\n",
            "Epoch:  98 Step:  1306  time: 1.279947 s d_loss: 0.66350365, g_loss: 898.07910156 -- mean_d_loss: 1.44281793, mean_g_loss: 1014.28674316\n",
            "Epoch:  98 Step:  1307  time: 1.335885 s d_loss: 0.66535848, g_loss: 1049.29077148 -- mean_d_loss: 1.43561924, mean_g_loss: 1014.61083984\n",
            "Epoch:  98 Step:  1308  time: 1.320513 s d_loss: 1.74665093, g_loss: 1026.17895508 -- mean_d_loss: 1.43847275, mean_g_loss: 1014.71697998\n",
            "Epoch:  98 Step:  1309  time: 1.331244 s d_loss: 1.06365538, g_loss: 1084.68273926 -- mean_d_loss: 1.43506539, mean_g_loss: 1015.35296631\n",
            "Epoch:  98 Step:  1310  time: 1.334575 s d_loss: 0.81948948, g_loss: 1177.45483398 -- mean_d_loss: 1.42951965, mean_g_loss: 1016.81335449\n",
            "Epoch:  98 Step:  1311  time: 1.297472 s d_loss: 1.37187791, g_loss: 1035.39648438 -- mean_d_loss: 1.42900491, mean_g_loss: 1016.97930908\n",
            "Epoch:  98 Step:  1312  time: 1.320550 s d_loss: 1.75780189, g_loss: 1113.29016113 -- mean_d_loss: 1.43191457, mean_g_loss: 1017.83160400\n",
            "Epoch:  98 Step:  1313  time: 1.278199 s d_loss: 0.85968852, g_loss: 994.99780273 -- mean_d_loss: 1.42689514, mean_g_loss: 1017.63128662\n",
            "Epoch:  98 Step:  1314  time: 1.281133 s d_loss: 0.92431271, g_loss: 989.03845215 -- mean_d_loss: 1.42252493, mean_g_loss: 1017.38269043\n",
            "Epoch:  98 Step:  1315  time: 1.320118 s d_loss: 0.94745451, g_loss: 853.82623291 -- mean_d_loss: 1.41842937, mean_g_loss: 1015.97271729\n",
            "Epoch:  98 Step:  1316  time: 1.319560 s d_loss: 45.56164551, g_loss: 935.25573730 -- mean_d_loss: 1.79572189, mean_g_loss: 1015.28283691\n",
            "Epoch:  98 Step:  1317  time: 1.317301 s d_loss: 1.12617600, g_loss: 1035.04284668 -- mean_d_loss: 1.79004776, mean_g_loss: 1015.45025635\n",
            "Epoch:  98 Step:  1318  time: 1.305409 s d_loss: 1.48901510, g_loss: 1062.00830078 -- mean_d_loss: 1.78751802, mean_g_loss: 1015.84149170\n",
            "Epoch:  98 Step:  1319  time: 1.301765 s d_loss: 1.17435086, g_loss: 1083.66284180 -- mean_d_loss: 1.78240824, mean_g_loss: 1016.40667725\n",
            "Epoch:  98 Step:  1320  time: 1.314163 s d_loss: 0.79360318, g_loss: 955.74462891 -- mean_d_loss: 1.77423632, mean_g_loss: 1015.90533447\n",
            "Epoch:  98 Step:  1321  time: 1.305165 s d_loss: 0.64677292, g_loss: 1051.56335449 -- mean_d_loss: 1.76499486, mean_g_loss: 1016.19763184\n",
            "Epoch:  98 Step:  1322  time: 1.319564 s d_loss: 0.97544599, g_loss: 960.60162354 -- mean_d_loss: 1.75857580, mean_g_loss: 1015.74560547\n",
            "Epoch:  98 Step:  1323  time: 1.309733 s d_loss: 0.71727800, g_loss: 1247.10900879 -- mean_d_loss: 1.75017834, mean_g_loss: 1017.61145020\n",
            "Epoch:  98 Step:  1324  time: 1.313995 s d_loss: 0.82918257, g_loss: 982.83489990 -- mean_d_loss: 1.74281025, mean_g_loss: 1017.33325195\n",
            "Epoch:  98 Step:  1325  time: 1.284029 s d_loss: 0.82654351, g_loss: 994.73791504 -- mean_d_loss: 1.73553824, mean_g_loss: 1017.15386963\n",
            "Epoch:  98 Step:  1326  time: 1.327813 s d_loss: 0.82808000, g_loss: 1123.75708008 -- mean_d_loss: 1.72839296, mean_g_loss: 1017.99328613\n",
            "Epoch:  98 Step:  1327  time: 1.317337 s d_loss: 0.49084431, g_loss: 917.00964355 -- mean_d_loss: 1.71872461, mean_g_loss: 1017.20434570\n",
            "Epoch:  98 Step:  1328  time: 1.293539 s d_loss: 0.74569458, g_loss: 1006.27752686 -- mean_d_loss: 1.71118176, mean_g_loss: 1017.11968994\n",
            "Epoch:  98 Step:  1329  time: 1.323467 s d_loss: 0.79235286, g_loss: 961.61676025 -- mean_d_loss: 1.70411384, mean_g_loss: 1016.69268799\n",
            "Epoch:  98 Step:  1330  time: 1.315151 s d_loss: 0.62261999, g_loss: 1127.73217773 -- mean_d_loss: 1.69585824, mean_g_loss: 1017.54034424\n",
            "Epoch:  98 Step:  1331  time: 1.316847 s d_loss: 0.74754387, g_loss: 987.64636230 -- mean_d_loss: 1.68867397, mean_g_loss: 1017.31378174\n",
            "Epoch:  98 Step:  1332  time: 1.317024 s d_loss: 0.77118397, g_loss: 922.07348633 -- mean_d_loss: 1.68177557, mean_g_loss: 1016.59771729\n",
            "Epoch:  98 Step:  1333  time: 1.324700 s d_loss: 2.38558650, g_loss: 1111.30175781 -- mean_d_loss: 1.68702793, mean_g_loss: 1017.30444336\n",
            "Epoch:  98 Step:  1334  time: 1.340867 s d_loss: 1.02873719, g_loss: 999.57653809 -- mean_d_loss: 1.68215168, mean_g_loss: 1017.17315674\n",
            "Epoch:  98 Step:  1335  time: 1.321149 s d_loss: 1.11948717, g_loss: 971.47424316 -- mean_d_loss: 1.67801440, mean_g_loss: 1016.83709717\n",
            "Epoch:  98 Step:  1336  time: 1.300262 s d_loss: 1.10710490, g_loss: 1138.69506836 -- mean_d_loss: 1.67384720, mean_g_loss: 1017.72650146\n",
            "Epoch:  98 Step:  1337  time: 1.293186 s d_loss: 0.99643904, g_loss: 1183.41821289 -- mean_d_loss: 1.66893840, mean_g_loss: 1018.92718506\n",
            "Epoch:  98 Step:  1338  time: 1.308855 s d_loss: 0.73639035, g_loss: 1022.66796875 -- mean_d_loss: 1.66222942, mean_g_loss: 1018.95416260\n",
            "Epoch:  98 Step:  1339  time: 1.346251 s d_loss: 0.60052150, g_loss: 968.06542969 -- mean_d_loss: 1.65464592, mean_g_loss: 1018.59063721\n",
            "Epoch:  98 Step:  1340  time: 1.298644 s d_loss: 0.71989256, g_loss: 870.21423340 -- mean_d_loss: 1.64801645, mean_g_loss: 1017.53833008\n",
            "Epoch:  98 Step:  1341  time: 1.315536 s d_loss: 0.62479669, g_loss: 862.98785400 -- mean_d_loss: 1.64081073, mean_g_loss: 1016.44995117\n",
            "Epoch:  98 Step:  1342  time: 1.321589 s d_loss: 0.69544768, g_loss: 1015.19348145 -- mean_d_loss: 1.63419974, mean_g_loss: 1016.44110107\n",
            "Epoch:  98 Step:  1343  time: 1.321263 s d_loss: 0.73677003, g_loss: 1083.50646973 -- mean_d_loss: 1.62796760, mean_g_loss: 1016.90679932\n",
            "Epoch:  98 Step:  1344  time: 1.306187 s d_loss: 0.80370629, g_loss: 988.30688477 -- mean_d_loss: 1.62228310, mean_g_loss: 1016.70959473\n",
            "Epoch:  98 Step:  1345  time: 1.291956 s d_loss: 1.24050295, g_loss: 934.53570557 -- mean_d_loss: 1.61966825, mean_g_loss: 1016.14672852\n",
            "Epoch:  98 Step:  1346  time: 1.323379 s d_loss: 0.81979162, g_loss: 1027.78881836 -- mean_d_loss: 1.61422694, mean_g_loss: 1016.22589111\n",
            "Epoch:  98 Step:  1347  time: 1.320395 s d_loss: 0.89922732, g_loss: 990.12866211 -- mean_d_loss: 1.60939586, mean_g_loss: 1016.04949951\n",
            "Epoch:  98 Step:  1348  time: 1.322325 s d_loss: 0.68723547, g_loss: 1119.94689941 -- mean_d_loss: 1.60320687, mean_g_loss: 1016.74682617\n",
            "Epoch:  98 Step:  1349  time: 1.311061 s d_loss: 2.80540347, g_loss: 955.81530762 -- mean_d_loss: 1.61122155, mean_g_loss: 1016.34063721\n",
            "Epoch:  98 Step:  1350  time: 1.314945 s d_loss: 1.08958781, g_loss: 1000.98889160 -- mean_d_loss: 1.60776699, mean_g_loss: 1016.23895264\n",
            "Epoch:  98 Step:  1351  time: 1.316457 s d_loss: 0.72073865, g_loss: 1010.16027832 -- mean_d_loss: 1.60193121, mean_g_loss: 1016.19891357\n",
            "Epoch:  98 Step:  1352  time: 1.302827 s d_loss: 0.59508467, g_loss: 995.17779541 -- mean_d_loss: 1.59535050, mean_g_loss: 1016.06146240\n",
            "Epoch:  98 Step:  1353  time: 1.307070 s d_loss: 0.79283571, g_loss: 1009.34362793 -- mean_d_loss: 1.59013927, mean_g_loss: 1016.01788330\n",
            "Epoch:  98 Step:  1354  time: 1.317242 s d_loss: 0.64326477, g_loss: 1085.11743164 -- mean_d_loss: 1.58403039, mean_g_loss: 1016.46368408\n",
            "Epoch:  98 Step:  1355  time: 1.312635 s d_loss: 0.95344859, g_loss: 881.25781250 -- mean_d_loss: 1.57998824, mean_g_loss: 1015.59698486\n",
            "Epoch:  98 Step:  1356  time: 1.315557 s d_loss: 0.74292356, g_loss: 867.79071045 -- mean_d_loss: 1.57465661, mean_g_loss: 1014.65557861\n",
            "Epoch:  98 Step:  1357  time: 1.286257 s d_loss: 0.82188976, g_loss: 929.47485352 -- mean_d_loss: 1.56989217, mean_g_loss: 1014.11639404\n",
            "Epoch:  98 Step:  1358  time: 1.319854 s d_loss: 0.84177709, g_loss: 931.38891602 -- mean_d_loss: 1.56531286, mean_g_loss: 1013.59613037\n",
            "Epoch:  98 Step:  1359  time: 1.309927 s d_loss: 0.60726053, g_loss: 967.04687500 -- mean_d_loss: 1.55932498, mean_g_loss: 1013.30517578\n",
            "Epoch:  98 Step:  1360  time: 1.287597 s d_loss: 0.96067351, g_loss: 1033.64318848 -- mean_d_loss: 1.55560672, mean_g_loss: 1013.43145752\n",
            "Epoch:  98 Step:  1361  time: 1.313848 s d_loss: 1.10675132, g_loss: 1050.42553711 -- mean_d_loss: 1.55283606, mean_g_loss: 1013.65979004\n",
            "Epoch:  98 Step:  1362  time: 1.291780 s d_loss: 0.61683404, g_loss: 1028.76232910 -- mean_d_loss: 1.54709363, mean_g_loss: 1013.75250244\n",
            "Epoch:  98 Step:  1363  time: 1.283852 s d_loss: 0.64942497, g_loss: 904.34924316 -- mean_d_loss: 1.54162014, mean_g_loss: 1013.08538818\n",
            "Epoch:  98 Step:  1364  time: 1.331020 s d_loss: 1.64744461, g_loss: 1038.33093262 -- mean_d_loss: 1.54226148, mean_g_loss: 1013.23834229\n",
            "Epoch:  98 Step:  1365  time: 1.308100 s d_loss: 0.64332330, g_loss: 1101.40417480 -- mean_d_loss: 1.53684616, mean_g_loss: 1013.76947021\n",
            "Epoch:  98 Step:  1366  time: 1.321579 s d_loss: 0.70263416, g_loss: 995.56079102 -- mean_d_loss: 1.53185093, mean_g_loss: 1013.66046143\n",
            "Epoch:  98 Step:  1367  time: 1.282006 s d_loss: 0.63530272, g_loss: 896.44567871 -- mean_d_loss: 1.52651429, mean_g_loss: 1012.96276855\n",
            "Epoch:  98 Step:  1368  time: 1.286956 s d_loss: 0.51983929, g_loss: 1090.47033691 -- mean_d_loss: 1.52055764, mean_g_loss: 1013.42138672\n",
            "Epoch:  98 Step:  1369  time: 1.295351 s d_loss: 0.57406390, g_loss: 922.94677734 -- mean_d_loss: 1.51499009, mean_g_loss: 1012.88922119\n",
            "Epoch:  98 Step:  1370  time: 1.316327 s d_loss: 1.79750276, g_loss: 900.34741211 -- mean_d_loss: 1.51664221, mean_g_loss: 1012.23107910\n",
            "Epoch:  98 Step:  1371  time: 1.332276 s d_loss: 0.88179272, g_loss: 1080.83435059 -- mean_d_loss: 1.51295137, mean_g_loss: 1012.62988281\n",
            "Epoch:  98 Step:  1372  time: 1.315394 s d_loss: 0.57869744, g_loss: 993.63403320 -- mean_d_loss: 1.50755107, mean_g_loss: 1012.52014160\n",
            "Epoch:  98 Step:  1373  time: 1.293686 s d_loss: 0.57505924, g_loss: 1158.49060059 -- mean_d_loss: 1.50219202, mean_g_loss: 1013.35900879\n",
            "Epoch:  98 Step:  1374  time: 1.312484 s d_loss: 0.63802665, g_loss: 1051.26123047 -- mean_d_loss: 1.49725389, mean_g_loss: 1013.57562256\n",
            "Epoch:  98 Step:  1375  time: 1.300454 s d_loss: 1.93656766, g_loss: 946.83300781 -- mean_d_loss: 1.49975002, mean_g_loss: 1013.19635010\n",
            "Epoch:  98 Step:  1376  time: 1.326910 s d_loss: 0.64654052, g_loss: 976.27532959 -- mean_d_loss: 1.49492955, mean_g_loss: 1012.98779297\n",
            "Epoch:  98 Step:  1377  time: 1.306695 s d_loss: 0.75818962, g_loss: 1191.84643555 -- mean_d_loss: 1.49079061, mean_g_loss: 1013.99261475\n",
            "Epoch:  98 Step:  1378  time: 1.323424 s d_loss: 0.72283095, g_loss: 1047.87963867 -- mean_d_loss: 1.48650026, mean_g_loss: 1014.18188477\n",
            "Epoch:  98 Step:  1379  time: 1.310572 s d_loss: 0.69819665, g_loss: 1083.11962891 -- mean_d_loss: 1.48212099, mean_g_loss: 1014.56494141\n",
            "Epoch:  98 Step:  1380  time: 1.326008 s d_loss: 0.61918223, g_loss: 1100.83447266 -- mean_d_loss: 1.47735322, mean_g_loss: 1015.04150391\n",
            "Epoch:  98 Step:  1381  time: 1.320661 s d_loss: 1.93221354, g_loss: 1106.24133301 -- mean_d_loss: 1.47985256, mean_g_loss: 1015.54260254\n",
            "Epoch:  98 Step:  1382  time: 1.324783 s d_loss: 0.75661749, g_loss: 1004.32434082 -- mean_d_loss: 1.47590041, mean_g_loss: 1015.48132324\n",
            "Epoch:  98 Step:  1383  time: 1.346362 s d_loss: 0.61918336, g_loss: 1289.22143555 -- mean_d_loss: 1.47124434, mean_g_loss: 1016.96899414\n",
            "Epoch:  98 Step:  1384  time: 1.315520 s d_loss: 0.63325232, g_loss: 1072.02087402 -- mean_d_loss: 1.46671450, mean_g_loss: 1017.26654053\n",
            "Epoch:  98 Step:  1385  time: 1.323952 s d_loss: 0.54537380, g_loss: 940.57427979 -- mean_d_loss: 1.46176112, mean_g_loss: 1016.85424805\n",
            "Epoch:  98 Step:  1386  time: 1.338212 s d_loss: 0.59419799, g_loss: 958.46789551 -- mean_d_loss: 1.45712185, mean_g_loss: 1016.54205322\n",
            "Epoch:  98 Step:  1387  time: 1.345431 s d_loss: 0.64732879, g_loss: 1053.95849609 -- mean_d_loss: 1.45281446, mean_g_loss: 1016.74102783\n",
            "Epoch:  98 Step:  1388  time: 1.334038 s d_loss: 0.53652424, g_loss: 964.14526367 -- mean_d_loss: 1.44796646, mean_g_loss: 1016.46270752\n",
            "Epoch:  98 Step:  1389  time: 1.312950 s d_loss: 0.50658834, g_loss: 1278.40380859 -- mean_d_loss: 1.44301176, mean_g_loss: 1017.84136963\n",
            "Epoch:  98 Step:  1390  time: 1.331794 s d_loss: 0.83893293, g_loss: 1044.09765625 -- mean_d_loss: 1.43984902, mean_g_loss: 1017.97882080\n",
            "Epoch:  98 Step:  1391  time: 1.334585 s d_loss: 0.77530891, g_loss: 1018.38562012 -- mean_d_loss: 1.43638790, mean_g_loss: 1017.98095703\n",
            "Epoch:  98 Step:  1392  time: 1.341957 s d_loss: 0.64407027, g_loss: 1092.38269043 -- mean_d_loss: 1.43228257, mean_g_loss: 1018.36639404\n",
            "Epoch:  98 Step:  1393  time: 1.311896 s d_loss: 1.67724037, g_loss: 1151.91735840 -- mean_d_loss: 1.43354535, mean_g_loss: 1019.05487061\n",
            "Epoch:  98 Step:  1394  time: 1.315298 s d_loss: 0.57331699, g_loss: 917.42065430 -- mean_d_loss: 1.42913377, mean_g_loss: 1018.53363037\n",
            "Epoch:  98 Step:  1395  time: 1.326442 s d_loss: 40.43406296, g_loss: 938.44433594 -- mean_d_loss: 1.62813854, mean_g_loss: 1018.12500000\n",
            "Epoch:  98 Step:  1396  time: 1.322200 s d_loss: 1.25182569, g_loss: 1218.26452637 -- mean_d_loss: 1.62622833, mean_g_loss: 1019.14093018\n",
            "Epoch:  98 Step:  1397  time: 1.322963 s d_loss: 1.00397968, g_loss: 980.29376221 -- mean_d_loss: 1.62308562, mean_g_loss: 1018.94476318\n",
            "Epoch:  98 Step:  1398  time: 1.309865 s d_loss: 1.02989745, g_loss: 1052.03710938 -- mean_d_loss: 1.62010479, mean_g_loss: 1019.11102295\n",
            "Epoch:  98 Step:  1399  time: 1.272215 s d_loss: 0.67826170, g_loss: 842.44769287 -- mean_d_loss: 1.61539555, mean_g_loss: 1018.22772217\n",
            "Epoch:  98 Step:  1400  time: 1.320473 s d_loss: 0.68977642, g_loss: 1116.84179688 -- mean_d_loss: 0.68977642, mean_g_loss: 1116.84179688\n",
            "Epoch:  98 Step:  1401  time: 1.310864 s d_loss: 0.63155431, g_loss: 1028.32080078 -- mean_d_loss: 0.66066539, mean_g_loss: 1072.58129883\n",
            "Epoch:  98 Step:  1402  time: 1.316679 s d_loss: 0.69407457, g_loss: 1012.57202148 -- mean_d_loss: 0.67180181, mean_g_loss: 1052.57824707\n",
            "Epoch:  98 Step:  1403  time: 1.309672 s d_loss: 0.64907837, g_loss: 962.25756836 -- mean_d_loss: 0.66612095, mean_g_loss: 1029.99804688\n",
            "Epoch:  98 Step:  1404  time: 1.300822 s d_loss: 0.69382232, g_loss: 964.00207520 -- mean_d_loss: 0.67166126, mean_g_loss: 1016.79882812\n",
            "Epoch:  98 Step:  1405  time: 1.275142 s d_loss: 0.75995469, g_loss: 1019.80505371 -- mean_d_loss: 0.68637681, mean_g_loss: 1017.29986572\n",
            "Epoch:  98 Step:  1406  time: 1.309841 s d_loss: 1.18066752, g_loss: 994.43432617 -- mean_d_loss: 0.75698978, mean_g_loss: 1014.03332520\n",
            "Epoch:  98 Step:  1407  time: 1.327430 s d_loss: 0.63629246, g_loss: 1066.77172852 -- mean_d_loss: 0.74190259, mean_g_loss: 1020.62561035\n",
            "Epoch:  98 Step:  1408  time: 1.297689 s d_loss: 2.26959634, g_loss: 986.10168457 -- mean_d_loss: 0.91164631, mean_g_loss: 1016.78961182\n",
            "Epoch:  98 Step:  1409  time: 1.289088 s d_loss: 3.19071531, g_loss: 870.03088379 -- mean_d_loss: 1.13955331, mean_g_loss: 1002.11376953\n",
            "Epoch:  98 Step:  1410  time: 1.313322 s d_loss: 0.75000542, g_loss: 782.21539307 -- mean_d_loss: 1.10413980, mean_g_loss: 982.12304688\n",
            "Epoch:  98 Step:  1411  time: 1.313840 s d_loss: 1.33713436, g_loss: 1068.36083984 -- mean_d_loss: 1.12355602, mean_g_loss: 989.30957031\n",
            "Epoch:  98 Step:  1412  time: 1.322587 s d_loss: 1.19445527, g_loss: 982.89160156 -- mean_d_loss: 1.12900984, mean_g_loss: 988.81585693\n",
            "Epoch:  98 Step:  1413  time: 1.318808 s d_loss: 2.31216550, g_loss: 1141.08081055 -- mean_d_loss: 1.21352100, mean_g_loss: 999.69195557\n",
            "Epoch:  98 Step:  1414  time: 1.311776 s d_loss: 1.38821220, g_loss: 1044.88964844 -- mean_d_loss: 1.22516704, mean_g_loss: 1002.70513916\n",
            "Epoch:  98 Step:  1415  time: 1.308822 s d_loss: 1.13258600, g_loss: 940.20477295 -- mean_d_loss: 1.21938074, mean_g_loss: 998.79888916\n",
            "Epoch:  98 Step:  1416  time: 1.309694 s d_loss: 0.46880490, g_loss: 897.41381836 -- mean_d_loss: 1.17522919, mean_g_loss: 992.83502197\n",
            "Epoch:  98 Step:  1417  time: 1.321928 s d_loss: 0.72428358, g_loss: 1032.99609375 -- mean_d_loss: 1.15017664, mean_g_loss: 995.06616211\n",
            "Epoch:  98 Step:  1418  time: 1.325291 s d_loss: 0.54145044, g_loss: 892.71801758 -- mean_d_loss: 1.11813843, mean_g_loss: 989.67950439\n",
            "Epoch:  98 Step:  1419  time: 1.310427 s d_loss: 0.87762213, g_loss: 953.98864746 -- mean_d_loss: 1.10611272, mean_g_loss: 987.89489746\n",
            "Epoch:  98 Step:  1420  time: 1.299550 s d_loss: 0.92187327, g_loss: 1096.52685547 -- mean_d_loss: 1.09733939, mean_g_loss: 993.06787109\n",
            "Epoch:  98 Step:  1421  time: 1.315515 s d_loss: 0.64479125, g_loss: 1079.15795898 -- mean_d_loss: 1.07676899, mean_g_loss: 996.98107910\n",
            "Epoch:  98 Step:  1422  time: 1.302503 s d_loss: 1.30289733, g_loss: 1104.29321289 -- mean_d_loss: 1.08660054, mean_g_loss: 1001.64685059\n",
            "Epoch:  98 Step:  1423  time: 1.317742 s d_loss: 0.75305218, g_loss: 846.55975342 -- mean_d_loss: 1.07270277, mean_g_loss: 995.18487549\n",
            "Epoch:  98 Step:  1424  time: 1.317633 s d_loss: 0.64745080, g_loss: 909.61871338 -- mean_d_loss: 1.05569267, mean_g_loss: 991.76226807\n",
            "Epoch:  98 Step:  1425  time: 1.303808 s d_loss: 0.52040070, g_loss: 975.73937988 -- mean_d_loss: 1.03510451, mean_g_loss: 991.14605713\n",
            "Epoch:  98 Step:  1426  time: 1.293308 s d_loss: 0.56199771, g_loss: 955.34283447 -- mean_d_loss: 1.01758206, mean_g_loss: 989.82000732\n",
            "Epoch:  98 Step:  1427  time: 1.300309 s d_loss: 0.53156304, g_loss: 1081.45654297 -- mean_d_loss: 1.00022423, mean_g_loss: 993.09277344\n",
            "Epoch:  98 Step:  1428  time: 1.318052 s d_loss: 1.09007096, g_loss: 1085.47241211 -- mean_d_loss: 1.00332236, mean_g_loss: 996.27825928\n",
            "Epoch:  98 Step:  1429  time: 1.334478 s d_loss: 1.22597706, g_loss: 946.16918945 -- mean_d_loss: 1.01074421, mean_g_loss: 994.60803223\n",
            "Epoch:  98 Step:  1430  time: 1.308323 s d_loss: 0.79246783, g_loss: 987.47180176 -- mean_d_loss: 1.00370300, mean_g_loss: 994.37780762\n",
            "Epoch:  98 Step:  1431  time: 1.319794 s d_loss: 0.69362903, g_loss: 932.06042480 -- mean_d_loss: 0.99401319, mean_g_loss: 992.43041992\n",
            "Epoch:  98 Step:  1432  time: 1.307366 s d_loss: 1.72043705, g_loss: 1087.89428711 -- mean_d_loss: 1.01602602, mean_g_loss: 995.32324219\n",
            "Epoch:  98 Step:  1433  time: 1.303555 s d_loss: 1.30948770, g_loss: 1090.68432617 -- mean_d_loss: 1.02465725, mean_g_loss: 998.12799072\n",
            "Epoch:  98 Step:  1434  time: 1.324943 s d_loss: 0.52965868, g_loss: 1078.54565430 -- mean_d_loss: 1.01051438, mean_g_loss: 1000.42565918\n",
            "Epoch:  98 Step:  1435  time: 1.338192 s d_loss: 0.73761547, g_loss: 969.20031738 -- mean_d_loss: 1.00293386, mean_g_loss: 999.55828857\n",
            "Epoch:  98 Step:  1436  time: 1.314691 s d_loss: 0.50678003, g_loss: 1248.24194336 -- mean_d_loss: 0.98952425, mean_g_loss: 1006.27947998\n",
            "Epoch:  98 Step:  1437  time: 1.303444 s d_loss: 0.55133724, g_loss: 860.04248047 -- mean_d_loss: 0.97799301, mean_g_loss: 1002.43115234\n",
            "Epoch:  98 Step:  1438  time: 1.345811 s d_loss: 0.86713129, g_loss: 1145.86547852 -- mean_d_loss: 0.97515041, mean_g_loss: 1006.10894775\n",
            "Epoch:  98 Step:  1439  time: 1.322687 s d_loss: 0.60103744, g_loss: 964.55413818 -- mean_d_loss: 0.96579754, mean_g_loss: 1005.07012939\n",
            "Epoch:  98 Step:  1440  time: 1.327036 s d_loss: 1.47476006, g_loss: 937.93804932 -- mean_d_loss: 0.97821116, mean_g_loss: 1003.43273926\n",
            "Epoch:  98 Step:  1441  time: 1.335133 s d_loss: 1.33321905, g_loss: 1068.05273438 -- mean_d_loss: 0.98666370, mean_g_loss: 1004.97137451\n",
            "Epoch:  98 Step:  1442  time: 1.319939 s d_loss: 0.72446656, g_loss: 1001.79083252 -- mean_d_loss: 0.98056614, mean_g_loss: 1004.89733887\n",
            "Epoch:  98 Step:  1443  time: 1.322086 s d_loss: 0.96380007, g_loss: 1110.24218750 -- mean_d_loss: 0.98018509, mean_g_loss: 1007.29156494\n",
            "Epoch:  98 Step:  1444  time: 1.290521 s d_loss: 2.68409801, g_loss: 1006.72180176 -- mean_d_loss: 1.01804984, mean_g_loss: 1007.27893066\n",
            "Epoch:  98 Step:  1445  time: 1.292926 s d_loss: 1.34212017, g_loss: 1319.79162598 -- mean_d_loss: 1.02509487, mean_g_loss: 1014.07269287\n",
            "Epoch:  98 Step:  1446  time: 1.313339 s d_loss: 1.51541018, g_loss: 935.01599121 -- mean_d_loss: 1.03552711, mean_g_loss: 1012.39062500\n",
            "Epoch:  98 Step:  1447  time: 1.327393 s d_loss: 1.67421627, g_loss: 873.21459961 -- mean_d_loss: 1.04883313, mean_g_loss: 1009.49114990\n",
            "Epoch:  98 Step:  1448  time: 1.335449 s d_loss: 3.51419592, g_loss: 955.61309814 -- mean_d_loss: 1.09914660, mean_g_loss: 1008.39160156\n",
            "Epoch:  98 Step:  1449  time: 1.309516 s d_loss: 3.98544288, g_loss: 978.88415527 -- mean_d_loss: 1.15687251, mean_g_loss: 1007.80139160\n",
            "Epoch:  98 Step:  1450  time: 1.332381 s d_loss: 3.67019939, g_loss: 1115.98217773 -- mean_d_loss: 1.20615351, mean_g_loss: 1009.92254639\n",
            "Epoch:  98 Step:  1451  time: 1.284814 s d_loss: 3.98294520, g_loss: 1079.31567383 -- mean_d_loss: 1.25955331, mean_g_loss: 1011.25708008\n",
            "Epoch:  98 Step:  1452  time: 1.351703 s d_loss: 8.08918858, g_loss: 965.17077637 -- mean_d_loss: 1.38841438, mean_g_loss: 1010.38751221\n",
            "Epoch:  98 Step:  1453  time: 1.309045 s d_loss: 1.09255159, g_loss: 1017.81671143 -- mean_d_loss: 1.38293540, mean_g_loss: 1010.52508545\n",
            "Epoch:  98 Step:  1454  time: 1.317333 s d_loss: 1.21734178, g_loss: 912.72692871 -- mean_d_loss: 1.37992454, mean_g_loss: 1008.74694824\n",
            "Epoch:  98 Step:  1455  time: 1.313615 s d_loss: 6.68978453, g_loss: 1115.63208008 -- mean_d_loss: 1.47474349, mean_g_loss: 1010.65563965\n",
            "Epoch:  98 Step:  1456  time: 1.306870 s d_loss: 24.35251999, g_loss: 1072.01452637 -- mean_d_loss: 1.87610805, mean_g_loss: 1011.73211670\n",
            "Epoch:  98 Step:  1457  time: 1.296638 s d_loss: 1.84085369, g_loss: 1106.40637207 -- mean_d_loss: 1.87550008, mean_g_loss: 1013.36444092\n",
            "Epoch:  98 Step:  1458  time: 1.323772 s d_loss: 7.47338247, g_loss: 1038.98010254 -- mean_d_loss: 1.97037947, mean_g_loss: 1013.79858398\n",
            "Epoch:  98 Step:  1459  time: 1.315830 s d_loss: 0.97007573, g_loss: 974.18225098 -- mean_d_loss: 1.95370781, mean_g_loss: 1013.13836670\n",
            "Epoch:  98 Step:  1460  time: 1.312279 s d_loss: 1.52864635, g_loss: 972.09521484 -- mean_d_loss: 1.94673955, mean_g_loss: 1012.46545410\n",
            "Epoch:  98 Step:  1461  time: 1.305967 s d_loss: 2.48335028, g_loss: 977.77667236 -- mean_d_loss: 1.95539463, mean_g_loss: 1011.90600586\n",
            "Epoch:  98 Step:  1462  time: 1.333413 s d_loss: 1.56031418, g_loss: 1050.07226562 -- mean_d_loss: 1.94912362, mean_g_loss: 1012.51177979\n",
            "Epoch:  98 Step:  1463  time: 1.312531 s d_loss: 1.34026706, g_loss: 1016.04809570 -- mean_d_loss: 1.93961012, mean_g_loss: 1012.56701660\n",
            "Epoch:  98 Step:  1464  time: 1.287782 s d_loss: 1.47966981, g_loss: 1090.92797852 -- mean_d_loss: 1.93253410, mean_g_loss: 1013.77258301\n",
            "Epoch:  98 Step:  1465  time: 1.315270 s d_loss: 2.42694426, g_loss: 1174.95800781 -- mean_d_loss: 1.94002509, mean_g_loss: 1016.21484375\n",
            "Epoch:  98 Step:  1466  time: 1.333532 s d_loss: 1.44969845, g_loss: 994.82666016 -- mean_d_loss: 1.93270671, mean_g_loss: 1015.89562988\n",
            "Epoch:  98 Step:  1467  time: 1.282538 s d_loss: 47.38706970, g_loss: 981.53088379 -- mean_d_loss: 2.60115314, mean_g_loss: 1015.39025879\n",
            "Epoch:  98 Step:  1468  time: 1.288334 s d_loss: 1.95168924, g_loss: 1022.91497803 -- mean_d_loss: 2.59174061, mean_g_loss: 1015.49932861\n",
            "Epoch:  98 Step:  1469  time: 1.307447 s d_loss: 2.61539936, g_loss: 1080.30541992 -- mean_d_loss: 2.59207869, mean_g_loss: 1016.42510986\n",
            "Epoch:  98 Step:  1470  time: 1.327505 s d_loss: 0.99688023, g_loss: 999.63403320 -- mean_d_loss: 2.56961131, mean_g_loss: 1016.18859863\n",
            "Epoch:  98 Step:  1471  time: 1.329378 s d_loss: 9.35974407, g_loss: 981.15600586 -- mean_d_loss: 2.66391850, mean_g_loss: 1015.70202637\n",
            "Epoch:  98 Step:  1472  time: 1.335902 s d_loss: 0.89951044, g_loss: 1205.97241211 -- mean_d_loss: 2.63974857, mean_g_loss: 1018.30841064\n",
            "Epoch:  98 Step:  1473  time: 1.321420 s d_loss: 0.67122775, g_loss: 1045.76757812 -- mean_d_loss: 2.61314702, mean_g_loss: 1018.67950439\n",
            "Epoch:  98 Step:  1474  time: 1.291618 s d_loss: 0.86090755, g_loss: 1113.86828613 -- mean_d_loss: 2.58978367, mean_g_loss: 1019.94866943\n",
            "Epoch:  98 Step:  1475  time: 1.316594 s d_loss: 0.82953537, g_loss: 943.08685303 -- mean_d_loss: 2.56662250, mean_g_loss: 1018.93731689\n",
            "Epoch:  98 Step:  1476  time: 1.346998 s d_loss: 0.91095591, g_loss: 926.02618408 -- mean_d_loss: 2.54512024, mean_g_loss: 1017.73059082\n",
            "Epoch:  98 Step:  1477  time: 1.316692 s d_loss: 1.23106349, g_loss: 979.17285156 -- mean_d_loss: 2.52827334, mean_g_loss: 1017.23626709\n",
            "Epoch:  98 Step:  1478  time: 1.338600 s d_loss: 3.21606636, g_loss: 1102.94067383 -- mean_d_loss: 2.53697968, mean_g_loss: 1018.32110596\n",
            "Epoch:  98 Step:  1479  time: 1.316477 s d_loss: 7.01795578, g_loss: 1026.46508789 -- mean_d_loss: 2.59299183, mean_g_loss: 1018.42297363\n",
            "Epoch:  98 Step:  1480  time: 1.330195 s d_loss: 1.60754538, g_loss: 884.01147461 -- mean_d_loss: 2.58082581, mean_g_loss: 1016.76348877\n",
            "Epoch:  98 Step:  1481  time: 1.340383 s d_loss: 1.67069292, g_loss: 1071.11315918 -- mean_d_loss: 2.56972671, mean_g_loss: 1017.42626953\n",
            "Epoch:  98 Step:  1482  time: 1.313318 s d_loss: 0.70633411, g_loss: 1108.91943359 -- mean_d_loss: 2.54727626, mean_g_loss: 1018.52862549\n",
            "Epoch:  98 Step:  1483  time: 1.310217 s d_loss: 0.92034632, g_loss: 953.37121582 -- mean_d_loss: 2.52790785, mean_g_loss: 1017.75299072\n",
            "Epoch:  98 Step:  1484  time: 1.314788 s d_loss: 0.86942798, g_loss: 1053.27343750 -- mean_d_loss: 2.50839639, mean_g_loss: 1018.17083740\n",
            "Epoch:  98 Step:  1485  time: 1.293254 s d_loss: 0.98033184, g_loss: 1095.76220703 -- mean_d_loss: 2.49062824, mean_g_loss: 1019.07312012\n",
            "Epoch:  98 Step:  1486  time: 1.337766 s d_loss: 0.69426745, g_loss: 911.44018555 -- mean_d_loss: 2.46998048, mean_g_loss: 1017.83593750\n",
            "Epoch:  98 Step:  1487  time: 1.296461 s d_loss: 1.14110041, g_loss: 1256.57714844 -- mean_d_loss: 2.45487952, mean_g_loss: 1020.54888916\n",
            "Epoch:  98 Step:  1488  time: 1.318584 s d_loss: 1.13371658, g_loss: 1097.87658691 -- mean_d_loss: 2.44003510, mean_g_loss: 1021.41772461\n",
            "Epoch:  98 Step:  1489  time: 1.286943 s d_loss: 0.68814647, g_loss: 1060.94726562 -- mean_d_loss: 2.42056942, mean_g_loss: 1021.85693359\n",
            "Epoch:  98 Step:  1490  time: 1.333705 s d_loss: 0.91363907, g_loss: 1029.55078125 -- mean_d_loss: 2.40400982, mean_g_loss: 1021.94146729\n",
            "Epoch:  98 Step:  1491  time: 1.325763 s d_loss: 0.63756257, g_loss: 914.34765625 -- mean_d_loss: 2.38480926, mean_g_loss: 1020.77191162\n",
            "Epoch:  98 Step:  1492  time: 1.287130 s d_loss: 1.06223881, g_loss: 1127.92236328 -- mean_d_loss: 2.37058806, mean_g_loss: 1021.92407227\n",
            "Epoch:  98 Step:  1493  time: 1.292396 s d_loss: 0.80627888, g_loss: 1091.83178711 -- mean_d_loss: 2.35394645, mean_g_loss: 1022.66772461\n",
            "Epoch:  98 Step:  1494  time: 1.318321 s d_loss: 0.60664201, g_loss: 881.79248047 -- mean_d_loss: 2.33555388, mean_g_loss: 1021.18481445\n",
            "Epoch:  98 Step:  1495  time: 1.286829 s d_loss: 0.69591498, g_loss: 944.70922852 -- mean_d_loss: 2.31847405, mean_g_loss: 1020.38818359\n",
            "Epoch:  98 Step:  1496  time: 1.318556 s d_loss: 0.71031183, g_loss: 938.24145508 -- mean_d_loss: 2.30189514, mean_g_loss: 1019.54132080\n",
            "Epoch:  98 Step:  1497  time: 1.318796 s d_loss: 0.79801571, g_loss: 1060.85412598 -- mean_d_loss: 2.28654957, mean_g_loss: 1019.96282959\n",
            "Epoch:  98 Step:  1498  time: 1.336789 s d_loss: 4.20041895, g_loss: 1111.73999023 -- mean_d_loss: 2.30588150, mean_g_loss: 1020.88989258\n",
            "Epoch:  98 Step:  1499  time: 1.309659 s d_loss: 0.65083879, g_loss: 896.54541016 -- mean_d_loss: 2.28933096, mean_g_loss: 1019.64648438\n",
            "Epoch:  98 Step:  1500  time: 1.316913 s d_loss: 0.57306093, g_loss: 1075.60498047 -- mean_d_loss: 2.27233815, mean_g_loss: 1020.20050049\n",
            "Epoch:  98 Step:  1501  time: 1.295888 s d_loss: 0.55671209, g_loss: 1007.33312988 -- mean_d_loss: 2.25551844, mean_g_loss: 1020.07440186\n",
            "Epoch:  98 Step:  1502  time: 1.302472 s d_loss: 0.65167642, g_loss: 982.73608398 -- mean_d_loss: 2.23994708, mean_g_loss: 1019.71185303\n",
            "Epoch:  98 Step:  1503  time: 1.317589 s d_loss: 0.92520958, g_loss: 943.28662109 -- mean_d_loss: 2.22730541, mean_g_loss: 1018.97698975\n",
            "Epoch:  98 Step:  1504  time: 1.321718 s d_loss: 0.79380000, g_loss: 873.33117676 -- mean_d_loss: 2.21365309, mean_g_loss: 1017.58990479\n",
            "Epoch:  98 Step:  1505  time: 1.295521 s d_loss: 0.67680693, g_loss: 968.16162109 -- mean_d_loss: 2.19915438, mean_g_loss: 1017.12359619\n",
            "Epoch:  98 Step:  1506  time: 1.313411 s d_loss: 9.86609936, g_loss: 1045.39868164 -- mean_d_loss: 2.27080822, mean_g_loss: 1017.38787842\n",
            "Epoch:  98 Step:  1507  time: 1.294971 s d_loss: 0.71789581, g_loss: 1048.69702148 -- mean_d_loss: 2.25642943, mean_g_loss: 1017.67773438\n",
            "Epoch:  98 Step:  1508  time: 1.293806 s d_loss: 0.70155245, g_loss: 950.00207520 -- mean_d_loss: 2.24216437, mean_g_loss: 1017.05682373\n",
            "Epoch:  98 Step:  1509  time: 1.346246 s d_loss: 1.09814644, g_loss: 1069.95971680 -- mean_d_loss: 2.23176432, mean_g_loss: 1017.53778076\n",
            "Epoch:  98 Step:  1510  time: 1.296481 s d_loss: 0.68664831, g_loss: 926.05004883 -- mean_d_loss: 2.21784425, mean_g_loss: 1016.71356201\n",
            "Epoch:  98 Step:  1511  time: 1.293752 s d_loss: 0.91953284, g_loss: 1051.17102051 -- mean_d_loss: 2.20625234, mean_g_loss: 1017.02117920\n",
            "Epoch:  98 Step:  1512  time: 1.316416 s d_loss: 0.82075316, g_loss: 1056.55480957 -- mean_d_loss: 2.19399118, mean_g_loss: 1017.37103271\n",
            "Epoch:  98 Step:  1513  time: 1.329012 s d_loss: 0.45793766, g_loss: 942.02764893 -- mean_d_loss: 2.17876267, mean_g_loss: 1016.71020508\n",
            "Epoch:  98 Step:  1514  time: 1.323801 s d_loss: 0.52478838, g_loss: 1012.14868164 -- mean_d_loss: 2.16438031, mean_g_loss: 1016.67053223\n",
            "Epoch:  98 Step:  1515  time: 1.328570 s d_loss: 1.06215870, g_loss: 951.26501465 -- mean_d_loss: 2.15487838, mean_g_loss: 1016.10668945\n",
            "Epoch:  98 Step:  1516  time: 1.312349 s d_loss: 0.64923245, g_loss: 1111.07214355 -- mean_d_loss: 2.14200974, mean_g_loss: 1016.91833496\n",
            "Epoch:  98 Step:  1517  time: 1.326316 s d_loss: 0.77058649, g_loss: 940.47521973 -- mean_d_loss: 2.13038731, mean_g_loss: 1016.27050781\n",
            "Epoch:  98 Step:  1518  time: 1.307368 s d_loss: 0.66935271, g_loss: 955.39025879 -- mean_d_loss: 2.11810994, mean_g_loss: 1015.75891113\n",
            "Epoch:  98 Step:  1519  time: 1.328952 s d_loss: 1.80646598, g_loss: 913.33886719 -- mean_d_loss: 2.11551285, mean_g_loss: 1014.90539551\n",
            "Epoch:  98 Step:  1520  time: 1.296894 s d_loss: 1.04168069, g_loss: 926.32592773 -- mean_d_loss: 2.10663819, mean_g_loss: 1014.17333984\n",
            "Epoch:  98 Step:  1521  time: 1.330656 s d_loss: 0.96857709, g_loss: 1084.85888672 -- mean_d_loss: 2.09730983, mean_g_loss: 1014.75274658\n",
            "Epoch:  98 Step:  1522  time: 1.317567 s d_loss: 1.07313061, g_loss: 1046.42431641 -- mean_d_loss: 2.08898330, mean_g_loss: 1015.01025391\n",
            "Epoch:  98 Step:  1523  time: 1.330287 s d_loss: 1.11442196, g_loss: 895.70495605 -- mean_d_loss: 2.08112383, mean_g_loss: 1014.04809570\n",
            "Epoch:  98 Step:  1524  time: 1.317199 s d_loss: 0.64299321, g_loss: 968.65295410 -- mean_d_loss: 2.06961894, mean_g_loss: 1013.68493652\n",
            "Epoch:  98 Step:  1525  time: 1.317943 s d_loss: 0.72897983, g_loss: 996.90283203 -- mean_d_loss: 2.05897880, mean_g_loss: 1013.55175781\n",
            "Epoch:  98 Step:  1526  time: 1.317374 s d_loss: 0.76713902, g_loss: 1040.24694824 -- mean_d_loss: 2.04880691, mean_g_loss: 1013.76202393\n",
            "Epoch:  98 Step:  1527  time: 1.329599 s d_loss: 0.78444946, g_loss: 1085.16699219 -- mean_d_loss: 2.03892922, mean_g_loss: 1014.31982422\n",
            "Epoch:  98 Step:  1528  time: 1.317649 s d_loss: 0.96129602, g_loss: 964.88146973 -- mean_d_loss: 2.03057551, mean_g_loss: 1013.93658447\n",
            "Epoch:  98 Step:  1529  time: 1.318411 s d_loss: 0.68623054, g_loss: 968.33233643 -- mean_d_loss: 2.02023435, mean_g_loss: 1013.58581543\n",
            "Epoch:  98 Step:  1530  time: 1.342441 s d_loss: 1.09245586, g_loss: 1010.04388428 -- mean_d_loss: 2.01315212, mean_g_loss: 1013.55877686\n",
            "Epoch:  98 Step:  1531  time: 1.320316 s d_loss: 0.92554104, g_loss: 1107.39794922 -- mean_d_loss: 2.00491261, mean_g_loss: 1014.26965332\n",
            "Epoch:  98 Step:  1532  time: 1.289753 s d_loss: 0.74546486, g_loss: 1081.39636230 -- mean_d_loss: 1.99544299, mean_g_loss: 1014.77429199\n",
            "Epoch:  98 Step:  1533  time: 1.326051 s d_loss: 1.08051574, g_loss: 1124.51123047 -- mean_d_loss: 1.98861516, mean_g_loss: 1015.59326172\n",
            "Epoch:  98 Step:  1534  time: 1.323080 s d_loss: 0.72825062, g_loss: 1025.99755859 -- mean_d_loss: 1.97927904, mean_g_loss: 1015.67034912\n",
            "Epoch:  98 Step:  1535  time: 1.296962 s d_loss: 3.00800133, g_loss: 865.88940430 -- mean_d_loss: 1.98684311, mean_g_loss: 1014.56903076\n",
            "Epoch:  98 Step:  1536  time: 1.305827 s d_loss: 0.86827141, g_loss: 1090.79370117 -- mean_d_loss: 1.97867846, mean_g_loss: 1015.12542725\n",
            "Epoch:  98 Step:  1537  time: 1.314583 s d_loss: 0.64904565, g_loss: 1130.35131836 -- mean_d_loss: 1.96904349, mean_g_loss: 1015.96038818\n",
            "Epoch:  98 Step:  1538  time: 1.334986 s d_loss: 0.69905114, g_loss: 951.13586426 -- mean_d_loss: 1.95990694, mean_g_loss: 1015.49401855\n",
            "Epoch:  98 Step:  1539  time: 1.352250 s d_loss: 54.97741699, g_loss: 1004.94879150 -- mean_d_loss: 2.33860350, mean_g_loss: 1015.41876221\n",
            "Epoch:  98 Step:  1540  time: 1.349032 s d_loss: 2.88441658, g_loss: 921.45263672 -- mean_d_loss: 2.34247446, mean_g_loss: 1014.75231934\n",
            "Epoch:  98 Step:  1541  time: 1.337075 s d_loss: 5.55713844, g_loss: 908.24121094 -- mean_d_loss: 2.36511302, mean_g_loss: 1014.00219727\n",
            "Epoch:  98 Step:  1542  time: 1.283524 s d_loss: 2.48277569, g_loss: 1138.38232422 -- mean_d_loss: 2.36593580, mean_g_loss: 1014.87194824\n",
            "Epoch:  98 Step:  1543  time: 1.327127 s d_loss: 39.94297409, g_loss: 1049.45776367 -- mean_d_loss: 2.62688732, mean_g_loss: 1015.11206055\n",
            "Epoch:  98 Step:  1544  time: 1.304504 s d_loss: 1.30064714, g_loss: 928.48974609 -- mean_d_loss: 2.61774111, mean_g_loss: 1014.51464844\n",
            "Epoch:  98 Step:  1545  time: 1.329142 s d_loss: 3.25402808, g_loss: 930.82385254 -- mean_d_loss: 2.62209916, mean_g_loss: 1013.94146729\n",
            "Epoch:  98 Step:  1546  time: 1.323316 s d_loss: 1.46822393, g_loss: 1059.21142578 -- mean_d_loss: 2.61424971, mean_g_loss: 1014.24945068\n",
            "Epoch:  98 Step:  1547  time: 1.297812 s d_loss: 31.52507973, g_loss: 1116.09838867 -- mean_d_loss: 2.80959320, mean_g_loss: 1014.93762207\n",
            "Epoch:  98 Step:  1548  time: 1.297437 s d_loss: 1.57590890, g_loss: 905.90966797 -- mean_d_loss: 2.80131340, mean_g_loss: 1014.20587158\n",
            "Epoch:  98 Step:  1549  time: 1.308185 s d_loss: 1.76209414, g_loss: 1040.56506348 -- mean_d_loss: 2.79438519, mean_g_loss: 1014.38159180\n",
            "Epoch:  98 Step:  1550  time: 1.293982 s d_loss: 1.87209177, g_loss: 996.06372070 -- mean_d_loss: 2.78827739, mean_g_loss: 1014.26025391\n",
            "Epoch:  98 Step:  1551  time: 1.321777 s d_loss: 1.05956900, g_loss: 862.22619629 -- mean_d_loss: 2.77690434, mean_g_loss: 1013.25994873\n",
            "Epoch:  98 Step:  1552  time: 1.306765 s d_loss: 1.16526318, g_loss: 1007.08166504 -- mean_d_loss: 2.76637053, mean_g_loss: 1013.21954346\n",
            "Epoch:  98 Step:  1553  time: 1.321643 s d_loss: 1.43264115, g_loss: 1013.93444824 -- mean_d_loss: 2.75770998, mean_g_loss: 1013.22424316\n",
            "Epoch:  98 Step:  1554  time: 1.328268 s d_loss: 1.07094419, g_loss: 913.49938965 -- mean_d_loss: 2.74682784, mean_g_loss: 1012.58087158\n",
            "Epoch:  98 Step:  1555  time: 1.322109 s d_loss: 0.87798405, g_loss: 1046.00451660 -- mean_d_loss: 2.73484802, mean_g_loss: 1012.79504395\n",
            "Epoch:  98 Step:  1556  time: 1.325688 s d_loss: 1.03319812, g_loss: 1032.60888672 -- mean_d_loss: 2.72400951, mean_g_loss: 1012.92126465\n",
            "Epoch:  98 Step:  1557  time: 1.329008 s d_loss: 0.80993646, g_loss: 1077.84765625 -- mean_d_loss: 2.71189523, mean_g_loss: 1013.33215332\n",
            "Epoch:  98 Step:  1558  time: 1.295635 s d_loss: 1.28692746, g_loss: 1096.90209961 -- mean_d_loss: 2.70293307, mean_g_loss: 1013.85778809\n",
            "Epoch:  98 Step:  1559  time: 1.320842 s d_loss: 1.94876862, g_loss: 1034.66259766 -- mean_d_loss: 2.69821954, mean_g_loss: 1013.98779297\n",
            "Epoch:  98 Step:  1560  time: 1.329383 s d_loss: 2.81036687, g_loss: 1070.00622559 -- mean_d_loss: 2.69891596, mean_g_loss: 1014.33569336\n",
            "Epoch:  98 Step:  1561  time: 1.328425 s d_loss: 0.79462999, g_loss: 919.42199707 -- mean_d_loss: 2.68716121, mean_g_loss: 1013.74981689\n",
            "Epoch:  98 Step:  1562  time: 1.340335 s d_loss: 1.12424815, g_loss: 1211.89062500 -- mean_d_loss: 2.67757273, mean_g_loss: 1014.96539307\n",
            "Epoch:  98 Step:  1563  time: 1.338116 s d_loss: 0.74002510, g_loss: 1027.61694336 -- mean_d_loss: 2.66575837, mean_g_loss: 1015.04248047\n",
            "Epoch:  98 Step:  1564  time: 1.310829 s d_loss: 0.82080448, g_loss: 1002.72131348 -- mean_d_loss: 2.65457678, mean_g_loss: 1014.96777344\n",
            "Epoch:  98 Step:  1565  time: 1.320937 s d_loss: 6.04299736, g_loss: 1094.82348633 -- mean_d_loss: 2.67498899, mean_g_loss: 1015.44891357\n",
            "Epoch:  98 Step:  1566  time: 1.321976 s d_loss: 0.69541514, g_loss: 1040.17114258 -- mean_d_loss: 2.66313505, mean_g_loss: 1015.59692383\n",
            "Epoch:  98 Step:  1567  time: 1.289057 s d_loss: 0.74186158, g_loss: 861.93127441 -- mean_d_loss: 2.65169883, mean_g_loss: 1014.68231201\n",
            "Epoch:  98 Step:  1568  time: 1.346200 s d_loss: 0.95732182, g_loss: 1037.04064941 -- mean_d_loss: 2.64167309, mean_g_loss: 1014.81463623\n",
            "Epoch:  98 Step:  1569  time: 1.323456 s d_loss: 0.74646270, g_loss: 1100.29040527 -- mean_d_loss: 2.63052487, mean_g_loss: 1015.31744385\n",
            "Epoch:  98 Step:  1570  time: 1.336309 s d_loss: 0.69401199, g_loss: 871.07891846 -- mean_d_loss: 2.61919999, mean_g_loss: 1014.47393799\n",
            "Epoch:  98 Step:  1571  time: 1.328825 s d_loss: 51.40176010, g_loss: 1048.34948730 -- mean_d_loss: 2.90281963, mean_g_loss: 1014.67089844\n",
            "Epoch:  98 Step:  1572  time: 1.288070 s d_loss: 2.03357720, g_loss: 1115.54028320 -- mean_d_loss: 2.89779496, mean_g_loss: 1015.25396729\n",
            "Epoch:  98 Step:  1573  time: 1.327306 s d_loss: 22.54382324, g_loss: 964.85974121 -- mean_d_loss: 3.01070333, mean_g_loss: 1014.96435547\n",
            "Epoch:  98 Step:  1574  time: 1.326848 s d_loss: 1.36994410, g_loss: 912.44384766 -- mean_d_loss: 3.00132751, mean_g_loss: 1014.37847900\n",
            "Epoch:  98 Step:  1575  time: 1.335563 s d_loss: 1.80850685, g_loss: 983.84594727 -- mean_d_loss: 2.99455023, mean_g_loss: 1014.20501709\n",
            "Epoch:  98 Step:  1576  time: 1.331284 s d_loss: 1.49075258, g_loss: 934.72619629 -- mean_d_loss: 2.98605394, mean_g_loss: 1013.75592041\n",
            "Epoch:  98 Step:  1577  time: 1.303603 s d_loss: 2.52254820, g_loss: 965.07336426 -- mean_d_loss: 2.98344994, mean_g_loss: 1013.48242188\n",
            "Epoch:  98 Step:  1578  time: 1.343944 s d_loss: 6.33498669, g_loss: 1020.51867676 -- mean_d_loss: 3.00217342, mean_g_loss: 1013.52172852\n",
            "Epoch:  98 Step:  1579  time: 1.282720 s d_loss: 1.77464736, g_loss: 1008.98144531 -- mean_d_loss: 2.99535394, mean_g_loss: 1013.49652100\n",
            "Epoch:  98 Step:  1580  time: 1.286673 s d_loss: 2.20926762, g_loss: 975.38684082 -- mean_d_loss: 2.99101090, mean_g_loss: 1013.28601074\n",
            "Epoch:  98 Step:  1581  time: 1.313971 s d_loss: 1.65860510, g_loss: 1043.49108887 -- mean_d_loss: 2.98369026, mean_g_loss: 1013.45190430\n",
            "Epoch:  98 Step:  1582  time: 1.284479 s d_loss: 6.63414621, g_loss: 1122.74865723 -- mean_d_loss: 3.00363803, mean_g_loss: 1014.04919434\n",
            "Epoch:  98 Step:  1583  time: 1.323427 s d_loss: 2.18632412, g_loss: 1078.29272461 -- mean_d_loss: 2.99919629, mean_g_loss: 1014.39837646\n",
            "Epoch:  98 Step:  1584  time: 1.313611 s d_loss: 26.07201767, g_loss: 1121.84326172 -- mean_d_loss: 3.12391424, mean_g_loss: 1014.97912598\n",
            "Epoch:  98 Step:  1585  time: 1.326272 s d_loss: 3.72719622, g_loss: 972.77447510 -- mean_d_loss: 3.12715745, mean_g_loss: 1014.75225830\n",
            "Epoch:  98 Step:  1586  time: 1.305654 s d_loss: 3.85156322, g_loss: 924.15600586 -- mean_d_loss: 3.13103127, mean_g_loss: 1014.26782227\n",
            "Epoch:  98 Step:  1587  time: 1.308089 s d_loss: 2.32893395, g_loss: 893.96655273 -- mean_d_loss: 3.12676477, mean_g_loss: 1013.62792969\n",
            "Epoch:  98 Step:  1588  time: 1.328509 s d_loss: 2.45342040, g_loss: 1238.37963867 -- mean_d_loss: 3.12320232, mean_g_loss: 1014.81701660\n",
            "Epoch:  98 Step:  1589  time: 1.317689 s d_loss: 3.12156129, g_loss: 1012.82824707 -- mean_d_loss: 3.12319374, mean_g_loss: 1014.80657959\n",
            "Epoch:  98 Step:  1590  time: 1.309774 s d_loss: 1.76318920, g_loss: 1043.39794922 -- mean_d_loss: 3.11607313, mean_g_loss: 1014.95623779\n",
            "Epoch:  98 Step:  1591  time: 1.313726 s d_loss: 1.78585899, g_loss: 976.47558594 -- mean_d_loss: 3.10914516, mean_g_loss: 1014.75579834\n",
            "Epoch:  98 Step:  1592  time: 1.338148 s d_loss: 1.73472977, g_loss: 1225.26745605 -- mean_d_loss: 3.10202384, mean_g_loss: 1015.84649658\n",
            "Epoch:  98 Step:  1593  time: 1.314787 s d_loss: 0.84745109, g_loss: 910.90185547 -- mean_d_loss: 3.09040260, mean_g_loss: 1015.30560303\n",
            "Epoch:  98 Step:  1594  time: 1.310458 s d_loss: 1.18395114, g_loss: 1113.54992676 -- mean_d_loss: 3.08062577, mean_g_loss: 1015.80938721\n",
            "Epoch:  98 Step:  1595  time: 1.331642 s d_loss: 0.85928565, g_loss: 1032.75842285 -- mean_d_loss: 3.06929255, mean_g_loss: 1015.89587402\n",
            "Epoch:  98 Step:  1596  time: 1.322361 s d_loss: 1.82835591, g_loss: 1103.76611328 -- mean_d_loss: 3.06299353, mean_g_loss: 1016.34191895\n",
            "Epoch:  98 Step:  1597  time: 1.319578 s d_loss: 0.78134054, g_loss: 1071.86083984 -- mean_d_loss: 3.05146980, mean_g_loss: 1016.62231445\n",
            "Epoch:  98 Step:  1598  time: 1.290604 s d_loss: 1.24545181, g_loss: 1205.66809082 -- mean_d_loss: 3.04239440, mean_g_loss: 1017.57232666\n",
            "Epoch:  98 Step:  1599  time: 1.304058 s d_loss: 0.70074415, g_loss: 1018.12194824 -- mean_d_loss: 3.03068614, mean_g_loss: 1017.57507324\n",
            "Epoch:  98 Step:  1600  time: 1.322672 s d_loss: 1.44778657, g_loss: 1141.90234375 -- mean_d_loss: 1.44778657, mean_g_loss: 1141.90234375\n",
            "Epoch:  98 Step:  1601  time: 1.317590 s d_loss: 0.72417283, g_loss: 940.01745605 -- mean_d_loss: 1.08597970, mean_g_loss: 1040.95996094\n",
            "Epoch:  98 Step:  1602  time: 1.318692 s d_loss: 0.84003907, g_loss: 1001.31567383 -- mean_d_loss: 1.00399947, mean_g_loss: 1027.74523926\n",
            "Epoch:  98 Step:  1603  time: 1.313167 s d_loss: 0.77324903, g_loss: 928.11151123 -- mean_d_loss: 0.94631183, mean_g_loss: 1002.83679199\n",
            "Epoch:  98 Step:  1604  time: 1.290291 s d_loss: 0.69678617, g_loss: 948.28259277 -- mean_d_loss: 0.89640677, mean_g_loss: 991.92596436\n",
            "Epoch:  98 Step:  1605  time: 1.294353 s d_loss: 0.76096141, g_loss: 1009.42980957 -- mean_d_loss: 0.87383252, mean_g_loss: 994.84326172\n",
            "Epoch:  98 Step:  1606  time: 1.324539 s d_loss: 15.94030762, g_loss: 1035.48266602 -- mean_d_loss: 3.02618623, mean_g_loss: 1000.64886475\n",
            "Epoch:  98 Step:  1607  time: 1.344077 s d_loss: 1.20857120, g_loss: 993.52880859 -- mean_d_loss: 2.79898429, mean_g_loss: 999.75885010\n",
            "Epoch:  98 Step:  1608  time: 1.321990 s d_loss: 0.97402495, g_loss: 993.89172363 -- mean_d_loss: 2.59621119, mean_g_loss: 999.10699463\n",
            "Epoch:  98 Step:  1609  time: 1.322385 s d_loss: 1.20991182, g_loss: 1081.06054688 -- mean_d_loss: 2.45758104, mean_g_loss: 1007.30236816\n",
            "Epoch:  98 Step:  1610  time: 1.334673 s d_loss: 0.74561334, g_loss: 1066.92297363 -- mean_d_loss: 2.30194759, mean_g_loss: 1012.72241211\n",
            "Epoch:  98 Step:  1611  time: 1.308222 s d_loss: 0.68400037, g_loss: 1142.49304199 -- mean_d_loss: 2.16711879, mean_g_loss: 1023.53662109\n",
            "Epoch:  98 Step:  1612  time: 1.312250 s d_loss: 0.60298103, g_loss: 1021.44287109 -- mean_d_loss: 2.04680037, mean_g_loss: 1023.37561035\n",
            "Epoch:  98 Step:  1613  time: 1.309622 s d_loss: 0.90844518, g_loss: 1058.10681152 -- mean_d_loss: 1.96548939, mean_g_loss: 1025.85632324\n",
            "Epoch:  98 Step:  1614  time: 1.320151 s d_loss: 0.77573168, g_loss: 904.59167480 -- mean_d_loss: 1.88617218, mean_g_loss: 1017.77209473\n",
            "Epoch:  98 Step:  1615  time: 1.318300 s d_loss: 0.93120843, g_loss: 952.67150879 -- mean_d_loss: 1.82648695, mean_g_loss: 1013.70330811\n",
            "Epoch:  98 Step:  1616  time: 1.319277 s d_loss: 6.39133692, g_loss: 949.88256836 -- mean_d_loss: 2.09500742, mean_g_loss: 1009.94909668\n",
            "Epoch:  98 Step:  1617  time: 1.334882 s d_loss: 6.20762396, g_loss: 937.72863770 -- mean_d_loss: 2.32348609, mean_g_loss: 1005.93682861\n",
            "Epoch:  98 Step:  1618  time: 1.325845 s d_loss: 1.83345139, g_loss: 963.02160645 -- mean_d_loss: 2.29769468, mean_g_loss: 1003.67816162\n",
            "Epoch:  98 Step:  1619  time: 1.354712 s d_loss: 1.29845095, g_loss: 1090.37561035 -- mean_d_loss: 2.24773264, mean_g_loss: 1008.01300049\n",
            "Epoch:  98 Step:  1620  time: 1.302940 s d_loss: 1.66664195, g_loss: 1310.49377441 -- mean_d_loss: 2.22006154, mean_g_loss: 1022.41687012\n",
            "Epoch:  98 Step:  1621  time: 1.327057 s d_loss: 2.61165237, g_loss: 957.18200684 -- mean_d_loss: 2.23786116, mean_g_loss: 1019.45159912\n",
            "Epoch:  98 Step:  1622  time: 1.332579 s d_loss: 2.77937388, g_loss: 1056.20031738 -- mean_d_loss: 2.26140523, mean_g_loss: 1021.04943848\n",
            "Epoch:  98 Step:  1623  time: 1.335725 s d_loss: 1.90098464, g_loss: 1115.18322754 -- mean_d_loss: 2.24638772, mean_g_loss: 1024.97167969\n",
            "Epoch:  98 Step:  1624  time: 1.325131 s d_loss: 1.10472095, g_loss: 1074.52258301 -- mean_d_loss: 2.20072103, mean_g_loss: 1026.95373535\n",
            "Epoch:  98 Step:  1625  time: 1.335815 s d_loss: 0.96683151, g_loss: 1004.70788574 -- mean_d_loss: 2.15326357, mean_g_loss: 1026.09814453\n",
            "Epoch:  98 Step:  1626  time: 1.318110 s d_loss: 0.86379999, g_loss: 898.70330811 -- mean_d_loss: 2.10550570, mean_g_loss: 1021.37976074\n",
            "Epoch:  98 Step:  1627  time: 1.336552 s d_loss: 0.77393192, g_loss: 911.67749023 -- mean_d_loss: 2.05794954, mean_g_loss: 1017.46185303\n",
            "Epoch:  98 Step:  1628  time: 1.346176 s d_loss: 0.73169738, g_loss: 916.01666260 -- mean_d_loss: 2.01221681, mean_g_loss: 1013.96374512\n",
            "Epoch:  98 Step:  1629  time: 1.323141 s d_loss: 0.84664297, g_loss: 1080.08105469 -- mean_d_loss: 1.97336423, mean_g_loss: 1016.16772461\n",
            "Epoch:  98 Step:  1630  time: 1.337513 s d_loss: 0.93985063, g_loss: 965.64904785 -- mean_d_loss: 1.94002509, mean_g_loss: 1014.53802490\n",
            "Epoch:  98 Step:  1631  time: 1.316685 s d_loss: 2.12017226, g_loss: 888.43011475 -- mean_d_loss: 1.94565463, mean_g_loss: 1010.59716797\n",
            "Epoch:  98 Step:  1632  time: 1.294402 s d_loss: 0.88335145, g_loss: 1076.86279297 -- mean_d_loss: 1.91346359, mean_g_loss: 1012.60522461\n",
            "Epoch:  98 Step:  1633  time: 1.293968 s d_loss: 0.67921466, g_loss: 1198.75317383 -- mean_d_loss: 1.87716210, mean_g_loss: 1018.08020020\n",
            "Epoch:  98 Step:  1634  time: 1.323762 s d_loss: 0.68434870, g_loss: 888.88543701 -- mean_d_loss: 1.84308171, mean_g_loss: 1014.38897705\n",
            "Epoch:  98 Step:  1635  time: 1.328456 s d_loss: 0.73866588, g_loss: 1235.19128418 -- mean_d_loss: 1.81240332, mean_g_loss: 1020.52233887\n",
            "Epoch:  98 Step:  1636  time: 1.325845 s d_loss: 0.57367384, g_loss: 865.84777832 -- mean_d_loss: 1.77892423, mean_g_loss: 1016.34197998\n",
            "Epoch:  98 Step:  1637  time: 1.324456 s d_loss: 0.95866632, g_loss: 1098.63720703 -- mean_d_loss: 1.75733852, mean_g_loss: 1018.50762939\n",
            "Epoch:  98 Step:  1638  time: 1.318322 s d_loss: 1.88571334, g_loss: 1112.48583984 -- mean_d_loss: 1.76063013, mean_g_loss: 1020.91729736\n",
            "Epoch:  98 Step:  1639  time: 1.315329 s d_loss: 1.23588157, g_loss: 1011.40759277 -- mean_d_loss: 1.74751127, mean_g_loss: 1020.67950439\n",
            "Epoch:  98 Step:  1640  time: 1.287103 s d_loss: 1.42833209, g_loss: 1087.62927246 -- mean_d_loss: 1.73972642, mean_g_loss: 1022.31237793\n",
            "Epoch:  98 Step:  1641  time: 1.314571 s d_loss: 1.11711204, g_loss: 894.12084961 -- mean_d_loss: 1.72490215, mean_g_loss: 1019.26025391\n",
            "Epoch:  98 Step:  1642  time: 1.290365 s d_loss: 1.79742479, g_loss: 1054.31872559 -- mean_d_loss: 1.72658873, mean_g_loss: 1020.07556152\n",
            "Epoch:  98 Step:  1643  time: 1.324830 s d_loss: 1.80184591, g_loss: 1039.66271973 -- mean_d_loss: 1.72829926, mean_g_loss: 1020.52075195\n",
            "Epoch:  98 Step:  1644  time: 1.314418 s d_loss: 0.86154091, g_loss: 861.24438477 -- mean_d_loss: 1.70903790, mean_g_loss: 1016.98132324\n",
            "Epoch:  98 Step:  1645  time: 1.311587 s d_loss: 3.75391388, g_loss: 1102.74145508 -- mean_d_loss: 1.75349176, mean_g_loss: 1018.84570312\n",
            "Epoch:  98 Step:  1646  time: 1.311906 s d_loss: 1.26509368, g_loss: 1155.31286621 -- mean_d_loss: 1.74310029, mean_g_loss: 1021.74926758\n",
            "Epoch:  98 Step:  1647  time: 1.334252 s d_loss: 2.04435134, g_loss: 1173.73754883 -- mean_d_loss: 1.74937630, mean_g_loss: 1024.91564941\n",
            "Epoch:  98 Step:  1648  time: 1.321153 s d_loss: 1.12760472, g_loss: 1142.31176758 -- mean_d_loss: 1.73668706, mean_g_loss: 1027.31152344\n",
            "Epoch:  98 Step:  1649  time: 1.324660 s d_loss: 3.20880651, g_loss: 1095.27880859 -- mean_d_loss: 1.76612949, mean_g_loss: 1028.67089844\n",
            "Epoch:  98 Step:  1650  time: 1.325347 s d_loss: 0.95054108, g_loss: 1063.95410156 -- mean_d_loss: 1.75013745, mean_g_loss: 1029.36267090\n",
            "Epoch:  98 Step:  1651  time: 1.316714 s d_loss: 1.32127070, g_loss: 1043.77587891 -- mean_d_loss: 1.74189007, mean_g_loss: 1029.63989258\n",
            "Epoch:  98 Step:  1652  time: 1.302956 s d_loss: 1.43296301, g_loss: 1107.05859375 -- mean_d_loss: 1.73606122, mean_g_loss: 1031.10058594\n",
            "Epoch:  98 Step:  1653  time: 1.322224 s d_loss: 2.12187457, g_loss: 901.62115479 -- mean_d_loss: 1.74320590, mean_g_loss: 1028.70288086\n",
            "Epoch:  98 Step:  1654  time: 1.323875 s d_loss: 0.69136900, g_loss: 1034.62500000 -- mean_d_loss: 1.72408152, mean_g_loss: 1028.81054688\n",
            "Epoch:  98 Step:  1655  time: 1.322971 s d_loss: 0.84444010, g_loss: 980.21069336 -- mean_d_loss: 1.70837367, mean_g_loss: 1027.94262695\n",
            "Epoch:  98 Step:  1656  time: 1.299611 s d_loss: 0.89927232, g_loss: 1033.15710449 -- mean_d_loss: 1.69417882, mean_g_loss: 1028.03417969\n",
            "Epoch:  98 Step:  1657  time: 1.352225 s d_loss: 1.09199858, g_loss: 1175.27807617 -- mean_d_loss: 1.68379629, mean_g_loss: 1030.57275391\n",
            "Epoch:  98 Step:  1658  time: 1.289125 s d_loss: 3.46605325, g_loss: 1064.25195312 -- mean_d_loss: 1.71400416, mean_g_loss: 1031.14367676\n",
            "Epoch:  98 Step:  1659  time: 1.326680 s d_loss: 1.02259386, g_loss: 1066.99243164 -- mean_d_loss: 1.70248055, mean_g_loss: 1031.74108887\n",
            "Epoch:  98 Step:  1660  time: 1.324216 s d_loss: 0.74882692, g_loss: 1023.79150391 -- mean_d_loss: 1.68684685, mean_g_loss: 1031.61083984\n",
            "Epoch:  98 Step:  1661  time: 1.332590 s d_loss: 0.90908998, g_loss: 1036.34448242 -- mean_d_loss: 1.67430234, mean_g_loss: 1031.68713379\n",
            "Epoch:  98 Step:  1662  time: 1.287120 s d_loss: 0.88820076, g_loss: 940.00817871 -- mean_d_loss: 1.66182458, mean_g_loss: 1030.23193359\n",
            "Epoch:  98 Step:  1663  time: 1.329388 s d_loss: 1.34535575, g_loss: 838.89544678 -- mean_d_loss: 1.65687966, mean_g_loss: 1027.24230957\n",
            "val: 0./dataset/val/2014-09-08 05_31_48.jpg\n",
            "val: 1./dataset/val/2014-12-07 05_00_46.jpg\n",
            "val: 2./dataset/val/2015-04-23 10_12_24.jpg\n",
            "val: 3./dataset/val/1.jpg\n",
            "val: 4./dataset/val/3.jpg\n",
            "val: 5./dataset/val/4.jpg\n",
            "val: 6./dataset/val/6.jpg\n",
            "val: 7./dataset/val/5.jpg\n",
            "val: 8./dataset/val/7.jpg\n",
            "val: 9./dataset/val/8.jpg\n",
            "val: 10./dataset/val/9.jpg\n",
            "val: 11./dataset/val/10.jpg\n",
            "val: 12./dataset/val/2.jpg\n",
            "val: 13./dataset/val/12.jpg\n",
            "val: 14./dataset/val/13.jpg\n",
            "val: 15./dataset/val/14.jpg\n",
            "val: 16./dataset/val/15.jpg\n",
            "val: 17./dataset/val/16.jpg\n",
            "val: 18./dataset/val/17.jpg\n",
            "val: 19./dataset/val/18.jpg\n",
            "val: 20./dataset/val/19.jpg\n",
            "val: 21./dataset/val/20.jpg\n",
            "val: 22./dataset/val/21.jpg\n",
            "val: 23./dataset/val/22.jpg\n",
            "val: 24./dataset/val/23.jpg\n",
            "val: 25./dataset/val/24.jpg\n",
            "val: 26./dataset/val/25.jpg\n",
            "val: 27./dataset/val/26.jpg\n",
            "val: 28./dataset/val/27.jpg\n",
            "val: 29./dataset/val/28.jpg\n",
            "val: 30./dataset/val/29.jpg\n",
            "val: 31./dataset/val/30.jpg\n",
            "val: 32./dataset/val/31.jpg\n",
            "val: 33./dataset/val/32.jpg\n",
            "val: 34./dataset/val/33.jpg\n",
            "val: 35./dataset/val/34.jpg\n",
            "val: 36./dataset/val/35.jpg\n",
            "val: 37./dataset/val/36.jpg\n",
            "val: 38./dataset/val/37.jpg\n",
            "val: 39./dataset/val/38.jpg\n",
            "val: 40./dataset/val/39.jpg\n",
            "val: 41./dataset/val/40.jpg\n",
            "val: 42./dataset/val/41.jpg\n",
            "val: 43./dataset/val/42.jpg\n",
            "val: 44./dataset/val/43.jpg\n",
            "val: 45./dataset/val/44.jpg\n",
            "val: 46./dataset/val/45.jpg\n",
            "val: 47./dataset/val/46.jpg\n",
            "val: 48./dataset/val/49.jpg\n",
            "val: 49./dataset/val/48.jpg\n",
            "val: 50./dataset/val/47.jpg\n",
            "val: 51./dataset/val/50.jpg\n",
            "val: 52./dataset/val/51.jpg\n",
            "val: 53./dataset/val/52.jpg\n",
            "val: 54./dataset/val/53.jpg\n",
            "val: 55./dataset/val/55.jpg\n",
            "val: 56./dataset/val/57.jpg\n",
            "val: 57./dataset/val/56.jpg\n",
            "val: 58./dataset/val/54.jpg\n",
            "val: 59./dataset/val/58.jpg\n",
            "val: 60./dataset/val/59.jpg\n",
            "val: 61./dataset/val/60.jpg\n",
            "val: 62./dataset/val/11.jpg\n",
            "val: 63./dataset/val/61.jpg\n",
            "val: 64./dataset/val/hww.jpg\n",
            "val: 65./dataset/val/lzl.jpg\n",
            "val: 66./dataset/val/wzy.jpg\n",
            "Epoch:  99 Step:     0  time: 1.357054 s d_loss: 1.00600696, g_loss: 935.76293945 -- mean_d_loss: 1.64686620, mean_g_loss: 1025.83496094\n",
            "Epoch:  99 Step:     1  time: 1.319411 s d_loss: 0.88562834, g_loss: 1080.17858887 -- mean_d_loss: 1.63533223, mean_g_loss: 1026.65832520\n",
            "Epoch:  99 Step:     2  time: 1.363860 s d_loss: 0.79840070, g_loss: 1060.31811523 -- mean_d_loss: 1.62284076, mean_g_loss: 1027.16076660\n",
            "Epoch:  99 Step:     3  time: 1.349001 s d_loss: 0.94624466, g_loss: 969.43298340 -- mean_d_loss: 1.61289084, mean_g_loss: 1026.31176758\n",
            "Epoch:  99 Step:     4  time: 1.316658 s d_loss: 0.62839413, g_loss: 955.24023438 -- mean_d_loss: 1.59862280, mean_g_loss: 1025.28186035\n",
            "Epoch:  99 Step:     5  time: 1.352805 s d_loss: 1.47389507, g_loss: 1061.26318359 -- mean_d_loss: 1.59684086, mean_g_loss: 1025.79589844\n",
            "Epoch:  99 Step:     6  time: 1.355160 s d_loss: 0.61763889, g_loss: 945.39147949 -- mean_d_loss: 1.58304930, mean_g_loss: 1024.66345215\n",
            "Epoch:  99 Step:     7  time: 1.364677 s d_loss: 0.52316839, g_loss: 1066.51782227 -- mean_d_loss: 1.56832874, mean_g_loss: 1025.24462891\n",
            "Epoch:  99 Step:     8  time: 1.363140 s d_loss: 0.70725536, g_loss: 1000.52453613 -- mean_d_loss: 1.55653322, mean_g_loss: 1024.90600586\n",
            "Epoch:  99 Step:     9  time: 1.353606 s d_loss: 0.56382018, g_loss: 1094.45947266 -- mean_d_loss: 1.54311812, mean_g_loss: 1025.84594727\n",
            "Epoch:  99 Step:    10  time: 1.351269 s d_loss: 0.95239025, g_loss: 1029.92749023 -- mean_d_loss: 1.53524184, mean_g_loss: 1025.90039062\n",
            "Epoch:  99 Step:    11  time: 1.344706 s d_loss: 0.80218709, g_loss: 921.80029297 -- mean_d_loss: 1.52559626, mean_g_loss: 1024.53063965\n",
            "Epoch:  99 Step:    12  time: 1.338614 s d_loss: 0.81875038, g_loss: 1022.65319824 -- mean_d_loss: 1.51641643, mean_g_loss: 1024.50634766\n",
            "Epoch:  99 Step:    13  time: 1.334990 s d_loss: 0.74140233, g_loss: 886.17803955 -- mean_d_loss: 1.50648034, mean_g_loss: 1022.73284912\n",
            "Epoch:  99 Step:    14  time: 1.317342 s d_loss: 0.64774525, g_loss: 1138.50561523 -- mean_d_loss: 1.49561036, mean_g_loss: 1024.19836426\n",
            "Epoch:  99 Step:    15  time: 1.313204 s d_loss: 0.71638876, g_loss: 1003.97796631 -- mean_d_loss: 1.48587012, mean_g_loss: 1023.94561768\n",
            "Epoch:  99 Step:    16  time: 1.334553 s d_loss: 0.47350067, g_loss: 1021.61572266 -- mean_d_loss: 1.47337174, mean_g_loss: 1023.91687012\n",
            "Epoch:  99 Step:    17  time: 1.318322 s d_loss: 0.84032512, g_loss: 972.45922852 -- mean_d_loss: 1.46565163, mean_g_loss: 1023.28936768\n",
            "Epoch:  99 Step:    18  time: 1.334804 s d_loss: 1.00140274, g_loss: 1133.03918457 -- mean_d_loss: 1.46005833, mean_g_loss: 1024.61169434\n",
            "Epoch:  99 Step:    19  time: 1.332070 s d_loss: 1.50101042, g_loss: 1148.38317871 -- mean_d_loss: 1.46054578, mean_g_loss: 1026.08508301\n",
            "Epoch:  99 Step:    20  time: 1.348693 s d_loss: 0.93607199, g_loss: 1007.30651855 -- mean_d_loss: 1.45437551, mean_g_loss: 1025.86413574\n",
            "Epoch:  99 Step:    21  time: 1.328235 s d_loss: 1.02296996, g_loss: 934.54980469 -- mean_d_loss: 1.44935918, mean_g_loss: 1024.80236816\n",
            "Epoch:  99 Step:    22  time: 1.326119 s d_loss: 0.79707158, g_loss: 943.47436523 -- mean_d_loss: 1.44186163, mean_g_loss: 1023.86755371\n",
            "Epoch:  99 Step:    23  time: 1.331330 s d_loss: 0.67713094, g_loss: 890.81976318 -- mean_d_loss: 1.43317151, mean_g_loss: 1022.35565186\n",
            "Epoch:  99 Step:    24  time: 1.301794 s d_loss: 0.50853741, g_loss: 992.60797119 -- mean_d_loss: 1.42278242, mean_g_loss: 1022.02142334\n",
            "Epoch:  99 Step:    25  time: 1.287103 s d_loss: 0.55354267, g_loss: 909.77746582 -- mean_d_loss: 1.41312420, mean_g_loss: 1020.77429199\n",
            "Epoch:  99 Step:    26  time: 1.282138 s d_loss: 0.96748912, g_loss: 1030.35986328 -- mean_d_loss: 1.40822709, mean_g_loss: 1020.87963867\n",
            "Epoch:  99 Step:    27  time: 1.299597 s d_loss: 0.81988001, g_loss: 1091.51696777 -- mean_d_loss: 1.40183210, mean_g_loss: 1021.64739990\n",
            "Epoch:  99 Step:    28  time: 1.314666 s d_loss: 0.60283118, g_loss: 959.20715332 -- mean_d_loss: 1.39324069, mean_g_loss: 1020.97607422\n",
            "Epoch:  99 Step:    29  time: 1.328797 s d_loss: 2.20521450, g_loss: 1014.26501465 -- mean_d_loss: 1.40187871, mean_g_loss: 1020.90466309\n",
            "Epoch:  99 Step:    30  time: 1.318254 s d_loss: 0.60185319, g_loss: 932.39648438 -- mean_d_loss: 1.39345729, mean_g_loss: 1019.97302246\n",
            "Epoch:  99 Step:    31  time: 1.295887 s d_loss: 0.76476264, g_loss: 1037.80517578 -- mean_d_loss: 1.38690841, mean_g_loss: 1020.15875244\n",
            "Epoch:  99 Step:    32  time: 1.318280 s d_loss: 0.58540618, g_loss: 1015.04589844 -- mean_d_loss: 1.37864542, mean_g_loss: 1020.10607910\n",
            "Epoch:  99 Step:    33  time: 1.323833 s d_loss: 1.00197494, g_loss: 1059.64501953 -- mean_d_loss: 1.37480175, mean_g_loss: 1020.50958252\n",
            "Epoch:  99 Step:    34  time: 1.292472 s d_loss: 0.61556530, g_loss: 946.64111328 -- mean_d_loss: 1.36713278, mean_g_loss: 1019.76342773\n",
            "Epoch:  99 Step:    35  time: 1.314496 s d_loss: 5.66936302, g_loss: 1114.83007812 -- mean_d_loss: 1.41015506, mean_g_loss: 1020.71405029\n",
            "Epoch:  99 Step:    36  time: 1.289032 s d_loss: 1.78808653, g_loss: 950.13061523 -- mean_d_loss: 1.41389692, mean_g_loss: 1020.01525879\n",
            "Epoch:  99 Step:    37  time: 1.277493 s d_loss: 1.00908053, g_loss: 956.71099854 -- mean_d_loss: 1.40992808, mean_g_loss: 1019.39459229\n",
            "Epoch:  99 Step:    38  time: 1.308336 s d_loss: 0.81489968, g_loss: 1004.04425049 -- mean_d_loss: 1.40415108, mean_g_loss: 1019.24560547\n",
            "Epoch:  99 Step:    39  time: 1.314331 s d_loss: 0.73844248, g_loss: 962.33020020 -- mean_d_loss: 1.39775014, mean_g_loss: 1018.69830322\n",
            "Epoch:  99 Step:    40  time: 1.302180 s d_loss: 0.52917123, g_loss: 912.18347168 -- mean_d_loss: 1.38947797, mean_g_loss: 1017.68383789\n",
            "Epoch:  99 Step:    41  time: 1.301829 s d_loss: 2.10322714, g_loss: 1050.36254883 -- mean_d_loss: 1.39621139, mean_g_loss: 1017.99212646\n",
            "Epoch:  99 Step:    42  time: 1.318233 s d_loss: 1.09386277, g_loss: 956.87121582 -- mean_d_loss: 1.39338565, mean_g_loss: 1017.42089844\n",
            "Epoch:  99 Step:    43  time: 1.281282 s d_loss: 1.02790964, g_loss: 1028.81579590 -- mean_d_loss: 1.39000165, mean_g_loss: 1017.52642822\n",
            "Epoch:  99 Step:    44  time: 1.288994 s d_loss: 0.83888489, g_loss: 936.64343262 -- mean_d_loss: 1.38494551, mean_g_loss: 1016.78430176\n",
            "Epoch:  99 Step:    45  time: 1.311810 s d_loss: 1.01965058, g_loss: 907.15454102 -- mean_d_loss: 1.38162470, mean_g_loss: 1015.78771973\n",
            "Epoch:  99 Step:    46  time: 1.277398 s d_loss: 0.79602069, g_loss: 971.42321777 -- mean_d_loss: 1.37634897, mean_g_loss: 1015.38800049\n",
            "Epoch:  99 Step:    47  time: 1.309152 s d_loss: 0.88689238, g_loss: 1069.00573730 -- mean_d_loss: 1.37197876, mean_g_loss: 1015.86676025\n",
            "Epoch:  99 Step:    48  time: 1.304575 s d_loss: 0.64486361, g_loss: 867.63342285 -- mean_d_loss: 1.36554420, mean_g_loss: 1014.55499268\n",
            "Epoch:  99 Step:    49  time: 1.301093 s d_loss: 0.49837434, g_loss: 1007.63085938 -- mean_d_loss: 1.35793734, mean_g_loss: 1014.49426270\n",
            "Epoch:  99 Step:    50  time: 1.308913 s d_loss: 0.92051893, g_loss: 1053.79785156 -- mean_d_loss: 1.35413373, mean_g_loss: 1014.83599854\n",
            "Epoch:  99 Step:    51  time: 1.299700 s d_loss: 6.70893669, g_loss: 1043.23718262 -- mean_d_loss: 1.40029573, mean_g_loss: 1015.08081055\n",
            "Epoch:  99 Step:    52  time: 1.327793 s d_loss: 0.91058385, g_loss: 1180.58935547 -- mean_d_loss: 1.39611018, mean_g_loss: 1016.49542236\n",
            "Epoch:  99 Step:    53  time: 1.297925 s d_loss: 0.99638009, g_loss: 869.55249023 -- mean_d_loss: 1.39272273, mean_g_loss: 1015.25012207\n",
            "Epoch:  99 Step:    54  time: 1.300148 s d_loss: 0.71180350, g_loss: 863.13739014 -- mean_d_loss: 1.38700068, mean_g_loss: 1013.97192383\n",
            "Epoch:  99 Step:    55  time: 1.297883 s d_loss: 1.09318030, g_loss: 1031.37377930 -- mean_d_loss: 1.38455224, mean_g_loss: 1014.11694336\n",
            "Epoch:  99 Step:    56  time: 1.318174 s d_loss: 0.96728271, g_loss: 946.98468018 -- mean_d_loss: 1.38110375, mean_g_loss: 1013.56213379\n",
            "Epoch:  99 Step:    57  time: 1.294305 s d_loss: 0.81061959, g_loss: 1054.83544922 -- mean_d_loss: 1.37642765, mean_g_loss: 1013.90045166\n",
            "Epoch:  99 Step:    58  time: 1.324702 s d_loss: 1.02882469, g_loss: 993.05224609 -- mean_d_loss: 1.37360168, mean_g_loss: 1013.73095703\n",
            "Epoch:  99 Step:    59  time: 1.312570 s d_loss: 0.53861398, g_loss: 975.90008545 -- mean_d_loss: 1.36686790, mean_g_loss: 1013.42584229\n",
            "Epoch:  99 Step:    60  time: 1.326415 s d_loss: 0.47862178, g_loss: 925.16406250 -- mean_d_loss: 1.35976195, mean_g_loss: 1012.71972656\n",
            "Epoch:  99 Step:    61  time: 1.300872 s d_loss: 0.45553401, g_loss: 1051.16174316 -- mean_d_loss: 1.35258555, mean_g_loss: 1013.02484131\n",
            "Epoch:  99 Step:    62  time: 1.296826 s d_loss: 0.56863749, g_loss: 888.61132812 -- mean_d_loss: 1.34641278, mean_g_loss: 1012.04522705\n",
            "Epoch:  99 Step:    63  time: 1.328008 s d_loss: 0.69661450, g_loss: 1156.89282227 -- mean_d_loss: 1.34133613, mean_g_loss: 1013.17681885\n",
            "Epoch:  99 Step:    64  time: 1.353884 s d_loss: 0.47164327, g_loss: 930.87426758 -- mean_d_loss: 1.33459437, mean_g_loss: 1012.53881836\n",
            "Epoch:  99 Step:    65  time: 1.328776 s d_loss: 0.50124270, g_loss: 952.98974609 -- mean_d_loss: 1.32818389, mean_g_loss: 1012.08074951\n",
            "Epoch:  99 Step:    66  time: 1.323207 s d_loss: 0.55376184, g_loss: 1144.30175781 -- mean_d_loss: 1.32227230, mean_g_loss: 1013.09002686\n",
            "Epoch:  99 Step:    67  time: 1.331047 s d_loss: 0.58861983, g_loss: 1010.88061523 -- mean_d_loss: 1.31671429, mean_g_loss: 1013.07324219\n",
            "Epoch:  99 Step:    68  time: 1.310180 s d_loss: 0.63651979, g_loss: 900.20129395 -- mean_d_loss: 1.31160009, mean_g_loss: 1012.22460938\n",
            "Epoch:  99 Step:    69  time: 1.303196 s d_loss: 0.75989294, g_loss: 1041.62707520 -- mean_d_loss: 1.30748284, mean_g_loss: 1012.44403076\n",
            "Epoch:  99 Step:    70  time: 1.300931 s d_loss: 0.71227753, g_loss: 1119.93615723 -- mean_d_loss: 1.30307388, mean_g_loss: 1013.24029541\n",
            "Epoch:  99 Step:    71  time: 1.297684 s d_loss: 1.32560194, g_loss: 1022.93554688 -- mean_d_loss: 1.30323958, mean_g_loss: 1013.31158447\n",
            "Epoch:  99 Step:    72  time: 1.342492 s d_loss: 0.56551480, g_loss: 881.21575928 -- mean_d_loss: 1.29785478, mean_g_loss: 1012.34741211\n",
            "Epoch:  99 Step:    73  time: 1.298812 s d_loss: 0.57752806, g_loss: 1017.24377441 -- mean_d_loss: 1.29263508, mean_g_loss: 1012.38293457\n",
            "Epoch:  99 Step:    74  time: 1.308210 s d_loss: 0.99212486, g_loss: 1060.82250977 -- mean_d_loss: 1.29047310, mean_g_loss: 1012.73144531\n",
            "Epoch:  99 Step:    75  time: 1.337600 s d_loss: 1.32687140, g_loss: 982.47888184 -- mean_d_loss: 1.29073310, mean_g_loss: 1012.51538086\n",
            "Epoch:  99 Step:    76  time: 1.327284 s d_loss: 0.87309682, g_loss: 1198.85107422 -- mean_d_loss: 1.28777111, mean_g_loss: 1013.83685303\n",
            "Epoch:  99 Step:    77  time: 1.317704 s d_loss: 0.65459162, g_loss: 1040.85351562 -- mean_d_loss: 1.28331208, mean_g_loss: 1014.02716064\n",
            "Epoch:  99 Step:    78  time: 1.331184 s d_loss: 0.48794103, g_loss: 1030.14477539 -- mean_d_loss: 1.27775013, mean_g_loss: 1014.13983154\n",
            "Epoch:  99 Step:    79  time: 1.313474 s d_loss: 1.77850866, g_loss: 1141.76354980 -- mean_d_loss: 1.28122759, mean_g_loss: 1015.02612305\n",
            "Epoch:  99 Step:    80  time: 1.330637 s d_loss: 0.70302033, g_loss: 945.76129150 -- mean_d_loss: 1.27723992, mean_g_loss: 1014.54846191\n",
            "Epoch:  99 Step:    81  time: 1.307607 s d_loss: 0.79941940, g_loss: 1000.07037354 -- mean_d_loss: 1.27396715, mean_g_loss: 1014.44940186\n",
            "Epoch:  99 Step:    82  time: 1.331565 s d_loss: 8.79577065, g_loss: 1068.97888184 -- mean_d_loss: 1.32513595, mean_g_loss: 1014.82037354\n",
            "Epoch:  99 Step:    83  time: 1.334556 s d_loss: 1.16711903, g_loss: 1009.42797852 -- mean_d_loss: 1.32406819, mean_g_loss: 1014.78387451\n",
            "Epoch:  99 Step:    84  time: 1.312215 s d_loss: 1.51061034, g_loss: 1147.93127441 -- mean_d_loss: 1.32532012, mean_g_loss: 1015.67755127\n",
            "Epoch:  99 Step:    85  time: 1.321738 s d_loss: 1.17997420, g_loss: 933.48144531 -- mean_d_loss: 1.32435119, mean_g_loss: 1015.12957764\n",
            "Epoch:  99 Step:    86  time: 1.307326 s d_loss: 0.73839653, g_loss: 1130.01391602 -- mean_d_loss: 1.32047069, mean_g_loss: 1015.89044189\n",
            "Epoch:  99 Step:    87  time: 1.323377 s d_loss: 1.37206876, g_loss: 983.36499023 -- mean_d_loss: 1.32081020, mean_g_loss: 1015.67639160\n",
            "Epoch:  99 Step:    88  time: 1.345029 s d_loss: 2.89736629, g_loss: 983.26647949 -- mean_d_loss: 1.33111453, mean_g_loss: 1015.46453857\n",
            "Epoch:  99 Step:    89  time: 1.326024 s d_loss: 1.33373690, g_loss: 1218.86547852 -- mean_d_loss: 1.33113158, mean_g_loss: 1016.78527832\n",
            "Epoch:  99 Step:    90  time: 1.301423 s d_loss: 1.39041591, g_loss: 1184.96484375 -- mean_d_loss: 1.33151400, mean_g_loss: 1017.87036133\n",
            "Epoch:  99 Step:    91  time: 1.326476 s d_loss: 1.05513430, g_loss: 1041.94238281 -- mean_d_loss: 1.32974231, mean_g_loss: 1018.02465820\n",
            "Epoch:  99 Step:    92  time: 1.298206 s d_loss: 4.58239031, g_loss: 961.47088623 -- mean_d_loss: 1.35045993, mean_g_loss: 1017.66442871\n",
            "Epoch:  99 Step:    93  time: 1.306969 s d_loss: 0.64402103, g_loss: 840.83807373 -- mean_d_loss: 1.34598875, mean_g_loss: 1016.54528809\n",
            "Epoch:  99 Step:    94  time: 1.331537 s d_loss: 0.54307342, g_loss: 993.19464111 -- mean_d_loss: 1.34093904, mean_g_loss: 1016.39837646\n",
            "Epoch:  99 Step:    95  time: 1.345594 s d_loss: 0.69818747, g_loss: 1051.94799805 -- mean_d_loss: 1.33692181, mean_g_loss: 1016.62060547\n",
            "Epoch:  99 Step:    96  time: 1.310499 s d_loss: 0.59877717, g_loss: 1150.73425293 -- mean_d_loss: 1.33233702, mean_g_loss: 1017.45361328\n",
            "Epoch:  99 Step:    97  time: 1.324889 s d_loss: 0.63322192, g_loss: 1015.48547363 -- mean_d_loss: 1.32802153, mean_g_loss: 1017.44146729\n",
            "Epoch:  99 Step:    98  time: 1.308656 s d_loss: 0.73470938, g_loss: 1144.19628906 -- mean_d_loss: 1.32438159, mean_g_loss: 1018.21911621\n",
            "Epoch:  99 Step:    99  time: 1.313673 s d_loss: 1.14936280, g_loss: 1015.45306396 -- mean_d_loss: 1.32331443, mean_g_loss: 1018.20227051\n",
            "Epoch:  99 Step:   100  time: 1.285127 s d_loss: 0.55547756, g_loss: 890.54943848 -- mean_d_loss: 1.31866086, mean_g_loss: 1017.42858887\n",
            "Epoch:  99 Step:   101  time: 1.320396 s d_loss: 0.72075939, g_loss: 1107.07641602 -- mean_d_loss: 1.31505907, mean_g_loss: 1017.96862793\n",
            "Epoch:  99 Step:   102  time: 1.297936 s d_loss: 0.52568972, g_loss: 868.41723633 -- mean_d_loss: 1.31033230, mean_g_loss: 1017.07318115\n",
            "Epoch:  99 Step:   103  time: 1.304651 s d_loss: 0.54089463, g_loss: 947.91467285 -- mean_d_loss: 1.30575240, mean_g_loss: 1016.66156006\n",
            "Epoch:  99 Step:   104  time: 1.299574 s d_loss: 0.75888622, g_loss: 794.54382324 -- mean_d_loss: 1.30251646, mean_g_loss: 1015.34729004\n",
            "Epoch:  99 Step:   105  time: 1.341739 s d_loss: 0.56220782, g_loss: 1184.11840820 -- mean_d_loss: 1.29816163, mean_g_loss: 1016.34008789\n",
            "Epoch:  99 Step:   106  time: 1.303841 s d_loss: 48.97131729, g_loss: 868.24865723 -- mean_d_loss: 1.57695210, mean_g_loss: 1015.47406006\n",
            "Epoch:  99 Step:   107  time: 1.329633 s d_loss: 1.63640535, g_loss: 1155.29614258 -- mean_d_loss: 1.57729781, mean_g_loss: 1016.28698730\n",
            "Epoch:  99 Step:   108  time: 1.292148 s d_loss: 1.96264362, g_loss: 887.76110840 -- mean_d_loss: 1.57952523, mean_g_loss: 1015.54406738\n",
            "Epoch:  99 Step:   109  time: 1.283158 s d_loss: 1.65124512, g_loss: 939.36517334 -- mean_d_loss: 1.57993746, mean_g_loss: 1015.10626221\n",
            "Epoch:  99 Step:   110  time: 1.297762 s d_loss: 1.02360475, g_loss: 1046.25903320 -- mean_d_loss: 1.57675838, mean_g_loss: 1015.28430176\n",
            "Epoch:  99 Step:   111  time: 1.324648 s d_loss: 4.97478437, g_loss: 1024.07116699 -- mean_d_loss: 1.59606540, mean_g_loss: 1015.33422852\n",
            "Epoch:  99 Step:   112  time: 1.290175 s d_loss: 0.75848609, g_loss: 919.93267822 -- mean_d_loss: 1.59133327, mean_g_loss: 1014.79528809\n",
            "Epoch:  99 Step:   113  time: 1.319380 s d_loss: 3.00282049, g_loss: 877.52416992 -- mean_d_loss: 1.59926283, mean_g_loss: 1014.02416992\n",
            "Epoch:  99 Step:   114  time: 1.306145 s d_loss: 2.96900845, g_loss: 1102.74511719 -- mean_d_loss: 1.60691500, mean_g_loss: 1014.51983643\n",
            "Epoch:  99 Step:   115  time: 1.292297 s d_loss: 0.77626300, g_loss: 1009.93048096 -- mean_d_loss: 1.60230041, mean_g_loss: 1014.49438477\n",
            "Epoch:  99 Step:   116  time: 1.295640 s d_loss: 0.79283166, g_loss: 1213.18798828 -- mean_d_loss: 1.59782827, mean_g_loss: 1015.59210205\n",
            "Epoch:  99 Step:   117  time: 1.325320 s d_loss: 34.54148865, g_loss: 815.16461182 -- mean_d_loss: 1.77883744, mean_g_loss: 1014.49090576\n",
            "Epoch:  99 Step:   118  time: 1.308451 s d_loss: 1.40060639, g_loss: 892.82122803 -- mean_d_loss: 1.77677059, mean_g_loss: 1013.82604980\n",
            "Epoch:  99 Step:   119  time: 1.301113 s d_loss: 1.06071186, g_loss: 970.42340088 -- mean_d_loss: 1.77287889, mean_g_loss: 1013.59020996\n",
            "Epoch:  99 Step:   120  time: 1.361995 s d_loss: 5.35398483, g_loss: 1001.12011719 -- mean_d_loss: 1.79223621, mean_g_loss: 1013.52282715\n",
            "Epoch:  99 Step:   121  time: 1.323698 s d_loss: 0.94001925, g_loss: 1034.52734375 -- mean_d_loss: 1.78765440, mean_g_loss: 1013.63574219\n",
            "Epoch:  99 Step:   122  time: 1.299789 s d_loss: 1.44012868, g_loss: 1231.93017578 -- mean_d_loss: 1.78579593, mean_g_loss: 1014.80316162\n",
            "Epoch:  99 Step:   123  time: 1.282517 s d_loss: 2.25898480, g_loss: 1061.34790039 -- mean_d_loss: 1.78831291, mean_g_loss: 1015.05072021\n",
            "Epoch:  99 Step:   124  time: 1.328375 s d_loss: 0.84402251, g_loss: 1095.77636719 -- mean_d_loss: 1.78331661, mean_g_loss: 1015.47784424\n",
            "Epoch:  99 Step:   125  time: 1.324036 s d_loss: 0.90207106, g_loss: 874.59039307 -- mean_d_loss: 1.77867854, mean_g_loss: 1014.73632812\n",
            "Epoch:  99 Step:   126  time: 1.287795 s d_loss: 1.14766669, g_loss: 1031.75207520 -- mean_d_loss: 1.77537477, mean_g_loss: 1014.82543945\n",
            "Epoch:  99 Step:   127  time: 1.314245 s d_loss: 1.31411195, g_loss: 983.02185059 -- mean_d_loss: 1.77297246, mean_g_loss: 1014.65972900\n",
            "Epoch:  99 Step:   128  time: 1.297093 s d_loss: 1.28382707, g_loss: 1046.75854492 -- mean_d_loss: 1.77043796, mean_g_loss: 1014.82611084\n",
            "Epoch:  99 Step:   129  time: 1.316105 s d_loss: 1.14274347, g_loss: 980.59008789 -- mean_d_loss: 1.76720238, mean_g_loss: 1014.64965820\n",
            "Epoch:  99 Step:   130  time: 1.325288 s d_loss: 1.55011392, g_loss: 924.14135742 -- mean_d_loss: 1.76608908, mean_g_loss: 1014.18548584\n",
            "Epoch:  99 Step:   131  time: 1.318945 s d_loss: 0.74960524, g_loss: 1107.42163086 -- mean_d_loss: 1.76090288, mean_g_loss: 1014.66119385\n",
            "Epoch:  99 Step:   132  time: 1.329957 s d_loss: 1.11156809, g_loss: 923.20751953 -- mean_d_loss: 1.75760674, mean_g_loss: 1014.19696045\n",
            "Epoch:  99 Step:   133  time: 1.298348 s d_loss: 0.71836233, g_loss: 1007.05505371 -- mean_d_loss: 1.75235808, mean_g_loss: 1014.16088867\n",
            "Epoch:  99 Step:   134  time: 1.300664 s d_loss: 1.54402673, g_loss: 1214.97558594 -- mean_d_loss: 1.75131118, mean_g_loss: 1015.16998291\n",
            "Epoch:  99 Step:   135  time: 1.292605 s d_loss: 0.73130101, g_loss: 1022.50659180 -- mean_d_loss: 1.74621105, mean_g_loss: 1015.20666504\n",
            "Epoch:  99 Step:   136  time: 1.315116 s d_loss: 0.68420750, g_loss: 970.00695801 -- mean_d_loss: 1.74092746, mean_g_loss: 1014.98175049\n",
            "Epoch:  99 Step:   137  time: 1.321419 s d_loss: 0.79192871, g_loss: 905.10687256 -- mean_d_loss: 1.73622942, mean_g_loss: 1014.43780518\n",
            "Epoch:  99 Step:   138  time: 1.307466 s d_loss: 0.85706657, g_loss: 1146.04577637 -- mean_d_loss: 1.73189855, mean_g_loss: 1015.08612061\n",
            "Epoch:  99 Step:   139  time: 1.312732 s d_loss: 0.80273020, g_loss: 1015.37280273 -- mean_d_loss: 1.72734380, mean_g_loss: 1015.08752441\n",
            "Epoch:  99 Step:   140  time: 1.314484 s d_loss: 0.73472768, g_loss: 1105.87670898 -- mean_d_loss: 1.72250187, mean_g_loss: 1015.53039551\n",
            "Epoch:  99 Step:   141  time: 1.316525 s d_loss: 0.78349310, g_loss: 1086.91467285 -- mean_d_loss: 1.71794367, mean_g_loss: 1015.87695312\n",
            "Epoch:  99 Step:   142  time: 1.322652 s d_loss: 0.79317093, g_loss: 888.83508301 -- mean_d_loss: 1.71347618, mean_g_loss: 1015.26318359\n",
            "Epoch:  99 Step:   143  time: 1.302583 s d_loss: 0.71507317, g_loss: 1062.47668457 -- mean_d_loss: 1.70867622, mean_g_loss: 1015.49023438\n",
            "Epoch:  99 Step:   144  time: 1.313396 s d_loss: 0.67196327, g_loss: 1151.88342285 -- mean_d_loss: 1.70371592, mean_g_loss: 1016.14288330\n",
            "Epoch:  99 Step:   145  time: 1.279816 s d_loss: 0.54187721, g_loss: 1029.65112305 -- mean_d_loss: 1.69818330, mean_g_loss: 1016.20721436\n",
            "Epoch:  99 Step:   146  time: 1.298798 s d_loss: 1.36803854, g_loss: 949.14904785 -- mean_d_loss: 1.69661868, mean_g_loss: 1015.88946533\n",
            "Epoch:  99 Step:   147  time: 1.322591 s d_loss: 0.62393844, g_loss: 1031.84704590 -- mean_d_loss: 1.69155884, mean_g_loss: 1015.96472168\n",
            "Epoch:  99 Step:   148  time: 1.316599 s d_loss: 0.86898786, g_loss: 954.02581787 -- mean_d_loss: 1.68769705, mean_g_loss: 1015.67395020\n",
            "Epoch:  99 Step:   149  time: 1.315903 s d_loss: 0.78875852, g_loss: 835.35144043 -- mean_d_loss: 1.68349636, mean_g_loss: 1014.83123779\n",
            "Epoch:  99 Step:   150  time: 1.341714 s d_loss: 0.74896908, g_loss: 1006.56469727 -- mean_d_loss: 1.67914963, mean_g_loss: 1014.79278564\n",
            "Epoch:  99 Step:   151  time: 1.320253 s d_loss: 0.62606418, g_loss: 971.45397949 -- mean_d_loss: 1.67427433, mean_g_loss: 1014.59216309\n",
            "Epoch:  99 Step:   152  time: 1.328158 s d_loss: 0.78829139, g_loss: 979.59399414 -- mean_d_loss: 1.67019153, mean_g_loss: 1014.43084717\n",
            "Epoch:  99 Step:   153  time: 1.318591 s d_loss: 0.54484856, g_loss: 949.54943848 -- mean_d_loss: 1.66502941, mean_g_loss: 1014.13323975\n",
            "Epoch:  99 Step:   154  time: 1.315907 s d_loss: 0.68404001, g_loss: 1169.66992188 -- mean_d_loss: 1.66055000, mean_g_loss: 1014.84344482\n",
            "Epoch:  99 Step:   155  time: 1.318816 s d_loss: 0.60062009, g_loss: 1064.73754883 -- mean_d_loss: 1.65573215, mean_g_loss: 1015.07025146\n",
            "Epoch:  99 Step:   156  time: 1.314784 s d_loss: 0.93644929, g_loss: 1014.86157227 -- mean_d_loss: 1.65247750, mean_g_loss: 1015.06927490\n",
            "Epoch:  99 Step:   157  time: 1.315145 s d_loss: 0.77049947, g_loss: 1078.31347656 -- mean_d_loss: 1.64850473, mean_g_loss: 1015.35418701\n",
            "Epoch:  99 Step:   158  time: 1.319176 s d_loss: 0.97675335, g_loss: 1078.24365234 -- mean_d_loss: 1.64549232, mean_g_loss: 1015.63623047\n",
            "Epoch:  99 Step:   159  time: 1.318683 s d_loss: 1.03164232, g_loss: 984.77832031 -- mean_d_loss: 1.64275193, mean_g_loss: 1015.49847412\n",
            "Epoch:  99 Step:   160  time: 1.296276 s d_loss: 0.79205149, g_loss: 1068.07958984 -- mean_d_loss: 1.63897109, mean_g_loss: 1015.73217773\n",
            "Epoch:  99 Step:   161  time: 1.294344 s d_loss: 0.73895240, g_loss: 1009.04553223 -- mean_d_loss: 1.63498867, mean_g_loss: 1015.70257568\n",
            "Epoch:  99 Step:   162  time: 1.314062 s d_loss: 0.63624948, g_loss: 1099.22363281 -- mean_d_loss: 1.63058901, mean_g_loss: 1016.07049561\n",
            "Epoch:  99 Step:   163  time: 1.299992 s d_loss: 0.63594306, g_loss: 1056.31762695 -- mean_d_loss: 1.62622654, mean_g_loss: 1016.24700928\n",
            "Epoch:  99 Step:   164  time: 1.293966 s d_loss: 0.96756411, g_loss: 974.19665527 -- mean_d_loss: 1.62335026, mean_g_loss: 1016.06341553\n",
            "Epoch:  99 Step:   165  time: 1.320983 s d_loss: 0.57250792, g_loss: 1096.22082520 -- mean_d_loss: 1.61878145, mean_g_loss: 1016.41186523\n",
            "Epoch:  99 Step:   166  time: 1.331622 s d_loss: 25.98390961, g_loss: 1024.58276367 -- mean_d_loss: 1.72425818, mean_g_loss: 1016.44726562\n",
            "Epoch:  99 Step:   167  time: 1.314049 s d_loss: 1.16073942, g_loss: 965.68164062 -- mean_d_loss: 1.72182930, mean_g_loss: 1016.22845459\n",
            "Epoch:  99 Step:   168  time: 1.337448 s d_loss: 1.06475806, g_loss: 1117.52673340 -- mean_d_loss: 1.71900916, mean_g_loss: 1016.66320801\n",
            "Epoch:  99 Step:   169  time: 1.306023 s d_loss: 0.87018818, g_loss: 996.82348633 -- mean_d_loss: 1.71538174, mean_g_loss: 1016.57843018\n",
            "Epoch:  99 Step:   170  time: 1.317441 s d_loss: 0.77382189, g_loss: 1064.69848633 -- mean_d_loss: 1.71137512, mean_g_loss: 1016.78326416\n",
            "Epoch:  99 Step:   171  time: 1.326864 s d_loss: 7.26832104, g_loss: 1106.91357422 -- mean_d_loss: 1.73492146, mean_g_loss: 1017.16510010\n",
            "Epoch:  99 Step:   172  time: 1.319366 s d_loss: 0.93196034, g_loss: 1077.51538086 -- mean_d_loss: 1.73153341, mean_g_loss: 1017.41973877\n",
            "Epoch:  99 Step:   173  time: 1.292211 s d_loss: 0.92897534, g_loss: 1124.55712891 -- mean_d_loss: 1.72816133, mean_g_loss: 1017.86993408\n",
            "Epoch:  99 Step:   174  time: 1.319091 s d_loss: 0.68651396, g_loss: 906.70812988 -- mean_d_loss: 1.72380304, mean_g_loss: 1017.40478516\n",
            "Epoch:  99 Step:   175  time: 1.340303 s d_loss: 1.19234097, g_loss: 990.37475586 -- mean_d_loss: 1.72158861, mean_g_loss: 1017.29217529\n",
            "Epoch:  99 Step:   176  time: 1.311728 s d_loss: 0.73219150, g_loss: 941.43029785 -- mean_d_loss: 1.71748316, mean_g_loss: 1016.97741699\n",
            "Epoch:  99 Step:   177  time: 1.300390 s d_loss: 0.94217831, g_loss: 1014.98413086 -- mean_d_loss: 1.71427941, mean_g_loss: 1016.96917725\n",
            "Epoch:  99 Step:   178  time: 1.289778 s d_loss: 0.61788982, g_loss: 989.68640137 -- mean_d_loss: 1.70976758, mean_g_loss: 1016.85693359\n",
            "Epoch:  99 Step:   179  time: 1.326841 s d_loss: 0.75200409, g_loss: 1284.77575684 -- mean_d_loss: 1.70584226, mean_g_loss: 1017.95495605\n",
            "Epoch:  99 Step:   180  time: 1.328635 s d_loss: 0.70587516, g_loss: 910.34863281 -- mean_d_loss: 1.70176077, mean_g_loss: 1017.51574707\n",
            "Epoch:  99 Step:   181  time: 1.336767 s d_loss: 0.44325426, g_loss: 1068.83129883 -- mean_d_loss: 1.69664502, mean_g_loss: 1017.72436523\n",
            "Epoch:  99 Step:   182  time: 1.317652 s d_loss: 0.61049873, g_loss: 941.30151367 -- mean_d_loss: 1.69224763, mean_g_loss: 1017.41491699\n",
            "Epoch:  99 Step:   183  time: 1.320556 s d_loss: 0.70407343, g_loss: 1103.12573242 -- mean_d_loss: 1.68826306, mean_g_loss: 1017.76049805\n",
            "Epoch:  99 Step:   184  time: 1.317212 s d_loss: 1.65561903, g_loss: 1010.24523926 -- mean_d_loss: 1.68813193, mean_g_loss: 1017.73034668\n",
            "Epoch:  99 Step:   185  time: 1.295706 s d_loss: 0.52896100, g_loss: 939.21838379 -- mean_d_loss: 1.68349528, mean_g_loss: 1017.41632080\n",
            "Epoch:  99 Step:   186  time: 1.309518 s d_loss: 0.53463089, g_loss: 983.15148926 -- mean_d_loss: 1.67891812, mean_g_loss: 1017.27984619\n",
            "Epoch:  99 Step:   187  time: 1.289255 s d_loss: 0.45893145, g_loss: 1018.90325928 -- mean_d_loss: 1.67407691, mean_g_loss: 1017.28625488\n",
            "Epoch:  99 Step:   188  time: 1.342782 s d_loss: 0.58216143, g_loss: 1240.75988770 -- mean_d_loss: 1.66976094, mean_g_loss: 1018.16961670\n",
            "Epoch:  99 Step:   189  time: 1.315352 s d_loss: 0.47238591, g_loss: 1078.05603027 -- mean_d_loss: 1.66504693, mean_g_loss: 1018.40539551\n",
            "Epoch:  99 Step:   190  time: 1.314806 s d_loss: 0.44488135, g_loss: 937.33526611 -- mean_d_loss: 1.66026187, mean_g_loss: 1018.08746338\n",
            "Epoch:  99 Step:   191  time: 1.311420 s d_loss: 0.48747617, g_loss: 1121.81835938 -- mean_d_loss: 1.65568078, mean_g_loss: 1018.49261475\n",
            "Epoch:  99 Step:   192  time: 1.323056 s d_loss: 0.60664129, g_loss: 1113.33715820 -- mean_d_loss: 1.65159881, mean_g_loss: 1018.86169434\n",
            "Epoch:  99 Step:   193  time: 1.316470 s d_loss: 0.45727605, g_loss: 964.75933838 -- mean_d_loss: 1.64696968, mean_g_loss: 1018.65203857\n",
            "Epoch:  99 Step:   194  time: 1.284508 s d_loss: 4.73287582, g_loss: 1092.05249023 -- mean_d_loss: 1.65888441, mean_g_loss: 1018.93542480\n",
            "Epoch:  99 Step:   195  time: 1.298146 s d_loss: 0.60327882, g_loss: 1129.17480469 -- mean_d_loss: 1.65482438, mean_g_loss: 1019.35949707\n",
            "Epoch:  99 Step:   196  time: 1.286991 s d_loss: 0.62631077, g_loss: 1055.80590820 -- mean_d_loss: 1.65088367, mean_g_loss: 1019.49914551\n",
            "Epoch:  99 Step:   197  time: 1.288064 s d_loss: 0.77740544, g_loss: 1073.95336914 -- mean_d_loss: 1.64754987, mean_g_loss: 1019.70703125\n",
            "Epoch:  99 Step:   198  time: 1.300010 s d_loss: 0.57423836, g_loss: 1057.89892578 -- mean_d_loss: 1.64346886, mean_g_loss: 1019.85229492\n",
            "Epoch:  99 Step:   199  time: 1.306474 s d_loss: 0.47249982, g_loss: 1141.61535645 -- mean_d_loss: 1.63903332, mean_g_loss: 1020.31353760\n",
            "Epoch:  99 Step:   200  time: 1.304568 s d_loss: 0.63646597, g_loss: 1113.55151367 -- mean_d_loss: 0.63646597, mean_g_loss: 1113.55151367\n",
            "Epoch:  99 Step:   201  time: 1.302031 s d_loss: 0.35658541, g_loss: 990.08178711 -- mean_d_loss: 0.49652570, mean_g_loss: 1051.81665039\n",
            "Epoch:  99 Step:   202  time: 1.321066 s d_loss: 0.73249263, g_loss: 909.60363770 -- mean_d_loss: 0.57518131, mean_g_loss: 1004.41229248\n",
            "Epoch:  99 Step:   203  time: 1.292690 s d_loss: 0.70961493, g_loss: 1025.97351074 -- mean_d_loss: 0.60878974, mean_g_loss: 1009.80261230\n",
            "Epoch:  99 Step:   204  time: 1.332796 s d_loss: 0.52934659, g_loss: 914.86975098 -- mean_d_loss: 0.59290111, mean_g_loss: 990.81604004\n",
            "Epoch:  99 Step:   205  time: 1.331434 s d_loss: 0.58083141, g_loss: 1007.31652832 -- mean_d_loss: 0.59088951, mean_g_loss: 993.56610107\n",
            "Epoch:  99 Step:   206  time: 1.310886 s d_loss: 0.58911496, g_loss: 930.93457031 -- mean_d_loss: 0.59063607, mean_g_loss: 984.61871338\n",
            "Epoch:  99 Step:   207  time: 1.327928 s d_loss: 0.49587104, g_loss: 990.26855469 -- mean_d_loss: 0.57879043, mean_g_loss: 985.32495117\n",
            "Epoch:  99 Step:   208  time: 1.330233 s d_loss: 0.42023852, g_loss: 976.29919434 -- mean_d_loss: 0.56117356, mean_g_loss: 984.32202148\n",
            "Epoch:  99 Step:   209  time: 1.330766 s d_loss: 0.51693064, g_loss: 989.29321289 -- mean_d_loss: 0.55674922, mean_g_loss: 984.81915283\n",
            "Epoch:  99 Step:   210  time: 1.306433 s d_loss: 0.59199232, g_loss: 856.19934082 -- mean_d_loss: 0.55995315, mean_g_loss: 973.12640381\n",
            "Epoch:  99 Step:   211  time: 1.307164 s d_loss: 0.61780661, g_loss: 1058.29565430 -- mean_d_loss: 0.56477427, mean_g_loss: 980.22387695\n",
            "Epoch:  99 Step:   212  time: 1.331232 s d_loss: 0.45688909, g_loss: 1142.64306641 -- mean_d_loss: 0.55647540, mean_g_loss: 992.71771240\n",
            "Epoch:  99 Step:   213  time: 1.323596 s d_loss: 0.54333037, g_loss: 1068.09863281 -- mean_d_loss: 0.55553645, mean_g_loss: 998.10205078\n",
            "Epoch:  99 Step:   214  time: 1.294999 s d_loss: 0.44896489, g_loss: 894.64678955 -- mean_d_loss: 0.54843169, mean_g_loss: 991.20501709\n",
            "Epoch:  99 Step:   215  time: 1.317175 s d_loss: 0.41917911, g_loss: 853.93011475 -- mean_d_loss: 0.54035342, mean_g_loss: 982.62530518\n",
            "Epoch:  99 Step:   216  time: 1.321117 s d_loss: 0.54610580, g_loss: 975.67352295 -- mean_d_loss: 0.54069179, mean_g_loss: 982.21630859\n",
            "Epoch:  99 Step:   217  time: 1.326436 s d_loss: 0.41184187, g_loss: 958.01531982 -- mean_d_loss: 0.53353339, mean_g_loss: 980.87182617\n",
            "Epoch:  99 Step:   218  time: 1.312039 s d_loss: 0.76408064, g_loss: 1009.44836426 -- mean_d_loss: 0.54566747, mean_g_loss: 982.37591553\n",
            "Epoch:  99 Step:   219  time: 1.323639 s d_loss: 0.94504541, g_loss: 1005.34741211 -- mean_d_loss: 0.56563640, mean_g_loss: 983.52453613\n",
            "Epoch:  99 Step:   220  time: 1.288422 s d_loss: 0.51889920, g_loss: 1014.54064941 -- mean_d_loss: 0.56341082, mean_g_loss: 985.00146484\n",
            "Epoch:  99 Step:   221  time: 1.319577 s d_loss: 0.56374782, g_loss: 1025.59228516 -- mean_d_loss: 0.56342608, mean_g_loss: 986.84649658\n",
            "Epoch:  99 Step:   222  time: 1.289829 s d_loss: 1.08855999, g_loss: 903.08374023 -- mean_d_loss: 0.58625799, mean_g_loss: 983.20465088\n",
            "Epoch:  99 Step:   223  time: 1.313727 s d_loss: 0.55231667, g_loss: 1038.42089844 -- mean_d_loss: 0.58484381, mean_g_loss: 985.50537109\n",
            "Epoch:  99 Step:   224  time: 1.321839 s d_loss: 0.61711103, g_loss: 938.17639160 -- mean_d_loss: 0.58613449, mean_g_loss: 983.61218262\n",
            "Epoch:  99 Step:   225  time: 1.319958 s d_loss: 0.63000369, g_loss: 1019.56872559 -- mean_d_loss: 0.58782178, mean_g_loss: 984.99511719\n",
            "Epoch:  99 Step:   226  time: 1.319071 s d_loss: 0.65068656, g_loss: 1154.58154297 -- mean_d_loss: 0.59015012, mean_g_loss: 991.27612305\n",
            "Epoch:  99 Step:   227  time: 1.327217 s d_loss: 0.66566771, g_loss: 1188.88403320 -- mean_d_loss: 0.59284717, mean_g_loss: 998.33355713\n",
            "Epoch:  99 Step:   228  time: 1.332185 s d_loss: 2.58094287, g_loss: 1132.19628906 -- mean_d_loss: 0.66140217, mean_g_loss: 1002.94946289\n",
            "Epoch:  99 Step:   229  time: 1.320621 s d_loss: 1.59370506, g_loss: 1061.61376953 -- mean_d_loss: 0.69247890, mean_g_loss: 1004.90496826\n",
            "Epoch:  99 Step:   230  time: 1.296880 s d_loss: 0.58570236, g_loss: 884.77014160 -- mean_d_loss: 0.68903452, mean_g_loss: 1001.02960205\n",
            "Epoch:  99 Step:   231  time: 1.318729 s d_loss: 0.54735738, g_loss: 1141.58703613 -- mean_d_loss: 0.68460709, mean_g_loss: 1005.42205811\n",
            "Epoch:  99 Step:   232  time: 1.288444 s d_loss: 0.50867474, g_loss: 930.15374756 -- mean_d_loss: 0.67927581, mean_g_loss: 1003.14123535\n",
            "Epoch:  99 Step:   233  time: 1.316364 s d_loss: 0.72163564, g_loss: 1048.55456543 -- mean_d_loss: 0.68052167, mean_g_loss: 1004.47692871\n",
            "Epoch:  99 Step:   234  time: 1.303258 s d_loss: 0.72357756, g_loss: 1056.39343262 -- mean_d_loss: 0.68175185, mean_g_loss: 1005.96026611\n",
            "Epoch:  99 Step:   235  time: 1.328186 s d_loss: 0.81217951, g_loss: 828.40966797 -- mean_d_loss: 0.68537486, mean_g_loss: 1001.02832031\n",
            "Epoch:  99 Step:   236  time: 1.332659 s d_loss: 0.72996283, g_loss: 968.04589844 -- mean_d_loss: 0.68657994, mean_g_loss: 1000.13690186\n",
            "Epoch:  99 Step:   237  time: 1.306753 s d_loss: 0.54486465, g_loss: 976.68041992 -- mean_d_loss: 0.68285060, mean_g_loss: 999.51965332\n",
            "Epoch:  99 Step:   238  time: 1.289070 s d_loss: 0.69064081, g_loss: 912.27954102 -- mean_d_loss: 0.68305033, mean_g_loss: 997.28277588\n",
            "Epoch:  99 Step:   239  time: 1.294362 s d_loss: 0.79527819, g_loss: 1065.66894531 -- mean_d_loss: 0.68585604, mean_g_loss: 998.99237061\n",
            "Epoch:  99 Step:   240  time: 1.314923 s d_loss: 1.49127579, g_loss: 972.87731934 -- mean_d_loss: 0.70550042, mean_g_loss: 998.35546875\n",
            "Epoch:  99 Step:   241  time: 1.316435 s d_loss: 0.72116834, g_loss: 953.87243652 -- mean_d_loss: 0.70587349, mean_g_loss: 997.29632568\n",
            "Epoch:  99 Step:   242  time: 1.324544 s d_loss: 0.48103347, g_loss: 1097.95507812 -- mean_d_loss: 0.70064467, mean_g_loss: 999.63714600\n",
            "Epoch:  99 Step:   243  time: 1.303760 s d_loss: 0.55395389, g_loss: 1075.29467773 -- mean_d_loss: 0.69731075, mean_g_loss: 1001.35662842\n",
            "Epoch:  99 Step:   244  time: 1.335114 s d_loss: 0.66991454, g_loss: 1023.70867920 -- mean_d_loss: 0.69670194, mean_g_loss: 1001.85327148\n",
            "Epoch:  99 Step:   245  time: 1.331863 s d_loss: 0.62470412, g_loss: 1087.50830078 -- mean_d_loss: 0.69513679, mean_g_loss: 1003.71533203\n",
            "Epoch:  99 Step:   246  time: 1.321925 s d_loss: 0.51919150, g_loss: 959.63684082 -- mean_d_loss: 0.69139326, mean_g_loss: 1002.77752686\n",
            "Epoch:  99 Step:   247  time: 1.294103 s d_loss: 0.46688321, g_loss: 1128.28320312 -- mean_d_loss: 0.68671602, mean_g_loss: 1005.39227295\n",
            "Epoch:  99 Step:   248  time: 1.319457 s d_loss: 0.44528899, g_loss: 1060.36401367 -- mean_d_loss: 0.68178892, mean_g_loss: 1006.51409912\n",
            "Epoch:  99 Step:   249  time: 1.291027 s d_loss: 0.57255435, g_loss: 932.60205078 -- mean_d_loss: 0.67960429, mean_g_loss: 1005.03588867\n",
            "Epoch:  99 Step:   250  time: 1.328847 s d_loss: 0.75538838, g_loss: 1051.35644531 -- mean_d_loss: 0.68109024, mean_g_loss: 1005.94409180\n",
            "Epoch:  99 Step:   251  time: 1.332609 s d_loss: 25.21920013, g_loss: 950.77783203 -- mean_d_loss: 1.15297699, mean_g_loss: 1004.88317871\n",
            "Epoch:  99 Step:   252  time: 1.313523 s d_loss: 1.53128266, g_loss: 1038.34179688 -- mean_d_loss: 1.16011488, mean_g_loss: 1005.51446533\n",
            "Epoch:  99 Step:   253  time: 1.300965 s d_loss: 1.34622967, g_loss: 930.37817383 -- mean_d_loss: 1.16356146, mean_g_loss: 1004.12304688\n",
            "Epoch:  99 Step:   254  time: 1.343871 s d_loss: 0.84729439, g_loss: 913.00268555 -- mean_d_loss: 1.15781116, mean_g_loss: 1002.46630859\n",
            "Epoch:  99 Step:   255  time: 1.325031 s d_loss: 0.69165701, g_loss: 1082.48059082 -- mean_d_loss: 1.14948690, mean_g_loss: 1003.89514160\n",
            "Epoch:  99 Step:   256  time: 1.310112 s d_loss: 0.55692220, g_loss: 959.47442627 -- mean_d_loss: 1.13909113, mean_g_loss: 1003.11584473\n",
            "Epoch:  99 Step:   257  time: 1.339212 s d_loss: 0.66639680, g_loss: 938.45013428 -- mean_d_loss: 1.13094115, mean_g_loss: 1002.00085449\n",
            "Epoch:  99 Step:   258  time: 1.314032 s d_loss: 0.49756569, g_loss: 954.27160645 -- mean_d_loss: 1.12020600, mean_g_loss: 1001.19195557\n",
            "Epoch:  99 Step:   259  time: 1.317033 s d_loss: 0.55521166, g_loss: 982.60119629 -- mean_d_loss: 1.11078954, mean_g_loss: 1000.88208008\n",
            "Epoch:  99 Step:   260  time: 1.311560 s d_loss: 0.50374210, g_loss: 930.68029785 -- mean_d_loss: 1.10083783, mean_g_loss: 999.73126221\n",
            "Epoch:  99 Step:   261  time: 1.326692 s d_loss: 0.66514057, g_loss: 943.98596191 -- mean_d_loss: 1.09381044, mean_g_loss: 998.83209229\n",
            "Epoch:  99 Step:   262  time: 1.316569 s d_loss: 0.49084771, g_loss: 904.40258789 -- mean_d_loss: 1.08423948, mean_g_loss: 997.33319092\n",
            "Epoch:  99 Step:   263  time: 1.332572 s d_loss: 0.96574861, g_loss: 1053.17163086 -- mean_d_loss: 1.08238816, mean_g_loss: 998.20568848\n",
            "Epoch:  99 Step:   264  time: 1.321034 s d_loss: 0.60248077, g_loss: 1052.22497559 -- mean_d_loss: 1.07500494, mean_g_loss: 999.03680420\n",
            "Epoch:  99 Step:   265  time: 1.294117 s d_loss: 0.66790402, g_loss: 996.24816895 -- mean_d_loss: 1.06883681, mean_g_loss: 998.99456787\n",
            "Epoch:  99 Step:   266  time: 1.291004 s d_loss: 0.57705975, g_loss: 989.17517090 -- mean_d_loss: 1.06149673, mean_g_loss: 998.84796143\n",
            "Epoch:  99 Step:   267  time: 1.347518 s d_loss: 0.56547761, g_loss: 901.36596680 -- mean_d_loss: 1.05420232, mean_g_loss: 997.41442871\n",
            "Epoch:  99 Step:   268  time: 1.303053 s d_loss: 0.56896830, g_loss: 925.78338623 -- mean_d_loss: 1.04717004, mean_g_loss: 996.37622070\n",
            "Epoch:  99 Step:   269  time: 1.323733 s d_loss: 0.68421495, g_loss: 1020.18530273 -- mean_d_loss: 1.04198492, mean_g_loss: 996.71643066\n",
            "Epoch:  99 Step:   270  time: 1.360410 s d_loss: 0.64627147, g_loss: 1187.65185547 -- mean_d_loss: 1.03641140, mean_g_loss: 999.40557861\n",
            "Epoch:  99 Step:   271  time: 1.290824 s d_loss: 0.55220860, g_loss: 934.79064941 -- mean_d_loss: 1.02968645, mean_g_loss: 998.50811768\n",
            "Epoch:  99 Step:   272  time: 1.321812 s d_loss: 0.55675948, g_loss: 969.42279053 -- mean_d_loss: 1.02320802, mean_g_loss: 998.10968018\n",
            "Epoch:  99 Step:   273  time: 1.299383 s d_loss: 2.09349036, g_loss: 926.06115723 -- mean_d_loss: 1.03767133, mean_g_loss: 997.13610840\n",
            "Epoch:  99 Step:   274  time: 1.322739 s d_loss: 0.77623683, g_loss: 924.63940430 -- mean_d_loss: 1.03418553, mean_g_loss: 996.16949463\n",
            "Epoch:  99 Step:   275  time: 1.303241 s d_loss: 0.60340959, g_loss: 992.15332031 -- mean_d_loss: 1.02851737, mean_g_loss: 996.11669922\n",
            "Epoch:  99 Step:   276  time: 1.310133 s d_loss: 0.57349098, g_loss: 919.20629883 -- mean_d_loss: 1.02260792, mean_g_loss: 995.11779785\n",
            "Epoch:  99 Step:   277  time: 1.326707 s d_loss: 0.67286301, g_loss: 1169.75048828 -- mean_d_loss: 1.01812410, mean_g_loss: 997.35668945\n",
            "Epoch:  99 Step:   278  time: 1.325666 s d_loss: 0.67635775, g_loss: 1185.93688965 -- mean_d_loss: 1.01379800, mean_g_loss: 999.74377441\n",
            "Epoch:  99 Step:   279  time: 1.324860 s d_loss: 0.88243431, g_loss: 863.86267090 -- mean_d_loss: 1.01215589, mean_g_loss: 998.04522705\n",
            "Epoch:  99 Step:   280  time: 1.312344 s d_loss: 0.94968635, g_loss: 1057.90307617 -- mean_d_loss: 1.01138461, mean_g_loss: 998.78424072\n",
            "Epoch:  99 Step:   281  time: 1.321082 s d_loss: 1.22084665, g_loss: 1214.30615234 -- mean_d_loss: 1.01393914, mean_g_loss: 1001.41253662\n",
            "Epoch:  99 Step:   282  time: 1.320641 s d_loss: 3.13931203, g_loss: 1073.47119141 -- mean_d_loss: 1.03954601, mean_g_loss: 1002.28070068\n",
            "Epoch:  99 Step:   283  time: 1.290015 s d_loss: 1.23317552, g_loss: 900.36926270 -- mean_d_loss: 1.04185116, mean_g_loss: 1001.06744385\n",
            "Epoch:  99 Step:   284  time: 1.287435 s d_loss: 1.22493613, g_loss: 1073.23120117 -- mean_d_loss: 1.04400504, mean_g_loss: 1001.91644287\n",
            "Epoch:  99 Step:   285  time: 1.324188 s d_loss: 0.86799425, g_loss: 1042.73559570 -- mean_d_loss: 1.04195845, mean_g_loss: 1002.39105225\n",
            "Epoch:  99 Step:   286  time: 1.320185 s d_loss: 0.57599336, g_loss: 915.29577637 -- mean_d_loss: 1.03660262, mean_g_loss: 1001.39001465\n",
            "Epoch:  99 Step:   287  time: 1.292282 s d_loss: 0.69053280, g_loss: 1010.07794189 -- mean_d_loss: 1.03267002, mean_g_loss: 1001.48870850\n",
            "Epoch:  99 Step:   288  time: 1.315790 s d_loss: 0.64942867, g_loss: 991.00341797 -- mean_d_loss: 1.02836394, mean_g_loss: 1001.37084961\n",
            "Epoch:  99 Step:   289  time: 1.323079 s d_loss: 0.50397879, g_loss: 879.38171387 -- mean_d_loss: 1.02253747, mean_g_loss: 1000.01544189\n",
            "Epoch:  99 Step:   290  time: 1.325537 s d_loss: 0.41023391, g_loss: 995.88562012 -- mean_d_loss: 1.01580882, mean_g_loss: 999.97003174\n",
            "Epoch:  99 Step:   291  time: 1.300621 s d_loss: 0.41324183, g_loss: 1012.08459473 -- mean_d_loss: 1.00925922, mean_g_loss: 1000.10174561\n",
            "Epoch:  99 Step:   292  time: 1.304268 s d_loss: 0.49750683, g_loss: 947.04675293 -- mean_d_loss: 1.00375640, mean_g_loss: 999.53125000\n",
            "Epoch:  99 Step:   293  time: 1.298850 s d_loss: 0.53406954, g_loss: 942.56762695 -- mean_d_loss: 0.99875981, mean_g_loss: 998.92529297\n",
            "Epoch:  99 Step:   294  time: 1.308841 s d_loss: 0.63276333, g_loss: 1027.99023438 -- mean_d_loss: 0.99490726, mean_g_loss: 999.23126221\n",
            "Epoch:  99 Step:   295  time: 1.308858 s d_loss: 0.62101340, g_loss: 1029.29309082 -- mean_d_loss: 0.99101251, mean_g_loss: 999.54443359\n",
            "Epoch:  99 Step:   296  time: 1.324393 s d_loss: 0.44859430, g_loss: 923.73022461 -- mean_d_loss: 0.98542053, mean_g_loss: 998.76281738\n",
            "Epoch:  99 Step:   297  time: 1.294808 s d_loss: 0.55447048, g_loss: 1069.23986816 -- mean_d_loss: 0.98102313, mean_g_loss: 999.48199463\n",
            "Epoch:  99 Step:   298  time: 1.280861 s d_loss: 0.49308780, g_loss: 990.75848389 -- mean_d_loss: 0.97609448, mean_g_loss: 999.39385986\n",
            "Epoch:  99 Step:   299  time: 1.285508 s d_loss: 0.61816472, g_loss: 938.04937744 -- mean_d_loss: 0.97251517, mean_g_loss: 998.78039551\n",
            "Epoch:  99 Step:   300  time: 1.295908 s d_loss: 0.66658020, g_loss: 949.17199707 -- mean_d_loss: 0.96948612, mean_g_loss: 998.28924561\n",
            "Epoch:  99 Step:   301  time: 1.290362 s d_loss: 0.56929290, g_loss: 1189.41040039 -- mean_d_loss: 0.96556264, mean_g_loss: 1000.16296387\n",
            "Epoch:  99 Step:   302  time: 1.321011 s d_loss: 0.54597461, g_loss: 1008.50506592 -- mean_d_loss: 0.96148896, mean_g_loss: 1000.24401855\n",
            "Epoch:  99 Step:   303  time: 1.309226 s d_loss: 10.85490322, g_loss: 987.18145752 -- mean_d_loss: 1.05661798, mean_g_loss: 1000.11840820\n",
            "Epoch:  99 Step:   304  time: 1.321162 s d_loss: 0.86635959, g_loss: 946.30010986 -- mean_d_loss: 1.05480599, mean_g_loss: 999.60577393\n",
            "Epoch:  99 Step:   305  time: 1.342788 s d_loss: 1.18036401, g_loss: 1053.16723633 -- mean_d_loss: 1.05599046, mean_g_loss: 1000.11108398\n",
            "Epoch:  99 Step:   306  time: 1.299378 s d_loss: 0.64112216, g_loss: 1038.68066406 -- mean_d_loss: 1.05211318, mean_g_loss: 1000.47149658\n",
            "Epoch:  99 Step:   307  time: 1.318190 s d_loss: 1.40041041, g_loss: 1106.94177246 -- mean_d_loss: 1.05533814, mean_g_loss: 1001.45739746\n",
            "Epoch:  99 Step:   308  time: 1.295284 s d_loss: 0.74732709, g_loss: 1176.61596680 -- mean_d_loss: 1.05251241, mean_g_loss: 1003.06439209\n",
            "Epoch:  99 Step:   309  time: 1.301307 s d_loss: 0.49899405, g_loss: 1185.19165039 -- mean_d_loss: 1.04748046, mean_g_loss: 1004.72009277\n",
            "Epoch:  99 Step:   310  time: 1.332205 s d_loss: 0.59242117, g_loss: 980.15380859 -- mean_d_loss: 1.04338086, mean_g_loss: 1004.49877930\n",
            "Epoch:  99 Step:   311  time: 1.316097 s d_loss: 0.97356558, g_loss: 961.86450195 -- mean_d_loss: 1.04275739, mean_g_loss: 1004.11816406\n",
            "Epoch:  99 Step:   312  time: 1.327083 s d_loss: 0.69081318, g_loss: 1012.20690918 -- mean_d_loss: 1.03964293, mean_g_loss: 1004.18969727\n",
            "Epoch:  99 Step:   313  time: 1.320338 s d_loss: 0.54524404, g_loss: 1136.49609375 -- mean_d_loss: 1.03530598, mean_g_loss: 1005.35034180\n",
            "Epoch:  99 Step:   314  time: 1.334219 s d_loss: 0.62794048, g_loss: 969.68811035 -- mean_d_loss: 1.03176367, mean_g_loss: 1005.04022217\n",
            "Epoch:  99 Step:   315  time: 1.335725 s d_loss: 0.52232212, g_loss: 995.45184326 -- mean_d_loss: 1.02737200, mean_g_loss: 1004.95758057\n",
            "Epoch:  99 Step:   316  time: 1.317587 s d_loss: 0.59404665, g_loss: 1082.70886230 -- mean_d_loss: 1.02366829, mean_g_loss: 1005.62213135\n",
            "Epoch:  99 Step:   317  time: 1.322431 s d_loss: 0.47546428, g_loss: 1110.11352539 -- mean_d_loss: 1.01902258, mean_g_loss: 1006.50769043\n",
            "Epoch:  99 Step:   318  time: 1.310553 s d_loss: 1.66185582, g_loss: 1110.97729492 -- mean_d_loss: 1.02442455, mean_g_loss: 1007.38555908\n",
            "Epoch:  99 Step:   319  time: 1.306445 s d_loss: 0.96821880, g_loss: 950.88232422 -- mean_d_loss: 1.02395606, mean_g_loss: 1006.91473389\n",
            "Epoch:  99 Step:   320  time: 1.331764 s d_loss: 0.97867703, g_loss: 972.39184570 -- mean_d_loss: 1.02358186, mean_g_loss: 1006.62939453\n",
            "Epoch:  99 Step:   321  time: 1.302968 s d_loss: 1.02175939, g_loss: 963.13610840 -- mean_d_loss: 1.02356696, mean_g_loss: 1006.27288818\n",
            "Epoch:  99 Step:   322  time: 1.317612 s d_loss: 0.79123050, g_loss: 1043.27246094 -- mean_d_loss: 1.02167797, mean_g_loss: 1006.57366943\n",
            "Epoch:  99 Step:   323  time: 1.317014 s d_loss: 1.18751979, g_loss: 1133.22607422 -- mean_d_loss: 1.02301550, mean_g_loss: 1007.59509277\n",
            "Epoch:  99 Step:   324  time: 1.330177 s d_loss: 0.50601614, g_loss: 853.80438232 -- mean_d_loss: 1.01887953, mean_g_loss: 1006.36474609\n",
            "Epoch:  99 Step:   325  time: 1.331042 s d_loss: 0.64342022, g_loss: 932.60363770 -- mean_d_loss: 1.01589966, mean_g_loss: 1005.77935791\n",
            "Epoch:  99 Step:   326  time: 1.327893 s d_loss: 0.73166674, g_loss: 1095.61035156 -- mean_d_loss: 1.01366162, mean_g_loss: 1006.48663330\n",
            "Epoch:  99 Step:   327  time: 1.322653 s d_loss: 0.83432227, g_loss: 1073.98535156 -- mean_d_loss: 1.01226056, mean_g_loss: 1007.01397705\n",
            "Epoch:  99 Step:   328  time: 1.315788 s d_loss: 0.41959599, g_loss: 954.03088379 -- mean_d_loss: 1.00766635, mean_g_loss: 1006.60327148\n",
            "Epoch:  99 Step:   329  time: 1.326537 s d_loss: 0.48560622, g_loss: 893.06878662 -- mean_d_loss: 1.00365055, mean_g_loss: 1005.72991943\n",
            "Epoch:  99 Step:   330  time: 1.296734 s d_loss: 0.62458408, g_loss: 981.03338623 -- mean_d_loss: 1.00075686, mean_g_loss: 1005.54138184\n",
            "Epoch:  99 Step:   331  time: 1.335506 s d_loss: 35.53364944, g_loss: 827.82293701 -- mean_d_loss: 1.26236963, mean_g_loss: 1004.19506836\n",
            "Epoch:  99 Step:   332  time: 1.323107 s d_loss: 4.46165085, g_loss: 1011.92541504 -- mean_d_loss: 1.28642440, mean_g_loss: 1004.25317383\n",
            "Epoch:  99 Step:   333  time: 1.312061 s d_loss: 1.78737605, g_loss: 935.28173828 -- mean_d_loss: 1.29016280, mean_g_loss: 1003.73846436\n",
            "Epoch:  99 Step:   334  time: 1.288828 s d_loss: 2.11871934, g_loss: 957.33404541 -- mean_d_loss: 1.29630029, mean_g_loss: 1003.39465332\n",
            "Epoch:  99 Step:   335  time: 1.321345 s d_loss: 2.35602021, g_loss: 1076.11071777 -- mean_d_loss: 1.30409229, mean_g_loss: 1003.92932129\n",
            "Epoch:  99 Step:   336  time: 1.299443 s d_loss: 3.04291797, g_loss: 1074.91235352 -- mean_d_loss: 1.31678450, mean_g_loss: 1004.44744873\n",
            "Epoch:  99 Step:   337  time: 1.297602 s d_loss: 2.58264494, g_loss: 977.93103027 -- mean_d_loss: 1.32595742, mean_g_loss: 1004.25531006\n",
            "Epoch:  99 Step:   338  time: 1.289217 s d_loss: 1.23917997, g_loss: 906.33264160 -- mean_d_loss: 1.32533312, mean_g_loss: 1003.55078125\n",
            "Epoch:  99 Step:   339  time: 1.289854 s d_loss: 0.67184609, g_loss: 973.18395996 -- mean_d_loss: 1.32066536, mean_g_loss: 1003.33392334\n",
            "Epoch:  99 Step:   340  time: 1.290397 s d_loss: 0.66823041, g_loss: 963.38232422 -- mean_d_loss: 1.31603813, mean_g_loss: 1003.05053711\n",
            "Epoch:  99 Step:   341  time: 1.314488 s d_loss: 0.53545344, g_loss: 1020.27722168 -- mean_d_loss: 1.31054091, mean_g_loss: 1003.17187500\n",
            "Epoch:  99 Step:   342  time: 1.319513 s d_loss: 0.59313726, g_loss: 1012.65191650 -- mean_d_loss: 1.30552423, mean_g_loss: 1003.23822021\n",
            "Epoch:  99 Step:   343  time: 1.311655 s d_loss: 1.21721435, g_loss: 1044.79907227 -- mean_d_loss: 1.30491090, mean_g_loss: 1003.52679443\n",
            "Epoch:  99 Step:   344  time: 1.339666 s d_loss: 0.76303488, g_loss: 927.27465820 -- mean_d_loss: 1.30117381, mean_g_loss: 1003.00097656\n",
            "Epoch:  99 Step:   345  time: 1.316563 s d_loss: 0.62031204, g_loss: 961.72113037 -- mean_d_loss: 1.29651034, mean_g_loss: 1002.71820068\n",
            "Epoch:  99 Step:   346  time: 1.322480 s d_loss: 0.52945834, g_loss: 1134.40478516 -- mean_d_loss: 1.29129231, mean_g_loss: 1003.61407471\n",
            "Epoch:  99 Step:   347  time: 1.314487 s d_loss: 0.47911224, g_loss: 1017.86645508 -- mean_d_loss: 1.28580463, mean_g_loss: 1003.71032715\n",
            "Epoch:  99 Step:   348  time: 1.306607 s d_loss: 0.79403579, g_loss: 1064.69433594 -- mean_d_loss: 1.28250420, mean_g_loss: 1004.11956787\n",
            "Epoch:  99 Step:   349  time: 1.317780 s d_loss: 1.15078771, g_loss: 953.93627930 -- mean_d_loss: 1.28162611, mean_g_loss: 1003.78497314\n",
            "Epoch:  99 Step:   350  time: 1.307549 s d_loss: 0.48750895, g_loss: 1084.29589844 -- mean_d_loss: 1.27636695, mean_g_loss: 1004.31817627\n",
            "Epoch:  99 Step:   351  time: 1.288278 s d_loss: 0.56494522, g_loss: 1032.55883789 -- mean_d_loss: 1.27168655, mean_g_loss: 1004.50402832\n",
            "Epoch:  99 Step:   352  time: 1.338433 s d_loss: 0.62988818, g_loss: 1248.85070801 -- mean_d_loss: 1.26749182, mean_g_loss: 1006.10101318\n",
            "Epoch:  99 Step:   353  time: 1.326680 s d_loss: 0.59614009, g_loss: 932.91754150 -- mean_d_loss: 1.26313233, mean_g_loss: 1005.62579346\n",
            "Epoch:  99 Step:   354  time: 1.328221 s d_loss: 0.47796005, g_loss: 896.61303711 -- mean_d_loss: 1.25806677, mean_g_loss: 1004.92248535\n",
            "Epoch:  99 Step:   355  time: 1.321869 s d_loss: 0.66203249, g_loss: 961.94885254 -- mean_d_loss: 1.25424600, mean_g_loss: 1004.64703369\n",
            "Epoch:  99 Step:   356  time: 1.291648 s d_loss: 2.47297859, g_loss: 1005.81866455 -- mean_d_loss: 1.26200867, mean_g_loss: 1004.65447998\n",
            "Epoch:  99 Step:   357  time: 1.295914 s d_loss: 0.76174289, g_loss: 986.22241211 -- mean_d_loss: 1.25884247, mean_g_loss: 1004.53778076\n",
            "Epoch:  99 Step:   358  time: 1.308536 s d_loss: 0.79668707, g_loss: 1313.45373535 -- mean_d_loss: 1.25593591, mean_g_loss: 1006.48065186\n",
            "Epoch:  99 Step:   359  time: 1.315588 s d_loss: 0.74632412, g_loss: 1149.55139160 -- mean_d_loss: 1.25275075, mean_g_loss: 1007.37481689\n",
            "Epoch:  99 Step:   360  time: 1.317320 s d_loss: 0.63525081, g_loss: 988.74804688 -- mean_d_loss: 1.24891543, mean_g_loss: 1007.25909424\n",
            "Epoch:  99 Step:   361  time: 1.318617 s d_loss: 0.50256950, g_loss: 907.93762207 -- mean_d_loss: 1.24430823, mean_g_loss: 1006.64599609\n",
            "Epoch:  99 Step:   362  time: 1.328435 s d_loss: 0.78995132, g_loss: 1082.36450195 -- mean_d_loss: 1.24152076, mean_g_loss: 1007.11053467\n",
            "Epoch:  99 Step:   363  time: 1.284379 s d_loss: 0.94290942, g_loss: 885.84533691 -- mean_d_loss: 1.23970008, mean_g_loss: 1006.37109375\n",
            "Epoch:  99 Step:   364  time: 1.327533 s d_loss: 0.93857712, g_loss: 1064.93994141 -- mean_d_loss: 1.23787510, mean_g_loss: 1006.72601318\n",
            "Epoch:  99 Step:   365  time: 1.317749 s d_loss: 0.78346670, g_loss: 1005.05401611 -- mean_d_loss: 1.23513770, mean_g_loss: 1006.71594238\n",
            "Epoch:  99 Step:   366  time: 1.356835 s d_loss: 0.75273365, g_loss: 998.25769043 -- mean_d_loss: 1.23224902, mean_g_loss: 1006.66522217\n",
            "Epoch:  99 Step:   367  time: 1.316579 s d_loss: 0.66011482, g_loss: 1158.38854980 -- mean_d_loss: 1.22884345, mean_g_loss: 1007.56835938\n",
            "Epoch:  99 Step:   368  time: 1.319345 s d_loss: 0.62277544, g_loss: 932.50146484 -- mean_d_loss: 1.22525716, mean_g_loss: 1007.12414551\n",
            "Epoch:  99 Step:   369  time: 1.317667 s d_loss: 0.70303875, g_loss: 1091.64343262 -- mean_d_loss: 1.22218525, mean_g_loss: 1007.62133789\n",
            "Epoch:  99 Step:   370  time: 1.339649 s d_loss: 0.51840591, g_loss: 1008.74194336 -- mean_d_loss: 1.21806955, mean_g_loss: 1007.62780762\n",
            "Epoch:  99 Step:   371  time: 1.314631 s d_loss: 0.61937904, g_loss: 1047.90771484 -- mean_d_loss: 1.21458888, mean_g_loss: 1007.86199951\n",
            "Epoch:  99 Step:   372  time: 1.323474 s d_loss: 0.49161288, g_loss: 1083.04064941 -- mean_d_loss: 1.21040976, mean_g_loss: 1008.29663086\n",
            "Epoch:  99 Step:   373  time: 1.324584 s d_loss: 0.65549976, g_loss: 962.86389160 -- mean_d_loss: 1.20722067, mean_g_loss: 1008.03546143\n",
            "Epoch:  99 Step:   374  time: 1.322864 s d_loss: 0.46693301, g_loss: 1028.39086914 -- mean_d_loss: 1.20299041, mean_g_loss: 1008.15179443\n",
            "Epoch:  99 Step:   375  time: 1.326648 s d_loss: 0.48420757, g_loss: 1023.00207520 -- mean_d_loss: 1.19890642, mean_g_loss: 1008.23614502\n",
            "Epoch:  99 Step:   376  time: 1.315813 s d_loss: 0.64830202, g_loss: 907.18835449 -- mean_d_loss: 1.19579566, mean_g_loss: 1007.66528320\n",
            "Epoch:  99 Step:   377  time: 1.320688 s d_loss: 0.66144663, g_loss: 1073.75366211 -- mean_d_loss: 1.19279373, mean_g_loss: 1008.03649902\n",
            "Epoch:  99 Step:   378  time: 1.324728 s d_loss: 0.80383027, g_loss: 867.74511719 -- mean_d_loss: 1.19062078, mean_g_loss: 1007.25280762\n",
            "Epoch:  99 Step:   379  time: 1.297958 s d_loss: 22.12045860, g_loss: 964.17102051 -- mean_d_loss: 1.30689764, mean_g_loss: 1007.01342773\n",
            "Epoch:  99 Step:   380  time: 1.313974 s d_loss: 1.54428828, g_loss: 904.20263672 -- mean_d_loss: 1.30820918, mean_g_loss: 1006.44543457\n",
            "Epoch:  99 Step:   381  time: 1.327522 s d_loss: 2.09526873, g_loss: 929.64086914 -- mean_d_loss: 1.31253374, mean_g_loss: 1006.02343750\n",
            "Epoch:  99 Step:   382  time: 1.319832 s d_loss: 1.12767172, g_loss: 1139.35913086 -- mean_d_loss: 1.31152356, mean_g_loss: 1006.75207520\n",
            "Epoch:  99 Step:   383  time: 1.312626 s d_loss: 0.57961428, g_loss: 1011.68835449 -- mean_d_loss: 1.30754578, mean_g_loss: 1006.77886963\n",
            "Epoch:  99 Step:   384  time: 1.285981 s d_loss: 0.75394380, g_loss: 1036.45996094 -- mean_d_loss: 1.30455327, mean_g_loss: 1006.93927002\n",
            "Epoch:  99 Step:   385  time: 1.333109 s d_loss: 0.73671174, g_loss: 1010.40570068 -- mean_d_loss: 1.30150044, mean_g_loss: 1006.95788574\n",
            "Epoch:  99 Step:   386  time: 1.295579 s d_loss: 1.07243180, g_loss: 1057.17456055 -- mean_d_loss: 1.30027544, mean_g_loss: 1007.22644043\n",
            "Epoch:  99 Step:   387  time: 1.312146 s d_loss: 0.53484821, g_loss: 1000.93896484 -- mean_d_loss: 1.29620397, mean_g_loss: 1007.19299316\n",
            "Epoch:  99 Step:   388  time: 1.324997 s d_loss: 0.45224139, g_loss: 1031.62036133 -- mean_d_loss: 1.29173863, mean_g_loss: 1007.32226562\n",
            "Epoch:  99 Step:   389  time: 1.284703 s d_loss: 8.99529076, g_loss: 1202.22607422 -- mean_d_loss: 1.33228362, mean_g_loss: 1008.34802246\n",
            "Epoch:  99 Step:   390  time: 1.329136 s d_loss: 1.12694860, g_loss: 1041.00256348 -- mean_d_loss: 1.33120859, mean_g_loss: 1008.51898193\n",
            "Epoch:  99 Step:   391  time: 1.342387 s d_loss: 1.40722775, g_loss: 980.77764893 -- mean_d_loss: 1.33160448, mean_g_loss: 1008.37451172\n",
            "Epoch:  99 Step:   392  time: 1.317586 s d_loss: 0.71087444, g_loss: 1040.70910645 -- mean_d_loss: 1.32838821, mean_g_loss: 1008.54199219\n",
            "Epoch:  99 Step:   393  time: 1.285952 s d_loss: 17.12540436, g_loss: 912.50781250 -- mean_d_loss: 1.40981615, mean_g_loss: 1008.04705811\n",
            "Epoch:  99 Step:   394  time: 1.323512 s d_loss: 0.87072986, g_loss: 916.98474121 -- mean_d_loss: 1.40705156, mean_g_loss: 1007.58007812\n",
            "Epoch:  99 Step:   395  time: 1.316212 s d_loss: 0.77364212, g_loss: 977.16711426 -- mean_d_loss: 1.40381992, mean_g_loss: 1007.42492676\n",
            "Epoch:  99 Step:   396  time: 1.314960 s d_loss: 0.92013139, g_loss: 1118.71716309 -- mean_d_loss: 1.40136468, mean_g_loss: 1007.98986816\n",
            "Epoch:  99 Step:   397  time: 1.328849 s d_loss: 0.64616293, g_loss: 907.71893311 -- mean_d_loss: 1.39755046, mean_g_loss: 1007.48339844\n",
            "Epoch:  99 Step:   398  time: 1.325337 s d_loss: 0.72492337, g_loss: 1357.76940918 -- mean_d_loss: 1.39417040, mean_g_loss: 1009.24365234\n",
            "Epoch:  99 Step:   399  time: 1.311416 s d_loss: 0.75516587, g_loss: 1102.76660156 -- mean_d_loss: 1.39097536, mean_g_loss: 1009.71124268\n",
            "Epoch:  99 Step:   400  time: 1.293497 s d_loss: 0.67350256, g_loss: 907.26086426 -- mean_d_loss: 0.67350256, mean_g_loss: 907.26086426\n",
            "Epoch:  99 Step:   401  time: 1.318404 s d_loss: 0.91590667, g_loss: 1102.85571289 -- mean_d_loss: 0.79470462, mean_g_loss: 1005.05828857\n",
            "Epoch:  99 Step:   402  time: 1.284951 s d_loss: 0.55254531, g_loss: 948.39221191 -- mean_d_loss: 0.71398479, mean_g_loss: 986.16961670\n",
            "Epoch:  99 Step:   403  time: 1.317893 s d_loss: 0.44286397, g_loss: 1104.31018066 -- mean_d_loss: 0.64620459, mean_g_loss: 1015.70471191\n",
            "Epoch:  99 Step:   404  time: 1.322107 s d_loss: 0.62700737, g_loss: 1063.28857422 -- mean_d_loss: 0.64236516, mean_g_loss: 1025.22143555\n",
            "Epoch:  99 Step:   405  time: 1.285531 s d_loss: 0.89835197, g_loss: 1020.07299805 -- mean_d_loss: 0.68502969, mean_g_loss: 1024.36340332\n",
            "Epoch:  99 Step:   406  time: 1.321476 s d_loss: 0.57501513, g_loss: 1045.23181152 -- mean_d_loss: 0.66931331, mean_g_loss: 1027.34460449\n",
            "Epoch:  99 Step:   407  time: 1.317267 s d_loss: 0.55781925, g_loss: 1056.51611328 -- mean_d_loss: 0.65537655, mean_g_loss: 1030.99108887\n",
            "Epoch:  99 Step:   408  time: 1.315442 s d_loss: 0.58499509, g_loss: 1014.13049316 -- mean_d_loss: 0.64755642, mean_g_loss: 1029.11767578\n",
            "Epoch:  99 Step:   409  time: 1.312575 s d_loss: 1.20278597, g_loss: 1256.70996094 -- mean_d_loss: 0.70307934, mean_g_loss: 1051.87695312\n",
            "Epoch:  99 Step:   410  time: 1.338250 s d_loss: 0.48185396, g_loss: 949.26635742 -- mean_d_loss: 0.68296796, mean_g_loss: 1042.54870605\n",
            "Epoch:  99 Step:   411  time: 1.335566 s d_loss: 0.59013295, g_loss: 1027.53369141 -- mean_d_loss: 0.67523170, mean_g_loss: 1041.29748535\n",
            "Epoch:  99 Step:   412  time: 1.333083 s d_loss: 0.66504586, g_loss: 1097.52001953 -- mean_d_loss: 0.67444813, mean_g_loss: 1045.62231445\n",
            "Epoch:  99 Step:   413  time: 1.296993 s d_loss: 0.52621371, g_loss: 1080.69653320 -- mean_d_loss: 0.66385996, mean_g_loss: 1048.12756348\n",
            "Epoch:  99 Step:   414  time: 1.312250 s d_loss: 0.59514600, g_loss: 916.91601562 -- mean_d_loss: 0.65927905, mean_g_loss: 1039.38012695\n",
            "Epoch:  99 Step:   415  time: 1.342578 s d_loss: 0.57399178, g_loss: 1036.18969727 -- mean_d_loss: 0.65394861, mean_g_loss: 1039.18078613\n",
            "Epoch:  99 Step:   416  time: 1.321433 s d_loss: 0.41131476, g_loss: 940.78771973 -- mean_d_loss: 0.63967603, mean_g_loss: 1033.39294434\n",
            "Epoch:  99 Step:   417  time: 1.315431 s d_loss: 0.64965379, g_loss: 1052.27770996 -- mean_d_loss: 0.64023036, mean_g_loss: 1034.44201660\n",
            "Epoch:  99 Step:   418  time: 1.294198 s d_loss: 27.11891365, g_loss: 858.61840820 -- mean_d_loss: 2.03384519, mean_g_loss: 1025.18823242\n",
            "Epoch:  99 Step:   419  time: 1.316966 s d_loss: 1.46520233, g_loss: 987.41186523 -- mean_d_loss: 2.00541306, mean_g_loss: 1023.29943848\n",
            "Epoch:  99 Step:   420  time: 1.298524 s d_loss: 1.30287194, g_loss: 956.73266602 -- mean_d_loss: 1.97195876, mean_g_loss: 1020.12957764\n",
            "Epoch:  99 Step:   421  time: 1.321013 s d_loss: 0.67707241, g_loss: 1067.70776367 -- mean_d_loss: 1.91310012, mean_g_loss: 1022.29217529\n",
            "Epoch:  99 Step:   422  time: 1.310667 s d_loss: 0.50605559, g_loss: 1113.54504395 -- mean_d_loss: 1.85192418, mean_g_loss: 1026.25964355\n",
            "Epoch:  99 Step:   423  time: 1.329037 s d_loss: 0.60645270, g_loss: 958.64367676 -- mean_d_loss: 1.80002964, mean_g_loss: 1023.44238281\n",
            "Epoch:  99 Step:   424  time: 1.301528 s d_loss: 8.78610325, g_loss: 907.33703613 -- mean_d_loss: 2.07947254, mean_g_loss: 1018.79821777\n",
            "Epoch:  99 Step:   425  time: 1.333096 s d_loss: 1.01324809, g_loss: 1050.71228027 -- mean_d_loss: 2.03846383, mean_g_loss: 1020.02569580\n",
            "Epoch:  99 Step:   426  time: 1.320181 s d_loss: 1.02379835, g_loss: 1101.69958496 -- mean_d_loss: 2.00088382, mean_g_loss: 1023.05065918\n",
            "Epoch:  99 Step:   427  time: 1.330975 s d_loss: 0.89544123, g_loss: 1138.40209961 -- mean_d_loss: 1.96140373, mean_g_loss: 1027.17028809\n",
            "Epoch:  99 Step:   428  time: 1.342804 s d_loss: 1.29127753, g_loss: 1120.99194336 -- mean_d_loss: 1.93829596, mean_g_loss: 1030.40551758\n",
            "Epoch:  99 Step:   429  time: 1.290334 s d_loss: 0.56151456, g_loss: 1031.12036133 -- mean_d_loss: 1.89240324, mean_g_loss: 1030.42944336\n",
            "Epoch:  99 Step:   430  time: 1.333188 s d_loss: 0.52737117, g_loss: 1148.37890625 -- mean_d_loss: 1.84836996, mean_g_loss: 1034.23425293\n",
            "Epoch:  99 Step:   431  time: 1.329654 s d_loss: 0.46605420, g_loss: 1241.54956055 -- mean_d_loss: 1.80517256, mean_g_loss: 1040.71289062\n",
            "Epoch:  99 Step:   432  time: 1.316490 s d_loss: 0.54231429, g_loss: 986.36163330 -- mean_d_loss: 1.76690412, mean_g_loss: 1039.06591797\n",
            "Epoch:  99 Step:   433  time: 1.348335 s d_loss: 0.57759196, g_loss: 954.43054199 -- mean_d_loss: 1.73192430, mean_g_loss: 1036.57666016\n",
            "Epoch:  99 Step:   434  time: 1.322746 s d_loss: 0.55166805, g_loss: 1049.17626953 -- mean_d_loss: 1.69820261, mean_g_loss: 1036.93664551\n",
            "Epoch:  99 Step:   435  time: 1.330862 s d_loss: 0.51628393, g_loss: 959.66784668 -- mean_d_loss: 1.66537154, mean_g_loss: 1034.79028320\n",
            "Epoch:  99 Step:   436  time: 1.321811 s d_loss: 0.61354595, g_loss: 974.26800537 -- mean_d_loss: 1.63694382, mean_g_loss: 1033.15454102\n",
            "Epoch:  99 Step:   437  time: 1.317782 s d_loss: 0.55392021, g_loss: 932.17138672 -- mean_d_loss: 1.60844326, mean_g_loss: 1030.49707031\n",
            "Epoch:  99 Step:   438  time: 1.320815 s d_loss: 0.46290603, g_loss: 889.63616943 -- mean_d_loss: 1.57907045, mean_g_loss: 1026.88537598\n",
            "Epoch:  99 Step:   439  time: 1.314875 s d_loss: 0.49552050, g_loss: 886.51684570 -- mean_d_loss: 1.55198169, mean_g_loss: 1023.37609863\n",
            "Epoch:  99 Step:   440  time: 1.306319 s d_loss: 0.75121897, g_loss: 1031.62768555 -- mean_d_loss: 1.53245103, mean_g_loss: 1023.57739258\n",
            "Epoch:  99 Step:   441  time: 1.290298 s d_loss: 0.69629431, g_loss: 914.85729980 -- mean_d_loss: 1.51254249, mean_g_loss: 1020.98876953\n",
            "Epoch:  99 Step:   442  time: 1.334120 s d_loss: 1.02708220, g_loss: 1046.46704102 -- mean_d_loss: 1.50125265, mean_g_loss: 1021.58129883\n",
            "Epoch:  99 Step:   443  time: 1.290785 s d_loss: 0.83072901, g_loss: 1033.73291016 -- mean_d_loss: 1.48601341, mean_g_loss: 1021.85748291\n",
            "Epoch:  99 Step:   444  time: 1.291630 s d_loss: 0.90706539, g_loss: 928.15673828 -- mean_d_loss: 1.47314787, mean_g_loss: 1019.77526855\n",
            "Epoch:  99 Step:   445  time: 1.298302 s d_loss: 0.83454180, g_loss: 1043.57617188 -- mean_d_loss: 1.45926511, mean_g_loss: 1020.29260254\n",
            "Epoch:  99 Step:   446  time: 1.295892 s d_loss: 0.84524411, g_loss: 1105.74401855 -- mean_d_loss: 1.44620097, mean_g_loss: 1022.11071777\n",
            "Epoch:  99 Step:   447  time: 1.294622 s d_loss: 1.32018173, g_loss: 999.96740723 -- mean_d_loss: 1.44357550, mean_g_loss: 1021.64941406\n",
            "Epoch:  99 Step:   448  time: 1.347204 s d_loss: 39.71305084, g_loss: 1062.18676758 -- mean_d_loss: 2.22458529, mean_g_loss: 1022.47674561\n",
            "Epoch:  99 Step:   449  time: 1.322443 s d_loss: 1.84794772, g_loss: 1098.92163086 -- mean_d_loss: 2.21705246, mean_g_loss: 1024.00561523\n",
            "Epoch:  99 Step:   450  time: 1.322304 s d_loss: 2.32126713, g_loss: 1090.33312988 -- mean_d_loss: 2.21909595, mean_g_loss: 1025.30615234\n",
            "Epoch:  99 Step:   451  time: 1.327821 s d_loss: 0.99917191, g_loss: 1055.89440918 -- mean_d_loss: 2.19563580, mean_g_loss: 1025.89440918\n",
            "Epoch:  99 Step:   452  time: 1.276083 s d_loss: 0.69577801, g_loss: 992.77709961 -- mean_d_loss: 2.16733646, mean_g_loss: 1025.26953125\n",
            "Epoch:  99 Step:   453  time: 1.285821 s d_loss: 0.90760088, g_loss: 928.27502441 -- mean_d_loss: 2.14400816, mean_g_loss: 1023.47332764\n",
            "Epoch:  99 Step:   454  time: 1.319072 s d_loss: 0.60137331, g_loss: 1106.89514160 -- mean_d_loss: 2.11596012, mean_g_loss: 1024.99011230\n",
            "Epoch:  99 Step:   455  time: 1.306854 s d_loss: 0.75556958, g_loss: 984.50891113 -- mean_d_loss: 2.09166741, mean_g_loss: 1024.26721191\n",
            "Epoch:  99 Step:   456  time: 1.303792 s d_loss: 0.55479842, g_loss: 1093.81152344 -- mean_d_loss: 2.06470490, mean_g_loss: 1025.48730469\n",
            "Epoch:  99 Step:   457  time: 1.317828 s d_loss: 0.54649413, g_loss: 959.16021729 -- mean_d_loss: 2.03852892, mean_g_loss: 1024.34362793\n",
            "Epoch:  99 Step:   458  time: 1.316726 s d_loss: 0.70732164, g_loss: 991.82104492 -- mean_d_loss: 2.01596594, mean_g_loss: 1023.79241943\n",
            "Epoch:  99 Step:   459  time: 1.323657 s d_loss: 0.64233327, g_loss: 1004.03771973 -- mean_d_loss: 1.99307215, mean_g_loss: 1023.46319580\n",
            "Epoch:  99 Step:   460  time: 1.318243 s d_loss: 2.51521134, g_loss: 1219.21679688 -- mean_d_loss: 2.00163174, mean_g_loss: 1026.67224121\n",
            "Epoch:  99 Step:   461  time: 1.345074 s d_loss: 0.53912300, g_loss: 855.76824951 -- mean_d_loss: 1.97804296, mean_g_loss: 1023.91577148\n",
            "Epoch:  99 Step:   462  time: 1.295970 s d_loss: 0.68564439, g_loss: 937.25952148 -- mean_d_loss: 1.95752871, mean_g_loss: 1022.54022217\n",
            "Epoch:  99 Step:   463  time: 1.315743 s d_loss: 0.50761271, g_loss: 966.65649414 -- mean_d_loss: 1.93487382, mean_g_loss: 1021.66705322\n",
            "Epoch:  99 Step:   464  time: 1.312902 s d_loss: 0.44878241, g_loss: 1009.52563477 -- mean_d_loss: 1.91201091, mean_g_loss: 1021.48028564\n",
            "Epoch:  99 Step:   465  time: 1.292175 s d_loss: 0.42604640, g_loss: 931.10150146 -- mean_d_loss: 1.88949633, mean_g_loss: 1020.11090088\n",
            "Epoch:  99 Step:   466  time: 1.324354 s d_loss: 0.97654319, g_loss: 870.32324219 -- mean_d_loss: 1.87587011, mean_g_loss: 1017.87524414\n",
            "Epoch:  99 Step:   467  time: 1.315481 s d_loss: 0.52148598, g_loss: 964.83898926 -- mean_d_loss: 1.85595262, mean_g_loss: 1017.09521484\n",
            "Epoch:  99 Step:   468  time: 1.278258 s d_loss: 0.60449827, g_loss: 994.90179443 -- mean_d_loss: 1.83781564, mean_g_loss: 1016.77355957\n",
            "Epoch:  99 Step:   469  time: 1.287805 s d_loss: 0.80662024, g_loss: 996.29974365 -- mean_d_loss: 1.82308424, mean_g_loss: 1016.48101807\n",
            "Epoch:  99 Step:   470  time: 1.318077 s d_loss: 1.18687439, g_loss: 1260.97473145 -- mean_d_loss: 1.81412339, mean_g_loss: 1019.92462158\n",
            "Epoch:  99 Step:   471  time: 1.341928 s d_loss: 0.52264434, g_loss: 1018.02880859 -- mean_d_loss: 1.79618621, mean_g_loss: 1019.89831543\n",
            "Epoch:  99 Step:   472  time: 1.289271 s d_loss: 0.66964668, g_loss: 938.46240234 -- mean_d_loss: 1.78075421, mean_g_loss: 1018.78277588\n",
            "Epoch:  99 Step:   473  time: 1.309128 s d_loss: 2.02180743, g_loss: 988.75079346 -- mean_d_loss: 1.78401160, mean_g_loss: 1018.37689209\n",
            "Epoch:  99 Step:   474  time: 1.319056 s d_loss: 0.99568623, g_loss: 959.10827637 -- mean_d_loss: 1.77350056, mean_g_loss: 1017.58666992\n",
            "Epoch:  99 Step:   475  time: 1.308548 s d_loss: 1.13632119, g_loss: 1121.23046875 -- mean_d_loss: 1.76511669, mean_g_loss: 1018.95043945\n",
            "Epoch:  99 Step:   476  time: 1.303740 s d_loss: 1.11877608, g_loss: 1072.36352539 -- mean_d_loss: 1.75672257, mean_g_loss: 1019.64416504\n",
            "Epoch:  99 Step:   477  time: 1.289790 s d_loss: 1.04719079, g_loss: 956.83654785 -- mean_d_loss: 1.74762607, mean_g_loss: 1018.83892822\n",
            "Epoch:  99 Step:   478  time: 1.315792 s d_loss: 0.87012410, g_loss: 1106.69042969 -- mean_d_loss: 1.73651838, mean_g_loss: 1019.95092773\n",
            "Epoch:  99 Step:   479  time: 1.291058 s d_loss: 0.90997249, g_loss: 1018.93151855 -- mean_d_loss: 1.72618651, mean_g_loss: 1019.93817139\n",
            "Epoch:  99 Step:   480  time: 1.319599 s d_loss: 0.73720151, g_loss: 950.60888672 -- mean_d_loss: 1.71397686, mean_g_loss: 1019.08227539\n",
            "Epoch:  99 Step:   481  time: 1.314642 s d_loss: 0.81944180, g_loss: 1007.28039551 -- mean_d_loss: 1.70306790, mean_g_loss: 1018.93835449\n",
            "Epoch:  99 Step:   482  time: 1.328359 s d_loss: 0.45978910, g_loss: 1011.36047363 -- mean_d_loss: 1.68808866, mean_g_loss: 1018.84704590\n",
            "Epoch:  99 Step:   483  time: 1.306784 s d_loss: 0.57358062, g_loss: 1173.03320312 -- mean_d_loss: 1.67482066, mean_g_loss: 1020.68255615\n",
            "Epoch:  99 Step:   484  time: 1.298759 s d_loss: 0.59379685, g_loss: 967.72747803 -- mean_d_loss: 1.66210270, mean_g_loss: 1020.05957031\n",
            "Epoch:  99 Step:   485  time: 1.295936 s d_loss: 0.71663654, g_loss: 993.96185303 -- mean_d_loss: 1.65110886, mean_g_loss: 1019.75610352\n",
            "Epoch:  99 Step:   486  time: 1.300961 s d_loss: 0.62610942, g_loss: 970.22357178 -- mean_d_loss: 1.63932729, mean_g_loss: 1019.18676758\n",
            "Epoch:  99 Step:   487  time: 1.324512 s d_loss: 0.67666131, g_loss: 1019.23010254 -- mean_d_loss: 1.62838793, mean_g_loss: 1019.18725586\n",
            "Epoch:  99 Step:   488  time: 1.287175 s d_loss: 0.82748049, g_loss: 933.04052734 -- mean_d_loss: 1.61938906, mean_g_loss: 1018.21929932\n",
            "Epoch:  99 Step:   489  time: 1.305437 s d_loss: 0.48832533, g_loss: 1207.32739258 -- mean_d_loss: 1.60682166, mean_g_loss: 1020.32049561\n",
            "Epoch:  99 Step:   490  time: 1.319775 s d_loss: 45.02238464, g_loss: 993.14733887 -- mean_d_loss: 2.08391571, mean_g_loss: 1020.02191162\n",
            "Epoch:  99 Step:   491  time: 1.298709 s d_loss: 2.36992121, g_loss: 790.60443115 -- mean_d_loss: 2.08702445, mean_g_loss: 1017.52819824\n",
            "Epoch:  99 Step:   492  time: 1.331707 s d_loss: 3.91330552, g_loss: 978.33227539 -- mean_d_loss: 2.10666180, mean_g_loss: 1017.10675049\n",
            "Epoch:  99 Step:   493  time: 1.316898 s d_loss: 1.45819283, g_loss: 990.62255859 -- mean_d_loss: 2.09976315, mean_g_loss: 1016.82507324\n",
            "Epoch:  99 Step:   494  time: 1.326674 s d_loss: 0.74524897, g_loss: 1021.85522461 -- mean_d_loss: 2.08550525, mean_g_loss: 1016.87799072\n",
            "Epoch:  99 Step:   495  time: 1.315252 s d_loss: 0.54874873, g_loss: 1000.60876465 -- mean_d_loss: 2.06949735, mean_g_loss: 1016.70849609\n",
            "Epoch:  99 Step:   496  time: 1.321241 s d_loss: 0.58340210, g_loss: 1193.04174805 -- mean_d_loss: 2.05417681, mean_g_loss: 1018.52636719\n",
            "Epoch:  99 Step:   497  time: 1.322566 s d_loss: 0.45289683, g_loss: 994.32226562 -- mean_d_loss: 2.03783727, mean_g_loss: 1018.27935791\n",
            "Epoch:  99 Step:   498  time: 1.340984 s d_loss: 0.57770163, g_loss: 873.70458984 -- mean_d_loss: 2.02308846, mean_g_loss: 1016.81896973\n",
            "Epoch:  99 Step:   499  time: 1.316337 s d_loss: 0.67432946, g_loss: 1040.84106445 -- mean_d_loss: 2.00960088, mean_g_loss: 1017.05920410\n",
            "Epoch:  99 Step:   500  time: 1.333991 s d_loss: 0.71613860, g_loss: 1032.11169434 -- mean_d_loss: 1.99679434, mean_g_loss: 1017.20825195\n",
            "Epoch:  99 Step:   501  time: 1.286706 s d_loss: 0.51752841, g_loss: 1093.83337402 -- mean_d_loss: 1.98229170, mean_g_loss: 1017.95947266\n",
            "Epoch:  99 Step:   502  time: 1.313801 s d_loss: 0.99512529, g_loss: 863.40625000 -- mean_d_loss: 1.97270763, mean_g_loss: 1016.45898438\n",
            "Epoch:  99 Step:   503  time: 1.297007 s d_loss: 0.51191676, g_loss: 965.17260742 -- mean_d_loss: 1.95866156, mean_g_loss: 1015.96582031\n",
            "Epoch:  99 Step:   504  time: 1.320135 s d_loss: 1.16397989, g_loss: 1012.35168457 -- mean_d_loss: 1.95109320, mean_g_loss: 1015.93139648\n",
            "Epoch:  99 Step:   505  time: 1.280568 s d_loss: 0.75677580, g_loss: 870.67138672 -- mean_d_loss: 1.93982613, mean_g_loss: 1014.56103516\n",
            "Epoch:  99 Step:   506  time: 1.315665 s d_loss: 0.72827667, g_loss: 939.41375732 -- mean_d_loss: 1.92850316, mean_g_loss: 1013.85870361\n",
            "Epoch:  99 Step:   507  time: 1.321203 s d_loss: 0.69493920, g_loss: 1143.39233398 -- mean_d_loss: 1.91708136, mean_g_loss: 1015.05810547\n",
            "Epoch:  99 Step:   508  time: 1.320684 s d_loss: 1.25199485, g_loss: 872.68487549 -- mean_d_loss: 1.91097963, mean_g_loss: 1013.75195312\n",
            "Epoch:  99 Step:   509  time: 1.322588 s d_loss: 0.54285014, g_loss: 1043.49438477 -- mean_d_loss: 1.89854205, mean_g_loss: 1014.02227783\n",
            "Epoch:  99 Step:   510  time: 1.293014 s d_loss: 1.03849602, g_loss: 1000.60491943 -- mean_d_loss: 1.89079392, mean_g_loss: 1013.90136719\n",
            "Epoch:  99 Step:   511  time: 1.300546 s d_loss: 1.86155272, g_loss: 1059.57812500 -- mean_d_loss: 1.89053285, mean_g_loss: 1014.30920410\n",
            "Epoch:  99 Step:   512  time: 1.297223 s d_loss: 0.73362207, g_loss: 1236.91357422 -- mean_d_loss: 1.88029480, mean_g_loss: 1016.27917480\n",
            "Epoch:  99 Step:   513  time: 1.312026 s d_loss: 1.08291519, g_loss: 956.11816406 -- mean_d_loss: 1.87330019, mean_g_loss: 1015.75146484\n",
            "Epoch:  99 Step:   514  time: 1.319572 s d_loss: 0.86796761, g_loss: 1045.31054688 -- mean_d_loss: 1.86455822, mean_g_loss: 1016.00848389\n",
            "Epoch:  99 Step:   515  time: 1.287763 s d_loss: 0.74729508, g_loss: 1070.70800781 -- mean_d_loss: 1.85492671, mean_g_loss: 1016.48004150\n",
            "Epoch:  99 Step:   516  time: 1.335238 s d_loss: 0.70668799, g_loss: 1034.02148438 -- mean_d_loss: 1.84511268, mean_g_loss: 1016.63000488\n",
            "Epoch:  99 Step:   517  time: 1.319876 s d_loss: 0.62675428, g_loss: 1100.09619141 -- mean_d_loss: 1.83478761, mean_g_loss: 1017.33734131\n",
            "Epoch:  99 Step:   518  time: 1.319311 s d_loss: 1.09882820, g_loss: 938.57788086 -- mean_d_loss: 1.82860315, mean_g_loss: 1016.67547607\n",
            "Epoch:  99 Step:   519  time: 1.314583 s d_loss: 0.79609263, g_loss: 931.45849609 -- mean_d_loss: 1.81999898, mean_g_loss: 1015.96539307\n",
            "Epoch:  99 Step:   520  time: 1.321527 s d_loss: 0.95757812, g_loss: 964.78631592 -- mean_d_loss: 1.81287146, mean_g_loss: 1015.54241943\n",
            "Epoch:  99 Step:   521  time: 1.325222 s d_loss: 0.92001802, g_loss: 1049.46276855 -- mean_d_loss: 1.80555296, mean_g_loss: 1015.82043457\n",
            "Epoch:  99 Step:   522  time: 1.302804 s d_loss: 1.14604771, g_loss: 1051.81970215 -- mean_d_loss: 1.80019116, mean_g_loss: 1016.11309814\n",
            "Epoch:  99 Step:   523  time: 1.322917 s d_loss: 1.36687183, g_loss: 1152.16748047 -- mean_d_loss: 1.79669654, mean_g_loss: 1017.21032715\n",
            "Epoch:  99 Step:   524  time: 1.323234 s d_loss: 0.96337903, g_loss: 1072.07397461 -- mean_d_loss: 1.79003000, mean_g_loss: 1017.64916992\n",
            "Epoch:  99 Step:   525  time: 1.317432 s d_loss: 0.73141801, g_loss: 1025.29589844 -- mean_d_loss: 1.78162837, mean_g_loss: 1017.70989990\n",
            "Epoch:  99 Step:   526  time: 1.318858 s d_loss: 0.71395212, g_loss: 1078.24414062 -- mean_d_loss: 1.77322149, mean_g_loss: 1018.18652344\n",
            "Epoch:  99 Step:   527  time: 1.312667 s d_loss: 0.74579334, g_loss: 964.51721191 -- mean_d_loss: 1.76519465, mean_g_loss: 1017.76721191\n",
            "Epoch:  99 Step:   528  time: 1.303597 s d_loss: 0.85196769, g_loss: 1138.79797363 -- mean_d_loss: 1.75811541, mean_g_loss: 1018.70544434\n",
            "Epoch:  99 Step:   529  time: 1.348679 s d_loss: 1.52711034, g_loss: 1029.79699707 -- mean_d_loss: 1.75633848, mean_g_loss: 1018.79077148\n",
            "Epoch:  99 Step:   530  time: 1.321702 s d_loss: 0.83265722, g_loss: 1018.34375000 -- mean_d_loss: 1.74928749, mean_g_loss: 1018.78735352\n",
            "Epoch:  99 Step:   531  time: 1.318724 s d_loss: 1.13795793, g_loss: 997.77038574 -- mean_d_loss: 1.74465621, mean_g_loss: 1018.62805176\n",
            "Epoch:  99 Step:   532  time: 1.307439 s d_loss: 1.49775827, g_loss: 990.40747070 -- mean_d_loss: 1.74279976, mean_g_loss: 1018.41589355\n",
            "Epoch:  99 Step:   533  time: 1.330024 s d_loss: 3.07228565, g_loss: 1160.61376953 -- mean_d_loss: 1.75272131, mean_g_loss: 1019.47705078\n",
            "Epoch:  99 Step:   534  time: 1.341268 s d_loss: 1.01196563, g_loss: 1134.58422852 -- mean_d_loss: 1.74723423, mean_g_loss: 1020.32965088\n",
            "Epoch:  99 Step:   535  time: 1.320870 s d_loss: 0.59666562, g_loss: 1024.71154785 -- mean_d_loss: 1.73877418, mean_g_loss: 1020.36187744\n",
            "Epoch:  99 Step:   536  time: 1.300128 s d_loss: 1.09326386, g_loss: 1085.55053711 -- mean_d_loss: 1.73406231, mean_g_loss: 1020.83770752\n",
            "Epoch:  99 Step:   537  time: 1.299688 s d_loss: 0.82610506, g_loss: 1023.64343262 -- mean_d_loss: 1.72748303, mean_g_loss: 1020.85803223\n",
            "Epoch:  99 Step:   538  time: 1.307986 s d_loss: 0.64675468, g_loss: 921.18176270 -- mean_d_loss: 1.71970797, mean_g_loss: 1020.14099121\n",
            "Epoch:  99 Step:   539  time: 1.327175 s d_loss: 0.96115702, g_loss: 1183.42565918 -- mean_d_loss: 1.71428978, mean_g_loss: 1021.30725098\n",
            "Epoch:  99 Step:   540  time: 1.326209 s d_loss: 0.62582916, g_loss: 966.76110840 -- mean_d_loss: 1.70657015, mean_g_loss: 1020.92041016\n",
            "Epoch:  99 Step:   541  time: 1.325365 s d_loss: 1.10919809, g_loss: 941.28814697 -- mean_d_loss: 1.70236325, mean_g_loss: 1020.35961914\n",
            "Epoch:  99 Step:   542  time: 1.327372 s d_loss: 1.01245284, g_loss: 979.91607666 -- mean_d_loss: 1.69753873, mean_g_loss: 1020.07684326\n",
            "Epoch:  99 Step:   543  time: 1.326261 s d_loss: 0.64790636, g_loss: 933.32391357 -- mean_d_loss: 1.69024956, mean_g_loss: 1019.47436523\n",
            "Epoch:  99 Step:   544  time: 1.316826 s d_loss: 0.51073778, g_loss: 1067.32385254 -- mean_d_loss: 1.68211496, mean_g_loss: 1019.80444336\n",
            "Epoch:  99 Step:   545  time: 1.314869 s d_loss: 0.59475875, g_loss: 860.53808594 -- mean_d_loss: 1.67466736, mean_g_loss: 1018.71350098\n",
            "Epoch:  99 Step:   546  time: 1.325487 s d_loss: 0.74367362, g_loss: 1116.92114258 -- mean_d_loss: 1.66833401, mean_g_loss: 1019.38159180\n",
            "Epoch:  99 Step:   547  time: 1.320220 s d_loss: 0.68037802, g_loss: 986.27185059 -- mean_d_loss: 1.66165864, mean_g_loss: 1019.15783691\n",
            "Epoch:  99 Step:   548  time: 1.300184 s d_loss: 0.94909674, g_loss: 1074.50512695 -- mean_d_loss: 1.65687633, mean_g_loss: 1019.52923584\n",
            "Epoch:  99 Step:   549  time: 1.321033 s d_loss: 0.53807008, g_loss: 1022.77124023 -- mean_d_loss: 1.64941764, mean_g_loss: 1019.55084229\n",
            "Epoch:  99 Step:   550  time: 1.313620 s d_loss: 0.61943650, g_loss: 981.87036133 -- mean_d_loss: 1.64259648, mean_g_loss: 1019.30133057\n",
            "Epoch:  99 Step:   551  time: 1.348825 s d_loss: 0.41107967, g_loss: 1072.73315430 -- mean_d_loss: 1.63449442, mean_g_loss: 1019.65283203\n",
            "Epoch:  99 Step:   552  time: 1.318429 s d_loss: 0.47076774, g_loss: 923.72985840 -- mean_d_loss: 1.62688839, mean_g_loss: 1019.02593994\n",
            "Epoch:  99 Step:   553  time: 1.317239 s d_loss: 20.27319336, g_loss: 1092.33398438 -- mean_d_loss: 1.74796844, mean_g_loss: 1019.50195312\n",
            "Epoch:  99 Step:   554  time: 1.354686 s d_loss: 1.40307677, g_loss: 963.11340332 -- mean_d_loss: 1.74574327, mean_g_loss: 1019.13812256\n",
            "Epoch:  99 Step:   555  time: 1.353705 s d_loss: 1.37049758, g_loss: 831.30194092 -- mean_d_loss: 1.74333775, mean_g_loss: 1017.93402100\n",
            "Epoch:  99 Step:   556  time: 1.316674 s d_loss: 1.39473653, g_loss: 1035.59069824 -- mean_d_loss: 1.74111748, mean_g_loss: 1018.04644775\n",
            "Epoch:  99 Step:   557  time: 1.296985 s d_loss: 1.23120809, g_loss: 966.46289062 -- mean_d_loss: 1.73789012, mean_g_loss: 1017.72003174\n",
            "Epoch:  99 Step:   558  time: 1.304513 s d_loss: 0.96410304, g_loss: 878.44287109 -- mean_d_loss: 1.73302364, mean_g_loss: 1016.84405518\n",
            "Epoch:  99 Step:   559  time: 1.325722 s d_loss: 0.85583860, g_loss: 1076.02978516 -- mean_d_loss: 1.72754121, mean_g_loss: 1017.21398926\n",
            "Epoch:  99 Step:   560  time: 1.275290 s d_loss: 0.49192491, g_loss: 1077.04663086 -- mean_d_loss: 1.71986639, mean_g_loss: 1017.58557129\n",
            "Epoch:  99 Step:   561  time: 1.287044 s d_loss: 0.74049193, g_loss: 801.98223877 -- mean_d_loss: 1.71382082, mean_g_loss: 1016.25469971\n",
            "Epoch:  99 Step:   562  time: 1.287478 s d_loss: 1.32317758, g_loss: 1174.84985352 -- mean_d_loss: 1.71142423, mean_g_loss: 1017.22766113\n",
            "Epoch:  99 Step:   563  time: 1.306872 s d_loss: 0.74420696, g_loss: 997.18225098 -- mean_d_loss: 1.70552659, mean_g_loss: 1017.10546875\n",
            "Epoch:  99 Step:   564  time: 1.317501 s d_loss: 0.47662103, g_loss: 1252.46215820 -- mean_d_loss: 1.69807863, mean_g_loss: 1018.53192139\n",
            "Epoch:  99 Step:   565  time: 1.314095 s d_loss: 0.54032373, g_loss: 901.19921875 -- mean_d_loss: 1.69110417, mean_g_loss: 1017.82513428\n",
            "Epoch:  99 Step:   566  time: 1.315935 s d_loss: 1.12784934, g_loss: 1044.53027344 -- mean_d_loss: 1.68773139, mean_g_loss: 1017.98504639\n",
            "Epoch:  99 Step:   567  time: 1.320446 s d_loss: 2.57619882, g_loss: 993.54687500 -- mean_d_loss: 1.69301987, mean_g_loss: 1017.83953857\n",
            "Epoch:  99 Step:   568  time: 1.314757 s d_loss: 0.41427895, g_loss: 1084.87658691 -- mean_d_loss: 1.68545330, mean_g_loss: 1018.23620605\n",
            "Epoch:  99 Step:   569  time: 1.314649 s d_loss: 0.75812465, g_loss: 971.65496826 -- mean_d_loss: 1.67999840, mean_g_loss: 1017.96221924\n",
            "Epoch:  99 Step:   570  time: 1.312026 s d_loss: 0.52029991, g_loss: 976.90893555 -- mean_d_loss: 1.67321658, mean_g_loss: 1017.72210693\n",
            "Epoch:  99 Step:   571  time: 1.315543 s d_loss: 1.56116927, g_loss: 987.99359131 -- mean_d_loss: 1.67256498, mean_g_loss: 1017.54931641\n",
            "Epoch:  99 Step:   572  time: 1.324917 s d_loss: 0.68325984, g_loss: 987.75268555 -- mean_d_loss: 1.66684651, mean_g_loss: 1017.37707520\n",
            "Epoch:  99 Step:   573  time: 1.298143 s d_loss: 0.49135181, g_loss: 976.80364990 -- mean_d_loss: 1.66009080, mean_g_loss: 1017.14385986\n",
            "Epoch:  99 Step:   574  time: 1.322822 s d_loss: 0.75615203, g_loss: 1079.86474609 -- mean_d_loss: 1.65492558, mean_g_loss: 1017.50225830\n",
            "Epoch:  99 Step:   575  time: 1.309456 s d_loss: 0.40225035, g_loss: 984.44189453 -- mean_d_loss: 1.64780807, mean_g_loss: 1017.31439209\n",
            "Epoch:  99 Step:   576  time: 1.324314 s d_loss: 1.01777446, g_loss: 997.62072754 -- mean_d_loss: 1.64424849, mean_g_loss: 1017.20312500\n",
            "Epoch:  99 Step:   577  time: 1.285080 s d_loss: 4.15489531, g_loss: 1025.69799805 -- mean_d_loss: 1.65835333, mean_g_loss: 1017.25085449\n",
            "Epoch:  99 Step:   578  time: 1.283179 s d_loss: 1.00352585, g_loss: 997.88537598 -- mean_d_loss: 1.65469515, mean_g_loss: 1017.14270020\n",
            "Epoch:  99 Step:   579  time: 1.312521 s d_loss: 1.00815821, g_loss: 981.63897705 -- mean_d_loss: 1.65110326, mean_g_loss: 1016.94549561\n",
            "Epoch:  99 Step:   580  time: 1.309456 s d_loss: 0.86027414, g_loss: 1183.13061523 -- mean_d_loss: 1.64673388, mean_g_loss: 1017.86358643\n",
            "Epoch:  99 Step:   581  time: 1.293194 s d_loss: 1.09977889, g_loss: 838.57470703 -- mean_d_loss: 1.64372873, mean_g_loss: 1016.87854004\n",
            "Epoch:  99 Step:   582  time: 1.297448 s d_loss: 0.48026663, g_loss: 905.56799316 -- mean_d_loss: 1.63737094, mean_g_loss: 1016.27026367\n",
            "Epoch:  99 Step:   583  time: 1.320845 s d_loss: 0.56148964, g_loss: 946.56970215 -- mean_d_loss: 1.63152385, mean_g_loss: 1015.89141846\n",
            "Epoch:  99 Step:   584  time: 1.299441 s d_loss: 1.39641380, g_loss: 977.28625488 -- mean_d_loss: 1.63025296, mean_g_loss: 1015.68267822\n",
            "Epoch:  99 Step:   585  time: 1.323649 s d_loss: 0.57391667, g_loss: 1166.88403320 -- mean_d_loss: 1.62457371, mean_g_loss: 1016.49560547\n",
            "Epoch:  99 Step:   586  time: 1.286988 s d_loss: 0.73091400, g_loss: 1122.51892090 -- mean_d_loss: 1.61979485, mean_g_loss: 1017.06256104\n",
            "Epoch:  99 Step:   587  time: 1.320932 s d_loss: 0.45543319, g_loss: 1026.33007812 -- mean_d_loss: 1.61360157, mean_g_loss: 1017.11187744\n",
            "Epoch:  99 Step:   588  time: 1.290675 s d_loss: 0.56835657, g_loss: 1122.28674316 -- mean_d_loss: 1.60807109, mean_g_loss: 1017.66833496\n",
            "Epoch:  99 Step:   589  time: 1.303021 s d_loss: 1.50109446, g_loss: 1093.69909668 -- mean_d_loss: 1.60750818, mean_g_loss: 1018.06848145\n",
            "Epoch:  99 Step:   590  time: 1.323296 s d_loss: 0.57580513, g_loss: 1134.72448730 -- mean_d_loss: 1.60210657, mean_g_loss: 1018.67926025\n",
            "Epoch:  99 Step:   591  time: 1.339747 s d_loss: 0.69856137, g_loss: 1057.36230469 -- mean_d_loss: 1.59740055, mean_g_loss: 1018.88067627\n",
            "Epoch:  99 Step:   592  time: 1.312035 s d_loss: 1.20853901, g_loss: 1119.74291992 -- mean_d_loss: 1.59538567, mean_g_loss: 1019.40332031\n",
            "Epoch:  99 Step:   593  time: 1.324377 s d_loss: 0.87527770, g_loss: 1177.03527832 -- mean_d_loss: 1.59167373, mean_g_loss: 1020.21582031\n",
            "Epoch:  99 Step:   594  time: 1.326515 s d_loss: 0.71485174, g_loss: 841.81591797 -- mean_d_loss: 1.58717716, mean_g_loss: 1019.30096436\n",
            "Epoch:  99 Step:   595  time: 1.328162 s d_loss: 0.59537691, g_loss: 1177.63098145 -- mean_d_loss: 1.58211684, mean_g_loss: 1020.10876465\n",
            "Epoch:  99 Step:   596  time: 1.332142 s d_loss: 0.53053498, g_loss: 879.80432129 -- mean_d_loss: 1.57677901, mean_g_loss: 1019.39648438\n",
            "Epoch:  99 Step:   597  time: 1.321945 s d_loss: 0.64293724, g_loss: 990.14208984 -- mean_d_loss: 1.57206261, mean_g_loss: 1019.24871826\n",
            "Epoch:  99 Step:   598  time: 1.314131 s d_loss: 0.65689951, g_loss: 1139.59887695 -- mean_d_loss: 1.56746376, mean_g_loss: 1019.85351562\n",
            "Epoch:  99 Step:   599  time: 1.320217 s d_loss: 4.02011776, g_loss: 1016.90563965 -- mean_d_loss: 1.57972705, mean_g_loss: 1019.83874512\n",
            "Epoch:  99 Step:   600  time: 1.319046 s d_loss: 1.18213701, g_loss: 995.51965332 -- mean_d_loss: 1.18213701, mean_g_loss: 995.51965332\n",
            "Epoch:  99 Step:   601  time: 1.297461 s d_loss: 1.18225205, g_loss: 1238.44165039 -- mean_d_loss: 1.18219447, mean_g_loss: 1116.98071289\n",
            "Epoch:  99 Step:   602  time: 1.316483 s d_loss: 0.94303977, g_loss: 1007.91217041 -- mean_d_loss: 1.10247624, mean_g_loss: 1080.62451172\n",
            "Epoch:  99 Step:   603  time: 1.336842 s d_loss: 0.52587265, g_loss: 1036.26940918 -- mean_d_loss: 0.95832539, mean_g_loss: 1069.53576660\n",
            "Epoch:  99 Step:   604  time: 1.322953 s d_loss: 0.75902629, g_loss: 860.69348145 -- mean_d_loss: 0.91846561, mean_g_loss: 1027.76733398\n",
            "Epoch:  99 Step:   605  time: 1.325214 s d_loss: 0.59048510, g_loss: 950.28027344 -- mean_d_loss: 0.86380219, mean_g_loss: 1014.85278320\n",
            "Epoch:  99 Step:   606  time: 1.306348 s d_loss: 1.61236548, g_loss: 1003.14208984 -- mean_d_loss: 0.97073978, mean_g_loss: 1013.17980957\n",
            "Epoch:  99 Step:   607  time: 1.325815 s d_loss: 0.60053492, g_loss: 935.99194336 -- mean_d_loss: 0.92446417, mean_g_loss: 1003.53137207\n",
            "Epoch:  99 Step:   608  time: 1.327050 s d_loss: 0.60967666, g_loss: 1116.96459961 -- mean_d_loss: 0.88948780, mean_g_loss: 1016.13507080\n",
            "Epoch:  99 Step:   609  time: 1.345809 s d_loss: 0.51867580, g_loss: 1029.08398438 -- mean_d_loss: 0.85240662, mean_g_loss: 1017.42999268\n",
            "Epoch:  99 Step:   610  time: 1.342114 s d_loss: 1.18303561, g_loss: 978.47277832 -- mean_d_loss: 0.88246381, mean_g_loss: 1013.88842773\n",
            "Epoch:  99 Step:   611  time: 1.306778 s d_loss: 1.59574890, g_loss: 1195.24743652 -- mean_d_loss: 0.94190425, mean_g_loss: 1029.00158691\n",
            "Epoch:  99 Step:   612  time: 1.293581 s d_loss: 0.50792468, g_loss: 1013.77282715 -- mean_d_loss: 0.90852123, mean_g_loss: 1027.83020020\n",
            "Epoch:  99 Step:   613  time: 1.331705 s d_loss: 0.57587904, g_loss: 985.04296875 -- mean_d_loss: 0.88476104, mean_g_loss: 1024.77392578\n",
            "Epoch:  99 Step:   614  time: 1.332450 s d_loss: 0.53862011, g_loss: 993.01147461 -- mean_d_loss: 0.86168498, mean_g_loss: 1022.65643311\n",
            "Epoch:  99 Step:   615  time: 1.322378 s d_loss: 0.49176908, g_loss: 954.35186768 -- mean_d_loss: 0.83856523, mean_g_loss: 1018.38739014\n",
            "Epoch:  99 Step:   616  time: 1.330200 s d_loss: 0.49988639, g_loss: 1086.18530273 -- mean_d_loss: 0.81864297, mean_g_loss: 1022.37548828\n",
            "Epoch:  99 Step:   617  time: 1.283642 s d_loss: 0.54215050, g_loss: 995.59313965 -- mean_d_loss: 0.80328226, mean_g_loss: 1020.88757324\n",
            "Epoch:  99 Step:   618  time: 1.308396 s d_loss: 0.62617588, g_loss: 918.38073730 -- mean_d_loss: 0.79396087, mean_g_loss: 1015.49249268\n",
            "Epoch:  99 Step:   619  time: 1.314109 s d_loss: 0.62267607, g_loss: 958.79296875 -- mean_d_loss: 0.78539664, mean_g_loss: 1012.65753174\n",
            "Epoch:  99 Step:   620  time: 1.318281 s d_loss: 0.58365738, g_loss: 1035.65051270 -- mean_d_loss: 0.77578998, mean_g_loss: 1013.75244141\n",
            "Epoch:  99 Step:   621  time: 1.333771 s d_loss: 0.51178473, g_loss: 928.31713867 -- mean_d_loss: 0.76378977, mean_g_loss: 1009.86895752\n",
            "Epoch:  99 Step:   622  time: 1.325157 s d_loss: 0.58281958, g_loss: 1064.13012695 -- mean_d_loss: 0.75592148, mean_g_loss: 1012.22814941\n",
            "Epoch:  99 Step:   623  time: 1.302037 s d_loss: 0.87278932, g_loss: 854.57312012 -- mean_d_loss: 0.76079100, mean_g_loss: 1005.65917969\n",
            "Epoch:  99 Step:   624  time: 1.306820 s d_loss: 0.75449562, g_loss: 957.52905273 -- mean_d_loss: 0.76053917, mean_g_loss: 1003.73400879\n",
            "Epoch:  99 Step:   625  time: 1.289871 s d_loss: 0.44673821, g_loss: 1070.36022949 -- mean_d_loss: 0.74846989, mean_g_loss: 1006.29650879\n",
            "Epoch:  99 Step:   626  time: 1.324878 s d_loss: 0.59815717, g_loss: 1019.38055420 -- mean_d_loss: 0.74290276, mean_g_loss: 1006.78112793\n",
            "Epoch:  99 Step:   627  time: 1.326328 s d_loss: 0.66303205, g_loss: 1197.59326172 -- mean_d_loss: 0.74005026, mean_g_loss: 1013.59582520\n",
            "Epoch:  99 Step:   628  time: 1.333843 s d_loss: 0.55300945, g_loss: 1034.85595703 -- mean_d_loss: 0.73360056, mean_g_loss: 1014.32891846\n",
            "Epoch:  99 Step:   629  time: 1.303134 s d_loss: 1.20263004, g_loss: 1094.11975098 -- mean_d_loss: 0.74923491, mean_g_loss: 1016.98858643\n",
            "Epoch:  99 Step:   630  time: 1.319073 s d_loss: 0.52328104, g_loss: 898.50305176 -- mean_d_loss: 0.74194604, mean_g_loss: 1013.16650391\n",
            "Epoch:  99 Step:   631  time: 1.318625 s d_loss: 0.52472550, g_loss: 957.10198975 -- mean_d_loss: 0.73515791, mean_g_loss: 1011.41448975\n",
            "Epoch:  99 Step:   632  time: 1.296581 s d_loss: 0.61787313, g_loss: 991.01519775 -- mean_d_loss: 0.73160380, mean_g_loss: 1010.79626465\n",
            "Epoch:  99 Step:   633  time: 1.319650 s d_loss: 0.46595117, g_loss: 890.56433105 -- mean_d_loss: 0.72379053, mean_g_loss: 1007.26000977\n",
            "Epoch:  99 Step:   634  time: 1.281349 s d_loss: 0.56195962, g_loss: 1034.46386719 -- mean_d_loss: 0.71916676, mean_g_loss: 1008.03729248\n",
            "Epoch:  99 Step:   635  time: 1.326119 s d_loss: 0.41865954, g_loss: 1059.23132324 -- mean_d_loss: 0.71081936, mean_g_loss: 1009.45928955\n",
            "Epoch:  99 Step:   636  time: 1.316343 s d_loss: 0.46408209, g_loss: 990.12402344 -- mean_d_loss: 0.70415080, mean_g_loss: 1008.93676758\n",
            "Epoch:  99 Step:   637  time: 1.296830 s d_loss: 0.48792106, g_loss: 1067.87658691 -- mean_d_loss: 0.69846052, mean_g_loss: 1010.48779297\n",
            "Epoch:  99 Step:   638  time: 1.283486 s d_loss: 0.53050834, g_loss: 1005.67700195 -- mean_d_loss: 0.69415408, mean_g_loss: 1010.36437988\n",
            "Epoch:  99 Step:   639  time: 1.316885 s d_loss: 0.38896659, g_loss: 1079.41296387 -- mean_d_loss: 0.68652439, mean_g_loss: 1012.09063721\n",
            "Epoch:  99 Step:   640  time: 1.331693 s d_loss: 0.65882045, g_loss: 1011.33947754 -- mean_d_loss: 0.68584871, mean_g_loss: 1012.07232666\n",
            "Epoch:  99 Step:   641  time: 1.285050 s d_loss: 1.07389140, g_loss: 1008.78424072 -- mean_d_loss: 0.69508779, mean_g_loss: 1011.99401855\n",
            "Epoch:  99 Step:   642  time: 1.319488 s d_loss: 0.70340210, g_loss: 1021.51409912 -- mean_d_loss: 0.69528115, mean_g_loss: 1012.21545410\n",
            "Epoch:  99 Step:   643  time: 1.311972 s d_loss: 0.66539901, g_loss: 1058.42712402 -- mean_d_loss: 0.69460201, mean_g_loss: 1013.26568604\n",
            "Epoch:  99 Step:   644  time: 1.315056 s d_loss: 0.57797623, g_loss: 1009.80102539 -- mean_d_loss: 0.69201034, mean_g_loss: 1013.18872070\n",
            "Epoch:  99 Step:   645  time: 1.319191 s d_loss: 0.66350931, g_loss: 985.49035645 -- mean_d_loss: 0.69139075, mean_g_loss: 1012.58660889\n",
            "Epoch:  99 Step:   646  time: 1.280122 s d_loss: 1.11000323, g_loss: 1093.49047852 -- mean_d_loss: 0.70029742, mean_g_loss: 1014.30798340\n",
            "Epoch:  99 Step:   647  time: 1.349441 s d_loss: 0.57467735, g_loss: 1152.32836914 -- mean_d_loss: 0.69768029, mean_g_loss: 1017.18341064\n",
            "Epoch:  99 Step:   648  time: 1.311572 s d_loss: 0.81837374, g_loss: 960.83032227 -- mean_d_loss: 0.70014346, mean_g_loss: 1016.03338623\n",
            "Epoch:  99 Step:   649  time: 1.320016 s d_loss: 1.60065722, g_loss: 1053.98010254 -- mean_d_loss: 0.71815377, mean_g_loss: 1016.79235840\n",
            "Epoch:  99 Step:   650  time: 1.290515 s d_loss: 1.41294837, g_loss: 1087.85437012 -- mean_d_loss: 0.73177719, mean_g_loss: 1018.18572998\n",
            "Epoch:  99 Step:   651  time: 1.326322 s d_loss: 2.06986022, g_loss: 924.14416504 -- mean_d_loss: 0.75750953, mean_g_loss: 1016.37725830\n",
            "Epoch:  99 Step:   652  time: 1.328715 s d_loss: 2.62325668, g_loss: 1115.26672363 -- mean_d_loss: 0.79271233, mean_g_loss: 1018.24304199\n",
            "Epoch:  99 Step:   653  time: 1.291307 s d_loss: 2.45532179, g_loss: 999.08325195 -- mean_d_loss: 0.82350135, mean_g_loss: 1017.88824463\n",
            "Epoch:  99 Step:   654  time: 1.290330 s d_loss: 1.44399393, g_loss: 1111.19860840 -- mean_d_loss: 0.83478302, mean_g_loss: 1019.58477783\n",
            "Epoch:  99 Step:   655  time: 1.298209 s d_loss: 0.82053810, g_loss: 1079.12426758 -- mean_d_loss: 0.83452863, mean_g_loss: 1020.64801025\n",
            "Epoch:  99 Step:   656  time: 1.294635 s d_loss: 0.47662544, g_loss: 826.50665283 -- mean_d_loss: 0.82824963, mean_g_loss: 1017.24206543\n",
            "Epoch:  99 Step:   657  time: 1.277459 s d_loss: 0.63107228, g_loss: 821.08752441 -- mean_d_loss: 0.82485002, mean_g_loss: 1013.86004639\n",
            "Epoch:  99 Step:   658  time: 1.294892 s d_loss: 0.76258034, g_loss: 932.55590820 -- mean_d_loss: 0.82379460, mean_g_loss: 1012.48199463\n",
            "Epoch:  99 Step:   659  time: 1.319693 s d_loss: 0.58283705, g_loss: 1084.27172852 -- mean_d_loss: 0.81977862, mean_g_loss: 1013.67852783\n",
            "Epoch:  99 Step:   660  time: 1.319819 s d_loss: 0.48400566, g_loss: 980.47155762 -- mean_d_loss: 0.81427413, mean_g_loss: 1013.13415527\n",
            "Epoch:  99 Step:   661  time: 1.299942 s d_loss: 0.74814576, g_loss: 1004.83416748 -- mean_d_loss: 0.81320757, mean_g_loss: 1013.00030518\n",
            "Epoch:  99 Step:   662  time: 1.344136 s d_loss: 0.69709432, g_loss: 1031.16381836 -- mean_d_loss: 0.81136447, mean_g_loss: 1013.28863525\n",
            "Epoch:  99 Step:   663  time: 1.322362 s d_loss: 0.79913372, g_loss: 969.70550537 -- mean_d_loss: 0.81117338, mean_g_loss: 1012.60766602\n",
            "Epoch:  99 Step:   664  time: 1.339422 s d_loss: 0.49532923, g_loss: 909.28649902 -- mean_d_loss: 0.80631429, mean_g_loss: 1011.01812744\n",
            "Epoch:  99 Step:   665  time: 1.304570 s d_loss: 0.43282542, g_loss: 1012.07678223 -- mean_d_loss: 0.80065536, mean_g_loss: 1011.03417969\n",
            "Epoch:  99 Step:   666  time: 1.311813 s d_loss: 0.46499154, g_loss: 1103.07312012 -- mean_d_loss: 0.79564548, mean_g_loss: 1012.40789795\n",
            "Epoch:  99 Step:   667  time: 1.312740 s d_loss: 0.50022990, g_loss: 868.95812988 -- mean_d_loss: 0.79130113, mean_g_loss: 1010.29833984\n",
            "Epoch:  99 Step:   668  time: 1.313756 s d_loss: 0.83621079, g_loss: 1147.09606934 -- mean_d_loss: 0.79195201, mean_g_loss: 1012.28088379\n",
            "Epoch:  99 Step:   669  time: 1.287332 s d_loss: 0.48693195, g_loss: 1009.65795898 -- mean_d_loss: 0.78759456, mean_g_loss: 1012.24340820\n",
            "Epoch:  99 Step:   670  time: 1.290353 s d_loss: 0.41793445, g_loss: 920.52429199 -- mean_d_loss: 0.78238809, mean_g_loss: 1010.95159912\n",
            "Epoch:  99 Step:   671  time: 1.328667 s d_loss: 0.40961200, g_loss: 1027.37036133 -- mean_d_loss: 0.77721059, mean_g_loss: 1011.17956543\n",
            "Epoch:  99 Step:   672  time: 1.308916 s d_loss: 0.45781767, g_loss: 1036.72570801 -- mean_d_loss: 0.77283537, mean_g_loss: 1011.52954102\n",
            "Epoch:  99 Step:   673  time: 1.291691 s d_loss: 0.42301020, g_loss: 988.23437500 -- mean_d_loss: 0.76810801, mean_g_loss: 1011.21472168\n",
            "Epoch:  99 Step:   674  time: 1.330124 s d_loss: 0.40572184, g_loss: 1211.49304199 -- mean_d_loss: 0.76327622, mean_g_loss: 1013.88513184\n",
            "Epoch:  99 Step:   675  time: 1.328534 s d_loss: 0.33749670, g_loss: 849.98022461 -- mean_d_loss: 0.75767386, mean_g_loss: 1011.72839355\n",
            "Epoch:  99 Step:   676  time: 1.344917 s d_loss: 0.47501841, g_loss: 865.62951660 -- mean_d_loss: 0.75400299, mean_g_loss: 1009.83105469\n",
            "Epoch:  99 Step:   677  time: 1.348902 s d_loss: 0.61753035, g_loss: 1021.77270508 -- mean_d_loss: 0.75225335, mean_g_loss: 1009.98419189\n",
            "Epoch:  99 Step:   678  time: 1.317264 s d_loss: 0.81529593, g_loss: 1077.66455078 -- mean_d_loss: 0.75305140, mean_g_loss: 1010.84088135\n",
            "Epoch:  99 Step:   679  time: 1.321919 s d_loss: 5.29498720, g_loss: 942.79180908 -- mean_d_loss: 0.80982560, mean_g_loss: 1009.99023438\n",
            "Epoch:  99 Step:   680  time: 1.335012 s d_loss: 0.90204674, g_loss: 1101.07434082 -- mean_d_loss: 0.81096411, mean_g_loss: 1011.11474609\n",
            "Epoch:  99 Step:   681  time: 1.320606 s d_loss: 1.26052618, g_loss: 1138.83825684 -- mean_d_loss: 0.81644660, mean_g_loss: 1012.67236328\n",
            "Epoch:  99 Step:   682  time: 1.296788 s d_loss: 0.70346427, g_loss: 1033.13354492 -- mean_d_loss: 0.81508535, mean_g_loss: 1012.91888428\n",
            "Epoch:  99 Step:   683  time: 1.348345 s d_loss: 0.67654461, g_loss: 1004.95800781 -- mean_d_loss: 0.81343603, mean_g_loss: 1012.82409668\n",
            "Epoch:  99 Step:   684  time: 1.292593 s d_loss: 0.50775892, g_loss: 881.79028320 -- mean_d_loss: 0.80983984, mean_g_loss: 1011.28253174\n",
            "Epoch:  99 Step:   685  time: 1.307601 s d_loss: 0.63947302, g_loss: 1004.39825439 -- mean_d_loss: 0.80785882, mean_g_loss: 1011.20251465\n",
            "Epoch:  99 Step:   686  time: 1.284006 s d_loss: 0.43209836, g_loss: 995.08349609 -- mean_d_loss: 0.80353975, mean_g_loss: 1011.01721191\n",
            "Epoch:  99 Step:   687  time: 1.292647 s d_loss: 0.64208585, g_loss: 935.98669434 -- mean_d_loss: 0.80170500, mean_g_loss: 1010.16461182\n",
            "Epoch:  99 Step:   688  time: 1.334631 s d_loss: 0.91467988, g_loss: 900.67321777 -- mean_d_loss: 0.80297440, mean_g_loss: 1008.93432617\n",
            "Epoch:  99 Step:   689  time: 1.321575 s d_loss: 0.75608623, g_loss: 1087.38464355 -- mean_d_loss: 0.80245346, mean_g_loss: 1009.80596924\n",
            "Epoch:  99 Step:   690  time: 1.286179 s d_loss: 48.44029236, g_loss: 943.37811279 -- mean_d_loss: 1.32594621, mean_g_loss: 1009.07598877\n",
            "Epoch:  99 Step:   691  time: 1.330795 s d_loss: 2.33313608, g_loss: 1126.63403320 -- mean_d_loss: 1.33689392, mean_g_loss: 1010.35375977\n",
            "Epoch:  99 Step:   692  time: 1.342312 s d_loss: 1.69047987, g_loss: 974.68054199 -- mean_d_loss: 1.34069598, mean_g_loss: 1009.97015381\n",
            "Epoch:  99 Step:   693  time: 1.290746 s d_loss: 0.99752778, g_loss: 999.21319580 -- mean_d_loss: 1.33704519, mean_g_loss: 1009.85571289\n",
            "Epoch:  99 Step:   694  time: 1.303864 s d_loss: 0.67699480, g_loss: 902.36865234 -- mean_d_loss: 1.33009732, mean_g_loss: 1008.72424316\n",
            "Epoch:  99 Step:   695  time: 1.318032 s d_loss: 0.84434307, g_loss: 981.10089111 -- mean_d_loss: 1.32503736, mean_g_loss: 1008.43652344\n",
            "Epoch:  99 Step:   696  time: 1.300941 s d_loss: 0.84522688, g_loss: 930.43652344 -- mean_d_loss: 1.32009089, mean_g_loss: 1007.63238525\n",
            "Epoch:  99 Step:   697  time: 1.325384 s d_loss: 0.44433272, g_loss: 1026.62866211 -- mean_d_loss: 1.31115460, mean_g_loss: 1007.82623291\n",
            "Epoch:  99 Step:   698  time: 1.329326 s d_loss: 0.67414522, g_loss: 954.44067383 -- mean_d_loss: 1.30472016, mean_g_loss: 1007.28692627\n",
            "Epoch:  99 Step:   699  time: 1.312532 s d_loss: 0.62670755, g_loss: 973.35510254 -- mean_d_loss: 1.29794002, mean_g_loss: 1006.94757080\n",
            "Epoch:  99 Step:   700  time: 1.329357 s d_loss: 0.71786433, g_loss: 1210.52551270 -- mean_d_loss: 1.29219675, mean_g_loss: 1008.96319580\n",
            "Epoch:  99 Step:   701  time: 1.324808 s d_loss: 0.66422582, g_loss: 944.75024414 -- mean_d_loss: 1.28604019, mean_g_loss: 1008.33361816\n",
            "Epoch:  99 Step:   702  time: 1.317383 s d_loss: 0.64515370, g_loss: 997.03540039 -- mean_d_loss: 1.27981806, mean_g_loss: 1008.22399902\n",
            "Epoch:  99 Step:   703  time: 1.317648 s d_loss: 0.76692206, g_loss: 962.10186768 -- mean_d_loss: 1.27488637, mean_g_loss: 1007.78051758\n",
            "Epoch:  99 Step:   704  time: 1.306206 s d_loss: 0.70710599, g_loss: 852.01489258 -- mean_d_loss: 1.26947892, mean_g_loss: 1006.29699707\n",
            "Epoch:  99 Step:   705  time: 1.302279 s d_loss: 0.58859110, g_loss: 1172.47778320 -- mean_d_loss: 1.26305544, mean_g_loss: 1007.86474609\n",
            "Epoch:  99 Step:   706  time: 1.298012 s d_loss: 0.53243703, g_loss: 808.49078369 -- mean_d_loss: 1.25622725, mean_g_loss: 1006.00146484\n",
            "Epoch:  99 Step:   707  time: 1.311981 s d_loss: 0.49431247, g_loss: 889.09753418 -- mean_d_loss: 1.24917245, mean_g_loss: 1004.91900635\n",
            "Epoch:  99 Step:   708  time: 1.350824 s d_loss: 0.47259003, g_loss: 981.57238770 -- mean_d_loss: 1.24204791, mean_g_loss: 1004.70477295\n",
            "Epoch:  99 Step:   709  time: 1.321383 s d_loss: 0.64217383, g_loss: 1059.31274414 -- mean_d_loss: 1.23659456, mean_g_loss: 1005.20123291\n",
            "Epoch:  99 Step:   710  time: 1.320997 s d_loss: 0.59203756, g_loss: 1014.08410645 -- mean_d_loss: 1.23078775, mean_g_loss: 1005.28125000\n",
            "Epoch:  99 Step:   711  time: 1.328919 s d_loss: 0.54033595, g_loss: 1087.81848145 -- mean_d_loss: 1.22462296, mean_g_loss: 1006.01818848\n",
            "Epoch:  99 Step:   712  time: 1.303885 s d_loss: 0.52296650, g_loss: 957.35290527 -- mean_d_loss: 1.21841359, mean_g_loss: 1005.58752441\n",
            "Epoch:  99 Step:   713  time: 1.306463 s d_loss: 0.58580512, g_loss: 1097.01806641 -- mean_d_loss: 1.21286440, mean_g_loss: 1006.38952637\n",
            "Epoch:  99 Step:   714  time: 1.324826 s d_loss: 0.81141162, g_loss: 1073.21142578 -- mean_d_loss: 1.20937359, mean_g_loss: 1006.97058105\n",
            "Epoch:  99 Step:   715  time: 1.293975 s d_loss: 0.62780499, g_loss: 916.98352051 -- mean_d_loss: 1.20436001, mean_g_loss: 1006.19482422\n",
            "Epoch:  99 Step:   716  time: 1.324294 s d_loss: 0.48975343, g_loss: 1003.99157715 -- mean_d_loss: 1.19825220, mean_g_loss: 1006.17602539\n",
            "Epoch:  99 Step:   717  time: 1.308906 s d_loss: 0.47531846, g_loss: 888.17724609 -- mean_d_loss: 1.19212556, mean_g_loss: 1005.17602539\n",
            "Epoch:  99 Step:   718  time: 1.329068 s d_loss: 0.49003184, g_loss: 843.86889648 -- mean_d_loss: 1.18622565, mean_g_loss: 1003.82049561\n",
            "Epoch:  99 Step:   719  time: 1.327878 s d_loss: 0.61371899, g_loss: 956.67797852 -- mean_d_loss: 1.18145490, mean_g_loss: 1003.42767334\n",
            "Epoch:  99 Step:   720  time: 1.325488 s d_loss: 0.65165544, g_loss: 895.80218506 -- mean_d_loss: 1.17707634, mean_g_loss: 1002.53820801\n",
            "Epoch:  99 Step:   721  time: 1.292825 s d_loss: 0.41580299, g_loss: 867.37927246 -- mean_d_loss: 1.17083645, mean_g_loss: 1001.43041992\n",
            "Epoch:  99 Step:   722  time: 1.348114 s d_loss: 0.62246507, g_loss: 1031.27136230 -- mean_d_loss: 1.16637814, mean_g_loss: 1001.67303467\n",
            "Epoch:  99 Step:   723  time: 1.322522 s d_loss: 0.51509589, g_loss: 1017.21441650 -- mean_d_loss: 1.16112578, mean_g_loss: 1001.79833984\n",
            "Epoch:  99 Step:   724  time: 1.290728 s d_loss: 0.70339841, g_loss: 1277.30859375 -- mean_d_loss: 1.15746403, mean_g_loss: 1004.00238037\n",
            "Epoch:  99 Step:   725  time: 1.325367 s d_loss: 0.55852389, g_loss: 883.20465088 -- mean_d_loss: 1.15271044, mean_g_loss: 1003.04364014\n",
            "Epoch:  99 Step:   726  time: 1.283932 s d_loss: 0.43897802, g_loss: 988.47729492 -- mean_d_loss: 1.14709055, mean_g_loss: 1002.92895508\n",
            "Epoch:  99 Step:   727  time: 1.324002 s d_loss: 0.69461435, g_loss: 900.19189453 -- mean_d_loss: 1.14355552, mean_g_loss: 1002.12634277\n",
            "Epoch:  99 Step:   728  time: 1.305077 s d_loss: 27.60869026, g_loss: 1209.74060059 -- mean_d_loss: 1.34871161, mean_g_loss: 1003.73577881\n",
            "Epoch:  99 Step:   729  time: 1.289400 s d_loss: 1.32940412, g_loss: 1044.98254395 -- mean_d_loss: 1.34856308, mean_g_loss: 1004.05303955\n",
            "Epoch:  99 Step:   730  time: 1.309510 s d_loss: 1.90338564, g_loss: 1007.29553223 -- mean_d_loss: 1.35279834, mean_g_loss: 1004.07775879\n",
            "Epoch:  99 Step:   731  time: 1.303416 s d_loss: 0.68166316, g_loss: 1070.28137207 -- mean_d_loss: 1.34771395, mean_g_loss: 1004.57928467\n",
            "Epoch:  99 Step:   732  time: 1.331486 s d_loss: 0.48856074, g_loss: 993.09252930 -- mean_d_loss: 1.34125412, mean_g_loss: 1004.49298096\n",
            "Epoch:  99 Step:   733  time: 1.324924 s d_loss: 0.56571603, g_loss: 895.77575684 -- mean_d_loss: 1.33546650, mean_g_loss: 1003.68164062\n",
            "Epoch:  99 Step:   734  time: 1.331054 s d_loss: 0.79160058, g_loss: 915.60656738 -- mean_d_loss: 1.33143783, mean_g_loss: 1003.02929688\n",
            "Epoch:  99 Step:   735  time: 1.316876 s d_loss: 0.51723558, g_loss: 873.12646484 -- mean_d_loss: 1.32545114, mean_g_loss: 1002.07409668\n",
            "Epoch:  99 Step:   736  time: 1.341761 s d_loss: 0.83896327, g_loss: 1044.08471680 -- mean_d_loss: 1.32190013, mean_g_loss: 1002.38067627\n",
            "Epoch:  99 Step:   737  time: 1.293086 s d_loss: 0.65803200, g_loss: 974.19219971 -- mean_d_loss: 1.31708944, mean_g_loss: 1002.17639160\n",
            "Epoch:  99 Step:   738  time: 1.323477 s d_loss: 1.04928613, g_loss: 954.72863770 -- mean_d_loss: 1.31516278, mean_g_loss: 1001.83508301\n",
            "Epoch:  99 Step:   739  time: 1.302225 s d_loss: 0.64427263, g_loss: 995.95013428 -- mean_d_loss: 1.31037080, mean_g_loss: 1001.79309082\n",
            "Epoch:  99 Step:   740  time: 1.318423 s d_loss: 1.28811240, g_loss: 1114.31372070 -- mean_d_loss: 1.31021297, mean_g_loss: 1002.59106445\n",
            "Epoch:  99 Step:   741  time: 1.287687 s d_loss: 0.71931076, g_loss: 996.24005127 -- mean_d_loss: 1.30605161, mean_g_loss: 1002.54632568\n",
            "Epoch:  99 Step:   742  time: 1.318719 s d_loss: 0.53181899, g_loss: 1145.97070312 -- mean_d_loss: 1.30063736, mean_g_loss: 1003.54925537\n",
            "Epoch:  99 Step:   743  time: 1.334063 s d_loss: 0.72784311, g_loss: 1268.86718750 -- mean_d_loss: 1.29665971, mean_g_loss: 1005.39172363\n",
            "Epoch:  99 Step:   744  time: 1.309047 s d_loss: 0.80930895, g_loss: 848.17492676 -- mean_d_loss: 1.29329860, mean_g_loss: 1004.30743408\n",
            "Epoch:  99 Step:   745  time: 1.303412 s d_loss: 1.16979945, g_loss: 1109.70361328 -- mean_d_loss: 1.29245281, mean_g_loss: 1005.02929688\n",
            "Epoch:  99 Step:   746  time: 1.330846 s d_loss: 0.85786992, g_loss: 1091.02148438 -- mean_d_loss: 1.28949642, mean_g_loss: 1005.61425781\n",
            "Epoch:  99 Step:   747  time: 1.353990 s d_loss: 0.70468974, g_loss: 974.80102539 -- mean_d_loss: 1.28554499, mean_g_loss: 1005.40606689\n",
            "Epoch:  99 Step:   748  time: 1.309110 s d_loss: 0.40156916, g_loss: 1007.99786377 -- mean_d_loss: 1.27961230, mean_g_loss: 1005.42346191\n",
            "Epoch:  99 Step:   749  time: 1.323327 s d_loss: 3.86951089, g_loss: 975.75695801 -- mean_d_loss: 1.29687822, mean_g_loss: 1005.22564697\n",
            "Epoch:  99 Step:   750  time: 1.320979 s d_loss: 0.68259740, g_loss: 1047.18566895 -- mean_d_loss: 1.29281020, mean_g_loss: 1005.50354004\n",
            "Epoch:  99 Step:   751  time: 1.304678 s d_loss: 0.60572273, g_loss: 1101.60266113 -- mean_d_loss: 1.28828990, mean_g_loss: 1006.13580322\n",
            "Epoch:  99 Step:   752  time: 1.289897 s d_loss: 0.74652386, g_loss: 899.20959473 -- mean_d_loss: 1.28474891, mean_g_loss: 1005.43688965\n",
            "Epoch:  99 Step:   753  time: 1.301968 s d_loss: 0.71024197, g_loss: 1010.86633301 -- mean_d_loss: 1.28101838, mean_g_loss: 1005.47210693\n",
            "Epoch:  99 Step:   754  time: 1.313716 s d_loss: 0.52849090, g_loss: 870.82800293 -- mean_d_loss: 1.27616334, mean_g_loss: 1004.60345459\n",
            "Epoch:  99 Step:   755  time: 1.320717 s d_loss: 0.58656299, g_loss: 1112.67541504 -- mean_d_loss: 1.27174282, mean_g_loss: 1005.29620361\n",
            "Epoch:  99 Step:   756  time: 1.332623 s d_loss: 0.53541666, g_loss: 961.99609375 -- mean_d_loss: 1.26705277, mean_g_loss: 1005.02038574\n",
            "Epoch:  99 Step:   757  time: 1.296876 s d_loss: 0.48924962, g_loss: 890.21496582 -- mean_d_loss: 1.26213002, mean_g_loss: 1004.29382324\n",
            "Epoch:  99 Step:   758  time: 1.320951 s d_loss: 0.63441813, g_loss: 915.78857422 -- mean_d_loss: 1.25818205, mean_g_loss: 1003.73712158\n",
            "Epoch:  99 Step:   759  time: 1.316434 s d_loss: 0.60045922, g_loss: 1013.83923340 -- mean_d_loss: 1.25407135, mean_g_loss: 1003.80029297\n",
            "Epoch:  99 Step:   760  time: 1.294479 s d_loss: 0.43743318, g_loss: 1054.99365234 -- mean_d_loss: 1.24899912, mean_g_loss: 1004.11828613\n",
            "Epoch:  99 Step:   761  time: 1.285735 s d_loss: 0.46855637, g_loss: 989.89550781 -- mean_d_loss: 1.24418151, mean_g_loss: 1004.03045654\n",
            "Epoch:  99 Step:   762  time: 1.326434 s d_loss: 0.54850417, g_loss: 972.47479248 -- mean_d_loss: 1.23991358, mean_g_loss: 1003.83685303\n",
            "Epoch:  99 Step:   763  time: 1.334792 s d_loss: 3.65236378, g_loss: 1181.14428711 -- mean_d_loss: 1.25462365, mean_g_loss: 1004.91796875\n",
            "Epoch:  99 Step:   764  time: 1.295500 s d_loss: 0.78221536, g_loss: 974.25146484 -- mean_d_loss: 1.25176048, mean_g_loss: 1004.73211670\n",
            "Epoch:  99 Step:   765  time: 1.323370 s d_loss: 0.70096987, g_loss: 937.10534668 -- mean_d_loss: 1.24844253, mean_g_loss: 1004.32470703\n",
            "Epoch:  99 Step:   766  time: 1.309726 s d_loss: 0.59456861, g_loss: 877.71032715 -- mean_d_loss: 1.24452710, mean_g_loss: 1003.56652832\n",
            "Epoch:  99 Step:   767  time: 1.327417 s d_loss: 0.57621229, g_loss: 946.42279053 -- mean_d_loss: 1.24054909, mean_g_loss: 1003.22637939\n",
            "Epoch:  99 Step:   768  time: 1.340013 s d_loss: 0.57681328, g_loss: 1042.08178711 -- mean_d_loss: 1.23662162, mean_g_loss: 1003.45629883\n",
            "Epoch:  99 Step:   769  time: 1.285881 s d_loss: 0.78596985, g_loss: 1056.84448242 -- mean_d_loss: 1.23397076, mean_g_loss: 1003.77032471\n",
            "Epoch:  99 Step:   770  time: 1.331816 s d_loss: 0.68018395, g_loss: 1065.24450684 -- mean_d_loss: 1.23073220, mean_g_loss: 1004.12982178\n",
            "Epoch:  99 Step:   771  time: 1.307203 s d_loss: 0.64299732, g_loss: 1070.69018555 -- mean_d_loss: 1.22731519, mean_g_loss: 1004.51678467\n",
            "Epoch:  99 Step:   772  time: 1.328670 s d_loss: 0.74962062, g_loss: 996.11376953 -- mean_d_loss: 1.22455394, mean_g_loss: 1004.46820068\n",
            "Epoch:  99 Step:   773  time: 1.303491 s d_loss: 38.97357178, g_loss: 909.61676025 -- mean_d_loss: 1.44150233, mean_g_loss: 1003.92303467\n",
            "Epoch:  99 Step:   774  time: 1.314035 s d_loss: 1.68356597, g_loss: 872.07214355 -- mean_d_loss: 1.44288552, mean_g_loss: 1003.16961670\n",
            "Epoch:  99 Step:   775  time: 1.307014 s d_loss: 1.59017622, g_loss: 963.46520996 -- mean_d_loss: 1.44372237, mean_g_loss: 1002.94409180\n",
            "Epoch:  99 Step:   776  time: 1.346423 s d_loss: 1.56558931, g_loss: 1109.45825195 -- mean_d_loss: 1.44441080, mean_g_loss: 1003.54583740\n",
            "Epoch:  99 Step:   777  time: 1.292086 s d_loss: 0.73588598, g_loss: 975.25701904 -- mean_d_loss: 1.44043040, mean_g_loss: 1003.38684082\n",
            "Epoch:  99 Step:   778  time: 1.340688 s d_loss: 1.05156648, g_loss: 1009.32250977 -- mean_d_loss: 1.43825805, mean_g_loss: 1003.42004395\n",
            "Epoch:  99 Step:   779  time: 1.290656 s d_loss: 1.28937638, g_loss: 1119.86376953 -- mean_d_loss: 1.43743086, mean_g_loss: 1004.06695557\n",
            "Epoch:  99 Step:   780  time: 1.320807 s d_loss: 1.55981493, g_loss: 927.55426025 -- mean_d_loss: 1.43810701, mean_g_loss: 1003.64416504\n",
            "Epoch:  99 Step:   781  time: 1.316210 s d_loss: 1.56354582, g_loss: 1016.70214844 -- mean_d_loss: 1.43879616, mean_g_loss: 1003.71594238\n",
            "Epoch:  99 Step:   782  time: 1.345270 s d_loss: 1.25402021, g_loss: 923.81213379 -- mean_d_loss: 1.43778646, mean_g_loss: 1003.27929688\n",
            "Epoch:  99 Step:   783  time: 1.314338 s d_loss: 1.03284574, g_loss: 1027.86791992 -- mean_d_loss: 1.43558574, mean_g_loss: 1003.41296387\n",
            "Epoch:  99 Step:   784  time: 1.305788 s d_loss: 20.03786850, g_loss: 992.14898682 -- mean_d_loss: 1.53613853, mean_g_loss: 1003.35211182\n",
            "Epoch:  99 Step:   785  time: 1.315900 s d_loss: 2.75685382, g_loss: 883.64508057 -- mean_d_loss: 1.54270160, mean_g_loss: 1002.70849609\n",
            "Epoch:  99 Step:   786  time: 1.300492 s d_loss: 1.78472304, g_loss: 993.74169922 -- mean_d_loss: 1.54399586, mean_g_loss: 1002.66052246\n",
            "Epoch:  99 Step:   787  time: 1.321176 s d_loss: 2.15678596, g_loss: 992.99835205 -- mean_d_loss: 1.54725552, mean_g_loss: 1002.60913086\n",
            "Epoch:  99 Step:   788  time: 1.295453 s d_loss: 3.34865284, g_loss: 1130.04736328 -- mean_d_loss: 1.55678678, mean_g_loss: 1003.28338623\n",
            "Epoch:  99 Step:   789  time: 1.320180 s d_loss: 5.23929119, g_loss: 981.94116211 -- mean_d_loss: 1.57616830, mean_g_loss: 1003.17108154\n",
            "Epoch:  99 Step:   790  time: 1.302324 s d_loss: 3.24393940, g_loss: 1107.02221680 -- mean_d_loss: 1.58490002, mean_g_loss: 1003.71472168\n",
            "Epoch:  99 Step:   791  time: 1.291765 s d_loss: 1.81318200, g_loss: 963.04980469 -- mean_d_loss: 1.58608902, mean_g_loss: 1003.50292969\n",
            "Epoch:  99 Step:   792  time: 1.298114 s d_loss: 1.18967950, g_loss: 941.48052979 -- mean_d_loss: 1.58403492, mean_g_loss: 1003.18157959\n",
            "Epoch:  99 Step:   793  time: 1.325552 s d_loss: 0.72970200, g_loss: 998.79559326 -- mean_d_loss: 1.57963121, mean_g_loss: 1003.15899658\n",
            "Epoch:  99 Step:   794  time: 1.295699 s d_loss: 1.00933027, g_loss: 927.61645508 -- mean_d_loss: 1.57670665, mean_g_loss: 1002.77154541\n",
            "Epoch:  99 Step:   795  time: 1.315786 s d_loss: 7.97763109, g_loss: 1142.15698242 -- mean_d_loss: 1.60936439, mean_g_loss: 1003.48272705\n",
            "Epoch:  99 Step:   796  time: 1.316022 s d_loss: 0.60791159, g_loss: 1000.52130127 -- mean_d_loss: 1.60428083, mean_g_loss: 1003.46765137\n",
            "Epoch:  99 Step:   797  time: 1.308388 s d_loss: 0.77680784, g_loss: 1235.73388672 -- mean_d_loss: 1.60010171, mean_g_loss: 1004.64068604\n",
            "Epoch:  99 Step:   798  time: 1.294912 s d_loss: 0.81710821, g_loss: 1047.31835938 -- mean_d_loss: 1.59616697, mean_g_loss: 1004.85516357\n",
            "Epoch:  99 Step:   799  time: 1.305896 s d_loss: 0.70477200, g_loss: 1132.35412598 -- mean_d_loss: 1.59171009, mean_g_loss: 1005.49267578\n",
            "Epoch:  99 Step:   800  time: 1.320989 s d_loss: 1.01616323, g_loss: 1256.92224121 -- mean_d_loss: 1.01616323, mean_g_loss: 1256.92224121\n",
            "Epoch:  99 Step:   801  time: 1.313203 s d_loss: 2.27620578, g_loss: 1125.97033691 -- mean_d_loss: 1.64618444, mean_g_loss: 1191.44628906\n",
            "Epoch:  99 Step:   802  time: 1.286471 s d_loss: 0.97233343, g_loss: 979.81555176 -- mean_d_loss: 1.42156744, mean_g_loss: 1120.90270996\n",
            "Epoch:  99 Step:   803  time: 1.353824 s d_loss: 0.95844620, g_loss: 960.23986816 -- mean_d_loss: 1.30578709, mean_g_loss: 1080.73693848\n",
            "Epoch:  99 Step:   804  time: 1.326690 s d_loss: 1.12711072, g_loss: 875.45288086 -- mean_d_loss: 1.27005172, mean_g_loss: 1039.68005371\n",
            "Epoch:  99 Step:   805  time: 1.311184 s d_loss: 0.77966642, g_loss: 1105.50317383 -- mean_d_loss: 1.18832088, mean_g_loss: 1050.65051270\n",
            "Epoch:  99 Step:   806  time: 1.281182 s d_loss: 1.10494208, g_loss: 893.73919678 -- mean_d_loss: 1.17640960, mean_g_loss: 1028.23461914\n",
            "Epoch:  99 Step:   807  time: 1.290061 s d_loss: 0.81219172, g_loss: 945.49304199 -- mean_d_loss: 1.13088238, mean_g_loss: 1017.89196777\n",
            "Epoch:  99 Step:   808  time: 1.340321 s d_loss: 1.12821662, g_loss: 945.00756836 -- mean_d_loss: 1.13058615, mean_g_loss: 1009.79370117\n",
            "Epoch:  99 Step:   809  time: 1.329049 s d_loss: 1.21027613, g_loss: 1311.24121094 -- mean_d_loss: 1.13855517, mean_g_loss: 1039.93847656\n",
            "Epoch:  99 Step:   810  time: 1.323828 s d_loss: 1.54901612, g_loss: 951.80615234 -- mean_d_loss: 1.17586982, mean_g_loss: 1031.92651367\n",
            "Epoch:  99 Step:   811  time: 1.313674 s d_loss: 1.80189157, g_loss: 997.75585938 -- mean_d_loss: 1.22803819, mean_g_loss: 1029.07897949\n",
            "Epoch:  99 Step:   812  time: 1.314817 s d_loss: 1.47831023, g_loss: 1079.93286133 -- mean_d_loss: 1.24728990, mean_g_loss: 1032.99072266\n",
            "Epoch:  99 Step:   813  time: 1.322590 s d_loss: 0.82455206, g_loss: 1147.50708008 -- mean_d_loss: 1.21709442, mean_g_loss: 1041.17053223\n",
            "Epoch:  99 Step:   814  time: 1.337010 s d_loss: 0.53908062, g_loss: 1002.89056396 -- mean_d_loss: 1.17189360, mean_g_loss: 1038.61853027\n",
            "Epoch:  99 Step:   815  time: 1.304764 s d_loss: 0.76020497, g_loss: 1052.44567871 -- mean_d_loss: 1.14616299, mean_g_loss: 1039.48266602\n",
            "Epoch:  99 Step:   816  time: 1.329117 s d_loss: 0.67075652, g_loss: 1069.86059570 -- mean_d_loss: 1.11819792, mean_g_loss: 1041.26965332\n",
            "Epoch:  99 Step:   817  time: 1.306411 s d_loss: 0.54376054, g_loss: 837.57653809 -- mean_d_loss: 1.08628476, mean_g_loss: 1029.95336914\n",
            "Epoch:  99 Step:   818  time: 1.327075 s d_loss: 0.67945433, g_loss: 1186.40502930 -- mean_d_loss: 1.06487262, mean_g_loss: 1038.18762207\n",
            "Epoch:  99 Step:   819  time: 1.317777 s d_loss: 47.04989624, g_loss: 1047.34399414 -- mean_d_loss: 3.36412382, mean_g_loss: 1038.64538574\n",
            "Epoch:  99 Step:   820  time: 1.318255 s d_loss: 2.17331386, g_loss: 1100.36535645 -- mean_d_loss: 3.30741882, mean_g_loss: 1041.58447266\n",
            "Epoch:  99 Step:   821  time: 1.316955 s d_loss: 1.85371304, g_loss: 917.10485840 -- mean_d_loss: 3.24134135, mean_g_loss: 1035.92626953\n",
            "Epoch:  99 Step:   822  time: 1.310273 s d_loss: 0.99925935, g_loss: 952.50720215 -- mean_d_loss: 3.14385962, mean_g_loss: 1032.29943848\n",
            "Epoch:  99 Step:   823  time: 1.309915 s d_loss: 0.70690382, g_loss: 966.75860596 -- mean_d_loss: 3.04231954, mean_g_loss: 1029.56848145\n",
            "Epoch:  99 Step:   824  time: 1.293763 s d_loss: 0.95893455, g_loss: 1154.62841797 -- mean_d_loss: 2.95898414, mean_g_loss: 1034.57092285\n",
            "Epoch:  99 Step:   825  time: 1.315907 s d_loss: 0.81736624, g_loss: 995.79772949 -- mean_d_loss: 2.87661409, mean_g_loss: 1033.07958984\n",
            "Epoch:  99 Step:   826  time: 1.323946 s d_loss: 0.65424198, g_loss: 1058.34606934 -- mean_d_loss: 2.79430413, mean_g_loss: 1034.01538086\n",
            "Epoch:  99 Step:   827  time: 1.318247 s d_loss: 1.02004409, g_loss: 1008.27185059 -- mean_d_loss: 2.73093772, mean_g_loss: 1033.09594727\n",
            "Epoch:  99 Step:   828  time: 1.319980 s d_loss: 0.60530114, g_loss: 933.42150879 -- mean_d_loss: 2.65763998, mean_g_loss: 1029.65893555\n",
            "Epoch:  99 Step:   829  time: 1.313654 s d_loss: 0.66563761, g_loss: 841.64904785 -- mean_d_loss: 2.59123969, mean_g_loss: 1023.39190674\n",
            "Epoch:  99 Step:   830  time: 1.308751 s d_loss: 0.64592904, g_loss: 947.85284424 -- mean_d_loss: 2.52848768, mean_g_loss: 1020.95520020\n",
            "Epoch:  99 Step:   831  time: 1.311829 s d_loss: 0.45232350, g_loss: 901.50073242 -- mean_d_loss: 2.46360755, mean_g_loss: 1017.22222900\n",
            "Epoch:  99 Step:   832  time: 1.304274 s d_loss: 0.48109511, g_loss: 978.80517578 -- mean_d_loss: 2.40353131, mean_g_loss: 1016.05810547\n",
            "Epoch:  99 Step:   833  time: 1.308978 s d_loss: 0.47281086, g_loss: 965.26147461 -- mean_d_loss: 2.34674549, mean_g_loss: 1014.56408691\n",
            "Epoch:  99 Step:   834  time: 1.301178 s d_loss: 0.72381037, g_loss: 1013.15765381 -- mean_d_loss: 2.30037570, mean_g_loss: 1014.52386475\n",
            "Epoch:  99 Step:   835  time: 1.315382 s d_loss: 0.54189050, g_loss: 969.33825684 -- mean_d_loss: 2.25152898, mean_g_loss: 1013.26879883\n",
            "Epoch:  99 Step:   836  time: 1.287756 s d_loss: 0.44731167, g_loss: 1008.35729980 -- mean_d_loss: 2.20276642, mean_g_loss: 1013.13598633\n",
            "Epoch:  99 Step:   837  time: 1.290446 s d_loss: 2.10594893, g_loss: 918.76971436 -- mean_d_loss: 2.20021868, mean_g_loss: 1010.65264893\n",
            "Epoch:  99 Step:   838  time: 1.296129 s d_loss: 0.57026446, g_loss: 1181.03393555 -- mean_d_loss: 2.15842485, mean_g_loss: 1015.02142334\n",
            "Epoch:  99 Step:   839  time: 1.292808 s d_loss: 3.26466060, g_loss: 1112.86254883 -- mean_d_loss: 2.18608093, mean_g_loss: 1017.46746826\n",
            "Epoch:  99 Step:   840  time: 1.312808 s d_loss: 0.79159629, g_loss: 959.20391846 -- mean_d_loss: 2.15206909, mean_g_loss: 1016.04638672\n",
            "Epoch:  99 Step:   841  time: 1.335898 s d_loss: 0.71713167, g_loss: 820.44775391 -- mean_d_loss: 2.11790395, mean_g_loss: 1011.38934326\n",
            "Epoch:  99 Step:   842  time: 1.309357 s d_loss: 0.88685584, g_loss: 1107.71398926 -- mean_d_loss: 2.08927488, mean_g_loss: 1013.62945557\n",
            "Epoch:  99 Step:   843  time: 1.311882 s d_loss: 0.93357402, g_loss: 975.83099365 -- mean_d_loss: 2.06300902, mean_g_loss: 1012.77044678\n",
            "Epoch:  99 Step:   844  time: 1.309813 s d_loss: 0.70527655, g_loss: 1118.52124023 -- mean_d_loss: 2.03283715, mean_g_loss: 1015.12042236\n",
            "Epoch:  99 Step:   845  time: 1.307737 s d_loss: 0.68775016, g_loss: 812.37969971 -- mean_d_loss: 2.00359607, mean_g_loss: 1010.71295166\n",
            "Epoch:  99 Step:   846  time: 1.323787 s d_loss: 0.89291495, g_loss: 973.78503418 -- mean_d_loss: 1.97996461, mean_g_loss: 1009.92730713\n",
            "Epoch:  99 Step:   847  time: 1.340566 s d_loss: 1.09125912, g_loss: 1084.96997070 -- mean_d_loss: 1.96144998, mean_g_loss: 1011.49066162\n",
            "Epoch:  99 Step:   848  time: 1.296391 s d_loss: 1.20868897, g_loss: 1047.47033691 -- mean_d_loss: 1.94608748, mean_g_loss: 1012.22491455\n",
            "Epoch:  99 Step:   849  time: 1.298269 s d_loss: 0.63073039, g_loss: 997.27770996 -- mean_d_loss: 1.91978025, mean_g_loss: 1011.92596436\n",
            "Epoch:  99 Step:   850  time: 1.304160 s d_loss: 0.50941521, g_loss: 1146.55847168 -- mean_d_loss: 1.89212608, mean_g_loss: 1014.56579590\n",
            "Epoch:  99 Step:   851  time: 1.318295 s d_loss: 0.59663481, g_loss: 994.85186768 -- mean_d_loss: 1.86721277, mean_g_loss: 1014.18664551\n",
            "Epoch:  99 Step:   852  time: 1.297940 s d_loss: 0.59909421, g_loss: 938.08941650 -- mean_d_loss: 1.84328592, mean_g_loss: 1012.75085449\n",
            "Epoch:  99 Step:   853  time: 1.322660 s d_loss: 0.55801523, g_loss: 954.53332520 -- mean_d_loss: 1.81948459, mean_g_loss: 1011.67279053\n",
            "Epoch:  99 Step:   854  time: 1.306814 s d_loss: 0.65674901, g_loss: 932.76257324 -- mean_d_loss: 1.79834390, mean_g_loss: 1010.23809814\n",
            "Epoch:  99 Step:   855  time: 1.345913 s d_loss: 0.54994607, g_loss: 1100.27465820 -- mean_d_loss: 1.77605116, mean_g_loss: 1011.84582520\n",
            "Epoch:  99 Step:   856  time: 1.342580 s d_loss: 0.63828242, g_loss: 928.82653809 -- mean_d_loss: 1.75609028, mean_g_loss: 1010.38940430\n",
            "Epoch:  99 Step:   857  time: 1.313540 s d_loss: 0.44821000, g_loss: 969.40869141 -- mean_d_loss: 1.73354065, mean_g_loss: 1009.68286133\n",
            "Epoch:  99 Step:   858  time: 1.298398 s d_loss: 0.47880280, g_loss: 880.78125000 -- mean_d_loss: 1.71227396, mean_g_loss: 1007.49810791\n",
            "Epoch:  99 Step:   859  time: 1.314427 s d_loss: 1.30838025, g_loss: 1083.93225098 -- mean_d_loss: 1.70554233, mean_g_loss: 1008.77203369\n",
            "Epoch:  99 Step:   860  time: 1.324752 s d_loss: 0.45468566, g_loss: 1040.49584961 -- mean_d_loss: 1.68503654, mean_g_loss: 1009.29205322\n",
            "Epoch:  99 Step:   861  time: 1.311080 s d_loss: 0.57411277, g_loss: 980.64050293 -- mean_d_loss: 1.66711843, mean_g_loss: 1008.82995605\n",
            "Epoch:  99 Step:   862  time: 1.301888 s d_loss: 0.60719734, g_loss: 1001.65502930 -- mean_d_loss: 1.65029430, mean_g_loss: 1008.71606445\n",
            "Epoch:  99 Step:   863  time: 1.330117 s d_loss: 0.50043708, g_loss: 988.21630859 -- mean_d_loss: 1.63232780, mean_g_loss: 1008.39575195\n",
            "Epoch:  99 Step:   864  time: 1.282697 s d_loss: 0.69827193, g_loss: 1174.29699707 -- mean_d_loss: 1.61795771, mean_g_loss: 1010.94805908\n",
            "Epoch:  99 Step:   865  time: 1.295545 s d_loss: 0.52361214, g_loss: 991.06005859 -- mean_d_loss: 1.60137677, mean_g_loss: 1010.64678955\n",
            "Epoch:  99 Step:   866  time: 1.295771 s d_loss: 0.57003617, g_loss: 1002.57055664 -- mean_d_loss: 1.58598363, mean_g_loss: 1010.52624512\n",
            "Epoch:  99 Step:   867  time: 1.314477 s d_loss: 0.47584134, g_loss: 934.48339844 -- mean_d_loss: 1.56965792, mean_g_loss: 1009.40795898\n",
            "Epoch:  99 Step:   868  time: 1.290194 s d_loss: 13.75742912, g_loss: 933.02935791 -- mean_d_loss: 1.74629235, mean_g_loss: 1008.30108643\n",
            "Epoch:  99 Step:   869  time: 1.311895 s d_loss: 1.39890766, g_loss: 870.83581543 -- mean_d_loss: 1.74132979, mean_g_loss: 1006.33728027\n",
            "Epoch:  99 Step:   870  time: 1.314310 s d_loss: 1.46818376, g_loss: 1111.68261719 -- mean_d_loss: 1.73748267, mean_g_loss: 1007.82098389\n",
            "Epoch:  99 Step:   871  time: 1.306161 s d_loss: 0.66859251, g_loss: 880.50994873 -- mean_d_loss: 1.72263694, mean_g_loss: 1006.05273438\n",
            "Epoch:  99 Step:   872  time: 1.283693 s d_loss: 0.55935860, g_loss: 991.11547852 -- mean_d_loss: 1.70670164, mean_g_loss: 1005.84814453\n",
            "Epoch:  99 Step:   873  time: 1.279219 s d_loss: 22.34377861, g_loss: 922.16101074 -- mean_d_loss: 1.98558104, mean_g_loss: 1004.71728516\n",
            "Epoch:  99 Step:   874  time: 1.298183 s d_loss: 1.52813816, g_loss: 960.83850098 -- mean_d_loss: 1.97948182, mean_g_loss: 1004.13220215\n",
            "Epoch:  99 Step:   875  time: 1.307370 s d_loss: 5.42649126, g_loss: 1110.06445312 -- mean_d_loss: 2.02483726, mean_g_loss: 1005.52600098\n",
            "Epoch:  99 Step:   876  time: 1.279537 s d_loss: 1.99911857, g_loss: 1169.14440918 -- mean_d_loss: 2.02450323, mean_g_loss: 1007.65087891\n",
            "Epoch:  99 Step:   877  time: 1.301234 s d_loss: 1.26116896, g_loss: 989.81237793 -- mean_d_loss: 2.01471686, mean_g_loss: 1007.42218018\n",
            "Epoch:  99 Step:   878  time: 1.297742 s d_loss: 1.38972878, g_loss: 977.64221191 -- mean_d_loss: 2.00680566, mean_g_loss: 1007.04516602\n",
            "Epoch:  99 Step:   879  time: 1.289556 s d_loss: 1.26958561, g_loss: 955.41296387 -- mean_d_loss: 1.99759042, mean_g_loss: 1006.39978027\n",
            "Epoch:  99 Step:   880  time: 1.307976 s d_loss: 1.20652258, g_loss: 1092.22607422 -- mean_d_loss: 1.98782420, mean_g_loss: 1007.45941162\n",
            "Epoch:  99 Step:   881  time: 1.339488 s d_loss: 0.56264997, g_loss: 979.34350586 -- mean_d_loss: 1.97044408, mean_g_loss: 1007.11651611\n",
            "Epoch:  99 Step:   882  time: 1.319366 s d_loss: 0.64850181, g_loss: 973.07244873 -- mean_d_loss: 1.95451701, mean_g_loss: 1006.70629883\n",
            "Epoch:  99 Step:   883  time: 1.311134 s d_loss: 0.72129494, g_loss: 920.62365723 -- mean_d_loss: 1.93983591, mean_g_loss: 1005.68151855\n",
            "Epoch:  99 Step:   884  time: 1.293260 s d_loss: 0.64366913, g_loss: 937.56481934 -- mean_d_loss: 1.92458677, mean_g_loss: 1004.88012695\n",
            "Epoch:  99 Step:   885  time: 1.310581 s d_loss: 0.63057518, g_loss: 1000.83526611 -- mean_d_loss: 1.90954006, mean_g_loss: 1004.83312988\n",
            "Epoch:  99 Step:   886  time: 1.319892 s d_loss: 0.54064935, g_loss: 1037.67736816 -- mean_d_loss: 1.89380562, mean_g_loss: 1005.21069336\n",
            "Epoch:  99 Step:   887  time: 1.320822 s d_loss: 0.49887925, g_loss: 925.84167480 -- mean_d_loss: 1.87795436, mean_g_loss: 1004.30877686\n",
            "Epoch:  99 Step:   888  time: 1.320393 s d_loss: 0.66199178, g_loss: 917.36315918 -- mean_d_loss: 1.86429179, mean_g_loss: 1003.33178711\n",
            "Epoch:  99 Step:   889  time: 1.311664 s d_loss: 0.62421513, g_loss: 984.87005615 -- mean_d_loss: 1.85051322, mean_g_loss: 1003.12664795\n",
            "Epoch:  99 Step:   890  time: 1.321465 s d_loss: 0.80809659, g_loss: 1015.50970459 -- mean_d_loss: 1.83905804, mean_g_loss: 1003.26269531\n",
            "Epoch:  99 Step:   891  time: 1.324205 s d_loss: 0.47929937, g_loss: 1017.30419922 -- mean_d_loss: 1.82427800, mean_g_loss: 1003.41534424\n",
            "Epoch:  99 Step:   892  time: 1.280513 s d_loss: 0.64381438, g_loss: 978.19567871 -- mean_d_loss: 1.81158483, mean_g_loss: 1003.14416504\n",
            "Epoch:  99 Step:   893  time: 1.321100 s d_loss: 0.51609492, g_loss: 990.73431396 -- mean_d_loss: 1.79780304, mean_g_loss: 1003.01214600\n",
            "Epoch:  99 Step:   894  time: 1.337531 s d_loss: 0.49756524, g_loss: 1097.32128906 -- mean_d_loss: 1.78411627, mean_g_loss: 1004.00482178\n",
            "Epoch:  99 Step:   895  time: 1.315287 s d_loss: 0.58556384, g_loss: 1130.43701172 -- mean_d_loss: 1.77163136, mean_g_loss: 1005.32183838\n",
            "Epoch:  99 Step:   896  time: 1.318709 s d_loss: 0.75703675, g_loss: 941.94128418 -- mean_d_loss: 1.76117158, mean_g_loss: 1004.66839600\n",
            "Epoch:  99 Step:   897  time: 1.320017 s d_loss: 16.50914383, g_loss: 845.95495605 -- mean_d_loss: 1.91166115, mean_g_loss: 1003.04888916\n",
            "Epoch:  99 Step:   898  time: 1.313262 s d_loss: 4.96900320, g_loss: 1118.41235352 -- mean_d_loss: 1.94254339, mean_g_loss: 1004.21417236\n",
            "Epoch:  99 Step:   899  time: 1.326676 s d_loss: 0.96585315, g_loss: 1033.62084961 -- mean_d_loss: 1.93277645, mean_g_loss: 1004.50817871\n",
            "Epoch:  99 Step:   900  time: 1.306344 s d_loss: 0.86670089, g_loss: 946.96350098 -- mean_d_loss: 1.92222130, mean_g_loss: 1003.93841553\n",
            "Epoch:  99 Step:   901  time: 1.317884 s d_loss: 1.45671725, g_loss: 967.69921875 -- mean_d_loss: 1.91765749, mean_g_loss: 1003.58319092\n",
            "Epoch:  99 Step:   902  time: 1.321054 s d_loss: 0.83968908, g_loss: 983.22167969 -- mean_d_loss: 1.90719175, mean_g_loss: 1003.38543701\n",
            "Epoch:  99 Step:   903  time: 1.319274 s d_loss: 0.71041644, g_loss: 974.98315430 -- mean_d_loss: 1.89568436, mean_g_loss: 1003.11236572\n",
            "Epoch:  99 Step:   904  time: 1.325809 s d_loss: 1.24414575, g_loss: 974.84106445 -- mean_d_loss: 1.88947916, mean_g_loss: 1002.84313965\n",
            "Epoch:  99 Step:   905  time: 1.332670 s d_loss: 0.58525562, g_loss: 1179.55187988 -- mean_d_loss: 1.87717509, mean_g_loss: 1004.51025391\n",
            "Epoch:  99 Step:   906  time: 1.294683 s d_loss: 0.66788197, g_loss: 971.75842285 -- mean_d_loss: 1.86587322, mean_g_loss: 1004.20416260\n",
            "Epoch:  99 Step:   907  time: 1.316376 s d_loss: 0.51768386, g_loss: 1007.86132812 -- mean_d_loss: 1.85338998, mean_g_loss: 1004.23797607\n",
            "Epoch:  99 Step:   908  time: 1.339390 s d_loss: 0.43775636, g_loss: 926.42028809 -- mean_d_loss: 1.84040260, mean_g_loss: 1003.52410889\n",
            "Epoch:  99 Step:   909  time: 1.331714 s d_loss: 0.56915605, g_loss: 1014.55871582 -- mean_d_loss: 1.82884574, mean_g_loss: 1003.62445068\n",
            "Epoch:  99 Step:   910  time: 1.319661 s d_loss: 1.35950458, g_loss: 1052.00927734 -- mean_d_loss: 1.82461739, mean_g_loss: 1004.06030273\n",
            "Epoch:  99 Step:   911  time: 1.318337 s d_loss: 1.24506080, g_loss: 883.59124756 -- mean_d_loss: 1.81944275, mean_g_loss: 1002.98474121\n",
            "Epoch:  99 Step:   912  time: 1.308263 s d_loss: 0.80959886, g_loss: 1015.56414795 -- mean_d_loss: 1.81050611, mean_g_loss: 1003.09600830\n",
            "Epoch:  99 Step:   913  time: 1.320704 s d_loss: 0.76868141, g_loss: 965.98876953 -- mean_d_loss: 1.80136728, mean_g_loss: 1002.77056885\n",
            "Epoch:  99 Step:   914  time: 1.312719 s d_loss: 1.50586760, g_loss: 980.02929688 -- mean_d_loss: 1.79879773, mean_g_loss: 1002.57281494\n",
            "Epoch:  99 Step:   915  time: 1.339611 s d_loss: 0.67146593, g_loss: 903.03942871 -- mean_d_loss: 1.78907931, mean_g_loss: 1001.71478271\n",
            "Epoch:  99 Step:   916  time: 1.334866 s d_loss: 0.70619422, g_loss: 1019.77813721 -- mean_d_loss: 1.77982390, mean_g_loss: 1001.86920166\n",
            "Epoch:  99 Step:   917  time: 1.315435 s d_loss: 0.50385523, g_loss: 896.66564941 -- mean_d_loss: 1.76901066, mean_g_loss: 1000.97760010\n",
            "Epoch:  99 Step:   918  time: 1.319607 s d_loss: 0.57573926, g_loss: 964.33276367 -- mean_d_loss: 1.75898325, mean_g_loss: 1000.66973877\n",
            "Epoch:  99 Step:   919  time: 1.322060 s d_loss: 0.75104284, g_loss: 917.40191650 -- mean_d_loss: 1.75058365, mean_g_loss: 999.97576904\n",
            "Epoch:  99 Step:   920  time: 1.290478 s d_loss: 0.41487253, g_loss: 1069.93322754 -- mean_d_loss: 1.73954475, mean_g_loss: 1000.55389404\n",
            "Epoch:  99 Step:   921  time: 1.319167 s d_loss: 1.41792572, g_loss: 1129.86462402 -- mean_d_loss: 1.73690844, mean_g_loss: 1001.61383057\n",
            "Epoch:  99 Step:   922  time: 1.316034 s d_loss: 2.44251919, g_loss: 1223.72656250 -- mean_d_loss: 1.74264514, mean_g_loss: 1003.41967773\n",
            "Epoch:  99 Step:   923  time: 1.318212 s d_loss: 0.86888725, g_loss: 1094.88635254 -- mean_d_loss: 1.73559868, mean_g_loss: 1004.15728760\n",
            "Epoch:  99 Step:   924  time: 1.287347 s d_loss: 0.62763697, g_loss: 1076.58898926 -- mean_d_loss: 1.72673500, mean_g_loss: 1004.73669434\n",
            "Epoch:  99 Step:   925  time: 1.327294 s d_loss: 0.45030212, g_loss: 878.83337402 -- mean_d_loss: 1.71660459, mean_g_loss: 1003.73748779\n",
            "Epoch:  99 Step:   926  time: 1.326640 s d_loss: 0.59213233, g_loss: 957.38232422 -- mean_d_loss: 1.70775044, mean_g_loss: 1003.37249756\n",
            "Epoch:  99 Step:   927  time: 1.278689 s d_loss: 0.59498459, g_loss: 929.82843018 -- mean_d_loss: 1.69905698, mean_g_loss: 1002.79791260\n",
            "Epoch:  99 Step:   928  time: 1.295140 s d_loss: 0.55642700, g_loss: 1045.74023438 -- mean_d_loss: 1.69019938, mean_g_loss: 1003.13079834\n",
            "Epoch:  99 Step:   929  time: 1.329363 s d_loss: 0.84613174, g_loss: 988.76342773 -- mean_d_loss: 1.68370652, mean_g_loss: 1003.02032471\n",
            "Epoch:  99 Step:   930  time: 1.311783 s d_loss: 0.59498960, g_loss: 856.44982910 -- mean_d_loss: 1.67539573, mean_g_loss: 1001.90148926\n",
            "Epoch:  99 Step:   931  time: 1.319834 s d_loss: 0.94991922, g_loss: 971.93621826 -- mean_d_loss: 1.66989970, mean_g_loss: 1001.67449951\n",
            "Epoch:  99 Step:   932  time: 1.320534 s d_loss: 3.93481541, g_loss: 1088.75170898 -- mean_d_loss: 1.68692911, mean_g_loss: 1002.32916260\n",
            "Epoch:  99 Step:   933  time: 1.322772 s d_loss: 0.60854554, g_loss: 806.64916992 -- mean_d_loss: 1.67888153, mean_g_loss: 1000.86895752\n",
            "Epoch:  99 Step:   934  time: 1.303951 s d_loss: 0.71030641, g_loss: 1095.34570312 -- mean_d_loss: 1.67170691, mean_g_loss: 1001.56872559\n",
            "Epoch:  99 Step:   935  time: 1.309999 s d_loss: 1.62106228, g_loss: 896.90075684 -- mean_d_loss: 1.67133451, mean_g_loss: 1000.79919434\n",
            "Epoch:  99 Step:   936  time: 1.323912 s d_loss: 0.60424548, g_loss: 959.83483887 -- mean_d_loss: 1.66354561, mean_g_loss: 1000.50012207\n",
            "Epoch:  99 Step:   937  time: 1.283047 s d_loss: 0.69086421, g_loss: 1030.75915527 -- mean_d_loss: 1.65649712, mean_g_loss: 1000.71942139\n",
            "Epoch:  99 Step:   938  time: 1.323839 s d_loss: 0.59869778, g_loss: 1016.19708252 -- mean_d_loss: 1.64888704, mean_g_loss: 1000.83081055\n",
            "Epoch:  99 Step:   939  time: 1.296421 s d_loss: 1.84759641, g_loss: 1215.54833984 -- mean_d_loss: 1.65030634, mean_g_loss: 1002.36450195\n",
            "Epoch:  99 Step:   940  time: 1.279694 s d_loss: 2.39403605, g_loss: 1052.37524414 -- mean_d_loss: 1.65558112, mean_g_loss: 1002.71917725\n",
            "Epoch:  99 Step:   941  time: 1.306886 s d_loss: 1.43566775, g_loss: 1291.47021484 -- mean_d_loss: 1.65403247, mean_g_loss: 1004.75262451\n",
            "Epoch:  99 Step:   942  time: 1.346509 s d_loss: 0.59057564, g_loss: 1011.51147461 -- mean_d_loss: 1.64659572, mean_g_loss: 1004.79992676\n",
            "Epoch:  99 Step:   943  time: 1.287444 s d_loss: 0.65882939, g_loss: 1014.08453369 -- mean_d_loss: 1.63973618, mean_g_loss: 1004.86437988\n",
            "Epoch:  99 Step:   944  time: 1.345092 s d_loss: 0.59654266, g_loss: 1026.65771484 -- mean_d_loss: 1.63254178, mean_g_loss: 1005.01464844\n",
            "Epoch:  99 Step:   945  time: 1.331732 s d_loss: 0.90674359, g_loss: 1060.27221680 -- mean_d_loss: 1.62757051, mean_g_loss: 1005.39306641\n",
            "Epoch:  99 Step:   946  time: 1.306866 s d_loss: 0.88743979, g_loss: 1024.42187500 -- mean_d_loss: 1.62253559, mean_g_loss: 1005.52252197\n",
            "Epoch:  99 Step:   947  time: 1.292466 s d_loss: 0.93358690, g_loss: 879.69348145 -- mean_d_loss: 1.61788058, mean_g_loss: 1004.67230225\n",
            "Epoch:  99 Step:   948  time: 1.304626 s d_loss: 0.74703425, g_loss: 879.79864502 -- mean_d_loss: 1.61203599, mean_g_loss: 1003.83422852\n",
            "Epoch:  99 Step:   949  time: 1.311154 s d_loss: 0.82054776, g_loss: 913.76391602 -- mean_d_loss: 1.60675931, mean_g_loss: 1003.23376465\n",
            "Epoch:  99 Step:   950  time: 1.303397 s d_loss: 0.61515522, g_loss: 1156.03576660 -- mean_d_loss: 1.60019243, mean_g_loss: 1004.24566650\n",
            "Epoch:  99 Step:   951  time: 1.296243 s d_loss: 0.47206536, g_loss: 995.00305176 -- mean_d_loss: 1.59277058, mean_g_loss: 1004.18481445\n",
            "Epoch:  99 Step:   952  time: 1.278897 s d_loss: 0.58437741, g_loss: 1044.55419922 -- mean_d_loss: 1.58617973, mean_g_loss: 1004.44860840\n",
            "Epoch:  99 Step:   953  time: 1.307426 s d_loss: 0.49265537, g_loss: 960.38220215 -- mean_d_loss: 1.57907891, mean_g_loss: 1004.16241455\n",
            "Epoch:  99 Step:   954  time: 1.317117 s d_loss: 0.46448177, g_loss: 1102.20068359 -- mean_d_loss: 1.57188797, mean_g_loss: 1004.79498291\n",
            "Epoch:  99 Step:   955  time: 1.299351 s d_loss: 0.59576160, g_loss: 1024.29187012 -- mean_d_loss: 1.56563079, mean_g_loss: 1004.91998291\n",
            "Epoch:  99 Step:   956  time: 1.314274 s d_loss: 0.84128851, g_loss: 985.19720459 -- mean_d_loss: 1.56101716, mean_g_loss: 1004.79437256\n",
            "Epoch:  99 Step:   957  time: 1.321370 s d_loss: 0.51887494, g_loss: 1065.12927246 -- mean_d_loss: 1.55442131, mean_g_loss: 1005.17620850\n",
            "Epoch:  99 Step:   958  time: 1.320775 s d_loss: 0.41594669, g_loss: 1166.39941406 -- mean_d_loss: 1.54726112, mean_g_loss: 1006.19024658\n",
            "Epoch:  99 Step:   959  time: 1.313370 s d_loss: 0.59270978, g_loss: 894.78259277 -- mean_d_loss: 1.54129517, mean_g_loss: 1005.49395752\n",
            "Epoch:  99 Step:   960  time: 1.317589 s d_loss: 0.62380207, g_loss: 927.88659668 -- mean_d_loss: 1.53559637, mean_g_loss: 1005.01196289\n",
            "Epoch:  99 Step:   961  time: 1.293948 s d_loss: 0.66052419, g_loss: 898.12304688 -- mean_d_loss: 1.53019464, mean_g_loss: 1004.35211182\n",
            "Epoch:  99 Step:   962  time: 1.323904 s d_loss: 0.44686672, g_loss: 913.40838623 -- mean_d_loss: 1.52354848, mean_g_loss: 1003.79418945\n",
            "Epoch:  99 Step:   963  time: 1.319551 s d_loss: 0.49476278, g_loss: 1008.85253906 -- mean_d_loss: 1.51727545, mean_g_loss: 1003.82507324\n",
            "Epoch:  99 Step:   964  time: 1.294728 s d_loss: 0.78417677, g_loss: 1106.57458496 -- mean_d_loss: 1.51283240, mean_g_loss: 1004.44781494\n",
            "Epoch:  99 Step:   965  time: 1.328028 s d_loss: 0.51843345, g_loss: 971.13500977 -- mean_d_loss: 1.50684214, mean_g_loss: 1004.24719238\n",
            "Epoch:  99 Step:   966  time: 1.290914 s d_loss: 1.17956984, g_loss: 902.38977051 -- mean_d_loss: 1.50488234, mean_g_loss: 1003.63726807\n",
            "Epoch:  99 Step:   967  time: 1.320205 s d_loss: 1.94506645, g_loss: 1015.85034180 -- mean_d_loss: 1.50750256, mean_g_loss: 1003.70989990\n",
            "Epoch:  99 Step:   968  time: 1.313493 s d_loss: 0.92598909, g_loss: 958.66931152 -- mean_d_loss: 1.50406158, mean_g_loss: 1003.44342041\n",
            "Epoch:  99 Step:   969  time: 1.322671 s d_loss: 0.64602780, g_loss: 1065.34497070 -- mean_d_loss: 1.49901438, mean_g_loss: 1003.80755615\n",
            "Epoch:  99 Step:   970  time: 1.318735 s d_loss: 0.68583608, g_loss: 1005.67407227 -- mean_d_loss: 1.49425900, mean_g_loss: 1003.81842041\n",
            "Epoch:  99 Step:   971  time: 1.325519 s d_loss: 0.43387285, g_loss: 1056.35070801 -- mean_d_loss: 1.48809385, mean_g_loss: 1004.12384033\n",
            "Epoch:  99 Step:   972  time: 1.307825 s d_loss: 0.53887343, g_loss: 1092.42578125 -- mean_d_loss: 1.48260713, mean_g_loss: 1004.63421631\n",
            "Epoch:  99 Step:   973  time: 1.344900 s d_loss: 0.57053679, g_loss: 990.82659912 -- mean_d_loss: 1.47736526, mean_g_loss: 1004.55487061\n",
            "Epoch:  99 Step:   974  time: 1.326300 s d_loss: 0.39483830, g_loss: 1213.06420898 -- mean_d_loss: 1.47117937, mean_g_loss: 1005.74633789\n",
            "Epoch:  99 Step:   975  time: 1.306792 s d_loss: 0.55608213, g_loss: 987.50061035 -- mean_d_loss: 1.46598005, mean_g_loss: 1005.64263916\n",
            "Epoch:  99 Step:   976  time: 1.315905 s d_loss: 0.51346338, g_loss: 1005.95214844 -- mean_d_loss: 1.46059859, mean_g_loss: 1005.64440918\n",
            "Epoch:  99 Step:   977  time: 1.309794 s d_loss: 0.52911460, g_loss: 905.06591797 -- mean_d_loss: 1.45536542, mean_g_loss: 1005.07934570\n",
            "Epoch:  99 Step:   978  time: 1.325150 s d_loss: 0.59420311, g_loss: 854.89294434 -- mean_d_loss: 1.45055449, mean_g_loss: 1004.24029541\n",
            "Epoch:  99 Step:   979  time: 1.304328 s d_loss: 0.94314384, g_loss: 1058.50292969 -- mean_d_loss: 1.44773555, mean_g_loss: 1004.54174805\n",
            "Epoch:  99 Step:   980  time: 1.323543 s d_loss: 0.60351110, g_loss: 1112.75476074 -- mean_d_loss: 1.44307137, mean_g_loss: 1005.13958740\n",
            "Epoch:  99 Step:   981  time: 1.324128 s d_loss: 0.42221856, g_loss: 967.53356934 -- mean_d_loss: 1.43746233, mean_g_loss: 1004.93292236\n",
            "Epoch:  99 Step:   982  time: 1.324852 s d_loss: 0.82399464, g_loss: 1077.49694824 -- mean_d_loss: 1.43411005, mean_g_loss: 1005.32946777\n",
            "Epoch:  99 Step:   983  time: 1.319880 s d_loss: 2.02902246, g_loss: 978.97723389 -- mean_d_loss: 1.43734324, mean_g_loss: 1005.18634033\n",
            "Epoch:  99 Step:   984  time: 1.335858 s d_loss: 1.91699862, g_loss: 980.11138916 -- mean_d_loss: 1.43993592, mean_g_loss: 1005.05078125\n",
            "Epoch:  99 Step:   985  time: 1.327340 s d_loss: 0.39556190, g_loss: 952.94934082 -- mean_d_loss: 1.43432105, mean_g_loss: 1004.77069092\n",
            "Epoch:  99 Step:   986  time: 1.332450 s d_loss: 0.57608110, g_loss: 1160.59960938 -- mean_d_loss: 1.42973161, mean_g_loss: 1005.60394287\n",
            "Epoch:  99 Step:   987  time: 1.282854 s d_loss: 0.60125130, g_loss: 1111.36755371 -- mean_d_loss: 1.42532480, mean_g_loss: 1006.16656494\n",
            "Epoch:  99 Step:   988  time: 1.298904 s d_loss: 0.38861445, g_loss: 999.53662109 -- mean_d_loss: 1.41983950, mean_g_loss: 1006.13146973\n",
            "Epoch:  99 Step:   989  time: 1.318019 s d_loss: 0.49843147, g_loss: 1004.81597900 -- mean_d_loss: 1.41499007, mean_g_loss: 1006.12451172\n",
            "Epoch:  99 Step:   990  time: 1.289570 s d_loss: 0.62254667, g_loss: 1169.85241699 -- mean_d_loss: 1.41084123, mean_g_loss: 1006.98175049\n",
            "Epoch:  99 Step:   991  time: 1.289089 s d_loss: 3.01503253, g_loss: 971.41430664 -- mean_d_loss: 1.41919649, mean_g_loss: 1006.79656982\n",
            "Epoch:  99 Step:   992  time: 1.338208 s d_loss: 0.96735001, g_loss: 979.43530273 -- mean_d_loss: 1.41685522, mean_g_loss: 1006.65478516\n",
            "Epoch:  99 Step:   993  time: 1.313965 s d_loss: 0.76579452, g_loss: 940.36950684 -- mean_d_loss: 1.41349936, mean_g_loss: 1006.31317139\n",
            "Epoch:  99 Step:   994  time: 1.335343 s d_loss: 0.65865773, g_loss: 1006.36437988 -- mean_d_loss: 1.40962839, mean_g_loss: 1006.31335449\n",
            "Epoch:  99 Step:   995  time: 1.318868 s d_loss: 0.46230552, g_loss: 1051.05480957 -- mean_d_loss: 1.40479517, mean_g_loss: 1006.54168701\n",
            "Epoch:  99 Step:   996  time: 1.339933 s d_loss: 0.74080145, g_loss: 968.88305664 -- mean_d_loss: 1.40142465, mean_g_loss: 1006.35058594\n",
            "Epoch:  99 Step:   997  time: 1.329071 s d_loss: 0.62234372, g_loss: 966.39575195 -- mean_d_loss: 1.39748991, mean_g_loss: 1006.14874268\n",
            "Epoch:  99 Step:   998  time: 1.285328 s d_loss: 0.96013016, g_loss: 1074.48645020 -- mean_d_loss: 1.39529216, mean_g_loss: 1006.49212646\n",
            "Epoch:  99 Step:   999  time: 1.321549 s d_loss: 2.91076636, g_loss: 1313.21667480 -- mean_d_loss: 1.40286958, mean_g_loss: 1008.02575684\n",
            "Epoch:  99 Step:  1000  time: 1.297957 s d_loss: 0.51235515, g_loss: 868.83679199 -- mean_d_loss: 0.51235515, mean_g_loss: 868.83679199\n",
            "Epoch:  99 Step:  1001  time: 1.295626 s d_loss: 0.85339028, g_loss: 999.36193848 -- mean_d_loss: 0.68287271, mean_g_loss: 934.09936523\n",
            "Epoch:  99 Step:  1002  time: 1.337995 s d_loss: 0.64378393, g_loss: 1050.32910156 -- mean_d_loss: 0.66984314, mean_g_loss: 972.84259033\n",
            "Epoch:  99 Step:  1003  time: 1.292629 s d_loss: 0.55622274, g_loss: 1011.67523193 -- mean_d_loss: 0.64143801, mean_g_loss: 982.55078125\n",
            "Epoch:  99 Step:  1004  time: 1.327513 s d_loss: 0.73349100, g_loss: 1130.71252441 -- mean_d_loss: 0.65984857, mean_g_loss: 1012.18310547\n",
            "Epoch:  99 Step:  1005  time: 1.320278 s d_loss: 0.65116584, g_loss: 1031.21606445 -- mean_d_loss: 0.65840149, mean_g_loss: 1015.35528564\n",
            "Epoch:  99 Step:  1006  time: 1.319902 s d_loss: 0.89606196, g_loss: 1059.54882812 -- mean_d_loss: 0.69235295, mean_g_loss: 1021.66864014\n",
            "Epoch:  99 Step:  1007  time: 1.302912 s d_loss: 0.89292276, g_loss: 910.36810303 -- mean_d_loss: 0.71742421, mean_g_loss: 1007.75610352\n",
            "Epoch:  99 Step:  1008  time: 1.325831 s d_loss: 0.58508092, g_loss: 984.52636719 -- mean_d_loss: 0.70271945, mean_g_loss: 1005.17504883\n",
            "Epoch:  99 Step:  1009  time: 1.309998 s d_loss: 0.45852867, g_loss: 1028.64477539 -- mean_d_loss: 0.67830032, mean_g_loss: 1007.52197266\n",
            "Epoch:  99 Step:  1010  time: 1.297295 s d_loss: 0.52561539, g_loss: 1022.94201660 -- mean_d_loss: 0.66441989, mean_g_loss: 1008.92382812\n",
            "Epoch:  99 Step:  1011  time: 1.287591 s d_loss: 0.44802094, g_loss: 928.36669922 -- mean_d_loss: 0.64638662, mean_g_loss: 1002.21075439\n",
            "Epoch:  99 Step:  1012  time: 1.312345 s d_loss: 0.77007347, g_loss: 1114.59912109 -- mean_d_loss: 0.65590101, mean_g_loss: 1010.85607910\n",
            "Epoch:  99 Step:  1013  time: 1.318666 s d_loss: 0.69565058, g_loss: 976.39624023 -- mean_d_loss: 0.65874034, mean_g_loss: 1008.39465332\n",
            "Epoch:  99 Step:  1014  time: 1.321275 s d_loss: 0.83050406, g_loss: 1013.71112061 -- mean_d_loss: 0.67019123, mean_g_loss: 1008.74908447\n",
            "Epoch:  99 Step:  1015  time: 1.323198 s d_loss: 0.74709833, g_loss: 950.41088867 -- mean_d_loss: 0.67499793, mean_g_loss: 1005.10296631\n",
            "Epoch:  99 Step:  1016  time: 1.304992 s d_loss: 0.64523083, g_loss: 865.07647705 -- mean_d_loss: 0.67324692, mean_g_loss: 996.86614990\n",
            "Epoch:  99 Step:  1017  time: 1.318808 s d_loss: 0.78560382, g_loss: 874.18957520 -- mean_d_loss: 0.67948896, mean_g_loss: 990.05078125\n",
            "Epoch:  99 Step:  1018  time: 1.306816 s d_loss: 2.71009254, g_loss: 1070.53991699 -- mean_d_loss: 0.78636283, mean_g_loss: 994.28698730\n",
            "Epoch:  99 Step:  1019  time: 1.311469 s d_loss: 1.53836358, g_loss: 848.44079590 -- mean_d_loss: 0.82396287, mean_g_loss: 986.99475098\n",
            "Epoch:  99 Step:  1020  time: 1.301194 s d_loss: 1.36502707, g_loss: 917.70654297 -- mean_d_loss: 0.84972781, mean_g_loss: 983.69531250\n",
            "Epoch:  99 Step:  1021  time: 1.326421 s d_loss: 1.16770577, g_loss: 927.80993652 -- mean_d_loss: 0.86418134, mean_g_loss: 981.15509033\n",
            "Epoch:  99 Step:  1022  time: 1.327675 s d_loss: 0.77630103, g_loss: 862.00415039 -- mean_d_loss: 0.86036044, mean_g_loss: 975.97460938\n",
            "Epoch:  99 Step:  1023  time: 1.329530 s d_loss: 0.76225448, g_loss: 996.07928467 -- mean_d_loss: 0.85627270, mean_g_loss: 976.81231689\n",
            "Epoch:  99 Step:  1024  time: 1.336241 s d_loss: 0.60258794, g_loss: 1013.88647461 -- mean_d_loss: 0.84612536, mean_g_loss: 978.29528809\n",
            "Epoch:  99 Step:  1025  time: 1.320784 s d_loss: 0.82270622, g_loss: 1193.35107422 -- mean_d_loss: 0.84522462, mean_g_loss: 986.56671143\n",
            "Epoch:  99 Step:  1026  time: 1.340691 s d_loss: 0.45569125, g_loss: 1083.43505859 -- mean_d_loss: 0.83079743, mean_g_loss: 990.15441895\n",
            "Epoch:  99 Step:  1027  time: 1.282429 s d_loss: 0.66576540, g_loss: 1033.77587891 -- mean_d_loss: 0.82490343, mean_g_loss: 991.71234131\n",
            "Epoch:  99 Step:  1028  time: 1.318003 s d_loss: 0.66326481, g_loss: 953.70349121 -- mean_d_loss: 0.81932968, mean_g_loss: 990.40167236\n",
            "Epoch:  99 Step:  1029  time: 1.288061 s d_loss: 0.78261572, g_loss: 1246.83239746 -- mean_d_loss: 0.81810588, mean_g_loss: 998.94934082\n",
            "Epoch:  99 Step:  1030  time: 1.306489 s d_loss: 0.98552972, g_loss: 987.07006836 -- mean_d_loss: 0.82350665, mean_g_loss: 998.56616211\n",
            "Epoch:  99 Step:  1031  time: 1.336185 s d_loss: 1.01054931, g_loss: 1068.02368164 -- mean_d_loss: 0.82935172, mean_g_loss: 1000.73669434\n",
            "Epoch:  99 Step:  1032  time: 1.334343 s d_loss: 1.03083777, g_loss: 918.08007812 -- mean_d_loss: 0.83545738, mean_g_loss: 998.23199463\n",
            "Epoch:  99 Step:  1033  time: 1.314216 s d_loss: 0.87201339, g_loss: 885.44232178 -- mean_d_loss: 0.83653253, mean_g_loss: 994.91461182\n",
            "Epoch:  99 Step:  1034  time: 1.296639 s d_loss: 4.56520081, g_loss: 1086.96533203 -- mean_d_loss: 0.94306594, mean_g_loss: 997.54461670\n",
            "Epoch:  99 Step:  1035  time: 1.321207 s d_loss: 0.68072069, g_loss: 1026.88854980 -- mean_d_loss: 0.93577862, mean_g_loss: 998.35968018\n",
            "Epoch:  99 Step:  1036  time: 1.281398 s d_loss: 0.52481049, g_loss: 909.82141113 -- mean_d_loss: 0.92467135, mean_g_loss: 995.96673584\n",
            "Epoch:  99 Step:  1037  time: 1.321922 s d_loss: 0.61802936, g_loss: 1081.89331055 -- mean_d_loss: 0.91660190, mean_g_loss: 998.22802734\n",
            "Epoch:  99 Step:  1038  time: 1.296686 s d_loss: 0.69382691, g_loss: 1039.63549805 -- mean_d_loss: 0.91088974, mean_g_loss: 999.28973389\n",
            "Epoch:  99 Step:  1039  time: 1.325814 s d_loss: 0.41562063, g_loss: 870.06921387 -- mean_d_loss: 0.89850795, mean_g_loss: 996.05926514\n",
            "Epoch:  99 Step:  1040  time: 1.317011 s d_loss: 31.05440903, g_loss: 1012.10803223 -- mean_d_loss: 1.63401771, mean_g_loss: 996.45074463\n",
            "Epoch:  99 Step:  1041  time: 1.310267 s d_loss: 1.98453343, g_loss: 948.84924316 -- mean_d_loss: 1.64236343, mean_g_loss: 995.31732178\n",
            "Epoch:  99 Step:  1042  time: 1.315658 s d_loss: 1.84652340, g_loss: 1103.86059570 -- mean_d_loss: 1.64711142, mean_g_loss: 997.84155273\n",
            "Epoch:  99 Step:  1043  time: 1.313436 s d_loss: 1.78869534, g_loss: 1130.99707031 -- mean_d_loss: 1.65032923, mean_g_loss: 1000.86779785\n",
            "Epoch:  99 Step:  1044  time: 1.312614 s d_loss: 4.02395868, g_loss: 1073.44140625 -- mean_d_loss: 1.70307648, mean_g_loss: 1002.48052979\n",
            "Epoch:  99 Step:  1045  time: 1.306512 s d_loss: 10.40229988, g_loss: 860.49914551 -- mean_d_loss: 1.89218998, mean_g_loss: 999.39404297\n",
            "Epoch:  99 Step:  1046  time: 1.317645 s d_loss: 2.02423620, g_loss: 1074.17382812 -- mean_d_loss: 1.89499962, mean_g_loss: 1000.98504639\n",
            "Epoch:  99 Step:  1047  time: 1.330631 s d_loss: 2.21220636, g_loss: 1213.16210938 -- mean_d_loss: 1.90160799, mean_g_loss: 1005.40545654\n",
            "Epoch:  99 Step:  1048  time: 1.330270 s d_loss: 1.37646687, g_loss: 1106.59960938 -- mean_d_loss: 1.89089084, mean_g_loss: 1007.47064209\n",
            "Epoch:  99 Step:  1049  time: 1.321397 s d_loss: 0.82136744, g_loss: 1009.92120361 -- mean_d_loss: 1.86950028, mean_g_loss: 1007.51971436\n",
            "Epoch:  99 Step:  1050  time: 1.289958 s d_loss: 1.18486166, g_loss: 847.74206543 -- mean_d_loss: 1.85607600, mean_g_loss: 1004.38677979\n",
            "Epoch:  99 Step:  1051  time: 1.326347 s d_loss: 1.54641759, g_loss: 1197.57495117 -- mean_d_loss: 1.85012102, mean_g_loss: 1008.10192871\n",
            "Epoch:  99 Step:  1052  time: 1.323682 s d_loss: 1.38574922, g_loss: 1247.13146973 -- mean_d_loss: 1.84135926, mean_g_loss: 1012.61193848\n",
            "Epoch:  99 Step:  1053  time: 1.314945 s d_loss: 1.31712079, g_loss: 818.82629395 -- mean_d_loss: 1.83165121, mean_g_loss: 1009.02337646\n",
            "Epoch:  99 Step:  1054  time: 1.323408 s d_loss: 1.33472359, g_loss: 1044.75476074 -- mean_d_loss: 1.82261622, mean_g_loss: 1009.67303467\n",
            "Epoch:  99 Step:  1055  time: 1.325056 s d_loss: 1.16717637, g_loss: 994.09686279 -- mean_d_loss: 1.81091189, mean_g_loss: 1009.39489746\n",
            "Epoch:  99 Step:  1056  time: 1.312141 s d_loss: 1.50298226, g_loss: 1014.90570068 -- mean_d_loss: 1.80550957, mean_g_loss: 1009.49157715\n",
            "Epoch:  99 Step:  1057  time: 1.333657 s d_loss: 1.74421442, g_loss: 964.32189941 -- mean_d_loss: 1.80445278, mean_g_loss: 1008.71276855\n",
            "Epoch:  99 Step:  1058  time: 1.291580 s d_loss: 1.82770979, g_loss: 976.70977783 -- mean_d_loss: 1.80484712, mean_g_loss: 1008.17034912\n",
            "Epoch:  99 Step:  1059  time: 1.296262 s d_loss: 1.41969824, g_loss: 946.06347656 -- mean_d_loss: 1.79842794, mean_g_loss: 1007.13519287\n",
            "Epoch:  99 Step:  1060  time: 1.302121 s d_loss: 0.89668047, g_loss: 875.63885498 -- mean_d_loss: 1.78364527, mean_g_loss: 1004.97955322\n",
            "Epoch:  99 Step:  1061  time: 1.317933 s d_loss: 0.84382099, g_loss: 1125.36364746 -- mean_d_loss: 1.76848674, mean_g_loss: 1006.92126465\n",
            "Epoch:  99 Step:  1062  time: 1.304824 s d_loss: 0.62828624, g_loss: 1081.95397949 -- mean_d_loss: 1.75038838, mean_g_loss: 1008.11224365\n",
            "Epoch:  99 Step:  1063  time: 1.316900 s d_loss: 0.59326881, g_loss: 1042.16467285 -- mean_d_loss: 1.73230839, mean_g_loss: 1008.64428711\n",
            "Epoch:  99 Step:  1064  time: 1.319544 s d_loss: 0.57545573, g_loss: 1098.28930664 -- mean_d_loss: 1.71451068, mean_g_loss: 1010.02343750\n",
            "Epoch:  99 Step:  1065  time: 1.301244 s d_loss: 0.56539112, g_loss: 1280.56872559 -- mean_d_loss: 1.69709969, mean_g_loss: 1014.12261963\n",
            "Epoch:  99 Step:  1066  time: 1.316499 s d_loss: 0.74528778, g_loss: 1165.29895020 -- mean_d_loss: 1.68289351, mean_g_loss: 1016.37896729\n",
            "Epoch:  99 Step:  1067  time: 1.317039 s d_loss: 0.45752686, g_loss: 1043.19653320 -- mean_d_loss: 1.66487348, mean_g_loss: 1016.77331543\n",
            "Epoch:  99 Step:  1068  time: 1.305923 s d_loss: 41.05030441, g_loss: 898.44384766 -- mean_d_loss: 2.23567677, mean_g_loss: 1015.05841064\n",
            "Epoch:  99 Step:  1069  time: 1.328406 s d_loss: 1.79033065, g_loss: 1075.38525391 -- mean_d_loss: 2.22931480, mean_g_loss: 1015.92022705\n",
            "Epoch:  99 Step:  1070  time: 1.316654 s d_loss: 2.06913614, g_loss: 1105.41259766 -- mean_d_loss: 2.22705865, mean_g_loss: 1017.18066406\n",
            "Epoch:  99 Step:  1071  time: 1.350854 s d_loss: 1.42297530, g_loss: 1087.26892090 -- mean_d_loss: 2.21589088, mean_g_loss: 1018.15405273\n",
            "Epoch:  99 Step:  1072  time: 1.322219 s d_loss: 1.37453687, g_loss: 1024.70959473 -- mean_d_loss: 2.20436549, mean_g_loss: 1018.24389648\n",
            "Epoch:  99 Step:  1073  time: 1.318090 s d_loss: 1.19408500, g_loss: 1171.48034668 -- mean_d_loss: 2.19071317, mean_g_loss: 1020.31463623\n",
            "Epoch:  99 Step:  1074  time: 1.321852 s d_loss: 5.19699478, g_loss: 1000.47845459 -- mean_d_loss: 2.23079681, mean_g_loss: 1020.05010986\n",
            "Epoch:  99 Step:  1075  time: 1.320410 s d_loss: 1.13181674, g_loss: 1062.04162598 -- mean_d_loss: 2.21633673, mean_g_loss: 1020.60260010\n",
            "Epoch:  99 Step:  1076  time: 1.328009 s d_loss: 1.05573428, g_loss: 946.60321045 -- mean_d_loss: 2.20126390, mean_g_loss: 1019.64154053\n",
            "Epoch:  99 Step:  1077  time: 1.317847 s d_loss: 1.07471228, g_loss: 1089.27172852 -- mean_d_loss: 2.18682098, mean_g_loss: 1020.53424072\n",
            "Epoch:  99 Step:  1078  time: 1.326632 s d_loss: 1.29167080, g_loss: 1017.56848145 -- mean_d_loss: 2.17548990, mean_g_loss: 1020.49676514\n",
            "Epoch:  99 Step:  1079  time: 1.309808 s d_loss: 0.96194166, g_loss: 989.73669434 -- mean_d_loss: 2.16032076, mean_g_loss: 1020.11218262\n",
            "Epoch:  99 Step:  1080  time: 1.313794 s d_loss: 0.80609733, g_loss: 1028.35437012 -- mean_d_loss: 2.14360189, mean_g_loss: 1020.21392822\n",
            "Epoch:  99 Step:  1081  time: 1.313023 s d_loss: 0.51273817, g_loss: 913.14324951 -- mean_d_loss: 2.12371325, mean_g_loss: 1018.90814209\n",
            "Epoch:  99 Step:  1082  time: 1.317532 s d_loss: 0.57488018, g_loss: 1046.17175293 -- mean_d_loss: 2.10505247, mean_g_loss: 1019.23663330\n",
            "Epoch:  99 Step:  1083  time: 1.298832 s d_loss: 0.57888603, g_loss: 1076.30920410 -- mean_d_loss: 2.08688402, mean_g_loss: 1019.91613770\n",
            "Epoch:  99 Step:  1084  time: 1.312746 s d_loss: 0.54104996, g_loss: 963.53027344 -- mean_d_loss: 2.06869769, mean_g_loss: 1019.25274658\n",
            "Epoch:  99 Step:  1085  time: 1.330064 s d_loss: 0.66782534, g_loss: 1018.37353516 -- mean_d_loss: 2.05240846, mean_g_loss: 1019.24255371\n",
            "Epoch:  99 Step:  1086  time: 1.338924 s d_loss: 0.52529126, g_loss: 961.75390625 -- mean_d_loss: 2.03485537, mean_g_loss: 1018.58172607\n",
            "Epoch:  99 Step:  1087  time: 1.300326 s d_loss: 0.50868100, g_loss: 1028.99560547 -- mean_d_loss: 2.01751232, mean_g_loss: 1018.70001221\n",
            "Epoch:  99 Step:  1088  time: 1.339884 s d_loss: 0.64348745, g_loss: 943.56396484 -- mean_d_loss: 2.00207400, mean_g_loss: 1017.85577393\n",
            "Epoch:  99 Step:  1089  time: 1.307402 s d_loss: 0.57240266, g_loss: 992.48071289 -- mean_d_loss: 1.98618877, mean_g_loss: 1017.57385254\n",
            "Epoch:  99 Step:  1090  time: 1.319247 s d_loss: 9.73886871, g_loss: 1127.62145996 -- mean_d_loss: 2.07138300, mean_g_loss: 1018.78320312\n",
            "Epoch:  99 Step:  1091  time: 1.313570 s d_loss: 0.99754167, g_loss: 1103.88256836 -- mean_d_loss: 2.05971074, mean_g_loss: 1019.70819092\n",
            "Epoch:  99 Step:  1092  time: 1.325768 s d_loss: 0.79935753, g_loss: 1045.74829102 -- mean_d_loss: 2.04615855, mean_g_loss: 1019.98822021\n",
            "Epoch:  99 Step:  1093  time: 1.323114 s d_loss: 0.68144041, g_loss: 975.09582520 -- mean_d_loss: 2.03164029, mean_g_loss: 1019.51062012\n",
            "Epoch:  99 Step:  1094  time: 1.345397 s d_loss: 0.63152415, g_loss: 914.58911133 -- mean_d_loss: 2.01690245, mean_g_loss: 1018.40618896\n",
            "Epoch:  99 Step:  1095  time: 1.320455 s d_loss: 2.41740656, g_loss: 1222.54797363 -- mean_d_loss: 2.02107430, mean_g_loss: 1020.53265381\n",
            "Epoch:  99 Step:  1096  time: 1.323456 s d_loss: 0.76551783, g_loss: 1019.31744385 -- mean_d_loss: 2.00813031, mean_g_loss: 1020.52014160\n",
            "Epoch:  99 Step:  1097  time: 1.305261 s d_loss: 1.11152983, g_loss: 1129.64904785 -- mean_d_loss: 1.99898136, mean_g_loss: 1021.63366699\n",
            "Epoch:  99 Step:  1098  time: 1.320220 s d_loss: 0.93133277, g_loss: 1060.88720703 -- mean_d_loss: 1.98819709, mean_g_loss: 1022.03021240\n",
            "Epoch:  99 Step:  1099  time: 1.326180 s d_loss: 0.54104477, g_loss: 970.61267090 -- mean_d_loss: 1.97372556, mean_g_loss: 1021.51599121\n",
            "Epoch:  99 Step:  1100  time: 1.324326 s d_loss: 17.48675728, g_loss: 1004.97204590 -- mean_d_loss: 2.12732005, mean_g_loss: 1021.35217285\n",
            "Epoch:  99 Step:  1101  time: 1.333123 s d_loss: 1.12189746, g_loss: 955.40551758 -- mean_d_loss: 2.11746287, mean_g_loss: 1020.70562744\n",
            "Epoch:  99 Step:  1102  time: 1.341821 s d_loss: 1.14425969, g_loss: 1031.68322754 -- mean_d_loss: 2.10801435, mean_g_loss: 1020.81219482\n",
            "Epoch:  99 Step:  1103  time: 1.324493 s d_loss: 0.67593896, g_loss: 998.37939453 -- mean_d_loss: 2.09424424, mean_g_loss: 1020.59655762\n",
            "Epoch:  99 Step:  1104  time: 1.318247 s d_loss: 0.60963410, g_loss: 931.85083008 -- mean_d_loss: 2.08010507, mean_g_loss: 1019.75134277\n",
            "Epoch:  99 Step:  1105  time: 1.292435 s d_loss: 1.92921865, g_loss: 1087.64733887 -- mean_d_loss: 2.07868171, mean_g_loss: 1020.39190674\n",
            "Epoch:  99 Step:  1106  time: 1.299001 s d_loss: 0.72732645, g_loss: 992.92077637 -- mean_d_loss: 2.06605220, mean_g_loss: 1020.13513184\n",
            "Epoch:  99 Step:  1107  time: 1.317075 s d_loss: 0.43733907, g_loss: 1064.27636719 -- mean_d_loss: 2.05097151, mean_g_loss: 1020.54382324\n",
            "Epoch:  99 Step:  1108  time: 1.302326 s d_loss: 0.65679854, g_loss: 1079.13208008 -- mean_d_loss: 2.03818083, mean_g_loss: 1021.08135986\n",
            "Epoch:  99 Step:  1109  time: 1.289133 s d_loss: 0.57717609, g_loss: 972.19567871 -- mean_d_loss: 2.02489901, mean_g_loss: 1020.63690186\n",
            "Epoch:  99 Step:  1110  time: 1.292889 s d_loss: 0.68519986, g_loss: 963.26538086 -- mean_d_loss: 2.01282954, mean_g_loss: 1020.12005615\n",
            "Epoch:  99 Step:  1111  time: 1.335269 s d_loss: 0.85335553, g_loss: 1050.77319336 -- mean_d_loss: 2.00247717, mean_g_loss: 1020.39373779\n",
            "Epoch:  99 Step:  1112  time: 1.298417 s d_loss: 0.57784468, g_loss: 1010.49346924 -- mean_d_loss: 1.98986995, mean_g_loss: 1020.30615234\n",
            "Epoch:  99 Step:  1113  time: 1.319873 s d_loss: 0.54673076, g_loss: 990.42944336 -- mean_d_loss: 1.97721088, mean_g_loss: 1020.04406738\n",
            "Epoch:  99 Step:  1114  time: 1.298204 s d_loss: 0.41644654, g_loss: 1037.41943359 -- mean_d_loss: 1.96363902, mean_g_loss: 1020.19519043\n",
            "Epoch:  99 Step:  1115  time: 1.330325 s d_loss: 0.60647863, g_loss: 982.42626953 -- mean_d_loss: 1.95193934, mean_g_loss: 1019.86962891\n",
            "Epoch:  99 Step:  1116  time: 1.306332 s d_loss: 0.82660574, g_loss: 974.06823730 -- mean_d_loss: 1.94232094, mean_g_loss: 1019.47814941\n",
            "Epoch:  99 Step:  1117  time: 1.306898 s d_loss: 0.89902401, g_loss: 1018.45678711 -- mean_d_loss: 1.93347943, mean_g_loss: 1019.46948242\n",
            "Epoch:  99 Step:  1118  time: 1.340661 s d_loss: 0.68649238, g_loss: 1009.36938477 -- mean_d_loss: 1.92300057, mean_g_loss: 1019.38458252\n",
            "Epoch:  99 Step:  1119  time: 1.312206 s d_loss: 0.51321465, g_loss: 881.62731934 -- mean_d_loss: 1.91125238, mean_g_loss: 1018.23657227\n",
            "Epoch:  99 Step:  1120  time: 1.332673 s d_loss: 0.64420938, g_loss: 944.88983154 -- mean_d_loss: 1.90078092, mean_g_loss: 1017.63043213\n",
            "Epoch:  99 Step:  1121  time: 1.302351 s d_loss: 0.51568228, g_loss: 979.05389404 -- mean_d_loss: 1.88942766, mean_g_loss: 1017.31420898\n",
            "Epoch:  99 Step:  1122  time: 1.285895 s d_loss: 0.44830456, g_loss: 1167.49230957 -- mean_d_loss: 1.87771118, mean_g_loss: 1018.53521729\n",
            "Epoch:  99 Step:  1123  time: 1.343427 s d_loss: 0.49991378, g_loss: 941.80358887 -- mean_d_loss: 1.86659992, mean_g_loss: 1017.91638184\n",
            "Epoch:  99 Step:  1124  time: 1.321972 s d_loss: 1.06074262, g_loss: 1089.92163086 -- mean_d_loss: 1.86015308, mean_g_loss: 1018.49243164\n",
            "Epoch:  99 Step:  1125  time: 1.323831 s d_loss: 0.51505327, g_loss: 1007.70367432 -- mean_d_loss: 1.84947777, mean_g_loss: 1018.40679932\n",
            "Epoch:  99 Step:  1126  time: 1.313386 s d_loss: 0.48870984, g_loss: 1097.53857422 -- mean_d_loss: 1.83876300, mean_g_loss: 1019.02990723\n",
            "Epoch:  99 Step:  1127  time: 1.314728 s d_loss: 0.53482080, g_loss: 1023.31250000 -- mean_d_loss: 1.82857597, mean_g_loss: 1019.06335449\n",
            "Epoch:  99 Step:  1128  time: 1.320869 s d_loss: 0.44715029, g_loss: 1074.51281738 -- mean_d_loss: 1.81786716, mean_g_loss: 1019.49322510\n",
            "Epoch:  99 Step:  1129  time: 1.292016 s d_loss: 0.52598494, g_loss: 983.86230469 -- mean_d_loss: 1.80792964, mean_g_loss: 1019.21911621\n",
            "Epoch:  99 Step:  1130  time: 1.316674 s d_loss: 0.55540955, g_loss: 999.27624512 -- mean_d_loss: 1.79836833, mean_g_loss: 1019.06689453\n",
            "Epoch:  99 Step:  1131  time: 1.298280 s d_loss: 0.46130615, g_loss: 1120.70532227 -- mean_d_loss: 1.78823912, mean_g_loss: 1019.83691406\n",
            "Epoch:  99 Step:  1132  time: 1.292867 s d_loss: 0.53699517, g_loss: 1085.01318359 -- mean_d_loss: 1.77883136, mean_g_loss: 1020.32696533\n",
            "Epoch:  99 Step:  1133  time: 1.293236 s d_loss: 0.52686781, g_loss: 1146.68310547 -- mean_d_loss: 1.76948833, mean_g_loss: 1021.26995850\n",
            "Epoch:  99 Step:  1134  time: 1.314539 s d_loss: 0.79646450, g_loss: 991.66076660 -- mean_d_loss: 1.76228070, mean_g_loss: 1021.05059814\n",
            "Epoch:  99 Step:  1135  time: 1.318126 s d_loss: 0.59874469, g_loss: 932.41015625 -- mean_d_loss: 1.75372529, mean_g_loss: 1020.39880371\n",
            "Epoch:  99 Step:  1136  time: 1.332323 s d_loss: 0.43103343, g_loss: 918.43457031 -- mean_d_loss: 1.74407053, mean_g_loss: 1019.65454102\n",
            "Epoch:  99 Step:  1137  time: 1.292637 s d_loss: 0.39556083, g_loss: 973.20843506 -- mean_d_loss: 1.73429871, mean_g_loss: 1019.31793213\n",
            "Epoch:  99 Step:  1138  time: 1.320970 s d_loss: 0.53416431, g_loss: 965.15924072 -- mean_d_loss: 1.72566462, mean_g_loss: 1018.92828369\n",
            "Epoch:  99 Step:  1139  time: 1.357927 s d_loss: 1.01810741, g_loss: 1022.17065430 -- mean_d_loss: 1.72061074, mean_g_loss: 1018.95147705\n",
            "Epoch:  99 Step:  1140  time: 1.344836 s d_loss: 0.67675620, g_loss: 891.21478271 -- mean_d_loss: 1.71320748, mean_g_loss: 1018.04553223\n",
            "Epoch:  99 Step:  1141  time: 1.297795 s d_loss: 0.46810374, g_loss: 1124.78356934 -- mean_d_loss: 1.70443916, mean_g_loss: 1018.79718018\n",
            "Epoch:  99 Step:  1142  time: 1.328068 s d_loss: 0.38425013, g_loss: 939.34899902 -- mean_d_loss: 1.69520712, mean_g_loss: 1018.24157715\n",
            "Epoch:  99 Step:  1143  time: 1.324072 s d_loss: 2.10419750, g_loss: 1087.50415039 -- mean_d_loss: 1.69804728, mean_g_loss: 1018.72253418\n",
            "Epoch:  99 Step:  1144  time: 1.314233 s d_loss: 0.65463120, g_loss: 1009.05120850 -- mean_d_loss: 1.69085133, mean_g_loss: 1018.65582275\n",
            "Epoch:  99 Step:  1145  time: 1.322799 s d_loss: 0.64884585, g_loss: 858.85839844 -- mean_d_loss: 1.68371439, mean_g_loss: 1017.56134033\n",
            "Epoch:  99 Step:  1146  time: 1.335569 s d_loss: 0.48295340, g_loss: 861.05700684 -- mean_d_loss: 1.67554593, mean_g_loss: 1016.49670410\n",
            "Epoch:  99 Step:  1147  time: 1.304768 s d_loss: 0.44510689, g_loss: 960.66033936 -- mean_d_loss: 1.66723216, mean_g_loss: 1016.11938477\n",
            "Epoch:  99 Step:  1148  time: 1.320464 s d_loss: 1.96031618, g_loss: 1054.69677734 -- mean_d_loss: 1.66919923, mean_g_loss: 1016.37835693\n",
            "Epoch:  99 Step:  1149  time: 1.315517 s d_loss: 0.80098927, g_loss: 917.95422363 -- mean_d_loss: 1.66341114, mean_g_loss: 1015.72216797\n",
            "Epoch:  99 Step:  1150  time: 1.312284 s d_loss: 1.15121615, g_loss: 1053.88476562 -- mean_d_loss: 1.66001916, mean_g_loss: 1015.97497559\n",
            "Epoch:  99 Step:  1151  time: 1.312644 s d_loss: 1.05739498, g_loss: 926.63452148 -- mean_d_loss: 1.65605450, mean_g_loss: 1015.38720703\n",
            "Epoch:  99 Step:  1152  time: 1.286560 s d_loss: 0.75410563, g_loss: 943.11218262 -- mean_d_loss: 1.65015936, mean_g_loss: 1014.91485596\n",
            "Epoch:  99 Step:  1153  time: 1.316724 s d_loss: 0.83675832, g_loss: 1161.97045898 -- mean_d_loss: 1.64487755, mean_g_loss: 1015.86975098\n",
            "Epoch:  99 Step:  1154  time: 1.328886 s d_loss: 0.66752583, g_loss: 910.97631836 -- mean_d_loss: 1.63857210, mean_g_loss: 1015.19293213\n",
            "Epoch:  99 Step:  1155  time: 1.311944 s d_loss: 0.82637006, g_loss: 1141.72607422 -- mean_d_loss: 1.63336563, mean_g_loss: 1016.00402832\n",
            "Epoch:  99 Step:  1156  time: 1.330242 s d_loss: 0.55218834, g_loss: 977.22967529 -- mean_d_loss: 1.62647915, mean_g_loss: 1015.75708008\n",
            "Epoch:  99 Step:  1157  time: 1.318093 s d_loss: 0.62552220, g_loss: 931.96978760 -- mean_d_loss: 1.62014389, mean_g_loss: 1015.22674561\n",
            "Epoch:  99 Step:  1158  time: 1.314419 s d_loss: 0.40895092, g_loss: 1041.61279297 -- mean_d_loss: 1.61252642, mean_g_loss: 1015.39270020\n",
            "Epoch:  99 Step:  1159  time: 1.326686 s d_loss: 0.41988355, g_loss: 1001.48449707 -- mean_d_loss: 1.60507238, mean_g_loss: 1015.30578613\n",
            "Epoch:  99 Step:  1160  time: 1.322269 s d_loss: 0.50720662, g_loss: 783.08935547 -- mean_d_loss: 1.59825337, mean_g_loss: 1013.86346436\n",
            "Epoch:  99 Step:  1161  time: 1.310812 s d_loss: 38.49896622, g_loss: 958.36517334 -- mean_d_loss: 1.82603550, mean_g_loss: 1013.52081299\n",
            "Epoch:  99 Step:  1162  time: 1.312667 s d_loss: 1.57748699, g_loss: 1057.99963379 -- mean_d_loss: 1.82451057, mean_g_loss: 1013.79370117\n",
            "Epoch:  99 Step:  1163  time: 1.336059 s d_loss: 2.08972859, g_loss: 920.26684570 -- mean_d_loss: 1.82612777, mean_g_loss: 1013.22338867\n",
            "Epoch:  99 Step:  1164  time: 1.323977 s d_loss: 1.70839751, g_loss: 1031.15954590 -- mean_d_loss: 1.82541430, mean_g_loss: 1013.33209229\n",
            "Epoch:  99 Step:  1165  time: 1.301010 s d_loss: 1.81409335, g_loss: 1058.98767090 -- mean_d_loss: 1.82534611, mean_g_loss: 1013.60711670\n",
            "Epoch:  99 Step:  1166  time: 1.318771 s d_loss: 1.15482044, g_loss: 1029.33007812 -- mean_d_loss: 1.82133090, mean_g_loss: 1013.70123291\n",
            "Epoch:  99 Step:  1167  time: 1.329835 s d_loss: 2.61817527, g_loss: 1080.49963379 -- mean_d_loss: 1.82607400, mean_g_loss: 1014.09887695\n",
            "Epoch:  99 Step:  1168  time: 1.332736 s d_loss: 0.83567953, g_loss: 1074.28198242 -- mean_d_loss: 1.82021368, mean_g_loss: 1014.45495605\n",
            "Epoch:  99 Step:  1169  time: 1.326783 s d_loss: 0.64227372, g_loss: 1015.45458984 -- mean_d_loss: 1.81328464, mean_g_loss: 1014.46081543\n",
            "Epoch:  99 Step:  1170  time: 1.293805 s d_loss: 0.50620329, g_loss: 1016.70068359 -- mean_d_loss: 1.80564082, mean_g_loss: 1014.47393799\n",
            "Epoch:  99 Step:  1171  time: 1.319764 s d_loss: 0.42814821, g_loss: 905.76873779 -- mean_d_loss: 1.79763222, mean_g_loss: 1013.84191895\n",
            "Epoch:  99 Step:  1172  time: 1.293994 s d_loss: 1.09492183, g_loss: 977.54577637 -- mean_d_loss: 1.79357028, mean_g_loss: 1013.63214111\n",
            "Epoch:  99 Step:  1173  time: 1.306838 s d_loss: 0.60299093, g_loss: 1202.76074219 -- mean_d_loss: 1.78672791, mean_g_loss: 1014.71911621\n",
            "Epoch:  99 Step:  1174  time: 1.292255 s d_loss: 0.73243535, g_loss: 1003.25170898 -- mean_d_loss: 1.78070331, mean_g_loss: 1014.65356445\n",
            "Epoch:  99 Step:  1175  time: 1.284041 s d_loss: 0.62560284, g_loss: 987.68212891 -- mean_d_loss: 1.77414024, mean_g_loss: 1014.50036621\n",
            "Epoch:  99 Step:  1176  time: 1.309721 s d_loss: 1.44211388, g_loss: 1019.02471924 -- mean_d_loss: 1.77226436, mean_g_loss: 1014.52593994\n",
            "Epoch:  99 Step:  1177  time: 1.317528 s d_loss: 0.98865062, g_loss: 938.03112793 -- mean_d_loss: 1.76786208, mean_g_loss: 1014.09619141\n",
            "Epoch:  99 Step:  1178  time: 1.294829 s d_loss: 0.95930433, g_loss: 890.91528320 -- mean_d_loss: 1.76334488, mean_g_loss: 1013.40808105\n",
            "Epoch:  99 Step:  1179  time: 1.302974 s d_loss: 1.47623682, g_loss: 1078.65625000 -- mean_d_loss: 1.76174974, mean_g_loss: 1013.77056885\n",
            "Epoch:  99 Step:  1180  time: 1.318609 s d_loss: 0.75298762, g_loss: 968.98321533 -- mean_d_loss: 1.75617647, mean_g_loss: 1013.52313232\n",
            "Epoch:  99 Step:  1181  time: 1.305825 s d_loss: 0.61299479, g_loss: 1068.07995605 -- mean_d_loss: 1.74989533, mean_g_loss: 1013.82287598\n",
            "Epoch:  99 Step:  1182  time: 1.331858 s d_loss: 0.60364413, g_loss: 1021.55493164 -- mean_d_loss: 1.74363172, mean_g_loss: 1013.86517334\n",
            "Epoch:  99 Step:  1183  time: 1.297341 s d_loss: 0.58670515, g_loss: 1000.33752441 -- mean_d_loss: 1.73734403, mean_g_loss: 1013.79168701\n",
            "Epoch:  99 Step:  1184  time: 1.329767 s d_loss: 0.61778522, g_loss: 942.08630371 -- mean_d_loss: 1.73129237, mean_g_loss: 1013.40411377\n",
            "Epoch:  99 Step:  1185  time: 1.317248 s d_loss: 0.47101474, g_loss: 939.18548584 -- mean_d_loss: 1.72451663, mean_g_loss: 1013.00512695\n",
            "Epoch:  99 Step:  1186  time: 1.356753 s d_loss: 0.39325857, g_loss: 985.35888672 -- mean_d_loss: 1.71739757, mean_g_loss: 1012.85729980\n",
            "Epoch:  99 Step:  1187  time: 1.312718 s d_loss: 0.46225244, g_loss: 938.08422852 -- mean_d_loss: 1.71072125, mean_g_loss: 1012.45953369\n",
            "Epoch:  99 Step:  1188  time: 1.317722 s d_loss: 0.49339494, g_loss: 1051.12329102 -- mean_d_loss: 1.70428050, mean_g_loss: 1012.66412354\n",
            "Epoch:  99 Step:  1189  time: 1.329422 s d_loss: 0.42911491, g_loss: 1128.09216309 -- mean_d_loss: 1.69756901, mean_g_loss: 1013.27160645\n",
            "Epoch:  99 Step:  1190  time: 1.329969 s d_loss: 47.59763718, g_loss: 990.19842529 -- mean_d_loss: 1.93788350, mean_g_loss: 1013.15087891\n",
            "Epoch:  99 Step:  1191  time: 1.279772 s d_loss: 5.30393982, g_loss: 1093.22705078 -- mean_d_loss: 1.95541513, mean_g_loss: 1013.56793213\n",
            "Epoch:  99 Step:  1192  time: 1.326200 s d_loss: 5.35223866, g_loss: 1106.17492676 -- mean_d_loss: 1.97301519, mean_g_loss: 1014.04779053\n",
            "Epoch:  99 Step:  1193  time: 1.319158 s d_loss: 1.11805689, g_loss: 1022.24157715 -- mean_d_loss: 1.96860814, mean_g_loss: 1014.08996582\n",
            "Epoch:  99 Step:  1194  time: 1.286773 s d_loss: 1.24372220, g_loss: 866.09948730 -- mean_d_loss: 1.96489072, mean_g_loss: 1013.33099365\n",
            "Epoch:  99 Step:  1195  time: 1.308162 s d_loss: 1.70688736, g_loss: 1156.39794922 -- mean_d_loss: 1.96357429, mean_g_loss: 1014.06091309\n",
            "Epoch:  99 Step:  1196  time: 1.322400 s d_loss: 1.04084527, g_loss: 1185.10400391 -- mean_d_loss: 1.95889032, mean_g_loss: 1014.92919922\n",
            "Epoch:  99 Step:  1197  time: 1.314846 s d_loss: 1.58292246, g_loss: 957.39477539 -- mean_d_loss: 1.95699143, mean_g_loss: 1014.63854980\n",
            "Epoch:  99 Step:  1198  time: 1.334763 s d_loss: 0.57433408, g_loss: 1087.59204102 -- mean_d_loss: 1.95004344, mean_g_loss: 1015.00518799\n",
            "Epoch:  99 Step:  1199  time: 1.312765 s d_loss: 0.63200694, g_loss: 961.65112305 -- mean_d_loss: 1.94345331, mean_g_loss: 1014.73846436\n",
            "Epoch:  99 Step:  1200  time: 1.323816 s d_loss: 0.56045884, g_loss: 932.29833984 -- mean_d_loss: 0.56045884, mean_g_loss: 932.29833984\n",
            "Epoch:  99 Step:  1201  time: 1.333887 s d_loss: 0.79637331, g_loss: 1216.97558594 -- mean_d_loss: 0.67841607, mean_g_loss: 1074.63696289\n",
            "Epoch:  99 Step:  1202  time: 1.328028 s d_loss: 0.72238314, g_loss: 931.27087402 -- mean_d_loss: 0.69307178, mean_g_loss: 1026.84826660\n",
            "Epoch:  99 Step:  1203  time: 1.331955 s d_loss: 0.61954790, g_loss: 1019.05749512 -- mean_d_loss: 0.67469078, mean_g_loss: 1024.90063477\n",
            "Epoch:  99 Step:  1204  time: 1.325937 s d_loss: 1.12468374, g_loss: 1018.83886719 -- mean_d_loss: 0.76468933, mean_g_loss: 1023.68829346\n",
            "Epoch:  99 Step:  1205  time: 1.318158 s d_loss: 0.77044755, g_loss: 886.87829590 -- mean_d_loss: 0.76564908, mean_g_loss: 1000.88665771\n",
            "Epoch:  99 Step:  1206  time: 1.332463 s d_loss: 27.02905464, g_loss: 1037.17895508 -- mean_d_loss: 4.51756430, mean_g_loss: 1006.07128906\n",
            "Epoch:  99 Step:  1207  time: 1.331775 s d_loss: 0.85436118, g_loss: 981.38995361 -- mean_d_loss: 4.05966377, mean_g_loss: 1002.98614502\n",
            "Epoch:  99 Step:  1208  time: 1.318607 s d_loss: 1.35691011, g_loss: 947.60314941 -- mean_d_loss: 3.75935793, mean_g_loss: 996.83245850\n",
            "Epoch:  99 Step:  1209  time: 1.344034 s d_loss: 0.85556531, g_loss: 835.19494629 -- mean_d_loss: 3.46897840, mean_g_loss: 980.66876221\n",
            "Epoch:  99 Step:  1210  time: 1.306383 s d_loss: 0.70430827, g_loss: 1203.96569824 -- mean_d_loss: 3.21764469, mean_g_loss: 1000.96850586\n",
            "Epoch:  99 Step:  1211  time: 1.335387 s d_loss: 2.20403695, g_loss: 1157.83642578 -- mean_d_loss: 3.13317752, mean_g_loss: 1014.04083252\n",
            "Epoch:  99 Step:  1212  time: 1.311203 s d_loss: 1.00290358, g_loss: 1109.86926270 -- mean_d_loss: 2.96931028, mean_g_loss: 1021.41223145\n",
            "Epoch:  99 Step:  1213  time: 1.301094 s d_loss: 1.23348582, g_loss: 950.96386719 -- mean_d_loss: 2.84532285, mean_g_loss: 1016.38024902\n",
            "Epoch:  99 Step:  1214  time: 1.285234 s d_loss: 0.72643602, g_loss: 859.08081055 -- mean_d_loss: 2.70406365, mean_g_loss: 1005.89361572\n",
            "Epoch:  99 Step:  1215  time: 1.319848 s d_loss: 0.76390517, g_loss: 1144.40771484 -- mean_d_loss: 2.58280373, mean_g_loss: 1014.55078125\n",
            "Epoch:  99 Step:  1216  time: 1.291471 s d_loss: 0.74923176, g_loss: 999.03112793 -- mean_d_loss: 2.47494674, mean_g_loss: 1013.63787842\n",
            "Epoch:  99 Step:  1217  time: 1.299321 s d_loss: 0.90009260, g_loss: 1024.55224609 -- mean_d_loss: 2.38745475, mean_g_loss: 1014.24426270\n",
            "Epoch:  99 Step:  1218  time: 1.348006 s d_loss: 0.65397573, g_loss: 937.71118164 -- mean_d_loss: 2.29621911, mean_g_loss: 1010.21618652\n",
            "Epoch:  99 Step:  1219  time: 1.315127 s d_loss: 0.88399518, g_loss: 1010.59948730 -- mean_d_loss: 2.22560787, mean_g_loss: 1010.23535156\n",
            "Epoch:  99 Step:  1220  time: 1.320710 s d_loss: 0.53548932, g_loss: 982.19097900 -- mean_d_loss: 2.14512587, mean_g_loss: 1008.89990234\n",
            "Epoch:  99 Step:  1221  time: 1.315425 s d_loss: 0.68991709, g_loss: 1039.03930664 -- mean_d_loss: 2.07898021, mean_g_loss: 1010.26989746\n",
            "Epoch:  99 Step:  1222  time: 1.310827 s d_loss: 2.04860449, g_loss: 1103.91564941 -- mean_d_loss: 2.07765937, mean_g_loss: 1014.34143066\n",
            "Epoch:  99 Step:  1223  time: 1.331647 s d_loss: 0.87613583, g_loss: 1008.33929443 -- mean_d_loss: 2.02759600, mean_g_loss: 1014.09136963\n",
            "Epoch:  99 Step:  1224  time: 1.291429 s d_loss: 0.61370146, g_loss: 964.47705078 -- mean_d_loss: 1.97104025, mean_g_loss: 1012.10681152\n",
            "Epoch:  99 Step:  1225  time: 1.302450 s d_loss: 0.62845379, g_loss: 1005.27551270 -- mean_d_loss: 1.91940224, mean_g_loss: 1011.84405518\n",
            "Epoch:  99 Step:  1226  time: 1.306129 s d_loss: 0.49710551, g_loss: 956.72314453 -- mean_d_loss: 1.86672449, mean_g_loss: 1009.80249023\n",
            "Epoch:  99 Step:  1227  time: 1.324800 s d_loss: 0.62741208, g_loss: 985.25781250 -- mean_d_loss: 1.82246327, mean_g_loss: 1008.92590332\n",
            "Epoch:  99 Step:  1228  time: 1.302498 s d_loss: 0.64285368, g_loss: 919.58282471 -- mean_d_loss: 1.78178704, mean_g_loss: 1005.84509277\n",
            "Epoch:  99 Step:  1229  time: 1.291282 s d_loss: 0.62199157, g_loss: 1104.45727539 -- mean_d_loss: 1.74312723, mean_g_loss: 1009.13214111\n",
            "Epoch:  99 Step:  1230  time: 1.327011 s d_loss: 1.55490875, g_loss: 1046.65612793 -- mean_d_loss: 1.73705566, mean_g_loss: 1010.34259033\n",
            "Epoch:  99 Step:  1231  time: 1.330583 s d_loss: 0.85731554, g_loss: 906.68255615 -- mean_d_loss: 1.70956373, mean_g_loss: 1007.10321045\n",
            "Epoch:  99 Step:  1232  time: 1.298063 s d_loss: 0.71829057, g_loss: 1093.95080566 -- mean_d_loss: 1.67952526, mean_g_loss: 1009.73498535\n",
            "Epoch:  99 Step:  1233  time: 1.320994 s d_loss: 0.58851242, g_loss: 897.57470703 -- mean_d_loss: 1.64743662, mean_g_loss: 1006.43609619\n",
            "Epoch:  99 Step:  1234  time: 1.308424 s d_loss: 1.41582692, g_loss: 1179.06787109 -- mean_d_loss: 1.64081919, mean_g_loss: 1011.36840820\n",
            "Epoch:  99 Step:  1235  time: 1.298672 s d_loss: 0.52000034, g_loss: 982.82958984 -- mean_d_loss: 1.60968542, mean_g_loss: 1010.57562256\n",
            "Epoch:  99 Step:  1236  time: 1.323467 s d_loss: 0.76482141, g_loss: 1002.09466553 -- mean_d_loss: 1.58685112, mean_g_loss: 1010.34637451\n",
            "Epoch:  99 Step:  1237  time: 1.315973 s d_loss: 0.58019137, g_loss: 972.44006348 -- mean_d_loss: 1.56036019, mean_g_loss: 1009.34887695\n",
            "Epoch:  99 Step:  1238  time: 1.323790 s d_loss: 0.52284724, g_loss: 948.01989746 -- mean_d_loss: 1.53375721, mean_g_loss: 1007.77636719\n",
            "Epoch:  99 Step:  1239  time: 1.324445 s d_loss: 0.46354344, g_loss: 1148.73266602 -- mean_d_loss: 1.50700188, mean_g_loss: 1011.30029297\n",
            "Epoch:  99 Step:  1240  time: 1.325139 s d_loss: 0.59384626, g_loss: 1029.46081543 -- mean_d_loss: 1.48472977, mean_g_loss: 1011.74322510\n",
            "Epoch:  99 Step:  1241  time: 1.321094 s d_loss: 0.71761137, g_loss: 962.58984375 -- mean_d_loss: 1.46646512, mean_g_loss: 1010.57293701\n",
            "Epoch:  99 Step:  1242  time: 1.351456 s d_loss: 0.96798843, g_loss: 1012.47711182 -- mean_d_loss: 1.45487261, mean_g_loss: 1010.61718750\n",
            "Epoch:  99 Step:  1243  time: 1.299854 s d_loss: 0.54371208, g_loss: 967.41870117 -- mean_d_loss: 1.43416440, mean_g_loss: 1009.63537598\n",
            "Epoch:  99 Step:  1244  time: 1.314286 s d_loss: 0.58638924, g_loss: 1001.52392578 -- mean_d_loss: 1.41532493, mean_g_loss: 1009.45513916\n",
            "Epoch:  99 Step:  1245  time: 1.308058 s d_loss: 0.55370784, g_loss: 1116.61547852 -- mean_d_loss: 1.39659417, mean_g_loss: 1011.78472900\n",
            "Epoch:  99 Step:  1246  time: 1.322215 s d_loss: 0.63002068, g_loss: 1113.03698730 -- mean_d_loss: 1.38028407, mean_g_loss: 1013.93902588\n",
            "Epoch:  99 Step:  1247  time: 1.309339 s d_loss: 0.73050213, g_loss: 1013.47033691 -- mean_d_loss: 1.36674690, mean_g_loss: 1013.92919922\n",
            "Epoch:  99 Step:  1248  time: 1.337903 s d_loss: 0.51671827, g_loss: 1040.45727539 -- mean_d_loss: 1.34939933, mean_g_loss: 1014.47058105\n",
            "Epoch:  99 Step:  1249  time: 1.324815 s d_loss: 0.58609670, g_loss: 792.20495605 -- mean_d_loss: 1.33413327, mean_g_loss: 1010.02520752\n",
            "Epoch:  99 Step:  1250  time: 1.311236 s d_loss: 0.46355179, g_loss: 1009.54632568 -- mean_d_loss: 1.31706309, mean_g_loss: 1010.01586914\n",
            "Epoch:  99 Step:  1251  time: 1.331972 s d_loss: 0.54426992, g_loss: 1087.76196289 -- mean_d_loss: 1.30220175, mean_g_loss: 1011.51098633\n",
            "Epoch:  99 Step:  1252  time: 1.304504 s d_loss: 36.72758102, g_loss: 855.87744141 -- mean_d_loss: 1.97060525, mean_g_loss: 1008.57452393\n",
            "Epoch:  99 Step:  1253  time: 1.319247 s d_loss: 2.95946622, g_loss: 986.19470215 -- mean_d_loss: 1.98891747, mean_g_loss: 1008.16009521\n",
            "Epoch:  99 Step:  1254  time: 1.312232 s d_loss: 4.51742697, g_loss: 944.80877686 -- mean_d_loss: 2.03489041, mean_g_loss: 1007.00823975\n",
            "Epoch:  99 Step:  1255  time: 1.306226 s d_loss: 0.70544308, g_loss: 1001.32257080 -- mean_d_loss: 2.01115012, mean_g_loss: 1006.90673828\n",
            "Epoch:  99 Step:  1256  time: 1.321893 s d_loss: 0.78826267, g_loss: 983.21813965 -- mean_d_loss: 1.98969603, mean_g_loss: 1006.49114990\n",
            "Epoch:  99 Step:  1257  time: 1.291094 s d_loss: 0.66115350, g_loss: 1126.11364746 -- mean_d_loss: 1.96679020, mean_g_loss: 1008.55358887\n",
            "Epoch:  99 Step:  1258  time: 1.323554 s d_loss: 1.05411887, g_loss: 1065.25830078 -- mean_d_loss: 1.95132113, mean_g_loss: 1009.51470947\n",
            "Epoch:  99 Step:  1259  time: 1.316643 s d_loss: 0.73855615, g_loss: 929.39758301 -- mean_d_loss: 1.93110836, mean_g_loss: 1008.17944336\n",
            "Epoch:  99 Step:  1260  time: 1.306319 s d_loss: 0.44032124, g_loss: 1022.14434814 -- mean_d_loss: 1.90666926, mean_g_loss: 1008.40838623\n",
            "Epoch:  99 Step:  1261  time: 1.323674 s d_loss: 0.52593833, g_loss: 1111.25097656 -- mean_d_loss: 1.88439941, mean_g_loss: 1010.06707764\n",
            "Epoch:  99 Step:  1262  time: 1.327268 s d_loss: 0.54484051, g_loss: 1022.37054443 -- mean_d_loss: 1.86313653, mean_g_loss: 1010.26239014\n",
            "Epoch:  99 Step:  1263  time: 1.341355 s d_loss: 0.47779506, g_loss: 1022.25335693 -- mean_d_loss: 1.84149063, mean_g_loss: 1010.44976807\n",
            "Epoch:  99 Step:  1264  time: 1.311136 s d_loss: 0.65584141, g_loss: 1073.00292969 -- mean_d_loss: 1.82324982, mean_g_loss: 1011.41210938\n",
            "Epoch:  99 Step:  1265  time: 1.321585 s d_loss: 0.42705020, g_loss: 1020.71166992 -- mean_d_loss: 1.80209529, mean_g_loss: 1011.55303955\n",
            "Epoch:  99 Step:  1266  time: 1.289898 s d_loss: 0.58743840, g_loss: 1048.54052734 -- mean_d_loss: 1.78396606, mean_g_loss: 1012.10504150\n",
            "Epoch:  99 Step:  1267  time: 1.321133 s d_loss: 0.46550858, g_loss: 949.30969238 -- mean_d_loss: 1.76457691, mean_g_loss: 1011.18164062\n",
            "Epoch:  99 Step:  1268  time: 1.318012 s d_loss: 0.48462898, g_loss: 939.75744629 -- mean_d_loss: 1.74602699, mean_g_loss: 1010.14648438\n",
            "Epoch:  99 Step:  1269  time: 1.348242 s d_loss: 0.47672668, g_loss: 908.14697266 -- mean_d_loss: 1.72789419, mean_g_loss: 1008.68939209\n",
            "Epoch:  99 Step:  1270  time: 1.317361 s d_loss: 0.41249603, g_loss: 1087.34912109 -- mean_d_loss: 1.70936751, mean_g_loss: 1009.79730225\n",
            "Epoch:  99 Step:  1271  time: 1.332334 s d_loss: 0.42565858, g_loss: 980.50946045 -- mean_d_loss: 1.69153821, mean_g_loss: 1009.39050293\n",
            "Epoch:  99 Step:  1272  time: 1.316783 s d_loss: 0.72737825, g_loss: 933.75524902 -- mean_d_loss: 1.67833054, mean_g_loss: 1008.35443115\n",
            "Epoch:  99 Step:  1273  time: 1.307998 s d_loss: 0.70758575, g_loss: 892.01849365 -- mean_d_loss: 1.66521239, mean_g_loss: 1006.78228760\n",
            "Epoch:  99 Step:  1274  time: 1.296120 s d_loss: 0.94213235, g_loss: 990.84301758 -- mean_d_loss: 1.65557134, mean_g_loss: 1006.56976318\n",
            "Epoch:  99 Step:  1275  time: 1.338141 s d_loss: 0.72458428, g_loss: 960.47607422 -- mean_d_loss: 1.64332151, mean_g_loss: 1005.96331787\n",
            "Epoch:  99 Step:  1276  time: 1.321043 s d_loss: 0.58861196, g_loss: 872.13415527 -- mean_d_loss: 1.62962401, mean_g_loss: 1004.22521973\n",
            "Epoch:  99 Step:  1277  time: 1.315912 s d_loss: 0.50588828, g_loss: 949.83459473 -- mean_d_loss: 1.61521721, mean_g_loss: 1003.52795410\n",
            "Epoch:  99 Step:  1278  time: 1.289986 s d_loss: 0.46820429, g_loss: 1115.95092773 -- mean_d_loss: 1.60069799, mean_g_loss: 1004.95104980\n",
            "Epoch:  99 Step:  1279  time: 1.299666 s d_loss: 0.43551937, g_loss: 1028.85131836 -- mean_d_loss: 1.58613324, mean_g_loss: 1005.24981689\n",
            "Epoch:  99 Step:  1280  time: 1.312555 s d_loss: 0.42244959, g_loss: 859.99304199 -- mean_d_loss: 1.57176673, mean_g_loss: 1003.45648193\n",
            "Epoch:  99 Step:  1281  time: 1.318215 s d_loss: 1.17590666, g_loss: 971.03063965 -- mean_d_loss: 1.56693923, mean_g_loss: 1003.06109619\n",
            "Epoch:  99 Step:  1282  time: 1.293254 s d_loss: 0.51787478, g_loss: 919.90386963 -- mean_d_loss: 1.55429983, mean_g_loss: 1002.05920410\n",
            "Epoch:  99 Step:  1283  time: 1.319109 s d_loss: 0.40002239, g_loss: 934.34179688 -- mean_d_loss: 1.54055846, mean_g_loss: 1001.25305176\n",
            "Epoch:  99 Step:  1284  time: 1.294789 s d_loss: 1.12065446, g_loss: 991.02221680 -- mean_d_loss: 1.53561831, mean_g_loss: 1001.13269043\n",
            "Epoch:  99 Step:  1285  time: 1.326461 s d_loss: 0.74925888, g_loss: 1041.16345215 -- mean_d_loss: 1.52647448, mean_g_loss: 1001.59820557\n",
            "Epoch:  99 Step:  1286  time: 1.290620 s d_loss: 2.14532208, g_loss: 963.59118652 -- mean_d_loss: 1.53358769, mean_g_loss: 1001.16137695\n",
            "Epoch:  99 Step:  1287  time: 1.295405 s d_loss: 0.39956191, g_loss: 956.73620605 -- mean_d_loss: 1.52070117, mean_g_loss: 1000.65649414\n",
            "Epoch:  99 Step:  1288  time: 1.319468 s d_loss: 1.02132404, g_loss: 1003.43066406 -- mean_d_loss: 1.51509011, mean_g_loss: 1000.68768311\n",
            "Epoch:  99 Step:  1289  time: 1.307367 s d_loss: 0.80529100, g_loss: 966.55358887 -- mean_d_loss: 1.50720346, mean_g_loss: 1000.30841064\n",
            "Epoch:  99 Step:  1290  time: 1.332582 s d_loss: 1.44483030, g_loss: 995.76989746 -- mean_d_loss: 1.50651801, mean_g_loss: 1000.25860596\n",
            "Epoch:  99 Step:  1291  time: 1.291596 s d_loss: 0.65655190, g_loss: 992.01037598 -- mean_d_loss: 1.49727929, mean_g_loss: 1000.16888428\n",
            "Epoch:  99 Step:  1292  time: 1.299760 s d_loss: 0.57006693, g_loss: 1109.74047852 -- mean_d_loss: 1.48730934, mean_g_loss: 1001.34710693\n",
            "Epoch:  99 Step:  1293  time: 1.330529 s d_loss: 0.69294745, g_loss: 1054.79272461 -- mean_d_loss: 1.47885859, mean_g_loss: 1001.91564941\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qNBAl83MjUUR"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AS6nDHZCsV61"
      },
      "source": [
        "%cd /content/AnimeGAN/\r\n",
        "%ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVs6lgVf6FIQ"
      },
      "source": [
        "!python test.py --checkpoint_dir checkpoint/AnimeGAN_Paprika_lsgan_300_300_1_3_10/ --test_dir dataset/test/real5 --style_name Pp"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IKHbpk2dvYhc"
      },
      "source": [
        "!ls\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FAvQFrIF4tvC"
      },
      "source": [
        "\n",
        "\n",
        "# **Zip and Download**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IMbbgGkm8fjt"
      },
      "source": [
        "**Zip checkpoint from /content/AnimeGAN/checkpoint folder **"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KQjjTB4o4vtm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d1a45d76-5ccd-418b-ea7f-e4ebb853df29"
      },
      "source": [
        "!zip -r /content/Shinkai_model.zip /content/AnimeGAN/checkpoint/"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  adding: content/AnimeGAN/checkpoint/ (stored 0%)\n",
            "  adding: content/AnimeGAN/checkpoint/AnimeGAN_Hayao_lsgan_300_300_1_2_10/ (stored 0%)\n",
            "  adding: content/AnimeGAN/checkpoint/AnimeGAN_Hayao_lsgan_300_300_1_2_10/checkpoints files (stored 0%)\n",
            "  adding: content/AnimeGAN/checkpoint/generator_Hayao_weight/ (stored 0%)\n",
            "  adding: content/AnimeGAN/checkpoint/generator_Hayao_weight/Hayao-60.ckpt.meta (deflated 93%)\n",
            "  adding: content/AnimeGAN/checkpoint/generator_Hayao_weight/Hayao-60.ckpt.index (deflated 66%)\n",
            "  adding: content/AnimeGAN/checkpoint/generator_Hayao_weight/Hayao-60.ckpt.data-00000-of-00001 (deflated 8%)\n",
            "  adding: content/AnimeGAN/checkpoint/generator_Hayao_weight/checkpoint (deflated 40%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FK26zeCn5BGg",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "e735f29e-f278-4a0e-8c96-788a5867fbad"
      },
      "source": [
        "from google.colab import files\n",
        "files.download(\"/content/Shinkai_model.zip\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_07482802-716b-486d-82e3-46cea5a0aa71\", \"Shinkai_model.zip\", 14664022)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kvCQMI0i5B0p",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "788e9a3c-ff1e-46dd-8a94-b0574d9e664c"
      },
      "source": [
        "print(\"hello\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "hello\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lsVxzMQSj35M"
      },
      "source": [
        "!rm -rf /content/AnimeGAN/dataset/test/real\n",
        "!rm -rf /content/AnimeGAN/dataset/test/real2\n",
        "!rm -rf /content/AnimeGAN/dataset/test/real3\n",
        "!rm -rf /content/AnimeGAN/dataset/test/real4\n",
        "!rm -rf /content/AnimeGAN/dataset/test/real5"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qMRoXqeCaSK7"
      },
      "source": [
        "!rm -rf /content/AnimeGAN/results/B"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
